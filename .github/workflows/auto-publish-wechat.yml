name: Auto Publish WeChat Articles

concurrency:
  # å…è®¸åŒä¸€å¤©æ‰‹åŠ¨è¡¥å‘å¤šç¯‡ï¼Œä¸äº’ç›¸å–æ¶ˆï¼ˆPages éƒ¨ç½²ä»ä¼šåœ¨ GitHub ä¾§æ’é˜Ÿï¼‰
  group: auto-publish-${{ github.workflow }}
  cancel-in-progress: false

"on":
  # å®šæ—¶è§¦å‘ï¼š
  # - ä¸»å‘å¸ƒï¼šæ¯å¤© 2 ç¯‡ï¼ˆåŒ—äº¬æ—¶é—´ 08:00 / 18:00ï¼‰
  # - å¤±è´¥é‡è¯•ï¼šæ¯ 2 å°æ—¶æ£€æŸ¥ä¸€æ¬¡æ˜¯å¦æœ‰å¾…é‡è¯•ä»»åŠ¡ï¼ˆæ— åˆ™è·³è¿‡ä¸å‘å¸ƒï¼‰
  schedule:
    # UTC: 00:00, 10:00  (CN: 08:00, 18:00)
    - cron: '0 0,10 * * *'
    # retry checker
    - cron: '0 */2 * * *'

  # æ‰‹åŠ¨è§¦å‘
  workflow_dispatch:
    inputs:
      topic:
        description: 'æ–‡ç« ä¸»é¢˜ï¼ˆç•™ç©ºåˆ™ä½¿ç”¨é¢„è®¾ä¸»é¢˜ï¼‰'
        required: false
        type: string
        default: ''
      industry:
        description: 'è¡Œä¸šé€‰æ‹©'
        required: false
        type: choice
        default: 'technology'
        options:
          - technology
          - finance
          - healthcare
          - education
          - automotive
          - retail
          - manufacturing
          - foreign_trade
          - scientific_instruments
          - reagents
          - lab_consumables
      force_timestamp:
        description: 'å¼ºåˆ¶æ—¶é—´æˆ³ï¼ˆç”¨äºè¡¥å‘/å¤ç°ï¼Œä¾‹å¦‚ 20260203-080000ï¼›ç•™ç©ºåˆ™è‡ªåŠ¨ç”ŸæˆåŒ—äº¬æ—¶é—´æ—¶é—´æˆ³ï¼‰'
        required: false
        type: string
        default: ''

env:
  HUGO_VERSION: '0.155.1'
  BLOG_URL: 'https://gsaecy.github.io'
  VOLC_REGION: 'cn-north-1'
  VOLC_SERVICE: 'cv'

jobs:
  generate-and-publish:
    runs-on: ubuntu-latest
    
    permissions:
      contents: write
      pages: write
      id-token: write
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          submodules: recursive
          fetch-depth: 0
      
      - name: Clean up any residual submodule configs
        run: |
          # ç§»é™¤å¯èƒ½æ®‹ç•™çš„ chrome-extension submodule é…ç½®
          if [ -f .gitmodules ]; then
            # å¤‡ä»½åŸæ–‡ä»¶
            cp .gitmodules .gitmodules.backup
            # ç§»é™¤ chrome-extension ç›¸å…³è¡Œ
            grep -v "chrome-extension" .gitmodules > .gitmodules.tmp && mv .gitmodules.tmp .gitmodules
          fi
          # ä» git config ä¸­ç§»é™¤
          git config --local --remove-section submodule.chrome-extension 2>/dev/null || true
          git config --local --remove-section submodule."chrome-extension/" 2>/dev/null || true
          echo "Submodule cleanup completed"
      
      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: ${{ env.HUGO_VERSION }}
          extended: true
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
      
      - name: Determine article topic
        id: topic
        run: |
          echo "ğŸ¯ ç¡®å®šæ–‡ç« ä¸»é¢˜..."

          # schedule è§¦å‘æ—¶ github.event.inputs ä¸ºç©ºï¼Œè¿™é‡Œå…œåº•
          INDUSTRY="${{ github.event.inputs.industry }}"

          # retry checker: schedule äº‹ä»¶åœ¨é 08:00/18:00ï¼ˆCNï¼‰æ—¶ï¼Œåªåšå¤±è´¥é‡è¯•æ£€æŸ¥ï¼Œä¸æ­£å¸¸å‘æ–‡
          # ä½¿ç”¨ UTC æ—¶é—´åˆ¤æ–­æ›´å¯é ï¼š00:00/10:00 UTC = 08:00/18:00 CST
          UTC_HOUR=$(date -u +%H)
          CN_EVENT="${{ github.event_name }}"
          IS_MAIN_WINDOW=0
          if [ "$UTC_HOUR" = "0" ] || [ "$UTC_HOUR" = "10" ]; then
            IS_MAIN_WINDOW=1
            echo "ğŸ¯ ä¸»å‘å¸ƒçª—å£ï¼šUTC $UTC_HOUR:00 = åŒ—äº¬æ—¶é—´ $(($UTC_HOUR + 8)):00"
          else
            echo "â° é‡è¯•æ£€æŸ¥çª—å£ï¼šUTC $UTC_HOUR:00 = åŒ—äº¬æ—¶é—´ $(($UTC_HOUR + 8)):00"
          fi

          if [ "$CN_EVENT" = "schedule" ] && [ "$IS_MAIN_WINDOW" = "0" ]; then
            if [ -f data/pending_retry.json ]; then
              DUE=$(python3 -c "import json, time; s=json.load(open('data/pending_retry.json','r',encoding='utf-8')); print(int(s.get('next_retry_epoch',0)))")
              NOW=$(TZ=Asia/Shanghai date +%s)
              if [ "$NOW" -ge "$DUE" ]; then
                INDUSTRY=$(python3 -c "import json; print(json.load(open('data/pending_retry.json','r',encoding='utf-8')).get('industry',''))")
                TOPIC_FORCE=$(python3 -c "import json; print(json.load(open('data/pending_retry.json','r',encoding='utf-8')).get('topic',''))")
                FORCE_TS=$(python3 -c "import json; print(json.load(open('data/pending_retry.json','r',encoding='utf-8')).get('force_timestamp',''))")
                echo "ğŸ” retry mode: industry=$INDUSTRY topic=$TOPIC_FORCE ts=$FORCE_TS"
              else
                echo "â³ pending retry exists but not due yet, skip publishing"
                echo "skip=true" >> $GITHUB_OUTPUT
                exit 0
              fi
            else
              echo "ğŸŸ¦ retry checker tick: no pending retry, skip publishing"
              echo "skip=true" >> $GITHUB_OUTPUT
              exit 0
            fi
          fi

          # âœ… è¡Œä¸šè½®æ¢ä¸æ•°é‡å¹³è¡¡ï¼šç»Ÿè®¡ä»“åº“ç°æœ‰æ–‡ç« æ•°é‡ï¼Œè¦æ±‚æœ€å¤§-æœ€å°ä¸è¶…è¿‡ 2
          # - è‹¥æ‰‹åŠ¨æŒ‡å®š industryï¼Œåˆ™å®Œå…¨å°Šé‡ç”¨æˆ·è¾“å…¥
          # - è‹¥æœªæŒ‡å®šï¼Œåˆ™ä¼˜å…ˆé€‰å‘å¸ƒæœ€å°‘çš„è¡Œä¸šï¼›å½“å·®è·>2 æ—¶åªä»æœ€å°‘è¡Œä¸šä¸­é€‰ï¼Œç›´åˆ°è¿½å¹³
          if [ -z "$INDUSTRY" ]; then
            CN_WDAY=$(TZ=Asia/Shanghai date +%u)  # 1(Mon)-7(Sun)
            CN_DATE=$(TZ=Asia/Shanghai date +%F)
            # å°† UTC å°æ—¶è½¬æ¢ä¸º CST å°æ—¶ç”¨äºè¡Œä¸šé€‰æ‹©é€»è¾‘
            CST_HOUR=$(( (UTC_HOUR + 8) % 24 ))
            INDUSTRY=$(python3 -c "import re; from pathlib import Path; industries=['technology','finance','healthcare','education','automotive','retail','manufacturing','foreign_trade','scientific_instruments','reagents','lab_consumables']; pat={k:re.compile(r'^'+re.escape(k)+r'-\\d{8}-\\d{6}\\.md$') for k in industries}; counts={k:0 for k in industries}; [counts.__setitem__(k, counts[k]+(1 if pat[k].match(p.name) else 0)) for p in Path('content/posts').glob('*.md') for k in industries]; minc=min(counts.values()) if counts else 0; cands=[k for k,v in counts.items() if v==minc]; hour=int('$CST_HOUR'); wday=int('$CN_WDAY'); is_weekend=(wday>=6); scores={k:0 for k in cands}; [scores.__setitem__(k, scores[k] + (3 if ((not is_weekend and k in ('technology','finance','manufacturing','foreign_trade')) or (is_weekend and k in ('retail','automotive','healthcare'))) else 0) + (2 if ((hour<12 and k in ('technology','education','manufacturing','scientific_instruments')) or (hour>=12 and k in ('finance','foreign_trade','retail','healthcare'))) else 0) + (1 if k in ('reagents','lab_consumables') else 0)) for k in cands]; print(sorted(cands, key=lambda x:(-scores.get(x,0), industries.index(x)))[0])")
          fi

          # ä¸»é¢˜ï¼šæ‰‹åŠ¨æŒ‡å®š > retry æŒ‡å®š > é¢„è®¾
          if [ -n "${{ github.event.inputs.topic }}" ]; then
            TOPIC="${{ github.event.inputs.topic }}"
            echo "ä½¿ç”¨æ‰‹åŠ¨æŒ‡å®šä¸»é¢˜: $TOPIC"
          elif [ -n "$TOPIC_FORCE" ]; then
            TOPIC="$TOPIC_FORCE"
            echo "ä½¿ç”¨é‡è¯•ä»»åŠ¡ä¸»é¢˜: $TOPIC"
          else
            case $INDUSTRY in
              technology) TOPIC="AIæŠ€æœ¯å‘å±•è¶‹åŠ¿ä¸è¡Œä¸šåº”ç”¨";;
              finance) TOPIC="æ•°å­—é‡‘èåˆ›æ–°ä¸é£é™©ç®¡ç†";;
              healthcare) TOPIC="æ™ºæ…§åŒ»ç–—æŠ€æœ¯çªç ´ä¸å¸‚åœºå‰æ™¯";;
              education) TOPIC="åœ¨çº¿æ•™è‚²æ¨¡å¼åˆ›æ–°ä¸æœªæ¥è¶‹åŠ¿";;
              automotive) TOPIC="æ–°èƒ½æºæ±½è½¦äº§ä¸šé“¾åˆ†æä¸æŠ•èµ„æœºä¼š";;
              retail) TOPIC="æ–°é›¶å”®æ•°å­—åŒ–è½¬å‹ä¸æ¶ˆè´¹è¶‹åŠ¿";;
              manufacturing) TOPIC="æ™ºèƒ½åˆ¶é€ æŠ€æœ¯å‡çº§ä¸äº§ä¸šå˜é©";;
              foreign_trade) TOPIC="ä¸­æ—¥å¤–è´¸äº¤æ˜“åŠ¨æ€ä¸äº§ä¸šæœºä¼š";;
              scientific_instruments) TOPIC="ç§‘ç ”ä»ªå™¨è¡Œä¸šåŠ¨æ€ä¸é‡‡è´­è¶‹åŠ¿";;
              reagents) TOPIC="ç”Ÿç‰©è¯•å‰‚è¡Œä¸šä¾›éœ€ä¸ä»·æ ¼è¶‹åŠ¿";;
              lab_consumables) TOPIC="ç§‘ç ”è€—æè¡Œä¸šå˜åŒ–ä¸ä¾›åº”é“¾è§‚å¯Ÿ";;
              *) TOPIC="è¡Œä¸šæŠ€æœ¯å‘å±•è¶‹åŠ¿åˆ†æ";;
            esac
            echo "ä½¿ç”¨é¢„è®¾ä¸»é¢˜ [$INDUSTRY]: $TOPIC"
          fi

          FORCE_TS_INPUT="${{ github.event.inputs.force_timestamp }}"
          if [ -n "$FORCE_TS_INPUT" ]; then
            TIMESTAMP="$FORCE_TS_INPUT"
          elif [ -n "$FORCE_TS" ]; then
            TIMESTAMP="$FORCE_TS"
          else
            # ç»Ÿä¸€ç”¨åŒ—äº¬æ—¶é—´ç”Ÿæˆæ—¶é—´æˆ³ï¼Œä¾¿äºå¯¹é½â€œ8ç‚¹/10ç‚¹â€è¿™ç§æ‰¿è¯º
            TIMESTAMP=$(TZ=Asia/Shanghai date +%Y%m%d-%H%M%S)
          fi

          # æ–‡ä»¶ååªç”¨è‹±æ–‡ï¼Œé¿å…ä¸­æ–‡ slug ä¸ºç©ºå¯¼è‡´è·¯å¾„å¼‚å¸¸
          FILENAME="${INDUSTRY}-${TIMESTAMP}"

          echo "skip=false" >> $GITHUB_OUTPUT
          echo "industry=$INDUSTRY" >> $GITHUB_OUTPUT
          echo "topic=$TOPIC" >> $GITHUB_OUTPUT
          echo "filename=$FILENAME" >> $GITHUB_OUTPUT
          echo "timestamp=$TIMESTAMP" >> $GITHUB_OUTPUT
      
      - name: Generate article (from top media)
        if: steps.topic.outputs.skip != 'true'
        id: generate
        env:
          TOPIC: ${{ steps.topic.outputs.topic }}
          INDUSTRY: ${{ steps.topic.outputs.industry }}
          FILENAME: ${{ steps.topic.outputs.filename }}
          DEEPSEEK_API_KEY: ${{ secrets.DEEPSEEK_API_KEY }}
          VOLC_ACCESS_KEY_ID: ${{ secrets.VOLC_ACCESS_KEY_ID }}
          VOLC_SECRET_ACCESS_KEY: ${{ secrets.VOLC_SECRET_ACCESS_KEY }}
        run: |
          echo "ğŸ—ï¸ é‡‡é›†è¡Œä¸šå¤´éƒ¨åª’ä½“RSSå¹¶ç”Ÿæˆæ–‡ç« ..."

          ORIGINAL_FILE="content/posts/${FILENAME}.md"
          WECHAT_FILE="content/posts/${FILENAME}-wechat.md"
          NEWS_JSON="data/raw/news_${FILENAME}.json"

          mkdir -p content/posts data/raw

          # å¦‚æœæ˜¯é‡è¯•/é‡å¤è§¦å‘ï¼Œä¸”åŒåæ–‡ç« å·²å­˜åœ¨ï¼šä¸è¦å†ç”Ÿæˆä¸€éï¼ˆé¿å…å‡ºç°å¤šç¯‡â€œåŒå†…å®¹ä¸åŒé…å›¾â€ï¼‰
          if [ -f "${ORIGINAL_FILE}" ]; then
            echo "ğŸŸ¨ æ–‡ç« å·²å­˜åœ¨ï¼Œè·³è¿‡é‡æ–°ç”Ÿæˆï¼š${ORIGINAL_FILE}"
            echo "original_file=${ORIGINAL_FILE}" >> $GITHUB_OUTPUT
            echo "wechat_file=${WECHAT_FILE}" >> $GITHUB_OUTPUT
            exit 0
          fi

          # é‡‡é›† RSS
          python3 scripts/collect_news.py --industry "${INDUSTRY}" --hours 24 --limit 25 --out "${NEWS_JSON}"

          COUNT=$(python3 -c "import json; print(json.load(open('${NEWS_JSON}','r',encoding='utf-8')).get('count',0))")
          echo "RSS collected count=${COUNT} (industry=${INDUSTRY})"

          # å…œåº•1ï¼šRSS=0 æ—¶ï¼Œä¼˜å…ˆç”¨â€œå…¨ç½‘çƒ­æ¦œèšåˆâ€é€‰é¢˜ï¼ˆæ›´å®æ—¶ï¼‰ï¼Œå¹¶ç”Ÿæˆå¯å¼•ç”¨çš„æ¥æºåˆ—è¡¨
          if [ "${COUNT}" = "0" ]; then
            echo "âš ï¸ å½“å‰è¡Œä¸š RSS=0ï¼Œå°è¯•ä»çƒ­æ¦œèšåˆAPIé€‰æ‹©çƒ­ç‚¹é€‰é¢˜..."
            if read HB_INDUSTRY HB_TOPIC < <(python3 scripts/fetch_hotboard_topics.py --out "${NEWS_JSON}" --shell); then
              echo "hotboard pick industry=${HB_INDUSTRY} topic=${HB_TOPIC}"
              INDUSTRY="${HB_INDUSTRY}"
              TOPIC="${HB_TOPIC}"
              FILENAME="${INDUSTRY}-${TIMESTAMP}"
              ORIGINAL_FILE="content/posts/${FILENAME}.md"
              WECHAT_FILE="content/posts/${FILENAME}-wechat.md"

              # å°†çƒ­æ¦œç´ ææ–‡ä»¶æ”¹ååˆ°ä¸æ–° FILENAME ä¸€è‡´ï¼Œä¾¿äºè¿½è¸ª
              NEW_NEWS_JSON="data/raw/news_${FILENAME}.json"
              if [ "${NEWS_JSON}" != "${NEW_NEWS_JSON}" ]; then
                mv "${NEWS_JSON}" "${NEW_NEWS_JSON}" || true
                NEWS_JSON="${NEW_NEWS_JSON}"
              fi

              COUNT=$(python3 -c "import json; print(json.load(open('${NEWS_JSON}','r',encoding='utf-8')).get('count',0))")
              echo "hotboard sources count=${COUNT}"
            else
              echo "âš ï¸ hotboard API å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨æœ¬åœ°çƒ­é—¨è¯é¢˜æ± å…œåº•"
            fi
          fi

          # å…œåº•2ï¼šå¦‚æœçƒ­æ¦œä¹Ÿä¸å¯ç”¨ï¼ˆCOUNTä»ä¸º0 æˆ–è„šæœ¬å¤±è´¥ï¼‰ï¼Œä½¿ç”¨æœ¬åœ°çƒ­é—¨è¯é¢˜æ± å¹¶å†æŠ“ä¸€æ¬¡RSS
          if [ "${COUNT}" = "0" ]; then
            echo "âš ï¸ çƒ­æ¦œä¸å¯ç”¨æˆ–æ— å€™é€‰ï¼Œå¯ç”¨æœ¬åœ°çƒ­é—¨è¯é¢˜æ± å…œåº•..."
            read FB_INDUSTRY FB_TOPIC < <(python3 scripts/pick_hot_topic.py --shell)
            echo "fallback industry=${FB_INDUSTRY} topic=${FB_TOPIC}"
            INDUSTRY="${FB_INDUSTRY}"
            TOPIC="${FB_TOPIC}"
            FILENAME="${INDUSTRY}-${TIMESTAMP}"
            ORIGINAL_FILE="content/posts/${FILENAME}.md"
            WECHAT_FILE="content/posts/${FILENAME}-wechat.md"
            NEWS_JSON="data/raw/news_${FILENAME}.json"
            python3 scripts/collect_news.py --industry "${INDUSTRY}" --hours 24 --limit 25 --out "${NEWS_JSON}"
            COUNT=$(python3 -c "import json; print(json.load(open('${NEWS_JSON}','r',encoding='utf-8')).get('count',0))")
            echo "fallback RSS collected count=${COUNT} (industry=${INDUSTRY})"
          fi

          # æ ‡é¢˜ï¼šåŒ…å«è¡Œä¸š + æ›´è´´åˆå†…å®¹ï¼ˆä¸åœ¨æ ‡é¢˜é‡Œå†™æ—¥æœŸï¼Œæ—¥æœŸå·²åœ¨æ–‡ç« å…ƒä¿¡æ¯é‡Œä½“ç°ï¼‰
          case $INDUSTRY in
            technology) IND_CN="ç§‘æŠ€";;
            finance) IND_CN="é‡‘è";;
            healthcare) IND_CN="åŒ»ç–—";;
            education) IND_CN="æ•™è‚²";;
            automotive) IND_CN="æ±½è½¦";;
            retail) IND_CN="é›¶å”®";;
            manufacturing) IND_CN="åˆ¶é€ ";;
            foreign_trade) IND_CN="å¤–è´¸(ä¸­æ—¥)";;
            scientific_instruments) IND_CN="ç§‘ç ”ä»ªå™¨";;
            reagents) IND_CN="è¯•å‰‚";;
            lab_consumables) IND_CN="ç§‘ç ”è€—æ";;
            *) IND_CN="$INDUSTRY";;
          esac

          TITLE="ã€${IND_CN}ã€‘${TOPIC}"

          COVER_OUT_DIR="static/images/posts/${FILENAME}"
          COVER_OUT_FILE="${COVER_OUT_DIR}/cover.jpg"
          COVER_REL="/images/posts/${FILENAME}/cover.jpg"
          mkdir -p "${COVER_OUT_DIR}" || true

          # å…ˆç”Ÿæˆæ–‡ç« ï¼ˆå°é¢è·¯å¾„å…ˆå›ºå®šä¸º /images/.../cover.jpgï¼‰ï¼Œä¾¿äºåç»­ç”¨â€œæ ‡é¢˜+å°æ ‡é¢˜+æ¥æºå…³é”®è¯â€é€‰å°é¢
          python3 scripts/generate_news_post.py --in "${NEWS_JSON}" --slug "${FILENAME}" --industry "${INDUSTRY}" --title "${TITLE}" --out "${ORIGINAL_FILE}" --cover "${COVER_REL}"

          # âœ… è®­ç»ƒï¼šæ›´æ–°â€œæ´»æ°´â€å…¬å…±å›¾ç‰‡æ± ï¼ˆä»…å…ƒæ•°æ®ï¼Œglobal cap=2000ï¼‰
          python3 scripts/update_public_image_pool.py --industry "${INDUSTRY}" --title "${TITLE}" --md "${ORIGINAL_FILE}" --news-json "${NEWS_JSON}" --pool "data/public_image_pool.json" --cap 2000 --page-size 25 || true

          # å°é¢ä¼˜å…ˆï¼šå…¬å…±å›¾ç‰‡æ± ï¼ˆå…è´¹ã€å¯æ§ï¼‰ï¼›å³æ¢¦ä½œä¸ºä¿åº•ï¼ˆè¶…é¢æ”¶è´¹ï¼‰
          if python3 scripts/pick_public_cover.py --pool "data/public_image_pool.json" --industry "${INDUSTRY}" --title "${TITLE}" --slug "${FILENAME}" --out "${COVER_OUT_FILE}" --md "${ORIGINAL_FILE}" --news-json "${NEWS_JSON}" >/tmp/cover_meta.json; then
            echo "âœ… cover from public pool"
          else
            echo "âš ï¸ public cover not available, fallback to jimeng"
            if python3 scripts/jimeng_generate_cover.py --slug "${FILENAME}" --title "${TITLE}" --industry "${INDUSTRY}" --out "${COVER_OUT_FILE}"; then
              python3 scripts/jimeng_usage.py --file data/usage/jimeng_usage.json --mark success || true
            else
              python3 scripts/jimeng_usage.py --file data/usage/jimeng_usage.json --mark fail || true
            fi
          fi

          # å¤åˆ¶ä¸€ä»½ç”¨äºå…¬ä¼—å·æ ¼å¼è½¬æ¢
          cp "${ORIGINAL_FILE}" "${WECHAT_FILE}"

          echo "âœ… æ–‡ç« å·²ç”Ÿæˆ: ${ORIGINAL_FILE}"
          echo "original_file=${ORIGINAL_FILE}" >> $GITHUB_OUTPUT
          echo "wechat_file=${WECHAT_FILE}" >> $GITHUB_OUTPUT
        shell: bash

      - name: Auto add charts (data-driven illustrations)
        if: steps.topic.outputs.skip != 'true'
        run: |
          echo "æ ¹æ®è¡¨æ ¼æ•°æ®ç”Ÿæˆæ’å›¾ï¼ˆå›¾è¡¨ï¼‰..."
          ORIGINAL_FILE="${{ steps.generate.outputs.original_file }}"
          
          if [ -f "$ORIGINAL_FILE" ]; then
            python3 scripts/auto_illustrate.py "$ORIGINAL_FILE"
            echo "å·²ä¸ºæ–‡ç« ç”Ÿæˆå›¾è¡¨æ’å›¾å¹¶å†™å…¥ static/images"
          else
            echo "æœªæ‰¾åˆ°æ–‡ç« æ–‡ä»¶ï¼Œè·³è¿‡æ’å›¾ç”Ÿæˆ"
          fi

      - name: Auto add public images (Wikimedia Commons)
        if: steps.topic.outputs.skip != 'true'
        run: |
          echo "ä»å…¬å¼€æ•°æ®æºè·å–é…å›¾ï¼ˆWikimedia Commonsï¼Œæ— éœ€API Keyï¼‰..."
          ORIGINAL_FILE="${{ steps.generate.outputs.original_file }}"
          
          if [ -f "$ORIGINAL_FILE" ]; then
            python3 scripts/auto_add_public_images.py "$ORIGINAL_FILE" || true
            echo "å·²å°è¯•ä¸ºæ–‡ç« æ’å…¥å…¬å¼€é…å›¾ï¼ˆå¹¶åœ¨æ–‡ä¸­å†™æ˜æ¥æºä¸è®¸å¯ï¼‰"
          else
            echo "æœªæ‰¾åˆ°æ–‡ç« æ–‡ä»¶ï¼Œè·³è¿‡å…¬å¼€é…å›¾"
          fi

      - name: Validate illustrations (non-blocking)
        if: steps.topic.outputs.skip != 'true'
        run: |
          echo "æ ¡éªŒæ’å›¾è§„åˆ™ï¼šè‡³å°‘1å¼ å…¬å¼€é…å›¾ + æ¯ä¸ªå…³é”®è¡¨æ ¼1å¼ å›¾è¡¨..."
          ORIGINAL_FILE="${{ steps.generate.outputs.original_file }}"
          python3 scripts/validate_illustrations.py "$ORIGINAL_FILE" || echo "::warning::illustrations validation failed (will continue publishing)"

      - name: Record failure (commit to repo)
        if: failure()
        run: |
          echo "è®°å½•å¤±è´¥ä¿¡æ¯åˆ°ä»“åº“ï¼Œå¹¶å†™å…¥å¾…é‡è¯•ä»»åŠ¡ï¼ˆ2å°æ—¶åé‡è¯•ï¼‰..."
          mkdir -p logs/auto-publish-failures data
          RUN_URL="https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
          TS="$(date -u '+%Y-%m-%dT%H:%M:%SZ')"
          FILE="logs/auto-publish-failures/${{ github.run_id }}.md"
          {
            echo "# Auto Publish Failure";
            echo "";
            echo "- time(UTC): ${TS}";
            echo "- run: ${RUN_URL}";
            echo "- event: ${{ github.event_name }}";
            echo "- ref: ${{ github.ref }}";
            echo "";
            echo "This file is generated automatically when the workflow fails.";
          } > "$FILE"

          # å†™å…¥å¾…é‡è¯•ä»»åŠ¡ï¼ˆ2å°æ—¶åï¼‰
          NEXT_EPOCH=$(python3 -c "import time; print(int(time.time())+7200)")
          python3 -c "import json; from pathlib import Path; Path('data').mkdir(parents=True, exist_ok=True); industry='${{ steps.topic.outputs.industry }}'; topic='${{ steps.topic.outputs.topic }}'; ts='${{ steps.topic.outputs.timestamp }}'; Path('data/pending_retry.json').write_text(json.dumps({'industry':industry,'topic':topic,'force_timestamp':ts,'next_retry_epoch':int(${NEXT_EPOCH}),'reason':'workflow_failed','run':'${RUN_URL}'}, ensure_ascii=False, indent=2)+'\\n', encoding='utf-8'); print('pending_retry written')"

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add "$FILE" data/pending_retry.json || true
          git commit -m "ğŸ§¾ è®°å½•è‡ªåŠ¨å‘å¸ƒå¤±è´¥å¹¶æ’é˜Ÿé‡è¯•ï¼šrun ${{ github.run_id }}" || true
          git push origin main || true
      
      - name: Format for WeChat
        if: steps.topic.outputs.skip != 'true'
        id: wechat
        run: |
          echo "è½¬æ¢ä¸ºå¾®ä¿¡å…¬ä¼—å·æ ¼å¼..."
          ORIGINAL_FILE="${{ steps.generate.outputs.original_file }}"

          if [ ! -f "$ORIGINAL_FILE" ]; then
            echo "æœªæ‰¾åˆ°æ–‡ç« æ–‡ä»¶ï¼Œæ— æ³•è½¬æ¢"
            exit 1
          fi

          # ç”Ÿæˆå…¬ä¼—å·æ’ç‰ˆæ–‡ä»¶ï¼ˆæ³¨æ„ï¼šä¸è¦è®©å®ƒå‚ä¸ Hugo æ„å»ºï¼Œå¦åˆ™ä¼šå¯¼è‡´åšå®¢å‡ºç°é‡å¤æ–‡ç« ï¼‰
          python3 format-wechat.py "$ORIGINAL_FILE"

          WECHAT_FILE="${ORIGINAL_FILE%.md}-wechat.md"
          if [ ! -f "$WECHAT_FILE" ]; then
            echo "å¾®ä¿¡å…¬ä¼—å·æ ¼å¼æ–‡ä»¶æœªç”Ÿæˆ"
            exit 1
          fi

          # å°†å…¬ä¼—å·æ–‡ä»¶ç§»å‡º content/postsï¼Œé¿å… Hugo ç”Ÿæˆç¬¬äºŒä¸ªåŒ slug é¡µé¢
          mkdir -p logs/wechat
          MOVED="logs/wechat/$(basename "$WECHAT_FILE")"
          mv "$WECHAT_FILE" "$MOVED"

          echo "å¾®ä¿¡å…¬ä¼—å·æ ¼å¼å·²ç”Ÿæˆ(ä¸å‘å¸ƒåˆ°åšå®¢): $MOVED"
          echo "wechat_file=$MOVED" >> $GITHUB_OUTPUT
      
      - name: Commit generated post & assets (persist history)
        if: steps.topic.outputs.skip != 'true'
        run: |
          echo "ğŸ“ å°†æ–°æ–‡ç« ä¸å›¾ç‰‡å†™å› main åˆ†æ”¯ï¼Œä¿è¯å†å²æ–‡ç« ä¸ä¼šè¢«è¦†ç›–..."

          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # è‹¥è¿™æ˜¯ä¸€æ¬¡é‡è¯•æˆåŠŸï¼Œæ¸…ç† pending æ ‡è®°
          if [ -f data/pending_retry.json ]; then
            rm -f data/pending_retry.json
          fi

          # æ–°æ–‡ç«  + é™æ€èµ„æº + æ•°æ®ï¼ˆç”¨äºå®¡è®¡/å›æº¯ï¼Œå¯æŒ‰éœ€åˆ å‡ï¼‰
          # æ³¨æ„ï¼šä¸è¦æŠŠâ€œå¯èƒ½ä¸å­˜åœ¨â€çš„è·¯å¾„æ”¾è¿›åŒä¸€ä¸ª git addï¼Œå¦åˆ™ä¼šå¯¼è‡´æ•´æ¡å‘½ä»¤å¤±è´¥ï¼Œä»è€Œä¸€ä¸ªæ–‡ä»¶ä¹Ÿæ²¡è¢« stageã€‚
          git add content/posts static/images logs/wechat || true
          if [ -d data/raw ]; then git add -f data/raw || true; fi
          if [ -f data/pending_retry.json ]; then git add data/pending_retry.json || true; fi

          if git diff --cached --quiet; then
            echo "æ²¡æœ‰éœ€è¦æäº¤çš„å˜æ›´ï¼ˆå¯èƒ½æ˜¯é‡å¤æ—¶é—´æˆ³/æ— æ–°å¢èµ„æºï¼‰"
          else
            git commit -m "ğŸ“ ä¿å­˜æ–°æ–‡ç« æºæ–‡ä»¶ä¸èµ„æº: ${{ steps.topic.outputs.filename }}"
            git push origin HEAD:main
          fi

      - name: Build Hugo site
        if: steps.topic.outputs.skip != 'true'
        run: |
          echo "ğŸ—ï¸ æ„å»ºHugoç½‘ç«™..."
          hugo --minify
      
      - name: Deploy to GitHub Pages
        if: steps.topic.outputs.skip != 'true'
        uses: peaceiris/actions-gh-pages@v3
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          publish_dir: ./public
          publish_branch: gh-pages
          # ä¸å¼ºåˆ¶ orphanï¼Œä¿ç•™ pages åˆ†æ”¯æäº¤å†å²ï¼ˆå¯é€‰ï¼Œä½†æœ‰åŠ©æ’æŸ¥ï¼‰
          force_orphan: false
          user_name: 'github-actions[bot]'
          user_email: 'github-actions[bot]@users.noreply.github.com'
          commit_message: 'ğŸš€ è‡ªåŠ¨å‘å¸ƒæ–‡ç« : ${{ steps.topic.outputs.topic }} [$(date +%Y%m%d-%H%M%S)]'
      
      - name: Generate deployment report
        if: steps.topic.outputs.skip != 'true'
        run: |
          echo "# è‡ªåŠ¨å‘å¸ƒæŠ¥å‘Š" > deployment-report.md
          echo "ç”Ÿæˆæ—¶é—´: $(date)" >> deployment-report.md
          echo "" >> deployment-report.md
          
          echo "## ğŸ“‹ å‘å¸ƒè¯¦æƒ…" >> deployment-report.md
          echo "- æ–‡ç« ä¸»é¢˜: ${{ steps.topic.outputs.topic }}" >> deployment-report.md
          echo "- ç”Ÿæˆæ—¶é—´: ${{ steps.topic.outputs.timestamp }}" >> deployment-report.md
          echo "- åŸå§‹æ–‡ç« : ${{ steps.generate.outputs.original_file }}" >> deployment-report.md
          echo "- å¾®ä¿¡å…¬ä¼—å·æ ¼å¼: ${{ steps.wechat.outputs.wechat_file }}" >> deployment-report.md
          echo "" >> deployment-report.md
          
          echo "## ğŸŒ è®¿é—®é“¾æ¥" >> deployment-report.md
          echo "- åšå®¢é¦–é¡µ: ${BLOG_URL}" >> deployment-report.md
          FILENAME="${{ steps.topic.outputs.filename }}"
          echo "- æ–‡ç« é¡µé¢: ${BLOG_URL}/posts/${FILENAME}/" >> deployment-report.md
          echo "" >> deployment-report.md
          
          echo "## â° ä¸‹æ¬¡å‘å¸ƒæ—¶é—´" >> deployment-report.md
          echo "ç³»ç»Ÿå°†åœ¨ä»¥ä¸‹æ—¶é—´è‡ªåŠ¨å‘å¸ƒæ–°æ–‡ç« ï¼š" >> deployment-report.md
          echo "- 08:00 (åŒ—äº¬æ—¶é—´)" >> deployment-report.md
          echo "- 18:00 (åŒ—äº¬æ—¶é—´)" >> deployment-report.md
          echo "" >> deployment-report.md
          
          echo "## ğŸ”§ æ‰‹åŠ¨è§¦å‘" >> deployment-report.md
          echo "å¦‚éœ€ç«‹å³å‘å¸ƒæ–‡ç« ï¼Œå¯åœ¨GitHub Actionsé¡µé¢æ‰‹åŠ¨è§¦å‘æ­¤å·¥ä½œæµã€‚" >> deployment-report.md
          
          cat deployment-report.md
      
      - name: Upload artifacts
        if: steps.topic.outputs.skip != 'true'
        uses: actions/upload-artifact@v4
        with:
          name: published-articles
          path: |
            content/posts/*.md
            deployment-report.md
          retention-days: 7
      
      - name: Send success notification
        if: success() && steps.topic.outputs.skip != 'true'
        env:
          FEISHU_WEBHOOK_URL: ${{ secrets.FEISHU_WEBHOOK_URL }}
        run: |
          echo "âœ… æ–‡ç« å‘å¸ƒæˆåŠŸï¼"
          echo "ä¸»é¢˜: ${{ steps.topic.outputs.topic }}"
          echo "æ—¶é—´: $(date)"
          echo "åšå®¢åœ°å€: ${BLOG_URL}"
          echo "æ–‡ç« é“¾æ¥: ${BLOG_URL}/posts/${{ steps.topic.outputs.filename }}/"

          # Jimeng usage summary (self-tracked)
          if [ -f data/usage/jimeng_usage.json ]; then
            USAGE=$(cat data/usage/jimeng_usage.json | python3 -c "import sys,json; j=json.load(sys.stdin); t=j.get('total',{}); print(f\"Jimengæœ¬æœˆ ç”¨é‡ï¼šæˆåŠŸ{t.get('success',0)}ï¼Œå¤±è´¥{t.get('fail',0)}\")")
          else
            USAGE="Jimengæœ¬æœˆ ç”¨é‡ï¼šæš‚æ— ç»Ÿè®¡"
          fi
          echo "$USAGE"
