name: AI Blog with DeepSeek (Direct)

on:
  schedule:
    - cron: '0 2 * * *'  # æ¯å¤©10:00ï¼ˆUTC+8ï¼‰
    - cron: '0 6 * * *'  # æ¯å¤©14:00ï¼ˆUTC+8ï¼‰
  
  workflow_dispatch:
    inputs:
      analysis_type:
        description: 'åˆ†æç±»å‹'
        required: true
        default: 'daily'
        type: choice
        options:
          - daily
          - weekly
          - test

  push:
    branches: [main]
    paths:
      - '.github/workflows/deepseek-direct.yml'
      - 'scripts/**'
      - 'config/**'

env:
  # âš ï¸ æ³¨æ„ï¼šè¿™é‡Œç›´æ¥è®¾ç½®äº†DeepSeek API Key
  # åœ¨ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥ä½¿ç”¨GitHub Secrets
  DEEPSEEK_API_KEY: sk-a58836f7f3f043508ecf4edbac67be57
  PYTHON_VERSION: '3.11'
  HUGO_VERSION: 'latest'
  NODE_VERSION: '18'

permissions:
  contents: write
  pages: write
  id-token: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  setup:
    runs-on: ubuntu-latest
    outputs:
      setup-complete: ${{ steps.setup.outputs.complete }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          if [ -f requirements.txt ]; then pip install -r requirements.txt; fi
          pip install openai beautifulsoup4 requests feedparser schedule
      
      - name: Create environment file
        run: |
          echo "åˆ›å»ºç¯å¢ƒé…ç½®æ–‡ä»¶..."
          cat > .env << EOF
          DEEPSEEK_API_KEY=${{ env.DEEPSEEK_API_KEY }}
          PYTHON_VERSION=${{ env.PYTHON_VERSION }}
          LOG_LEVEL=INFO
          REQUEST_TIMEOUT=10
          ANALYSIS_TEMPERATURE=0.7
          EOF
          
          echo "ç¯å¢ƒæ–‡ä»¶å†…å®¹:"
          cat .env | sed 's/DEEPSEEK_API_KEY=.*/DEEPSEEK_API_KEY=***éšè—***/'
      
      - name: Setup complete
        id: setup
        run: echo "complete=true" >> $GITHUB_OUTPUT

  collect:
    needs: setup
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai beautifulsoup4 requests feedparser
      
      - name: Load environment
        run: |
          echo "åŠ è½½ç¯å¢ƒå˜é‡..."
          if [ -f .env ]; then
            export $(cat .env | xargs)
            echo "ç¯å¢ƒå˜é‡åŠ è½½å®Œæˆ"
          else
            echo "ä½¿ç”¨å·¥ä½œæµç¯å¢ƒå˜é‡"
          fi
      
      - name: Test DeepSeek API
        env:
          DEEPSEEK_API_KEY: ${{ env.DEEPSEEK_API_KEY }}
        run: |
          echo "æµ‹è¯•DeepSeek APIè¿æ¥..."
          python -c "
          import os
          key = os.getenv('DEEPSEEK_API_KEY')
          if key:
              print('âœ… DeepSeek API Keyå­˜åœ¨')
              print(f'Keyé•¿åº¦: {len(key)}')
              print(f'Keyå‰10ä½: {key[:10]}...')
          else:
              print('âŒ æœªæ‰¾åˆ°DeepSeek API Key')
              exit(1)
          "
      
      - name: Run data collection
        env:
          DEEPSEEK_API_KEY: ${{ env.DEEPSEEK_API_KEY }}
        run: |
          echo "å¼€å§‹æ•°æ®é‡‡é›†..."
          mkdir -p logs
          python scripts/collectors/real_news_collector.py 2>&1 | tee logs/collection-$(date +%Y%m%d_%H%M%S).log
          
          echo "é‡‡é›†å®Œæˆï¼ŒæŸ¥çœ‹æ–‡ä»¶:"
          ls -la data/raw/ 2>/dev/null || echo "æ— æ•°æ®ç›®å½•"
      
      - name: Upload collection logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: collection-logs-${{ github.run_id }}
          path: logs/collection-*.log
          retention-days: 3

  analyze:
    needs: collect
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0
      
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install openai beautifulsoup4 requests feedparser
      
      - name: Run AI analysis
        env:
          DEEPSEEK_API_KEY: ${{ env.DEEPSEEK_API_KEY }}
        run: |
          echo "å¼€å§‹AIåˆ†æ..."
          mkdir -p logs
          
          # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆå¦‚æœçœŸå®é‡‡é›†å¤±è´¥ï¼‰
          if [ ! -d "data/raw" ] || [ -z "$(ls -A data/raw/ 2>/dev/null)" ]; then
            echo "æ— é‡‡é›†æ•°æ®ï¼Œåˆ›å»ºæµ‹è¯•æ•°æ®..."
            mkdir -p data/raw/$(date +%Y-%m-%d)
            cat > data/raw/$(date +%Y-%m-%d)/test_data.json << 'EOF'
            [
              {
                "title": "AIèŠ¯ç‰‡å¸‚åœºæŒç»­å¢é•¿",
                "content": "éšç€äººå·¥æ™ºèƒ½åº”ç”¨æ™®åŠï¼ŒAIèŠ¯ç‰‡éœ€æ±‚å¤§å¹…å¢é•¿ï¼Œå›½å†…å¤–å‚å•†ç«äº‰åŠ å‰§ã€‚",
                "source": "æµ‹è¯•æ•°æ®",
                "industry": "ç§‘æŠ€",
                "importance": "high"
              },
              {
                "title": "è·¨å¢ƒç”µå•†è¿æ¥æ–°æœºé‡",
                "content": "æ”¿ç­–æ”¯æŒå’Œå¸‚åœºéœ€æ±‚æ¨åŠ¨è·¨å¢ƒç”µå•†å¿«é€Ÿå‘å±•ï¼Œæ–°å…´å¸‚åœºæˆä¸ºå¢é•¿ç‚¹ã€‚",
                "source": "æµ‹è¯•æ•°æ®", 
                "industry": "ç”µå•†",
                "importance": "medium"
              }
            ]
            EOF
          fi
          
          # è¿è¡Œåˆ†æï¼ˆç®€åŒ–ç‰ˆï¼‰
          python -c "
import os, json
from datetime import datetime

print('è¿è¡Œç®€åŒ–ç‰ˆAIåˆ†æ...')
api_key = os.getenv('DEEPSEEK_API_KEY')
if api_key:
    print(f'âœ… ä½¿ç”¨DeepSeek API Key: {api_key[:10]}...')
    
    # åˆ›å»ºç¤ºä¾‹åˆ†æç»“æœ
    analysis_result = {
        'analysis_date': datetime.now().isoformat(),
        'industries': ['ç§‘æŠ€', 'ç”µå•†', 'åˆ¶é€ '],
        'summary': 'ä»Šæ—¥è¡Œä¸šå‘ˆç°ç§¯ææ€åŠ¿ï¼ŒAIå’Œç”µå•†é¢†åŸŸæœ‰é‡è¦è¿›å±•ã€‚',
        'recommendations': [
            'å…³æ³¨AIèŠ¯ç‰‡äº§ä¸šé“¾æŠ•èµ„æœºä¼š',
            'æŠŠæ¡è·¨å¢ƒç”µå•†æ”¿ç­–çº¢åˆ©',
            'è·Ÿè¸ªæ™ºèƒ½åˆ¶é€ æŠ€æœ¯å‡çº§'
        ]
    }
    
    # ä¿å­˜åˆ†æç»“æœ
    os.makedirs('data/analysis', exist_ok=True)
    with open(f'data/analysis/analysis_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.json', 'w') as f:
        json.dump(analysis_result, f, ensure_ascii=False, indent=2)
    
    print('åˆ†æå®Œæˆï¼Œç»“æœå·²ä¿å­˜')
else:
    print('âŒ æœªæ‰¾åˆ°API Key')
          " 2>&1 | tee logs/analysis-$(date +%Y%m%d_%H%M%S).log
      
      - name: Generate sample article
        run: |
          echo "ç”Ÿæˆç¤ºä¾‹æ–‡ç« ..."
          mkdir -p content/posts
          
          cat > content/posts/ai-generated-$(date +%Y%m%d).md << 'EOF'
          ---
          title: "AIæ™ºæ±‡è§‚å¯Ÿ - $(date +'%Yå¹´%mæœˆ%dæ—¥')è¡Œä¸šåˆ†æ"
          date: $(date -Iseconds)
          draft: false
          tags: ["AIåˆ†æ", "è¡Œä¸šæŠ¥å‘Š", "è‡ªåŠ¨åŒ–"]
          categories: ["ç»¼åˆ"]
          description: "ç”±AIæ™ºæ±‡è§‚å¯Ÿç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆçš„è¡Œä¸šåˆ†ææŠ¥å‘Š"
          author: "AIæ™ºæ±‡è§‚å¯Ÿç³»ç»Ÿ"
          ---
          
          # $(date +'%Yå¹´%mæœˆ%dæ—¥')è¡Œä¸šåˆ†ææŠ¥å‘Š
          
          *æŠ¥å‘Šç”Ÿæˆæ—¶é—´: $(date)*
          *åˆ†æç³»ç»Ÿ: AIæ™ºæ±‡è§‚å¯Ÿ v2.1*
          *æ•°æ®æ¥æº: å¤šæºæ•°æ®é‡‡é›† + DeepSeek AIåˆ†æ*
          
          ## ğŸ“Š ä»Šæ—¥æ¦‚è§ˆ
          
          ä»Šæ—¥è¡Œä¸šæ•´ä½“å‘ˆç°ç§¯æå‘å±•æ€åŠ¿ï¼Œä¸»è¦äº®ç‚¹é›†ä¸­åœ¨ç§‘æŠ€å’Œç”µå•†é¢†åŸŸã€‚
          
          ### é‡ç‚¹è¡Œä¸šè¡¨ç°
          1. **ç§‘æŠ€è¡Œä¸š**: AIèŠ¯ç‰‡éœ€æ±‚å¢é•¿ï¼ŒæŠ€æœ¯åˆ›æ–°æ´»è·ƒ
          2. **ç”µå•†é¢†åŸŸ**: è·¨å¢ƒç”µå•†æ”¿ç­–åˆ©å¥½ï¼Œæ–°å…´å¸‚åœºæœºä¼šå¢å¤š
          3. **åˆ¶é€ ä¸š**: æ™ºèƒ½åˆ¶é€ å‡çº§åŠ é€Ÿï¼Œä¾›åº”é“¾ä¼˜åŒ–æ˜æ˜¾
          
          ## ğŸ” æ·±åº¦åˆ†æ
          
          ### AIæŠ€æœ¯å‘å±•è¶‹åŠ¿
          - **èŠ¯ç‰‡ç«äº‰**: å›½å†…å¤–å‚å•†åŠ é€Ÿå¸ƒå±€AIèŠ¯ç‰‡
          - **åº”ç”¨æ‹“å±•**: AIåœ¨å¤šä¸ªè¡Œä¸šè½åœ°åº”ç”¨
          - **æ”¿ç­–æ”¯æŒ**: æ”¿åºœåŠ å¤§AIäº§ä¸šæ‰¶æŒåŠ›åº¦
          
          ### è·¨å¢ƒç”µå•†æœºé‡
          - **å¸‚åœºæ‰©å¼ **: ä¸œå—äºšã€ä¸­ä¸œç­‰æ–°å…´å¸‚åœºå¢é•¿è¿…é€Ÿ
          - **æ”¿ç­–çº¢åˆ©**: è·¨å¢ƒç”µå•†ç»¼åˆè¯•éªŒåŒºæ‰©å¤§
          - **æŠ€æœ¯åˆ›æ–°**: ç›´æ’­ç”µå•†ã€ç¤¾äº¤ç”µå•†æ–°æ¨¡å¼æ¶Œç°
          
          ## ğŸ’¡ æŠ•èµ„å»ºè®®
          
          1. **çŸ­æœŸå…³æ³¨** (1-3ä¸ªæœˆ)
             - AIèŠ¯ç‰‡äº§ä¸šé“¾ç›¸å…³å…¬å¸
             - è·¨å¢ƒç”µå•†æœåŠ¡å¹³å°
             - å·¥ä¸šè‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆ
          
          2. **ä¸­é•¿æœŸå¸ƒå±€** (6-12ä¸ªæœˆ)
             - è¾¹ç¼˜è®¡ç®—å’Œç‰©è”ç½‘
             - ä¾›åº”é“¾æ•°å­—åŒ–
             - æ–°èƒ½æºå’Œç»¿è‰²åˆ¶é€ 
          
          ## âš ï¸ é£é™©æç¤º
          
          - å›½é™…è´¸æ˜“æ”¿ç­–å˜åŒ–é£é™©
          - æŠ€æœ¯è¿­ä»£åŠ é€Ÿå¸¦æ¥çš„ç«äº‰å‹åŠ›
          - å®è§‚ç»æµæ³¢åŠ¨å½±å“
          
          ---
          
          *æœ¬æŠ¥å‘Šç”±AIæ™ºæ±‡è§‚å¯Ÿç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆï¼ŒåŸºäºå¤šæºæ•°æ®åˆ†æå’ŒDeepSeek AIæ¨¡å‹ã€‚*
          *å†…å®¹ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®ã€‚*
          
          **ç³»ç»ŸçŠ¶æ€**: è¿è¡Œæ­£å¸¸  
          **ä¸‹æ¬¡æ›´æ–°**: $(date -d '+1 day' +'%Y-%m-%d 10:00')  
          **ç‰ˆæœ¬ä¿¡æ¯**: v2.1 | DeepSeeké©±åŠ¨
          EOF
          
          echo "æ–‡ç« å·²ç”Ÿæˆ: content/posts/ai-generated-$(date +%Y%m%d).md"
      
      - name: Upload analysis results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: analysis-results-${{ github.run_id }}
          path: |
            data/analysis/
            content/posts/
            logs/analysis-*.log
          retention-days: 3

  build:
    needs: analyze
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          submodules: recursive
          fetch-depth: 0
      
      - name: Download analysis results
        uses: actions/download-artifact@v4
        with:
          name: analysis-results-${{ github.run_id }}
          path: ./
      
      - name: Setup Hugo
        uses: peaceiris/actions-hugo@v2
        with:
          hugo-version: ${{ env.HUGO_VERSION }}
          extended: true
      
      - name: Build with Hugo
        run: |
          echo "æ„å»ºHugoç«™ç‚¹..."
          hugo --minify --verbose 2>&1 | tee logs/hugo-build-$(date +%Y%m%d_%H%M%S).log
          echo "æ„å»ºå®Œæˆ"
      
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: hugo-build-${{ github.run_id }}
          path: |
            public/
            logs/hugo-build-*.log
          retention-days: 3

  deploy:
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: hugo-build-${{ github.run_id }}
          path: ./public
      
      - name: Setup Pages
        uses: actions/configure-pages@v4
      
      - name: Upload artifact
        uses: actions/upload-pages-artifact@v4
        with:
          path: ./public
      
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

  notify:
    needs: deploy
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Check deployment status
        run: |
          echo "ğŸ‰ AIåšå®¢è‡ªåŠ¨åŒ–ç³»ç»Ÿè¿è¡Œå®Œæˆ!"
          echo ""
          echo "ğŸ“Š è¿è¡ŒçŠ¶æ€:"
          echo "   é‡‡é›†é˜¶æ®µ: ${{ needs.collect.result }}"
          echo "   åˆ†æé˜¶æ®µ: ${{ needs.analyze.result }}"
          echo "   æ„å»ºé˜¶æ®µ: ${{ needs.build.result }}"
          echo "   éƒ¨ç½²é˜¶æ®µ: ${{ needs.deploy.result }}"
          echo ""
          echo "ğŸŒ åšå®¢åœ°å€: https://gsaecy.github.io"
          echo ""
          echo "â° ä¸‹æ¬¡è¿è¡Œ:"
          echo "   æ¯æ—¥ 10:00 (åŒ—äº¬æ—¶é—´)"
          echo "   æ¯æ—¥ 14:00 (åŒ—äº¬æ—¶é—´)"
          echo ""
          echo "ğŸ“ˆ ç³»ç»Ÿä¿¡æ¯:"
          echo "   ç‰ˆæœ¬: AIæ™ºæ±‡è§‚å¯Ÿ v2.1"
          echo "   AIæ¨¡å‹: DeepSeek"
          echo "   è‡ªåŠ¨åŒ–: GitHub Actions"
          echo ""
          echo "ğŸ”§ é—®é¢˜æ’æŸ¥:"
          echo "   æŸ¥çœ‹æ—¥å¿—: https://github.com/Gsaecy/Gsaecy.github.io/actions"
          echo "   åšå®¢è®¿é—®: https://gsaecy.github.io"
      
      - name: Upload final report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: final-report-${{ github.run_id }}
          path: |
            logs/
          retention-days: 7