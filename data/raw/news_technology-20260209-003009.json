{
  "industry": "technology",
  "collected_at": "2026-02-08T16:31:21.112849+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "From Svedka to Anthropic, brands make bold plays with AI in Super Bowl ads",
      "url": "https://techcrunch.com/2026/02/08/super-bowl-60-ai-ads-svedka-anthropic-brands-commercials/",
      "published": "2026-02-08T16:18:16+00:00",
      "summary": "From the first AI-generated Big Game ad courtesy of Svedka to Anthropic's beef with OpenAI, here are the biggest ads from Super Bowl LX.",
      "content_text": "Following last year’s trend of showcasing AI in multimillion-dollar ad spots, the 2026 Super Bowl advertisements took it a step further by leveraging AI both to create the commercials and to promote the latest AI products. Love it or hate it, the technology has become a star in its own right, alongside the latest movie trailers and snack brands. Let’s explore the biggest moments from this year’s Big Game ads, which featured everything from robots and AI glasses to a touch of drama involving tech founders. Svedka Vodka brand Svedka went with what it touts as the first “primarily” AI-generated national Super Bowl spot. The 30-second ad, titled “Shake Your Bots Off,” features the company’s robot character, Fembot, and her new companion, Brobot, dancing their circuits off at a human party. According to Svedka’s parent company, Sazerac, it took roughly four months to reconstruct the Fembot and train the AI to mimic facial expressions and body movements, The Wall Street Journal reported . However, the vodka brand noted that certain aspects were still handled by humans, such as developing the storyline. VIDEO ​The company partnered with AI company Silverside to create the Super Bowl spot, according to ADWEEK . Silverside AI is the same team behind recent AI-generated Coca-Cola commercials that sparked controversy . ​It’s a bold move to debut AI-generated content during the Super Bowl, an event known for star-studded, high-production ads. The heavy reliance on AI is polarizing, fueling debates over whether AI will replace creative jobs. Techcrunch event Boston, MA | June 23, 2026 Either way, Svedka definitely got people talking. Anthropic Anthropic’s ad wasn’t just about selling its Claude chatbot; it was about throwing shade. The commercial took a jab at OpenAI’s plan to introduce ads to ChatGPT , with a tagline: “Ads are coming to AI. But not to Claude.” Rather than focus solely on Claude’s features, it poked fun at the idea of your helpful AI assistant suddenly turning into a hype man for “Step Boost Maxx” insoles, for example. It wasn’t a standard product pitch, and it escalated into an online feud . OpenAI’s Sam Altman fired back on social media, calling the ad “clearly dishonest.” So while we didn’t get any more Kendrick vs. Drake rap beef this time around, maybe we did get our own AI, nerdy version of it . VIDEO Meta spotlighted its Oakley-branded AI glasses , designed for sports, workouts, and adventures, including extreme scenarios such as chasing down a departing plane. The ad showcased thrill-seekers, from skydivers to mountain bikers, using the glasses to capture epic moments. Famous faces like IShowSpeed and filmmaker Spike Lee made appearances, demonstrating capabilities like filming a basketball dunk in slow motion, posting hands-free to Instagram, and other advanced features. The tech giant also featured its wearable AI tech in last year’s Super Bowl ad to spark consumer interest, with stars like Chris Pratt, Chris Hemsworth, and Kris Jenner showing off Ray-Ban Meta glasses. VIDEO Amazon Amazon’s ad took a cheeky (and slightly unsettling) approach, starring Chris Hemsworth in a satirical “AI is out to get me” storyline. The commercial exaggerates common fears about AI, with Hemsworth humorously accusing Alexa+ of plotting against him. Scenes included Alexa+ closing the garage door on his head and shutting the pool cover while he swam, each mishap escalating in absurdity. Beyond the dark comedy, the ad introduced the new Alexa+, showcasing its enhanced intelligence and capabilities, ranging from managing smart home devices to planning vacations. Alexa+ had been available in early access for over a year and officially launched to all U.S. users on Wednesday. VIDEO Ring Ring’s commercial spotlighted its “Search Party” feature , which leverages AI and a community network to reunite lost pets with their owners. The ad followed a young girl searching for her dog Milo, illustrating how users can upload a pet’s photo to the app, where AI works to identify matches and taps into nearby cameras and the broader Ring user community to help track down missing furry family members. Ring recently announced that anyone can now use Search Party, even without owning a Ring security camera. According to the company, the feature has already helped reunite more than one lost dog with its owner every day. VIDEO Google Google’s ad showcased the Nano Banana Pro , its newest image-generation model. The commercial followed a mother and son as they used AI to envision and design their new home, uploading photos of bare rooms and turning them into personalized spaces with just a few prompts. VIDEO Ramp Ramp scored big by getting Brian Baumgartner — the actor who played Kevin in “The Office” — for its Super Bowl commercial. In the spot, Baumgartner uses Ramp’s AI-powered spend management platform to “multiply” himself, effortlessly tackling a mountain of work. The ad highlights how Ramp’s all-in-one solution helps teams focus on the most important tasks through smart automation. And, as a playful nod to his TV persona, Baumgartner is seen carrying a pot of chili in the ad, referencing Kevin’s legendary scene where he brings his cherished recipe for his co-workers to try, only to disastrously spill the entire pot on the floor. VIDEO Rippling Rippling, the cloud-based workforce management platform, went all in on its first-ever Super Bowl ad . The company tapped comedian Tim Robinson in a spot about onboarding an alien monster, poking fun at HR headaches and the promise of AI automation. VIDEO Hims & Hers Health company Hims & Hers used its Super Bowl spot to address disparities in healthcare access. The ad cleverly references the lengths the wealthy go to for health and longevity, even appearing to poke fun at Jeff Bezos’ Blue Origin spaceflight in 2021 and Bryan Johnson’s expensive anti-aging routines . In recent years, the company launched an AI-powered “MedMatch” tool to deliver more personalized treatment recommendations, especially for mental health and wellness. VIDEO Wix Website builder Wix spotlighted its new AI-powered Wix Harmony platform, promising website creation as easy as chatting with a friend. Unveiled in January, the flagship platform combines AI-driven creation and “vibe coding” with full visual editing and customization. Wix’s biggest competitor, Squarespace, also has a Super Bowl ad this year. Squarespace’s ad has a more cinematic approach starring Emma Stone and directed by Yorgos Lanthimos. VIDEO This post was initially published on February 6, 2026.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/svedkasuperbowl2026.png?w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "The iPhone 17e could launch soon with MagSafe and an A19 chip",
      "url": "https://www.theverge.com/tech/875454/iphone-17e-launching-soon-magsafe-a19",
      "published": "2026-02-08T15:26:33+00:00",
      "summary": "Almost exactly one year after launching the iPhone 16e, Apple is preparing to launch the 17e, according to Mark Gurman. The iPhone 17e will feature an upgraded A19 chip from the iPhone 17 lineup, plus MagSafe charging, and move Apple's in-house cellular chips. Just as importantly, the company apparently plans to keep the price at [&#8230;]",
      "content_text": "Almost exactly one year after launching the iPhone 16e, Apple is preparing to launch the 17e , according to Mark Gurman . The iPhone 17e will feature an upgraded A19 chip from the iPhone 17 lineup, plus MagSafe charging, and move Apple’s in-house cellular chips. Just as importantly, the company apparently plans to keep the price at $599, despite soaring RAM and storage prices. Gurman says Apple is planning to pitch the iPhone 17e aggressively in emerging markets and to enterprises. He claims that, with almost no changes expected from the Pixel 10a and Samsung focused on the higher end of the market, Apple sees an opening. We also expect Apple to launch an updated iPad and iPad Air around the same time, alongside the spec-bumped MacBook Pros and a MacBook Air with an M5 processor. The base-model iPad will be moving to an A18 chip, which means it will support Apple Intelligence, while the iPad Air will move to an M4 and switch to an OLED display. Gurman says most of these launches should be expected by early March.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/gettyimages-2207365267.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Noam Chomsky's wife responds to Epstein controversy",
      "url": "https://www.aaronmate.net/p/noam-chomskys-wife-responds-to-epstein",
      "published": "2026-02-08T15:21:21+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.aaronmate.net/p/noam-chomskys-wife-responds-to-epstein\">https://www.aaronmate.net/p/noam-chomskys-wife-responds-to-epstein</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46935011\">https://news.ycombinator.com/item?id=46935011</a></p> <p>Points: 17</p> <p># Comments: 12</p>",
      "content_text": "Note: Noam Chomsky’s friendship with Jeffrey Epstein has become the source of controversy. After suffering a severe stroke in June 2023, Chomsky is unable to comment on it. His wife Valeria has responded to questions surrounding their contacts with Epstein in the statement below. I am publishing it here, with minor typographical corrections. As many are aware, my husband, Noam Chomsky, now 97, is confronting significant health challenges after suffering a devastating stroke in June 2023. Currently, Noam is under 24/7 medical care and is completely unable to speak or engage in public discourse. Since this health crisis, I have been entirely absorbed in Noam’s treatment and recovery, solely responsible for him and his medical treatment. Noam and I don’t have any kind of public relations assistance. For this reason, only now have I been able to address the matter of our contacts with Jeffrey Epstein. Noam and I have felt a profound weight regarding the unresolved questions surrounding our past interactions with Epstein. We do not wish to leave this chapter shrouded in ambiguity. Throughout his life, Noam has insisted that intellectuals have a responsibility to speak the truth and expose lies — especially when those truths are uncomfortable to themselves. As is widely known, one of Noam’s characteristics is to believe in the good faith of people. Noam’s overly trust[ing] nature, in this specific case, led to severe poor judgment on both our parts. Questions have rightly been raised about Noam’s meetings with Epstein, and about administrative assistance his office provided regarding a private financial matter—one that had absolutely no relation to any of Epstein’s criminal conduct. Noam and I were introduced to Epstein at the same time, during one of Noam’s professional events in 2015, when Epstein’s 2008 conviction in the State of Florida was known by very few people, while most of the public – including Noam and I – was unaware of it. That only changed after the November 2018 report by Miami Herald. When we were introduced to Epstein, he presented himself as a philanthropist of science and a financial expert. By presenting himself this way, Epstein gained Noam’s attention, and they began corresponding. Unknowingly, we opened a door to a Trojan horse. Epstein began to encircle Noam, sending gifts and creating opportunities for interesting discussions in areas Noam has been working on extensively. We regret that we did not perceive this as a strategy to ensnare us and to try to undermine the causes Noam stands for. We had lunch, at Epstein’s ranch, once, in connection with a professional event; we attended dinners at his townhouse in Manhattan and stayed a few times in an apartment he offered when we visited New York City. We also visited Epstein’s Paris apartment one afternoon for the occasion of a work trip. In all cases, these visits were related to Noam’s professional commitments. We never went to his island or knew about anything that happened there. We attended social meetings, lunches, and dinners where Epstein was present and academic matters were discussed. We never witnessed any inappropriate, criminal, or reproachable behavior from Epstein or others. At no time did we see children or underage individuals present. Epstein proposed meetings between Noam and figures that Noam had interest in, due to their different perspectives on themes related to Noam’s work and thought. It was in this academic context that Noam wrote a letter of recommendation. Noam’s email to Epstein, in which Epstein sought advice about the press, should be read in context. Epstein had claimed to Noam that he [Epstein] was being unfairly persecuted, and Noam spoke from his own experience in political controversies with the media. Epstein created a manipulative narrative about his case, which Noam, in good faith, believed in. It is now clear that it was all orchestrated, having as, at least, one of Epstein’s intentions to try to have someone like Noam repairing Epstein’s reputation by association. Noam’s criticism was never directed at the women’s movement; on the contrary, he has always supported gender equity and women’s rights. What happened was that Epstein took advantage of Noam’s public criticism towards what came to be known as “cancel culture” to present himself as a victim of it. Only after Epstein’s second arrest in [July] 2019 did we learn the full extent and gravity of what were then accusations—and are now confirmed—heinous crimes against women and children. We were careless in not thoroughly researching his background. This was a grave mistake, and for that lapse in judgment, I apologize on behalf of both of us. Noam shared with me, before his stroke, that he felt the same way. In 2023, Noam’s initial public response to inquiries about Epstein failed to adequately acknowledge the gravity of Epstein’s crimes and the enduring pain of his victims, primarily because Noam took it as obvious that he condemned such crimes. However, a firm and explicit stance on such matters is always required. It was deeply disturbing for both of us to realize we had engaged with someone who presented as a helpful friend but led a hidden life of criminal, inhumane, and perverted acts. Since the revelation of the extent of his crimes, we have been shocked. In order to clarify the check: Epstein asked Noam to develop a linguistic challenge that Epstein wished to establish as a regular prize. Noam worked on it, and Epstein sent a check for US$20,000 as payment. Epstein’s office contacted me to arrange for the check to be sent to our home address. Regarding the reported transfer of approximately $270,000, I must clarify that these were entirely Noam’s own funds. At the time, Noam had identified inconsistencies in his retirement resources that threatened his economic independence and caused him great distress. Epstein offered technical assistance to resolve this specific situation. On this matter, Epstein acted accordingly, recovering the funds for Noam, in a display of help and very likely as part of a machination to gain greater access to Noam. Epstein acted solely as a financial advisor for this specific matter. To the best of my knowledge, Epstein never had access to our bank or investment accounts. It is also important to clarify that Noam and I never had any investments with Epstein or his office—individually or as a couple. I hope this retrospectively clarifies and explains Noam Chomsky’s interactions with Epstein. Noam and I recognize the gravity of Jeffrey Epstein’s crimes and the profound suffering of his victims. Nothing in this statement is intended to minimize that suffering, and we express our unrestricted solidarity with the victims. February 7, 2026. Valéria Chomsky",
      "cover_image_url": "https://substackcdn.com/image/fetch/$s_!DPQb!,f_auto,q_auto:best,fl_progressive:steep/https%3A%2F%2Fmate.substack.com%2Ftwitter%2Fsubscribe-card.jpg%3Fv%3D-1176442768%26version%3D9"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "How I Built the Star Trek LCARS control panel of my dreams",
      "url": "https://www.theverge.com/tech/862070/lcars-homes-assistant-star-trek",
      "published": "2026-02-08T15:00:00+00:00",
      "summary": "One of my pandemic hobbies that stuck was home automation. I discovered Home Assistant - the popular open source, extremely customizable home automation platform - and all the intricate things you can do with it to make your home work better. I have ADHD and have found Home Assistant to be a valuable tool for [&#8230;]",
      "content_text": "One of my pandemic hobbies that stuck was home automation. I discovered Home Assistant — the popular open source, extremely customizable home automation platform — and all the intricate things you can do with it to make your home work better. I have ADHD and have found Home Assistant to be a valuable tool for managing executive dysfunction. I use it for audible calendar reminders, laundry reminders, timers, and monitoring my doorbell camera and my nanny cam for my dog. Its also a great source of pure nerdy joy for me. And I recently took the most joyously nerdy step yet in my home automation fixation. Home Assistant lets you create custom dashboards to interact with your smart home devices. Community members spend untold hours perfecting their dashboards and some of them are really impressive . I even discovered a community theme for Home Assistant that goes a long way to looking like the LCARS computer control system in the Next Generation era of Star Trek I grew up on. LCARS is not a practical or useful computer interface. Its stated purpose is to “ suggest something well-organized when a viewer sees [it] in the background of a scene .” What it is, though, is gorgeous. The aesthetic got hold of me at eight years old and has never let go. The homescreen of my iPhone’s dashboard. Most of my home automation happens through actual automation without my input, and I do make extensive use of voice control ( yes, “Computer” is my wake word. The false alarms when I’m watching Star Trek are worth it). But there are some things I’ll always want a dashboard for. Sometimes you want to control things manually. It’s nice for weather displays or triggering custom lighting scenes. Since the beginning of my infatuation with Home Assistant, I’ve been dying to use an LCARS-style interface. The theme linked above is very good — I use it for my phone’s main dashboard. But it’s not perfect. The sizing and the proportions of the elbow dividers is a little off, and the buttons are all broken up into two pieces. It’s small stuff. But I’m the kind of fan who wants to take the accuracy thing as far as it can go. So I made my own. I recently discovered LVGL (Light and Versatile Graphics Library), which lets you make graphic interfaces that are far more customizable and sophisticated than the stock Home Assistant dashboard setup. I figured there had to be some way to make LVGL talk to Home Assistant. The final piece of the puzzle was ESPHome . ESPHome is an open-source firmware framework that lets coding novices like me use relatively simple markup language to program Wifi-enabled microcontrollers like the ESP32, ESP8266, and RP2040, and it integrates deeply with Home Assistant. The possibilities are immense. I use ESPHome components as motion detectors, presence sensors, an air quality sensor, and controllers for LED strips. And ESPHome supports LVGL on specific display hardware. So I bought this Waveshare 7” touch display with an ESP32-S3 microcontroller built in and I got to work. I spent hours scouring the internet to find screenshots and fan recreations of some of the many LCARS panels featured in ’90s-era Star Trek. And I narrowed it down to this: Not exactly clear on what this does. But it looks very cool. http://www.lcars.org.uk/Adges%20Welcome.htm It’s a graphic you see in Tuvok’s quarters in Star Trek: Voyager . I’m not sure what it’s supposed to do in the show, but it has plenty of colorful buttons and rounded corners. And crucially there are two gauges at the top for who knows what. But to me those looked like lighting brightness controls. So I had my design. Next was to build it. To build an interface in ESPHome using LVGL, you use YAML to specify the characteristics (size, positioning, color, etc) of the graphic element you want. LVGL calls them “widgets.” So I first created my design in Adobe Illustrator as a reference. The advantage of building in Illustrator first is that the properties panel gives me all the numbers I need to build my YAML. I then began the rather tedious task of recreating that design in the ESPHome editor in Home Assistant. Thankfully you don’t need to know C (the language LVGL is written for) to use it in ESPHome. Instead you use YAML, which is much more forgiving for an enthusiastic amateur like me. Component by component, I specified the dimensions of each button, its location, its color, what label it would have, and its shape. It’s best practice in LVGL to use the inbuilt widgets instead of just inserting pictures. LVGL does have that capability, but ESP32 microcontrollers don’t have tons of spare resources, and images will eat them fast. The only actual images used in this design are the two gauges at the top right. All the other shapes are LVGL button widgets. A small snippet of the YAML that makes all this work. I did have to cheat a little for the irregular shapes. Some of the buttons in the LCARS interface only have two rounded corners. LVGL buttons are all or nothing when it comes to rounded corners. Thankfully though, LVGL doesn’t mind if you stack shapes on top of each other. For the buttons that are half rounded, I simply stacked a circle on the end of a square button. They’re the same color, so it looks like a single shape. The elbows in the middle are made in a similar way. Add a black background, and make the shapes the same color, and you have LCARS Eventually I got there. An honest to goodness authentic-looking LCARS touchscreen in my living room. 12-year-old me would be so impressed. 41-year-old me certainly is. All that was left was to connect it to my devices. While undertaking this project, I was hanging out in my living room, so I chose my living room lamps. (Yes, I made this entire project before I had a clear idea of what exactly I would be doing with it. This is not a hobby for people who are entirely pragmatically minded.) I configured a certain button to turn white when the lights were on, and return to its original color when the lights were off. A different button actually toggled the lights on and off. The more buttons that do more things, the more authentic it feels to me. And this panel has more buttons than I have lights in my house. One of the gauges both reflects and controls the brightness of those lamps. There are status buttons that show me whether my home’s operating mode is “normal” or “cozy,” which determines the lighting scenes in my extensive WLED setup. Still not quite perfect. But gosh do I love it. The touchscreen with the panel rests on a stand near my couch. It’s not remotely practical. We already knew that about LCARS. However, it is beautiful. And it makes my nerd heart extremely happy that I can now control my house the way my childhood heroes controlled their starships. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Ursa Wright Entertainment Smart Home Star Trek Tech TV Shows",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/GettyImages-454259088.jpg?quality=90&strip=all&crop=0%2C15.095986038394%2C100%2C69.808027923211&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "GuliKit’s tiny dongle lets you connect a PS5 controller to your Switch 2",
      "url": "https://www.theverge.com/tech/874842/gulikit-hyperlink-gen2-usb-adapter-wireless-switch-2-hands-on",
      "published": "2026-02-08T15:00:00+00:00",
      "summary": "Dongles have a well-earned reputation for being a nuisance. They're often costly and annoying to deal with, but for gamers, there's one that I love to recommend that's neither. 8BitDo's $20 USB Adapter 2 lets you wirelessly link controllers to the Switch 2 that would otherwise be unsupported, like the Sony DualSense (complete with rumble [&#8230;]",
      "content_text": "Dongles have a well-earned reputation for being a nuisance. They’re often costly and annoying to deal with, but for gamers, there’s one that I love to recommend that’s neither. 8BitDo’s $20 USB Adapter 2 lets you wirelessly link controllers to the Switch 2 that would otherwise be unsupported, like the Sony DualSense (complete with rumble and motion controls), Microsoft’s latest Xbox gamepads, and more. You can plug it into the Switch 2’s dock or use a USB-A-to-USB-C adapter to connect it directly to the console. It’s great to save money, since I can simply use a controller that I already own instead of buying a new one. And I sometimes forget that I’m using a PS5 controller in games like Splatoon 3 because its motion controls feel just as accurate as a controller made for the Switch. There’s another similar dongle available that’s a smidge cheaper and a lot smaller. The GuliKit Hyperlink Gen 2 USB-A adapter comes included with the company’s TT Pro and TT Max controllers, or you can buy it alone for $16.99 at Amazon . It’s compatible with Xbox controllers and PlayStation 4 and 5 controllers. Similarly, you can plug it into a Nintendo Switch 2, a PC, a Steam Deck or other handheld PCs, and Android devices. But GuliKit’s list of supported controllers isn’t as extensive as 8BitDo, which dates back to the PS3 and Wii era and also includes its fleet of wireless controllers. Nice as this is, there are some features neither dongle offers: remote console wake-up (you first have to turn on the console manually to pair the controller) or wireless audio (the 3.5mm headphone jacks in the DualSense and Xbox controllers are useless when paired to either). Lastly, you can only connect one controller at a time to each dongle (you’ll need to buy two in order to pair a second controller). I don’t think any of those are deal-breakers, but they’re worth knowing before you buy one. Then there are things that only 8BitDo’s dongle can do. For one, you can customize the heck out of several non-8BitDo controller models with its free Ultimate Software, including button remapping, macros, vibration intensity, trigger range, and stick sensitivity. Currently, GuliKit offers no such software, although its PR manager, Olivia Chen, told me that the company aims to release Android and iOS apps with similar functionality in Q2 2026. Also, the 8BitDo model lets you input button combinations that trigger different connection modes, including Xinput, Dinput, Mac mode, and Switch mode. As for what the GuliKit has going for it, the rumble in some games (namely Hollow Knight: Silksong , the game I’ve been playing the most recently) feels more like the HD rumble offered in good Switch controllers, like the EasySMX S10. The 8BitDo, by comparison, makes this game’s rumble feel like an afterthought. However, other games are a toss-up on which dongle offers a better-feeling rumble effect. Donkey Kong Bananza ’s intense rumble for even the slightest of movements feels like garbage on the DualSense, no matter the dongle it’s connected to. If you ask GuliKit, the Hyperlink Gen 2’s biggest feature is its PC-exclusive low-latency wireless connection. It can boost controller polling rate (or how quickly your controller inputs are sent to the gaming device) beyond what consoles are capable of, and it’s supposed to also reduce input latency. The improved latency didn’t have as pronounced of an impact as I had hoped, although I enjoyed the easy setup and improved connection overall — something that both dongles (and countless Bluetooth dongles made for PC) can offer. For some, buying a new controller that’s guaranteed to work well with your Switch 2 is worth an added cost. If that’s you, allow me to direct your attention to my buying guide full of good yet relatively affordable Switch 2 controllers . But if you’re keen on repurposing hardware that you already have, these low-cost dongles make a lot of sense to try. Photography by Cameron Faulkner / The Verge",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/P2060751.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "RFC 3092 - Etymology of \"Foo\"",
      "url": "https://datatracker.ietf.org/doc/html/rfc3092",
      "published": "2026-02-08T14:32:28+00:00",
      "summary": "<p>Article URL: <a href=\"https://datatracker.ietf.org/doc/html/rfc3092\">https://datatracker.ietf.org/doc/html/rfc3092</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46934499\">https://news.ycombinator.com/item?id=46934499</a></p> <p>Points: 36</p> <p># Comments: 7</p>",
      "content_text": "Network Working Group D. Eastlake 3rd Request for Comments: 3092 Motorola Category: Informational C. Manros Xerox E. Raymond Open Source Initiative 1 April 2001 Etymology of \"Foo\" Status of this Memo This memo provides information for the Internet community. It does not specify an Internet standard of any kind. Distribution of this memo is unlimited. Copyright Notice Copyright (C) The Internet Society (2001). All Rights Reserved. Abstract Approximately 212 RFCs so far, starting with RFC 269 , contain the terms `foo', `bar', or `foobar' as metasyntactic variables without any proper explanation or definition. This document rectifies that deficiency. Table of Contents 1 . Introduction............................................ 1 2 . Definition and Etymology................................ 2 3 . Acronyms................................................ 5 Appendix................................................... 7 Security Considerations................................... 11 References................................................ 12 Authors' Addresses........................................ 13 Full Copyright Statement.................................. 14 1 . Introduction Approximately 212 RFCs, or about 7% of RFCs issued so far, starting with [ RFC269 ], contain the terms `foo', `bar', or `foobar' used as a metasyntactic variable without any proper explanation or definition. This may seem trivial, but a number of newcomers, especially if English is not their native language, have had problems in understanding the origin of those terms. This document rectifies that deficiency. Eastlake, et al. Informational [Page 1] RFC 3092 Etymology of \"Foo\" 1 April 2001 Section 2 below describes the definition and etymology of these words and Section 3 interprets them as acronyms. As an Appendix, we include a table of RFC occurrences of these words as metasyntactic variables. 2 . Definition and Etymology bar /bar/ n. [ JARGON ] 1. The second metasyntactic variable, after foo and before baz. \"Suppose we have two functions: FOO and BAR. FOO calls BAR....\" 2. Often appended to foo to produce foobar. foo /foo/ 1. interj. Term of disgust. 2. Used very generally as a sample name for absolutely anything, esp. programs and files (esp. scratch files). 3. First on the standard list of metasyntactic variables used in syntax examples (bar, baz, qux, quux, corge, grault, garply, waldo, fred, plugh, xyzzy, thud). [ JARGON ] When used in connection with `bar' it is generally traced to the WW II era Army slang acronym FUBAR (`Fucked Up Beyond All Repair'), later modified to foobar. Early versions of the Jargon File [ JARGON ] interpreted this change as a post-war bowdlerization, but it now seems more likely that FUBAR was itself a derivative of `foo' perhaps influenced by German `furchtbar' (terrible) - `foobar' may actually have been the original form. For, it seems, the word `foo' itself had an immediate prewar history in comic strips and cartoons. In the 1938 Warner Brothers cartoon directed by Robert Clampett, \"The Daffy Doc\", a very early version of Daffy Duck holds up a sign saying \"SILENCE IS FOO!\" `FOO' and `BAR' also occurred in Walt Kelly's \"Pogo\" strips. The earliest documented uses were in the surrealist \"Smokey Stover\" comic strip by Bill Holman about a fireman. This comic strip appeared in various American comics including \"Everybody's\" between about 1930 and 1952. It frequently included the word \"FOO\" on license plates of cars, in nonsense sayings in the background of some frames such as \"He who foos last foos best\" or \"Many smoke but foo men chew\", and had Smokey say \"Where there's foo, there's fire\". Bill Holman, the author of the strip, filled it with odd jokes and personal contrivances, including other Eastlake, et al. Informational [Page 2] RFC 3092 Etymology of \"Foo\" 1 April 2001 nonsense phrases such as \"Notary Sojac\" and \"1506 nix nix\". According to the Warner Brothers Cartoon Companion [ WBCC ] Holman claimed to have found the word \"foo\" on the bottom of a Chinese figurine. This is plausible; Chinese statuettes often have apotropaic inscriptions, and this may have been the Chinese word `fu' (sometimes transliterated `foo'), which can mean \"happiness\" when spoken with the proper tone (the lion-dog guardians flanking the steps of many Chinese restaurants are properly called \"fu dogs\") [ PERS ]. English speakers' reception of Holman's `foo' nonsense word was undoubtedly influenced by Yiddish `feh' and English `fooey' and `fool'. [ JARGON , FOLDOC ] Holman's strip featured a firetruck called the Foomobile that rode on two wheels. The comic strip was tremendously popular in the late 1930s, and legend has it that a manufacturer in Indiana even produced an operable version of Holman's Foomobile. According to the Encyclopedia of American Comics [ EAC ], `Foo' fever swept the U.S., finding its way into popular songs and generating over 500 `Foo Clubs.' The fad left `foo' references embedded in popular culture (including the couple of appearances in Warner Brothers cartoons of 1938-39) but with their origins rapidly forgotten. [ JARGON ] One place they are known to have remained live is in the U.S. military during the WWII years. In 1944-45, the term `foo fighters' [ FF ] was in use by radar operators for the kind of mysterious or spurious trace that would later be called a UFO (the older term resurfaced in popular American usage in 1995 via the name of one of the better grunge-rock bands [ BFF ]). Informants connected the term to the Smokey Stover strip [ PERS ]. The U.S. and British militaries frequently swapped slang terms during the war. Period sources reported that `FOO' became a semi-legendary subject of WWII British-army graffiti more or less equivalent to the American Kilroy [ WORDS ]. Where British troops went, the graffito \"FOO was here\" or something similar showed up. Several slang dictionaries aver that FOO probably came from Forward Observation Officer, but this (like the contemporaneous \"FUBAR\") was probably a backronym [ JARGON ]. Forty years later, Paul Dickson's excellent book \"Words\" [ WORDS ] traced \"Foo\" to an unspecified British naval magazine in 1946, quoting as follows: \"Mr. Foo is a mysterious Second World War product, gifted with bitter omniscience and sarcasm.\" Earlier versions of the Jargon File suggested the possibility that hacker usage actually sprang from \"FOO, Lampoons and Parody\", the title of a comic book first issued in September 1958, a joint Eastlake, et al. Informational [Page 3] RFC 3092 Etymology of \"Foo\" 1 April 2001 project of Charles and Robert Crumb. Though Robert Crumb (then in his mid-teens) later became one of the most important and influential artists in underground comics, this venture was hardly a success; indeed, the brothers later burned most of the existing copies in disgust. The title FOO was featured in large letters on the front cover. However, very few copies of this comic actually circulated, and students of Crumb's `oeuvre' have established that this title was a reference to the earlier Smokey Stover comics. The Crumbs may also have been influenced by a short-lived Canadian parody magazine named `Foo' published in 1951-52. [ JARGON ] An old-time member reports that in the 1959 \"Dictionary of the TMRC Language\", compiled at TMRC (the Tech Model Railroad Club at MIT) there was an entry for Foo. The current on-line version, in which \"Foo\" is the only word coded to appear red, has the following [ TMRC ]: Foo: The sacred syllable (FOO MANI PADME HUM); to be spoken only when under obligation to commune with the Deity. Our first obligation is to keep the Foo Counters turning. This definition used Bill Holman's nonsense word, then only two decades old and demonstrably still live in popular culture and slang, to make a \"ha ha only serious\" analogy with esoteric Tibetan Buddhism. Today's hackers would find it difficult to resist elaborating a joke like that, and it is not likely 1959's were any less susceptible. [ JARGON ] 4. [ EF ] Prince Foo was the last ruler of Pheebor and owner of the Phee Helm, about 400 years before the reign of Entharion. When Foo was beheaded by someone he called an \"eastern fop\" from Borphee, the glorious age of Pheebor ended, and Borphee rose to the prominence it now enjoys. 5. [ OED ] A 13th-16th century usage for the devil or any other enemy. The earliest citation it gives is from the year 1366, Chaucer A B C (84): \"Lat not our alder foo [devil] make his bobance [boast]\". Chaucer's \"Foo\" is probably related to modern English \"foe\". 6. Rare species of dog. A spitz-type dog discovered to exist after having long been considered extinct, the Chinese Foo Dog, or Sacred Dog of Sinkiang, may have originated through a crossing of Northern European hunting dogs and the ancient Chow Chow from Mongolia or be the missing link between the Chinese Wolf and the Chow Chow. It probably derives its name from foochow, of the kind or style Eastlake, et al. Informational [Page 4] RFC 3092 Etymology of \"Foo\" 1 April 2001 prevalent in Foochow, of or from the city of Foochow (now Minhow) in southeast China. [ DOG ] foobar n. [ JARGON ] A widely used metasyntactic variable; see foo for etymology. Probably originally propagated through DECsystem manuals by Digital Equipment Corporation (DEC) in 1960s and early 1970s; confirmed sightings there go back to 1972. Hackers do not generally use this to mean FUBAR in either the slang or jargon sense. It has been plausibly suggested that \"foobar\" spread among early computer engineers partly because of FUBAR and partly because \"foo bar\" parses in electronics techspeak as an inverted foo signal. foo-fighter n. World War II term for Unidentified Flying Objects (UFOs) noted by both German and British military. See [ FF ] and entry above for \"foo\". 3 . Acronyms The following information is derived primarily from the compilations at University Cork College < http://www.ucc.ie/acronyms > and Acronym Finder < http://www.AcronymFinder.com > generally filtered for computer usage. .bar: Generic file extension which is not meant to imply anything about the file type. BAR: Base Address Register Buffer Address Register FOO: Forward Observation Observer. FOO Of Oberlin. An organization whose name is a recursive acronym. Motto: The FOO, the Proud, the FOO. See < http://cs.oberlin.edu/students/jmankoff/FOO/home.html >. File Open for Output. An NFILE error code [ RFC1037 ]. Eastlake, et al. Informational [Page 5] RFC 3092 Etymology of \"Foo\" 1 April 2001 FOOBAR: FTP Operation Over Big Address Records [ RFC1639 ]. (Particularly appropriate given that the first RFC to use \"foo\", [ RFC269 ], was also about file transfer.) FUBAR: Failed UniBus Address Register - in a VAX, from Digital Equipment Corporation Engineering. Fucked Up Beyond All Recognition/Repair - From US Military in World War II. Sometimes sanitized to \"Fouled Up ...\". FUBARD - Past tense of FUBAR. Eastlake, et al. Informational [Page 6] RFC 3092 Etymology of \"Foo\" 1 April 2001 Appendix Below is a table of RFC occurrences of these words as metasyntactic variables. (This excludes other uses that are reasonably clear like \"vertical bar\" or \"bar BoF\".) Many of these uses are for example domain names. That usage may decrease with the specification in [RFC 2606] of a Best Current Practice for example domain names. +------+-----+-----+---------+-------+-----+ | RFC# | bar | foo | foo.bar | fubar | # | | | | | foobar | | | +------+-----+-----+---------+-------+-----+ | 269 | X | X | | | 1 | | 441 | X | X | | | 2 | | 614 | | X | | | 3 | | 686 | | X | | | 4 | | 691 | | X | | | 5 | | 733 | X | X | | | 6 | | 742 | | X | | | 7 | | 743 | X | X | | | 8 | | 756 | | X | | | 9 | | 765 | X | X | | | 10 | | 772 | X | X | | X | 11 | | 775 | | | X | | 12 | | 780 | X | X | | X | 13 | | 788 | X | X | | | 14 | | 810 | X | X | X | | 15 | | 819 | | X | | | 16 | | 821 | X | X | | | 17 | | 822 | X | X | | | 18 | | 882 | X | X | | | 19 | | 883 | | X | | | 20 | | 897 | X | X | | | 21 | | 913 | | X | | | 22 | | 921 | X | X | | | 23 | | 934 | | X | | | 24 | | 952 | X | X | X | | 25 | | 959 | | | X | | 26 | | 976 | | | X | | 27 | | 977 | | X | X | | 28 | | 987 | | | X | | 29 | | 1013 | | X | | | 30 | | 1033 | X | X | | | 31 | | 1035 | | X | | | 32 | | 1037 | | X | | | 33 | | 1056 | X | X | X | | 34 | | 1068 | | X | | | 35 | | 1137 | | | X | | 36 | Eastlake, et al. Informational [Page 7] RFC 3092 Etymology of \"Foo\" 1 April 2001 | 1138 | | X | X | | 37 | | 1148 | | X | X | | 38 | | 1173 | | | X | | 39 | | 1176 | | | X | | 40 | | 1186 | | X | | | 41 | | 1194 | | X | | | 42 | | 1196 | | X | | | 43 | | 1203 | | X | X | | 44 | | 1288 | | X | | | 45 | | 1291 | | X | | | 46 | | 1309 | | X | | | 47 | | 1327 | | X | X | | 48 | | 1341 | X | X | X | | 49 | | 1343 | | X | X | | 50 | | 1344 | | X | | | 51 | | 1348 | | | X | | 52 | | 1386 | | X | | | 53 | | 1408 | | X | | | 54 | | 1411 | | X | | | 55 | | 1412 | | X | | | 56 | | 1459 | X | X | X | X | 57 | | 1480 | | X | | | 58 | | 1505 | | X | | | 59 | | 1519 | | X | | | 60 | | 1521 | X | X | | | 61 | | 1523 | | X | | | 62 | | 1524 | | X | X | | 63 | | 1526 | X | X | | | 64 | | 1535 | X | X | X | | 65 | | 1536 | X | | X | | 66 | | 1537 | | X | X | | 67 | | 1563 | | X | | | 68 | | 1564 | | | X | | 69 | | 1572 | | X | | | 70 | | 1573 | | X | | | 71 | | 1622 | | X | | | 72 | | 1635 | | | X | | 73 | | 1636 | | X | X | | 74 | | 1642 | | X | | | 75 | | 1645 | | | X | | 76 | | 1649 | | X | | | 77 | | 1664 | | | X | | 78 | | 1681 | | | X | | 79 | | 1697 | | X | | | 80 | | 1716 | | X | | | 81 | | 1718 | | X | | | 82 | | 1730 | X | X | X | | 83 | | 1734 | | | X | | 84 | Eastlake, et al. Informational [Page 8] RFC 3092 Etymology of \"Foo\" 1 April 2001 | 1738 | | X | | | 85 | | 1783 | | | X | | 86 | | 1784 | | | X | | 87 | | 1786 | X | X | | | 88 | | 1813 | X | X | | | 89 | | 1835 | | X | X | | 90 | | 1856 | | | X | | 91 | | 1861 | | | X | | 92 | | 1866 | | X | | | 93 | | 1894 | | | X | | 94 | | 1896 | | X | | | 95 | | 1898 | | X | | | 96 | | 1913 | | X | X | | 97 | | 1945 | X | X | | | 98 | | 1985 | | X | X | | 99 | | 2015 | X | X | | | 100 | | 2017 | | X | | | 101 | | 2033 | X | X | | | 102 | | 2045 | | | X | | 103 | | 2046 | X | X | | | 104 | | 2049 | X | X | | | 105 | | 2055 | | X | | | 106 | | 2060 | X | X | X | | 107 | | 2065 | | X | | | 108 | | 2068 | | | X | | 109 | | 2071 | | X | | | 110 | | 2088 | | | X | | 111 | | 2109 | | X | | | 112 | | 2110 | | X | X | | 113 | | 2111 | X | X | X | | 114 | | 2141 | | X | | | 115 | | 2150 | | X | | | 116 | | 2152 | | X | | | 117 | | 2156 | | X | X | | 118 | | 2163 | | | X | | 119 | | 2167 | | | X | | 120 | | 2168 | | | X | | 121 | | 2169 | | | X | | 122 | | 2180 | X | X | | | 123 | | 2193 | X | X | | | 124 | | 2224 | | X | | | 125 | | 2227 | X | X | | | 126 | | 2233 | | X | | | 127 | | 2234 | X | X | X | | 128 | | 2243 | | X | | | 129 | | 2255 | | X | X | | 130 | | 2280 | X | X | | | 131 | | 2295 | | X | | | 132 | Eastlake, et al. Informational [Page 9] RFC 3092 Etymology of \"Foo\" 1 April 2001 | 2302 | | X | | | 133 | | 2311 | X | | | | 134 | | 2326 | X | X | X | | 135 | | 2342 | | X | | | 136 | | 2348 | | | X | | 137 | | 2349 | | | X | | 138 | | 2359 | | | X | | 139 | | 2369 | X | X | X | | 140 | | 2378 | | X | | | 141 | | 2384 | | | X | | 142 | | 2392 | X | X | X | | 143 | | 2396 | | | X | | 144 | | 2401 | | | X | | 145 | | 2407 | | | X | | 146 | | 2421 | | X | | | 147 | | 2425 | | | X | | 148 | | 2434 | | X | | | 149 | | 2446 | | X | X | | 150 | | 2447 | X | X | | | 151 | | 2458 | | X | X | | 152 | | 2459 | | | X | | 153 | | 2476 | | X | | | 154 | | 2483 | X | X | | | 155 | | 2486 | | X | | | 156 | | 2505 | X | X | | | 157 | | 2518 | X | X | X | | 158 | | 2535 | | X | | | 159 | | 2538 | | X | | | 160 | | 2543 | X | X | X | | 161 | | 2554 | | | X | | 162 | | 2557 | | X | X | | 163 | | 2565 | | X | X | | 164 | | 2569 | X | X | | | 165 | | 2593 | X | X | | | 166 | | 2595 | | X | | | 167 | | 2608 | | X | | | 168 | | 2609 | | X | | | 169 | ",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "AI fatigue is real and nobody talks about it",
      "url": "https://siddhantkhare.com/writing/ai-fatigue-is-real",
      "published": "2026-02-08T14:19:32+00:00",
      "summary": "<p>Article URL: <a href=\"https://siddhantkhare.com/writing/ai-fatigue-is-real\">https://siddhantkhare.com/writing/ai-fatigue-is-real</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46934404\">https://news.ycombinator.com/item?id=46934404</a></p> <p>Points: 242</p> <p># Comments: 188</p>",
      "content_text": "I shipped more code last quarter than any quarter in my career. I also felt more drained than any quarter in my career. These two facts are not unrelated. I build AI agent infrastructure for a living. I'm one of the core maintainers of OpenFGA (CNCF Incubating), I built agentic-authz for agent authorization, I built Distill for context deduplication, I shipped MCP servers. I'm not someone who dabbles with AI on the side. I'm deep in it. I build the tools that other engineers use to make AI agents work in production. And yet, I hit a wall. The kind of exhaustion that no amount of tooling or workflow optimization could fix. If you're an engineer who uses AI daily - for design reviews, code generation, debugging, documentation, architecture decisions - and you've noticed that you're somehow more tired than before AI existed, this post is for you. You're not imagining it. You're not weak. You're experiencing something real that the industry is aggressively pretending doesn't exist. And if someone who builds agent infrastructure full-time can burn out on AI, it can happen to anyone. I want to talk about it honestly. Not the \"AI is amazing and here's my workflow\" version. The real version. The one where you stare at your screen at 11pm, surrounded by AI-generated code you still need to review, wondering why the tool that was supposed to save you time has consumed your entire day. The paradox nobody warned us about Here's the thing that broke my brain for a while: AI genuinely makes individual tasks faster. That's not a lie. What used to take me 3 hours now takes 45 minutes. Drafting a design doc, scaffolding a new service, writing test cases, researching an unfamiliar API. All faster. But my days got harder. Not easier. Harder. The reason is simple once you see it, but it took me months to figure out. When each task takes less time, you don't do fewer tasks. You do more tasks. Your capacity appears to expand, so the work expands to fill it. And then some. Your manager sees you shipping faster, so the expectations adjust. You see yourself shipping faster, so your own expectations adjust. The baseline moves. Before AI, I might spend a full day on one design problem. I'd sketch on paper, think in the shower, go for a walk, come back with clarity. The pace was slow but the cognitive load was manageable. One problem. One day. Deep focus. Now? I might touch six different problems in a day. Each one \"only takes an hour with AI.\" But context-switching between six problems is brutally expensive for the human brain. The AI doesn't get tired between problems. I do. This is the paradox: AI reduces the cost of production but increases the cost of coordination, review, and decision-making. And those costs fall entirely on the human. You became a reviewer and you didn't sign up for it Before AI, my job was: think about a problem, write code, test it, ship it. I was the creator. The maker. That's what drew most of us to engineering in the first place - the act of building. After AI, my job increasingly became: prompt, wait, read output, evaluate output, decide if output is correct, decide if output is safe, decide if output matches the architecture, fix the parts that don't, re-prompt, repeat. I became a reviewer. A judge. A quality inspector on an assembly line that never stops. This is a fundamentally different kind of work. Creating is energizing. Reviewing is draining. There's research on this - the psychological difference between generative tasks and evaluative tasks. Generative work gives you flow states. Evaluative work gives you decision fatigue. I noticed it first during a week where I was using AI heavily for a new microservice. By Wednesday, I couldn't make simple decisions anymore. What should this function be named? I didn't care. Where should this config live? I didn't care. My brain was full. Not from writing code - from judging code. Hundreds of small judgments, all day, every day. The cruel irony is that AI-generated code requires more careful review than human-written code. When a colleague writes code, I know their patterns, their strengths, their blind spots. I can skim the parts I trust and focus on the parts I don't. With AI, every line is suspect. The code looks confident. It compiles. It might even pass tests. But it could be subtly wrong in ways that only surface in production, under load, at 3am. So you read every line. And reading code you didn't write, that was generated by a system that doesn't understand your codebase's history or your team's conventions, is exhausting work. This is also why I think agent security and authorization matter so much. If we can't review everything AI produces - and we can't, not at scale - then we need systems that constrain what agents can do in the first place. Least-privilege access, scoped tokens, audit trails. The less you have to worry about \"did the AI do something dangerous,\" the more cognitive budget you have for the work that actually matters. This isn't just a security problem. It's a human sustainability problem. The nondeterminism problem Engineers are trained on determinism. Same input, same output. That's the contract. That's what makes debugging possible. That's what makes reasoning about systems possible. AI broke that contract. I had a prompt that worked perfectly on Monday. Generated clean, well-structured code for an API endpoint. I used the same prompt on Tuesday for a similar endpoint. The output was structurally different, used a different error handling pattern, and introduced a dependency I didn't ask for. Why? No reason. Or rather, no reason I can access. There's no stack trace for \"the model decided to go a different direction today.\" There's no log that says \"temperature sampling chose path B instead of path A.\" It just... happened differently. For someone whose entire career is built on \"if it broke, I can find out why,\" this is deeply unsettling. Not in a dramatic way. In a slow, grinding, background-anxiety way. You can never fully trust the output. You can never fully relax. Every interaction requires vigilance. I tried to fight this. I version-controlled my prompts. I built elaborate system messages. I created templates. Some of it helped. None of it solved the fundamental problem: you are collaborating with a probabilistic system, and your brain is wired for deterministic ones. That mismatch is a constant, low-grade source of stress. This frustration is actually what led me to build Distill - deterministic context deduplication for LLMs. No LLM calls, no embeddings, no probabilistic heuristics. Pure algorithms that clean your context in ~12ms. I wanted at least one part of the AI pipeline to be something I could reason about, debug, and trust. If the model's output is going to be nondeterministic, the least I can do is make sure the input is clean and predictable. The engineers I've talked to who handle this best are the ones who've made peace with it. They treat AI output like a first draft from a smart but unreliable intern. They expect to rewrite 30% of it. They budget time for that rewriting. They don't get frustrated when the output is wrong because they never expected it to be right. They expected it to be useful. There's a difference. The FOMO treadmill Take a breath and try to keep up with just the last few months. Claude Code ships sub-agents, then skills, then an Agent SDK, then Claude Cowork. OpenAI launches Codex CLI, then GPT-5.3-Codex - a model that literally helped code itself. New coding agents announce background mode with hundreds of concurrent autonomous sessions. Google drops Gemini CLI. GitHub adds an MCP Registry. Acquisitions happen weekly. Amazon Q Developer gets agentic upgrades. CrewAI, AutoGen, LangGraph, MetaGPT - pick your agent framework, there's a new one every week. Google announces A2A (Agent-to-Agent protocol) to compete with Anthropic's MCP. OpenAI ships its own Swarm framework. Kimi K2.5 drops with agent swarm architecture orchestrating 100 parallel agents. \"Vibe coding\" becomes a thing. OpenClaw launches a skills marketplace and within one week, researchers find 400+ malicious agent skills uploaded to ClawHub. And somewhere in the middle of all this, someone on LinkedIn posts \"if you're not using AI agents with sub-agent orchestration in 2026, you're already obsolete.\" That's not a year. That's a few months. And I'm leaving stuff out. I fell into this trap hard. I was spending weekends evaluating new tools. Reading every changelog. Watching every demo. Trying to stay at the frontier because I was terrified of falling behind. Here's what that actually looked like: I'd spend Saturday afternoon setting up a new AI coding tool. By Sunday I'd have a basic workflow. By the following Wednesday, someone would post about a different tool that was \"way better.\" I'd feel a pang of anxiety. By the next weekend, I'd be setting up the new thing. The old thing would sit unused. One coding assistant to the next to the next and back to the first one. Each migration cost me a weekend and gave me maybe a 5% improvement that I couldn't even measure properly. Multiply this by every category - coding assistants, chat interfaces, agent frameworks, multi-agent orchestration platforms, MCP servers, context management tools, prompt libraries, swarm architectures, skills marketplaces - and you get a person who is perpetually learning new tools and never getting deep with any of them. The Hacker News front page alone is enough to give you whiplash. One day it's \"Show HN: Autonomous Research Swarm\" and the next it's \"Ask HN: How will AI swarms coordinate?\" Nobody knows. Everyone's building anyway. The worst part is the knowledge decay. I spent two weeks building a sophisticated prompt engineering workflow in early 2025. Carefully crafted system prompts, few-shot examples, chain-of-thought templates. It worked well. Three months later, the model updated, the prompting best practices shifted, and half my templates produced worse results than a simple one-liner. Those two weeks were gone. Not invested. Spent. The same thing happened with my MCP server setup - I built five custom servers (Dev.to publisher, Apple Notes integration, Python and TypeScript sandboxes, more), then the protocol evolved, then the MCP Registry launched on GitHub and suddenly there were thousands of pre-built ones. Some of my custom work became redundant overnight. The agent framework churn is even worse. I watched teams go from LangChain to CrewAI to AutoGen to custom orchestration in the span of a year. Each migration meant rewriting integrations, relearning APIs, rebuilding workflows. The people who waited and did nothing often ended up in a better position than the people who adopted early and had to migrate twice. I've since adopted a different approach. Instead of chasing every new tool, I go deep on the infrastructure layer underneath them. Tools come and go. The problems they solve don't. Context efficiency, agent authorization, audit trails, runtime security - these are durable problems regardless of which framework is trending this month. That's why I built agentic-authz on OpenFGA instead of tying it to any specific agent framework. That's why Distill works at the context level, not the prompt level. Build on the layer that doesn't churn. I still track the landscape closely - you have to when you're building infrastructure for it. But I track it to understand where the ecosystem is going, not to adopt every new thing. There's a difference between being informed and being reactive. The \"just one more prompt\" trap This one is insidious. You're trying to get AI to generate something specific. The first output is 70% right. So you refine your prompt. The second output is 75% right but broke something the first one had correct. Third attempt: 80% right but now the structure is different. Fourth attempt: you've been at this for 45 minutes and you could have written the thing from scratch in 20. I call this the prompt spiral. It's the AI equivalent of yak shaving. You started with a clear goal. Thirty minutes later you're debugging your prompt instead of debugging your code. You're optimizing your instructions to a language model instead of solving the actual problem. The prompt spiral is especially dangerous because it feels productive. You're iterating. You're getting closer. Each attempt is slightly better. But the marginal returns are diminishing fast, and you've lost sight of the fact that the goal was never \"get the AI to produce perfect output.\" The goal was to ship the feature. I now have a hard rule: three attempts. If the AI doesn't get me to 70% usable in three prompts, I write it myself. No exceptions. This single rule has saved me more time than any prompting technique I've ever learned. Perfectionism meets probabilistic output Engineers tend toward perfectionism. We like clean code. We like tests that pass. We like systems that behave predictably. This is a feature, not a bug - it's what makes us good at building reliable software. AI output is never perfect. It's always \"pretty good.\" 70-80% there. The variable names are slightly off. The error handling is incomplete. The edge cases are ignored. The abstraction is wrong for your codebase. It works, but it's not right. For a perfectionist, this is torture. Because \"almost right\" is worse than \"completely wrong.\" Completely wrong, you throw away and start over. Almost right, you spend an hour tweaking. And tweaking AI output is uniquely frustrating because you're fixing someone else's design decisions - decisions that were made by a system that doesn't share your taste, your context, or your standards. I had to learn to let go. Not of quality - I still care about quality. But of the expectation that AI would produce quality. I now treat every AI output as a rough draft. A starting point. Raw material. I mentally label it \"draft\" the moment it appears, and that framing change alone reduced my frustration by half. The engineers who struggle most with AI are often the best engineers. The ones with the highest standards. The ones who notice every imperfection. AI rewards a different skill: the ability to extract value from imperfect output quickly, without getting emotionally invested in making it perfect. The thinking atrophy This is the one that scares me most. I noticed it during a design review meeting. Someone asked me to reason through a concurrency problem on the whiteboard. No laptop. No AI. Just me and a marker. And I struggled. Not because I didn't know the concepts - I did. But because I hadn't exercised that muscle in months. I'd been outsourcing my first-draft thinking to AI for so long that my ability to think from scratch had degraded. It's like GPS and navigation. Before GPS, you built mental maps. You knew your city. You could reason about routes. After years of GPS, you can't navigate without it. The skill atrophied because you stopped using it. The same thing is happening with AI and engineering thinking. When you always ask AI first, you stop building the neural pathways that come from struggling with a problem yourself. The struggle is where learning happens. The confusion is where understanding forms. Skip that, and you get faster output but shallower understanding. I now deliberately spend the first hour of my day without AI. I think on paper. I sketch architectures by hand. I reason through problems the slow way. It feels inefficient. It is inefficient. But it keeps my thinking sharp, and that sharpness pays dividends for the rest of the day when I do use AI - because I can evaluate its output better when my own reasoning is warmed up. The comparison trap Social media is full of people who seem to have AI figured out. They post their workflows. Their productivity numbers. Their \"I built this entire app in 2 hours with AI\" threads. And you look at your own experience - the failed prompts, the wasted time, the code you had to rewrite - and you think: what's ",
      "cover_image_url": "https://siddhantkhare.com/api/og?title=AI+fatigue+is+real+and+nobody+talks+about+it&description=You%27re+using+AI+to+be+more+productive.+So+why+are+you+more+exhausted+than+ever%3F+The+paradox+every+engineer+needs+to+confront.&tags=ai%2Cmental-health%2Cengineering%2Cpersonal&date=2026-02-08&readingTime=16"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "I Am Happier Writing Code by Hand",
      "url": "https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/",
      "published": "2026-02-08T14:12:18+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/\">https://www.abhinavomprakash.com/posts/i-am-happier-writing-code-by-hand/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46934344\">https://news.ycombinator.com/item?id=46934344</a></p> <p>Points: 181</p> <p># Comments: 121</p>",
      "content_text": "I felt the familiar feeling of depression and lethargy creep in while my eyes darted from watching claude-code work and my phone. “What’s the point of it all?” I thought, LLMs can generate decent-ish and correct-ish looking code while I have more time to do what? doomscroll? This was the third time I gave claude-code a try. I felt the same feelings every single time and ended up deleting claude-code after 2-3 weeks, and whaddyouknow? Every. Single. Time. I rediscovered the joy of coding. Yes, coding is not software engineering, but for me, it is a fun and essential part of it. In order to be effective at software engineering, you must be familiar with the problem space, and this requires thinking and wrestling with the problem. You can’t truly know the pain of using an API by just reading its documentation or implementation. You have to use it to experience it. The act of writing code, despite being slower, was a way for me to wrestle with the problem space, a way for me to find out that my initial ideas didn’t work, a way for thinking. Vibe coding interfered with that. If you’re thinking without writing, you only think you’re thinking. – Leslie Lamport The other major part of the job is to ensure correctness. For me, it is much harder to verify the correctness of code I didn’t write compared to code I wrote. The process of writing code helps internalize the context and is easier for my brain to think deeply about it. If I outsource this to an LLM, I skip over the process of internalizing the problem domain and I can’t be certain that the generated code is correct. By design, vibe coding has an addictive nature to it, you write some instructions, and code that looks correct is generated. Bam! Dopamine hit! If the code isn’t correct, then it’s just one prompt away from being correct, right? right? Vibe coding also has the profound effect of turning my brain off and passively accepting changes. When it is time to use my brain, the inertia is much harder to overcome and it is easy to choose the lazy way out. At my lowest point, I even asked it to do a find-and-replace in a file. Something that takes a few seconds, now took minutes and a network call. Even if I generate a 1,000 line PR in 30 minutes I still need to understand and review it. Since I am responsible for the code I ship, this makes me the bottleneck. The common view of vibe coding is that it is neither good nor bad, it is a tool. But tools shape your workflow and your thought process, and if a tool prevents you from thinking deeply, I don’t think it is a good tool. If you are a knowledge worker, your core competency is your ability to think, and if a tool interferes with that, be afraid, be very afraid. Now, I would be lying if I said I didn’t use LLMs to generate code. I still use Claude, but I do so in a more controlled manner. I copy-paste files that I think are necessary to provide the context, and then I copy-paste code and ask it to make changes to it or write tests for it. This friction has several benefits. I can’t make changes that span multiple files, this means the generated diff isn’t too large, and if I have to manually change other files I know how the code fits in. Manually giving claude the context forces me to be familiar with the codebase myself, rather than tell it to just “cook”. It turns code generation from a passive action to a deliberate thoughtful action. It also keeps my brain engaged and active, which means I can still enter the flow state . I have found this to be the best of both worlds and a way to preserve my happiness at work. Ultimately, life is too short to not optimize for happiness. Maybe (a big maybe) generating entire features would make me more productive, but if it causes existential dread and makes me depressed, I don’t see it being productive in the long run. Maybe you relate to some of the feelings. Maybe you don’t. But don’t be afraid to choose differently.",
      "cover_image_url": "https://abhinavomprakash.com/%3Clink%20or%20path%20of%20image%20for%20opengraph,%20twitter-cards%3E"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Running Your Own AS: BGP on FreeBSD with FRR, GRE Tunnels, and Policy Routing",
      "url": "https://blog.hofstede.it/running-your-own-as-bgp-on-freebsd-with-frr-gre-tunnels-and-policy-routing/",
      "published": "2026-02-08T14:02:58+00:00",
      "summary": "<p>Article URL: <a href=\"https://blog.hofstede.it/running-your-own-as-bgp-on-freebsd-with-frr-gre-tunnels-and-policy-routing/\">https://blog.hofstede.it/running-your-own-as-bgp-on-freebsd-with-frr-gre-tunnels-and-policy-routing/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46934266\">https://news.ycombinator.com/item?id=46934266</a></p> <p>Points: 33</p> <p># Comments: 8</p>",
      "content_text": "Running your own Autonomous System on the public internet sounds like something reserved for ISPs and large enterprises. It’s not. With sponsoring LIRs making AS numbers and IPv6 prefixes accessible to individuals, and FreeBSD providing the routing tools to make it work, you can announce your own address space to the Default-Free Zone from a single virtual machine. This article walks through the complete setup: obtaining resources from RIPE via a sponsoring LIR , configuring a FreeBSD BGP router with FRR , building GRE / GIF tunnels to distribute prefixes to remote servers, and solving the routing challenge that arises when a server needs to speak from two different IPv6 address spaces simultaneously. Note on addresses: All provider-assigned IP addresses, hostnames, and management IPs in this article have been replaced with RFC 5737 / RFC 3849 documentation ranges. My own AS number ( AS201379 ) and prefix (2a06:9801:1c::/48) are public BGP resources and shown as-is. The upstream AS numbers ( AS34927 , AS209735 ) are equally visible in public routing tables. Why Run Your Own AS ? Provider-assigned IPv6 addresses are tied to that provider. Move to a different hoster and your addresses change - along with DNS records, firewall rules, reputation, and every system that references them. With your own AS and prefix, your addresses follow you. Migrate a server, update a tunnel endpoint, and traffic flows again without touching a single service configuration. There are also less practical reasons. Understanding BGP transforms how you think about internet routing. Watching your prefix propagate through the DFZ and appear on looking glasses worldwide is genuinely satisfying. And if you run services across multiple providers, having provider-independent addressing simplifies the architecture considerably. Obtaining Resources To announce prefixes on the internet, you need two things from a Regional Internet Registry (in Europe, that’s RIPE NCC ): An AS number - your identity in BGP . Mine is AS201379 . An IPv6 prefix - the address space you’ll announce. I received 2a06:9801:1c::/48. As an individual, you don’t need to become a RIPE member (which involves fees and bureaucracy). Instead, you work with a sponsoring LIR - an existing RIPE member who sponsors your resource registration. Several LIRs cater to hobbyists and small operators. The process typically involves: Filling out a request form with your intended use case Creating the appropriate RIPE database objects (aut-num, inet6num, route6) Setting up RPKI ROAs (Route Origin Authorizations) to cryptographically bind your prefix to your AS Once the paperwork is done, you need upstream connectivity - someone willing to carry your BGP sessions and announce your routes to the rest of the internet. Architecture Overview The setup involves two tiers: a BGP router that peers with upstream providers, and downstream servers that receive tunneled subnets from the router’s /48. ┌──────────────────────────────┐ │ Default-Free Zone │ └──────┬──────────────┬─────────┘ │ │ AS34927 (iFog) AS209735 (Lagrange) │ │ GRE tunnel Direct peering │ │ ┌──────┴──────────────┴─────────┐ │ router01 (BGP Router) │ │ FreeBSD + FRR │ │ AS201379 │ │ 2a06:9801:1c::/48 │ └──────┬──────────────┬─────────┘ │ │ GIF tunnel GIF tunnel (proto 41) (proto 41) │ │ ┌──────┴───┐ ┌──────┴──────────┐ │ vps01 │ │ dcgw01 │ │ VPS │ │ DC OPNsense │ │ :1000:: │ │ :2000::/62 │ │ /64 │ │ │ └──────────┘ └──────────────────┘ The BGP router ( router01 ) announces 2a06:9801:1c::/48 to two upstream providers and maintains a blackhole route for the aggregate. Individual /64s (and a /62 for my Colocation datacenter) are tunneled to downstream servers via GIF tunnels (IPv6-in-IPv4 encapsulation). Each server receives real, globally routable addresses from my prefix while keeping its existing provider-assigned IPv6 fully operational. The BGP Router The router runs on a FreeBSD VM at a colocation facility with direct connectivity to two upstream networks. Let’s walk through each layer. Network Configuration The router’s /etc/rc.conf sets up the physical interface, tunnel interfaces, and static routes: hostname = \"router01\" # Security kern_securelevel_enable = \"YES\" kern_securelevel = \"2\" # Physical interface ifconfig_vtnet0 = \"inet 198.51.100.10/24 -rxcsum -txcsum -rxcsum6 -txcsum6 -lro -tso\" ifconfig_vtnet0_ipv6 = \"inet6 2001:db8:100::96/64\" defaultrouter = \"198.51.100.1\" ipv6_defaultrouter = \"2001:db8:100::1\" # Loopback alias for originated prefix ifconfig_lo0_alias0 = \"inet6 2a06:9801:1c::1 prefixlen 64\" # Tunnel interfaces cloned_interfaces = \"gif0 gif1 gre0\" kld_list = \"if_gif if_gre\" # GRE Tunnel to transit provider (iFog) ifconfig_gre0 = \"tunnel 198.51.100.10 198.51.100.44\" ifconfig_gre0_ipv6 = \"inet6 2001:db8:300::2 2001:db8:300::1 prefixlen 128\" ifconfig_gre0_descr = \"Transit-iFog\" # GIF Tunnel to VPS (vps01) ifconfig_gif0 = \"tunnel 198.51.100.10 203.0.113.10\" ifconfig_gif0_ipv6 = \"inet6 2a06:9801:1c:ffff::1 2a06:9801:1c:ffff::2 prefixlen 128\" ifconfig_gif0_descr = \"Tunnel-to-VPS\" ipv6_route_cloud = \"2a06:9801:1c:1000::/64 2a06:9801:1c:ffff::2\" # GIF Tunnel to datacenter firewall (dcgw01) ifconfig_gif1 = \"tunnel 198.51.100.10 192.0.2.50\" ifconfig_gif1_ipv6 = \"inet6 2a06:9801:1c:ffff::3 2a06:9801:1c:ffff::4 prefixlen 128\" ifconfig_gif1_descr = \"Tunnel-to-Datacenter\" ipv6_route_dc = \"2a06:9801:1c:2000::/62 2a06:9801:1c:ffff::4\" # Blackhole route for the aggregate + downstream routes ipv6_static_routes = \"myblock cloud dc\" ipv6_route_myblock = \"2a06:9801:1c::/48 -reject\" ipv6_gateway_enable = \"YES\" # Services pf_enable = \"YES\" pflog_enable = \"YES\" frr_enable = \"YES\" zfs_enable = \"YES\" sshd_enable = \"YES\" A few things worth explaining: The blackhole route ( -reject for the /48) is essential. Without it, traffic for unassigned subnets within your prefix would follow the default route back to the upstream, creating a routing loop. The blackhole ensures unrouted traffic is dropped locally. Point-to-point tunnel addresses use /128 prefixes on the 2a06:9801:1c:ffff::/64 link subnet. Each tunnel gets a pair of addresses from this range. Downstream routes point specific subnets at the far end of each tunnel. The /64 for the VPS and /62 for the datacenter are routed to their respective tunnel endpoints. GRE vs GIF : The iFog peering uses GRE because that’s what the provider requires. The downstream tunnels use GIF (protocol 41, IPv6-in-IPv4) which is simpler and has less overhead. FRR Configuration FRR (Free Range Routing) handles the BGP sessions. The configuration lives at /usr/local/etc/frr/frr.conf : frr version 10.5.1 frr defaults traditional hostname router01 log syslog informational service integrated-vtysh-config ! ipv6 prefix-list PL-MY-NET seq 5 permit 2a06:9801:1c::/48 ! ipv6 prefix-list PL-BOGONS seq 5 deny ::/0 le 7 ipv6 prefix-list PL-BOGONS seq 10 deny ::/8 ipv6 prefix-list PL-BOGONS seq 15 deny 100::/8 ipv6 prefix-list PL-BOGONS seq 20 deny 200::/7 ipv6 prefix-list PL-BOGONS seq 25 deny 400::/6 ipv6 prefix-list PL-BOGONS seq 30 deny 800::/5 ipv6 prefix-list PL-BOGONS seq 35 deny 1000::/4 ipv6 prefix-list PL-BOGONS seq 40 deny 4000::/3 ipv6 prefix-list PL-BOGONS seq 45 deny 6000::/3 ipv6 prefix-list PL-BOGONS seq 50 deny 8000::/3 ipv6 prefix-list PL-BOGONS seq 55 deny a000::/3 ipv6 prefix-list PL-BOGONS seq 60 deny c000::/3 ipv6 prefix-list PL-BOGONS seq 65 deny e000::/4 ipv6 prefix-list PL-BOGONS seq 70 deny f000::/5 ipv6 prefix-list PL-BOGONS seq 75 deny f800::/6 ipv6 prefix-list PL-BOGONS seq 80 deny fc00::/7 ipv6 prefix-list PL-BOGONS seq 85 deny fe80::/10 ipv6 prefix-list PL-BOGONS seq 90 deny fec0::/10 ipv6 prefix-list PL-BOGONS seq 95 deny ff00::/8 ipv6 prefix-list PL-BOGONS seq 100 deny 2a06:9801:1c::/48 ipv6 prefix-list PL-BOGONS seq 105 deny ::/0 ge 49 ipv6 prefix-list PL-BOGONS seq 110 permit ::/0 le 48 ! route-map RM-IFOG-OUT permit 10 match ipv6 address prefix-list PL-MY-NET set community 34927:9501 34927:9301 additive exit ! route-map RM-LAGRANGE-OUT permit 10 match ipv6 address prefix-list PL-MY-NET set as-path prepend 201379 201379 exit ! route-map RM-IFOG-IN permit 10 match ipv6 address prefix-list PL-BOGONS exit ! route-map RM-LAGRANGE-IN permit 10 match ipv6 address prefix-list PL-BOGONS exit ! ipv6 route 2a06:9801:1c::/48 blackhole ! router bgp 201379 bgp router-id 198.51.100.10 no bgp default ipv4-unicast neighbor 2001:db8:300::1 remote-as 34927 neighbor 2001:db8:300::1 description Upstream-iFog neighbor 2001:db8:300::1 ttl-security hops 1 neighbor 2001:db8:300::1 update-source gre0 neighbor 2001:db8:100::ff remote-as 209735 neighbor 2001:db8:100::ff description Upstream-Lagrange neighbor 2001:db8:100::ff ttl-security hops 1 neighbor 2001:db8:100::ff update-source 2001:db8:100::96 ! address-family ipv6 unicast network 2a06:9801:1c::/48 neighbor 2001:db8:300::1 activate neighbor 2001:db8:300::1 soft-reconfiguration inbound neighbor 2001:db8:300::1 maximum-prefix 250000 90 restart 30 neighbor 2001:db8:300::1 route-map RM-IFOG-IN in neighbor 2001:db8:300::1 route-map RM-IFOG-OUT out neighbor 2001:db8:100::ff activate neighbor 2001:db8:100::ff soft-reconfiguration inbound neighbor 2001:db8:100::ff maximum-prefix 250000 90 restart 30 neighbor 2001:db8:100::ff route-map RM-LAGRANGE-IN in neighbor 2001:db8:100::ff route-map RM-LAGRANGE-OUT out exit-address-family exit There’s a lot happening here. Let me break down the key design decisions. Prefix Lists Two prefix lists control what gets sent and received: PL - MY - NET : Matches only our /48. Used in outbound route-maps to ensure we only ever announce our own prefix. PL - BOGONS : A comprehensive bogon filter for inbound routes. This rejects non-routable address space (link-local, ULA , multicast, documentation ranges), our own prefix (to prevent loops), and anything more specific than a /48 or less specific than a /8. The final permit ::/0 le 48 at the end accepts everything that survived the deny rules. The bogon filter deserves emphasis. Accepting bad routes from peers can cause anything from black-holed traffic to becoming an unwitting participant in route hijacks. Filter aggressively on inbound. Route Maps Each peer gets its own pair of inbound/outbound route maps: Outbound to iFog ( RM-IFOG-OUT ): Announces our /48 with BGP communities 34927:9501 and 34927:9301 . These are iFog-specific communities that control route propagation - in this case, requesting announcement to specific peering partners. Outbound to Lagrange ( RM-LAGRANGE-OUT ): Announces our /48 with AS -path prepending (adds our ASN twice). This makes the Lagrange path appear longer to the rest of the internet, steering inbound traffic to prefer the iFog path. Useful for traffic engineering when one upstream has better connectivity. Inbound from both : Apply the bogon filter to reject garbage routes. BGP Session Details no bgp default ipv4-unicast : We’re IPv6-only. Don’t activate IPv4 address family by default. ttl-security hops 1 : GTSM (Generalized TTL Security Mechanism) - reject BGP packets with TTL less than 254. This prevents remote attacks on the BGP session since only directly connected peers can send packets with TTL 255. soft-reconfiguration inbound : Store received routes before applying filters. This lets you change inbound policy without resetting the BGP session. maximum-prefix 250000 90 restart 30 : Safety valve. If a peer sends more than 250,000 prefixes (or 90% of that as a warning), tear down the session and retry after 30 minutes. Protects against route leaks from upstream. Firewall on the Router The BGP router’s PF configuration protects the control plane while allowing data plane forwarding: # --- Macros --- ext_if = \"vtnet0\" dc_tun = \"gif1\" vps_tun = \"gif0\" trusted_ipv4 = \"{ 198.51.100.100, 198.51.100.101 }\" trusted_ipv6 = \"{ 2001:db8:ffff:1::/64, 2001:db8:ffff:2::/64 }\" bgp_peers_v4 = \"{ 198.51.100.20 }\" bgp_peers_v6 = \"{ 2001:db8:100::ff }\" ifog_gre_endpoint = \"198.51.100.44\" ifog_bgp_peer = \"2001:db8:300::1\" my_network_v6 = \"2a06:9801:1c::/48\" vps_v4 = \"203.0.113.10\" # --- Tables --- table < bruteforce > persist table < trusted_v4 > const { $ trusted_ipv4 } table < trusted_v6 > const { $ trusted_ipv6 } table < bgp_peers_v4 > const { $ bgp_peers_v4 } table < bgp_peers_v6 > const { $ bgp_peers_v6 } table < bogons > const { 0.0 . 0.0 / 8 , 10.0 . 0.0 / 8 , 172.16 . 0.0 / 12 , \\ 192.168 . 0.0 / 16 , 169.254 . 0.0 / 16 , :: / 96 , fc00 :: / 7 , \\ fec0 :: / 10 , ff00 :: / 8 } # --- Options --- set skip on lo0 set block - policy drop set loginterface $ ext_if # --- Scrub --- scrub in all fragment reassemble scrub on $ vps_tun max - mss 1440 scrub on $ dc_tun max - mss 1140 scrub on gre0 max - mss 1400 # --- Filtering --- block log all block in quick on $ ext_if from { < bogons > , $ my_network_v6 } to any antispoof quick for { $ ext_if } # --- Control Plane --- # SSH from trusted sources only pass in quick on $ ext_if proto tcp from < trusted_v4 > to ( $ ext_if ) port 22 \\ flags S / SA keep state \\ ( max - src - conn 5 , max - src - conn - rate 3 / 30 , \\ overload < bruteforce > flush global ) pass in quick on $ ext_if proto tcp from < trusted_v6 > to ( $ ext_if ) port 22 \\ flags S / SA keep state \\ ( max - src - conn 5 , max - src - conn - rate 3 / 30 , \\ overload < bruteforce > flush global ) # BGP (TCP 179) - strictly limited to known peers pass in quick on $ ext_if proto tcp from < bgp_peers_v4 > to ( $ ext_if ) port 179 \\ flags S / SA keep state pass in quick on $ ext_if proto tcp from < bgp_peers_v6 > to ( $ ext_if ) port 179 \\ flags S / SA keep state # GRE tunnel from iFog pass in quick on $ ext_if proto gre from $ ifog_gre_endpoint to ( $ ext_if ) pass in quick on gre0 proto tcp from $ ifog_bgp_peer to any port 179 # ICMPv6: essential for NDP, PMTUD, and diagnostics pass in quick inet6 proto ipv6 - icmp icmp6 - type { \\ echoreq , echorep , neighbrsol , neighbradv , \\ toobig , timex , paramprob , routersol } pass in quick inet proto icmp icmp - type { echoreq , unreach , timex } # --- Data Plane --- # Inbound traffic destined for our prefix pass in quick on $ ext_if inet6 from any to $ my_network_v6 keep state pass in quick on gre0 inet6 from any to $ my_network_v6 keep state # Return traffic from downstream tunnels pass in quick on $ vps_tun inet6 from $ my_network_v6 to any keep state pass in quick on $ dc_tun inet6 from $ my_network_v6 to any keep state # GIF tunnel encapsulation (proto 41) from downstream endpoints pass in quick on $ ext_if proto 41 from $ vps_v4 to ( $ ext_if ) # Outbound pass out quick all keep state The firewall cleanly separates control plane ( SSH , BGP sessions) from data plane (forwarded traffic). The control plane rules are strict: BGP is locked to known peer addresses, SSH to trusted management IPs. The data plane rules are simpler since the router just needs to forward packets between upstreams and downstream tunnels. The block in quick on $ext_if from { <bogons>, $my_network_v6 } rule is important - it drops packets claiming to come from our own prefix arriving on the external interface. If someone on the internet spoofs a source address from our range, this catches it before it enters the forwarding path. Note the per-tunnel MSS clamping in the scrub section. Each tunnel has different overhead ( GRE adds more headers than GIF ), so the MSS values differ. Getting this wrong causes mysterious connection stalls with large packets. The Downstream Server: Dual-Stack with Policy Routing This is where things get interesting. The VPS ( vps01 ) already has provider-assigned IPv6 from its hoster. Jails on this server use addresses from both address spaces: Provider IPv6 (2001:db8:200:0:1000::/68) - the hoster’s addresses, NATed to the host BGP IPv6 (2a06:9801:1c:1000::/64) - our own prefix, routed natively via the GIF tunnel Private IPv4 (10.254.254.0/24) - NATed to the host’s public IPv4 The challenge: when a jail sends traffic from its BGP address (2a06:…), that traffic must exit through the GIF tunnel to the BGP router -",
      "cover_image_url": "https://blog.hofstede.it/images/2026-02-08-running-your-own-as-bgp-freebsd.png"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Section 230 turns 30 as it faces its biggest tests yet",
      "url": "https://www.theverge.com/policy/875300/section-230-turns-30-social-media-addiction-cases-sunset",
      "published": "2026-02-08T14:00:00+00:00",
      "summary": "Thirty years ago today, Section 230 of the Communications Decency Act, a bill credited with creating the groundwork for the modern internet, became law and set off a chain of events that would make it a lightning rod for the techlash. The statute has survived everything from the dot-com bubble to a Supreme Court challenge [&#8230;]",
      "content_text": "Thirty years ago today, Section 230 of the Communications Decency Act, a bill credited with creating the groundwork for the modern internet, became law and set off a chain of events that would make it a lightning rod for the techlash. The statute has survived everything from the dot-com bubble to a Supreme Court challenge that struck down the surrounding text in the CDA. But as it marks this major milestone, Section 230 is facing what could be among its biggest threats to date, as prominent lawmakers plot to bring it down and a mountain of legal challenges give courts the chance to narrow its scope. Section 230, once dubbed “the twenty-six words that created the internet,” reads : “No provider or user of an interactive computer service shall be treated as the publisher or speaker of any information provided by another information content provider.” In other words, online platforms that host user-generated content can’t be held responsible for what those users choose to say on their platforms. Its “Good Samaritan” provision allows for those platforms to moderate content in good faith, shielding them from civil liability for blocking access to obscene, violent, or harassing content. The law does not shield platforms from claims under criminal law. In the years since President Bill Clinton signed the broader Telecommunications Act of 1996, Section 230 has become practically a caricature. Depending who you ask, it may either be at the root of most harm perpetuated by social media platforms or the very thing keeping the internet afloat. What started as an extremely popular act to prevent a fledgling tech industry from being crushed under the weight of frivolous lawsuits about hosting user-generated content has become one of the most reviled laws among many members of Congress — some of whom voted for it in the first place. “As minority leader in the house in 1996, I voted for it because social media platforms told us that without that protection, America would never have an internet economy. They also said that the platforms were just a dumb pipe that just carried content produced by others,” former Rep. Dick Gephardt (D-MO) said in a press conference last week that featured actor Joseph Gordon-Levitt alongside parents who lost kids following harms they say were facilitated by internet platforms, from sextortion to fentanyl poisoning. They were gathered to advocate for a bill introduced by Sens. Dick Durbin (D-IL) and Lindsey Graham (R-SC) to sunset Section 230 in two years, with the hope it will force lawmakers and tech companies to finally break the status quo and put them under pressure to come up with workable reforms. At the time of his vote, Gephardt says, lawmakers had no idea what algorithms were and how they would come to capture people’s attention for hours on end and “brainwash” them. Armed with new knowledge about the technology, he says, it’s time to “correct the action that I and many others made 30 years ago.” Now would be “the worst possible time to repeal Section 230” Gephardt’s sentiment about Section 230 may be widely shared, but it also faces stiff opposition. Sen. Ron Wyden (D-OR), a co-author of the law whose name was attached to the amendment that would become known as Section 230, doesn’t see the law as a mistake. In fact, he tells The Verge in a phone interview, now would be “the worst possible time to repeal Section 230.” “Trump and the MAGA billionaire cronies would be in the driver’s seat to rewrite our laws over online speech,” Wyden warns, saying it would be like “handing [Trump] a grenade launcher pointed right at people who want to have a voice.” While many Section 230 opponents think of platforms like Instagram and YouTube as the behemoth players they believe have benefited too long from the law’s protections, Wyden says platforms like Bluesky and Wikipedia, and groups that use social media to monitor the actions of ICE , would also suffer without it. Thirty years later, he says, “the law stands for exactly the same thing, which is: Are you going to stand up for people who don’t have power, don’t have clout, and are looking for a way to be heard? Because the people at the top, the people with lots of money, they’re always going to have ways to get their message out and to get their content out. And the First Amendment and what we’re talking about is a lifeline for folks of modest kind of means.” Wyden recalls cooking up the text that would become Section 230 with former Rep. Chris Cox (R-CA) over lunch “in a little cubby where members of Congress could grab a sandwich and complain about the world.” The bill would help resolve a concerning trend that rose out of a pair of recent legal cases: Courts were finding that online platforms could be held liable for what users posted on them if they made any effort to remove or limit posts they found objectionable, but so long as they did nothing at all, they might escape accountability. Today, Section 230’s defenders say that it’s necessary to incentivize tech platforms to do the basic moderation at scale that keeps them from becoming instant cesspools, and prevents them from being incentivized to remove posts that the government might take issue with. That’s become especially salient at a time when many tech executives have rubbed shoulders with President Donald Trump , settled lawsuits with him for millions of dollars , and updated their moderation standards once he resumed office. “What would the internet look like without 230?” asks Amy Bos, VP of government affairs at NetChoice, a group whose members span the tech industry, including Meta, Google, Pinterest, and Reddit. “It would force platforms, websites to remove third-party content. This is content created by everyday Americans.” But opponents of Section 230 say that now deep-pocketed companies unfairly benefit from the protections once meant for a startup industry. In court, Section 230 often acts as a “do not pass Go” card on lawsuits brought against tech platforms. Few plaintiffs have managed to overcome that hurdle. But this year, several cases are going to trial that could reshape the outer bounds of Section 230’s broad protections. The cases, which include one against Meta brought by New Mexico’s attorney general for its alleged facilitation of child predators, and others brought by individual plaintiffs and school districts who say they were harmed by social media’s allegedly addictive designs, will give juries the chance to decide what constitutes a decision a platform can be found negligent for making, and what is protected speech under the First Amendment or covered third-party content under Section 230. “I think we need to take 230 away, rewrite it to restart the clock” The cases could create a chance for the Supreme Court to ultimately weigh in on the appropriate application of Section 230 in the modern day. At the press conference in support of sunsetting Section 230, Dani Pinter, chief legal officer of the National Center on Sexual Exploitation (NCOSE), tells The Verge that the way courts have interpreted the statute over the years is a large part of the problem. “Even with the language of 230 how it is now, I don’t believe they should be given immunity in some of the cases they are,” Pinter says of the tech companies. “I think part of it is judges and lawyers don’t necessarily really get how these tech companies function.” That created a dynamic that allowed the case law around Section 230 to take on “a life of its own,” according to Pinter. “I think we need to take 230 away, rewrite it to restart the clock.” Wyden says he’s open to some targeted reform of the law, including around tech companies’ own product design choices, which is the issue at the center of the cases going to trial this year. He agrees with the outcome of a case against Snap that found Section 230 couldn’t bar the company from facing a lawsuit for allegedly encouraging reckless driving with its Snapchat speed filters. “We are not against talking about targeted changes, but my principles have been: It can’t target constitutionally protected speech, it can’t discourage moderation,” Wyden says. “And the bills I’ve seen violate one or both of these tenets.” When The Verge asked Durbin during the press conference whether he saw validity in concerns that repealing Section 230 would make it more likely that tech companies would remove content that the administration might find objectionable, Durbin responded, “The only business enterprise in America which is held harmless from their own wrongdoing is Big Tech.” Though he said he’s “all for the Constitution and free expression … there are limits.” Section 230 was last updated in 2018, with passage of the Allow States and Victims to Fight Online Sex Trafficking Act (FOSTA) , which carved out a new exception that removed liability protection for conduct that “promotes or facilitates prostitution,” or from facing civil or criminal charges of sex trafficking. The change helped lead to the shuttering of the classified advertising site Backpage.com , which was largely viewed as a victory by proponents. But sex workers said the absence of a system that let them vet potential clients more easily made them less safe. Three years after it was signed into law, a report from the US Government Accountability Office (GAO) found that the carve-out was used very rarely to bring cases in court. Several grieving parents at the press conference have stumbled into Section 230 as they sought some form of justice for their children’s deaths. Kristin Bride’s son Carson died by suicide at age 16 after being cyberbullied on an app called Yolo, which was integrated into Snapchat and let users send anonymous messages. Bride described the “second darkest day” of her life, after the day her son died, as the one when an attorney told her that because of Section 230, she had no legal recourse against the social media platforms. Even though an appeals court eventually let Bride move forward with her lawsuit for product misrepresentation against Yolo and the case has continued, it’s not in the way she’d imagined. “I had wanted discovery, a jury, a trial, and an opportunity to face the creator of Yolo, Gregoire Henrion, and look him in the eyes and let him know how much his priorities for making fast money over kids’ online safety have destroyed our family,” she says. “But this will never happen. Because after years of Section 230 appeals, Yolo is now a shell without funding, unable to hire attorneys to defend the case.” There’s one emerging area of tech that both Section 230’s authors and its fiercest critics agree shouldn’t hold water: AI. “The law plainly states that it does not protect anyone who creates or develops content, even in part–and generative AI applications such as ChatGPT, by definition, create content,” Cox and Wyden wrote in a 2023 op-ed in Fortune . In the AI age, lawmakers are replicating similar debates to those that took place 30 years ago about how to balance fostering a nascent industry while ensuring it doesn’t get to run wild. Ahead of the anniversary of Section 230, a coalition of groups that advocate for online safety measures for kids and AI urged Senate leaders “not to create a new shield for Big Tech by advancing legislation that would broadly preempt state artificial intelligence (AI) laws,” warning that repeated efforts to do so could “recreate the same dynamics that followed the passage of Section 230.” Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Lauren Feiner Policy Politics Report Speech",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/STKS519_FREE_SPEECH_CVIRGINIA_E.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "GitHub Agentic Workflows",
      "url": "https://github.github.io/gh-aw/",
      "published": "2026-02-08T13:40:56+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.github.io/gh-aw/\">https://github.github.io/gh-aw/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46934107\">https://news.ycombinator.com/item?id=46934107</a></p> <p>Points: 38</p> <p># Comments: 25</p>",
      "content_text": "Imagine a world where improvements to your repositories are delivered automatically each morning. Issues are automatically triaged, CI failures analyzed, documentation maintained, test coverage improved and compliance monitored - all defined via simple markdown files. GitHub Agentic Workflows deliver this: automated repository agents, running in GitHub Actions, with security-first design principles. Workflows run with read-only permissions by default. Write operations require explicit approval through sanitized safe outputs (pre-approved GitHub operations), with sandboxed execution, tool allowlisting, and network isolation ensuring AI agents operate within controlled boundaries. How they work: Write - Create a .md file with your automation instructions in natural language Compile - Run gh aw compile to transform it into a secure GitHub Actions workflow ( .lock.yml ) Run - GitHub Actions executes your workflow automatically based on your triggers Here’s a simple workflow that runs daily to create an upbeat status report: title-prefix : \" [team-status] \" labels : [ report , daily-status ] Create an upbeat daily status report for the team as a GitHub issue. The gh aw cli converts this into a GitHub Actions Workflow (.yml) that runs an AI agent (Copilot, Claude, Codex, …) in a containerized environment on a schedule or manually. The AI coding agent reads your repository context, analyzes issues, generates visualizations, and creates reports - all defined in natural language rather than complex code. Your browser doesn't support HTML5 video. Download the video here . Install the extension, add a sample workflow, and trigger your first run - all from the command line in minutes. Your browser doesn't support HTML5 video. Download the video here . Create custom agentic workflows directly from the GitHub web interface using natural language. Daily code simplification, refactoring, and style improvements Slash commands for on-demand analysis and automation Continuous documentation maintenance and consistency Automated triage, labeling, and project coordination Daily reports, trend analysis, and workflow health monitoring Scanning, alert triage, and compliance monitoring CI failure diagnosis, test improvements, and quality checks Feature sync and cross-repo tracking workflows DailyOps, research, and automated maintenance Note GitHub Agentic Workflows is in early development and may change significantly. Using agentic workflows requires careful attention to security considerations and careful human supervision, and even then things can still go wrong. Use it with caution, and at your own risk.",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "Best Wireless Earbuds (2026): Apple, Sony, Bose, and More",
      "url": "https://www.wired.com/gallery/best-wirefree-earbuds/",
      "published": "2026-02-08T13:05:00+00:00",
      "summary": "Ready to cut the cord? These are our favorite buds that will never, ever get tangled.",
      "content_text": "Other Earbuds We Like Every month seems to bring new sets of earbuds with longer battery life, new features, and more compact designs. As such, we can't list everything we like. But if you're still hunting, here are some other recommendations. Nothing Ear (a) for $59 : It has taken a lot for me to recommend a pair of ostensible AirPods Pro clones as the best earbuds for most people, but that speaks to just how much I actually like the Nothing Ear (a) . These stylish little yellow earbuds come in a sleek, clear charging case, and they have excellent sound and decent noise cancellation for under $100 retail. I liked how easily they paired with Android and iOS devices and that the lightweight, compact design helped them stay comfortable during longer listening sessions. The larger, more expensive Nothing Ear are also good, but they don't quite match the Ear (a)’s svelte figure. Status Audio Pro X for $239 : The multi-driver array inside these cool-looking earbuds from little-known brand Status Audio helps them rise above the rest when it comes to audio quality. A dynamic driver down low pairs with a set of Knowles balanced armatures for upper mids and highs, providing a ton of musical separation between instruments, and offering some of the best detail down low that we've heard in a pair of buds so far. The warm EQ works well with pop music and acoustic music alike, and the Pro X support Sony's LDAC Bluetooth codec for near-lossless streaming quality. We compared them with the best from Sony, Bose, Sennheiser, and Technics, and found that the Pro X hold their own valiantly, with only the call quality coming in a touch below what others have to offer. Technics EAH-AZ80 for $165 : Technics’ follow-up to the fantastic EAH-AZ80 provides trickle-down driver technology from the brand’s hi-fi in-ears, the EAH-TZ700. The result for the AZ100 is even richer and more detailed sound that digs deep into instrumental textures to reveal new dimensions in old songs. The buds add new features like Dolby-powered Spatial Audio and Bluetooth LE Audio support for futureproofing, along with old favorites like three-device multipoint pairing and mildly improved noise canceling. The slimmer design isn’t as ergonomic as the AZ80 to my ears, but they’re still comfy, and battery life of up to 10 hours per charge with ANC lets you listen long past Bose and Apple buds. —Ryan Waniata Beyerdynamic Amiron 300 for $150: These premium earbuds from Beyerdynamic look nondescript and sound fantastic, but they lack any of the superlative qualities of the buds on the list above. If you're after a clean-looking pair of headphones with fantastic vocal definition, they're worth considering. Audio-Technica ATH-CKS50TW2 for $159 : These buds from Audio Technica boast 15 hours of battery life with noise canceling on, which is the longest we've tested in a pair of earbuds. Despite a somewhat bulky appearance, they actually remain very ergonomic, with multiple pairs of included eartips to guarantee a good fit. A cool magnetic feature allows you to clip the buds together when they're not in their wireless charging case to engage standby mode. These aren't the best-sounding buds for the money, nor do they have the best noise reduction, but if you want a pair that will last you throughout multiple workdays (or one really long one), these are a great option. ( Note: These have been in and out of stock on Amazon.) Soundcore Space A40 for $45 : While they're no longer on our main list, the Space A40 are still some of my favorite buds for the money, providing good features, clear sound, and excellent noise canceling for their price class. They also look polished, with only their lack of auto-pause sensors betraying their low price. Samsung Galaxy Buds 2 Pro for $100–$200: The Galaxy Buds 2 Pro are getting older, but they're still among the best buds to pair with a Samsung phone . They don't have the multi-device connectivity of our top pick for Android users, and their five-hour battery is looking pretty short these days, but they provide excellent sound quality, IPX7 waterproofing, and a distinctive design that doesn't just ape the AirPods Pro. That makes them well worth considering on sale. Sony Linkbuds Fit for $200 : Sony’s Linkbuds Fit offer rich and punchy sound, naturalistic transparency mode, and a light and comfy fit, helping them live up to their intent as a “wear anywhere” solution. They provide some solid features, but skimp on battery life with just 5.5 hours per charge, and their noise canceling is just OK. Their oddly unresponsive touch controls and reliance on flimsy silicone sleeves further diminish their value, but they're still Sony buds and could be worth nabbing on a good sale. Montblanc MTB 03 for $395 : These earbuds are priced out of reach for most buyers, but if you've got the cash, you'll be rewarded with a luxury experience worthy of the brand. Montblanc has called in some heavy hitters from the audio industry to design and voice these buds. The result is a small, comfortable, and quite flashy-looking pair of wireless earbuds that sound really impressive. Raycon Everyday Earbuds for $80 : These YouTuber-beloved earbuds are actually a decent cheap pair . They are small and light, and they come with an IPX6 rating, which makes them great for workouts. Earbuds to Avoid As a general rule, you should avoid earbuds that don't support the Bluetooth 5.0 standard (or higher), or don't offer at least five hours of battery life—more like six these days. Batteries in wireless headphones degrade over time, so the better your battery life is at first, the more tolerable it will be in two to three years. Apple AirPods (Previous or Current Gen) for $119–$170 : These headphones do some things well, we just don't like them all that much. ( Read our latest review. ) They get OK battery life, come in a compact case, and work well for calls, but they don't fit all ears well, and since they don't have ear tips or wings, you're out of luck if they're loose. The priciest model adds noise canceling, which works about as well as you'd expect for a pair that doesn't offer a proper seal. Want clear music, good noise canceling, and advanced features made for iPhones for less than the AirPods Pro 3? Get the AirPods Pro Gen 2 , which sometimes cost more (and sometimes less) but are legitimately great. Beats Solo Buds for $70 : These are lackluster in virtually every possible way , especially when it comes to features for the money. Their best traits are their micro-size and big battery, but that's about it. It's odd, because we like other headphones from the brand, but these just don't keep pace. The best we can say is they are cheap. Samsung Galaxy Buds 3 for $170 : A Cybertrucked pair of AirPods clones , the headphones in the new Galaxy Buds line work worse than they already look. With no eartips, these are uncomfortable to wear for long periods, and the noise canceling is all but useless. How We Define Wireless Earbuds AccordionItemContainerButton We've seen this category go by many names: true wireless earbuds, truly wireless earbuds, completely wireless earbuds, fully wireless earbuds, wirefree earbuds, etc . These days, if a pair of earbuds connects to your phone/computer via Bluetooth and has no cord that connects the left bud to the right, we just call them wireless. Wireless sets typically come with two popcorn-sized buds, each with a battery inside, and a charging cradle that carries extra battery power and keeps them safe when you're not wearing ’em. Some wireless earbuds have a cable or neckband that connects the two buds together, usually found on workout buds from brands like Shokz. Ridding yourself of all cords can feel liberating, but these do come with issues, such as limited battery life (don't buy any with less than five hours), confusing controls, and reliance on a charging case. They're also easier to lose than traditional earbuds, and replacing one bud can be expensive. That said, this is one of the most innovative categories in tech, offering a flurry of new features from heart rate monitors to OTC hearing aid functionality , with more added in each new generation. These days features like noise canceling and transparency mode are standard, while the burgeoning open-ear category offers a more natural way to keep aware of your surrounding. AccordionItemContainerButton We test headphones and earbuds the way that we live. We take them to the gym, wear them around offices, travel with them, and generally try to use them as we anticipate potential buyers will use them. If a pair advertises dust or water resistance, we test that. We drop-test cases and test cables, charging times, and battery life, and we note everything we find exceptional to our readers. While we do not typically use a set playlist of music to test each pair, we aim to test acoustic, rock, hip hop, pop, country, and a variety of other genres with every pair of headphones, ensuring offer a good perspective on sound signature across genres and volumes. For noise reduction, we test the headphones in real-world environments and note our findings. When possible, we attempt to have headphones worn by a variety of people with different head and ear shapes, to ensure we're thinking about the widest audience possible. Power up with unlimited access to WIRED . Get best-in-class reporting and exclusive subscriber content that's too important to ignore. Subscribe Today .",
      "cover_image_url": "https://media.wired.com/photos/69866b7687d616d0d134feab/191:100/w_1280,c_limit/Update-%20The%20Best%20Wireless%20Earbuds%20We've%20Tested.png"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Digital car keys are getting more sophisticated",
      "url": "https://www.theverge.com/transportation/873197/digital-key-car-ccc-plugfest-rivian",
      "published": "2026-02-08T13:00:00+00:00",
      "summary": "Last month, over a dozen automobile and smartphone manufacturers gathered in Palo Alto, California, for the 16th annual \"Plugfest,\" hosted by the Car Connectivity Consortium (CCC) to test out the latest in digital key technology. Digital keys, which allow vehicle owners to lock, unlock, and start their cars using smartphones or other digital devices, are [&#8230;]",
      "content_text": "Last month, over a dozen automobile and smartphone manufacturers gathered in Palo Alto, California, for the 16th annual “Plugfest,” hosted by the Car Connectivity Consortium (CCC) to test out the latest in digital key technology. Digital keys , which allow vehicle owners to lock, unlock, and start their cars using smartphones or other digital devices, are becoming more commonplace. And the goal of Plugfest was to provide a place for CCC members — ranging from automakers and smart device manufacturers to cloud providers and chip makers — to come together to test interoperability and real-world performance across vehicles, devices, and wireless technologies. Plugfest is an opportunity for companies that are typically heated rivals to come together in the spirit of cooperation to ensure that digital keys work across different devices and vehicle brands. But the event was also an acknowledgement that as modern cars get more complex, these validation efforts will grow increasingly important to ensure that digital keys can keep pace with the innovation in the auto and smartphone markets. As automakers turn their focus to software-defined vehicles that can receive over-the-air updates and seemingly improve over time, digital keys will need to improve too. Plugfest is an opportunity for companies that are typically heated rivals to come together in the spirit of cooperation to ensure that digital keys work across different devices and vehicle brands “It’s a hard technology problem when you’re trying to resolve wireless access with such fragmented set of device hardware and then device software,” Wassym Bensaid, chief software officer at Rivian, told The Verge . RV Tech, the joint venture between Rivian and Volkswagen, hosted Plugfest this past month. Bensaid said the complexity favors companies like Rivian with more vertical integration. Seamless phone-to-car connectivity requires deep integration across vehicle software, cloud systems, and a highly fragmented device ecosystem spanning iOS and multiple Android variants with differing wireless characteristics. Industry standards like CCC are essential, he argued, when aligning these technologies. Much of the power seems to rest in the hands of phone manufacturers, who need to ensure that each auto brand adheres to their rigid standards around data security and privacy. At last year’s WWDC, for example, Apple announced that it would soon support digital car keys from 13 vehicle brands, including Audi, Cadillac, Chevy, Hyundai, Kia, GMC, Volvo, Rivian, and others — bringing the total number to 33 brands. The keys are added to the Wallet app, and can be used to lock, unlock, and start the vehicle using technology like NFC, UWB, or BLE — depending on which are supported by the vehicle. CCC is doing most of the heavy lifting by bringing together most major car companies as well as Apple, Samsung, and Xiaomi. It also includes the FiRa Consortium, a nonprofit that supports ultra wideband and includes Apple, Google, Cisco, Samsung, Qualcomm, and others as members. CCC President Alysia Johnson said that since launching the Digital Key Certification Program in late 2023 , the group has seen a dramatic increase in certifications, from two in 2024 to 115 in 2025. This year, CCC is rolling out version 4 of its specification, which offers more support for fleet owners like municipal governments, as well as rental car companies. Another major enhancement is improved “friend sharing,” which allows vehicle owners to securely and easily share access with others, regardless of the recipient’s phone type or manufacturer. Johnson gave the example of letting your neighbor borrow your car if theirs broke down by texting them a secure copy of your car key. And as soon as they’re done, you can easily revoke access to the digital key. “It’s just like sharing a photo, if you’ve ever texted a photo to somebody,” she said. “They don’t need to have an app for my vehicle. They don’t need to have my same kind of phone.” Digital keys are hardly a flawless system. Reddit is teeming with posts from people complaining about their digital keys in a variety subreddits, including those for Kia, BYD, Rivian, Volvo, and others. “I’ll be standing there with the app open and it won’t recognize I’m there,” one Tesla Model 3 owner said in a post last month . Like any software-based system, flaws remain a persistent problem. From Rivian’s position, UWB represents the technology with the most reliability, Bensaid said. UWB’s superior accuracy and security, particularly when combined with BLE for proximity-based locking and unlocking, gives customers a better experience through its accuracy, he added. “Some of the anecdotal feedback that we had from our customers as we launched CCC end of last year, some of them are pointing to accuracy at the edge,” Bensaid said, “which is something that they’re really enjoying now.” Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Andrew J. Hawkins Cars Electric Cars Tech Transportation",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/25114965/P90354782_highRes_bmw_digital_key_06_2.jpg?quality=90&strip=all&crop=0%2C10.752607989199%2C100%2C78.494784021602&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Netflix’s Warner Bros. merger puts rival streamers in survival mode",
      "url": "https://www.theverge.com/column/874781/netflix-warner-bros-merger-other-streamers",
      "published": "2026-02-08T13:00:00+00:00",
      "summary": "This is The Stepback, a weekly newsletter breaking down one essential story from the tech world. For more news about the streaming wars, follow Emma Roth. The Stepback arrives in our subscribers' inboxes at 8AM ET. Opt in for The Stepback here. How it started From 2019 to around 2021, we were in the midst [&#8230;]",
      "content_text": "This is The Stepback , a weekly newsletter breaking down one essential story from the tech world. For more news about the streaming wars, follow Emma Roth . The Stepback arrives in our subscribers’ inboxes at 8AM ET. Opt in for The Stepback here . From 2019 to around 2021, we were in the midst of a streaming renaissance. Paramount Plus, Disney Plus, Apple TV, Peacock, and HBO Max all made their debuts, challenging the dominance of Netflix and other legacy streamers like Hulu and Amazon Prime Video. New indie streaming services, like the cinephile-focused Criterion Channel, emerged during this time. Subscription prices were still relatively low. Heck, Disney Plus cost just $6.99 without ads at launch (it costs $11.99 with ads now and $18.99 without). Fierce competition in the industry also brought about a slew of original series, like Ted Lasso , The Mandalorian , and Star Trek: Strange New Worlds, that made services other than Netflix actually worth subscribing to. But things changed around 2022. As an influx of new services flooded the market, the covid streaming signup boom wound down and many Netflix competitors struggled to reach profitability. Studios slashed orders for adult scripted series, while canceling others . Even Netflix, which reported losing subscribers for the first time in over a decade in April 2022, was feeling the pressure. The previously ad-free Netflix, Disney Plus, HBO Max, and Amazon Prime Video responded to the crunch by sticking commercials into their streams, as services began hiking prices for subscribers and clamping down on password sharing . While Netflix has added 25 million more subscribers in 2025 — bringing its global total to 325 million — signups to other services have begun to plateau. Peacock most recently reported adding three million subscribers over the last few months of 2025, while Paramount grew by 1.4 million subs during its third quarter. Disney last said Disney Plus added 1.5 million subscribers in the US and Canada in the three months leading up to November 2025 — but, like Netflix, it has stopped reporting these numbers each quarter. It’s getting more difficult for Netflix competitors to scrape up new subscribers, and many are offering exclusive sporting events to draw more signups. Paramount Plus, for example, is now the exclusive home to the UFC , while NBA fans can only watch Monday night games on Peacock through the 2025 to 2026 season. Apple TV also exclusively streams Major League Soccer games , and the same will go for Formula 1 races when the 2026 season kicks off in March. Advertising has also become an even bigger source of revenue for streamers , as companies discover new and annoying ways to bombard you with ads . Data from the market research firm Antenna revealed that 46 percent of people in the US subscribed to Disney Plus, Hulu, HBO Max, Netflix, Paramount Plus, Peacock, and Discovery Plus have ad-supported plans. Netflix’s $82.7 billion Warner Bros. acquisition is going to have a monumental impact on the streaming landscape. With the deal, Netflix will be in control of the content served to the 325 million and 128 million people signed up to its own streaming service and HBO Max, respectively. There may be substantial overlap there, though, as Netflix co-CEO Ted Sarandos said during a February 3rd antitrust hearing that 80 percent of HBO Max subscribers are also signed up to Netflix. Now, instead of fighting Netflix alone, competitors will likely have to do it together, whether through new bundles or consolidation. We’ve already seen bundling take off in recent years, which not only attracts subscribers by serving as a cheaper alternative to individual subscriptions, but is also shown to reduce churn, as subscribers considering cancelling a bundle might not want to cut off access to multiple services at once. Data from Antenna revealed that 80 percent of the 1.6 million people who signed up for the Disney Plus, Hulu, and HBO Max bundle that launched in 2024 remained subscribed three months later. Further consolidation is in the future, too. Disney is on track to fully merge Hulu within the Disney Plus app by the end of this year. Paramount, which has been fighting for months to wrestle Warner Bros. away from Netflix, is also rumored to merge its Paramount Plus streaming service with Peacock . Though it’s starting to look like Netflix is going to emerge as the winner of the streaming race, its Warner Bros. merger still faces regulatory hurdles. Earlier this week, the Senate Judiciary antitrust subcommittee raised concerns that the acquisition could result in higher prices for customers, harm the theater business, or reduce entertainment jobs. Meanwhile, Sen. Eric Schmitt (R-MO) accused Netflix of hosting the “wokest content in the history of the world.” Netflix is currently locked in a battle for viewer attention with YouTube, TikTok, and even games like Fortnite . As much as Netflix might try to challenge them by launching podcasts , trying out short-form video feeds , revamping its user interface on mobile , and focusing on cloud gaming, it’s going to be difficult to compete with platforms that are free. YouTube may not be thought of as a streamer in the traditional sense, but it has once again been crowned the top-watched service for the third year in a row, according to data from Nielsen . Netflix competes with the platform “in every dimension for talent, for ad dollars, for subscription dollars, and for all forms of content,” Sarandos said during an earnings call in January . Disney is making some big moves, too. In addition to bringing a feed of AI-generated videos to the Disney Plus app, theme parks head Josh D’Amaro will take over as CEO of the company in March. Netflix’s latest attempt to get more eyeballs — and ears — on its platform is via podcasts. In addition to licensing shows from Spotify, iHeartMedia, and Barstool Sports, Netflix has launched some original video podcasts of its own , featuring comedian Pete Davidson and former NFL star Michael Irvin. For more on the Netflix and Warner Bros. merger, check out this deep dive on Decoder with Verge alum Julia Alexander. If you’re wondering how Netflix’s Warner Bros. acquisition could impact HBO, The Wrap has a fascinating report about what might happen to the network’s content and linear channels, and whether Netflix will integrate HBO Max into its streaming service. Netflix has been streaming a lot of live events lately. The Wall Street Journal digs into how Netflix learned from its early streams and what it’s doing to prevent glitches in the future. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Emma Roth Column Streaming The Stepback",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/268313_Smaller_streamers_before_and_after_Netflix_deal_CVirginia2.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Sculpting Cinema Through Graphs",
      "url": "https://cinegraphs.ai/",
      "published": "2026-02-08T12:00:02+00:00",
      "summary": "<p>Hi HN, I'm a computer systems engineering student in Mexico who switched from film school. I built CineGraphs because my filmmaker friends and I kept hitting the same wall—we'd have a vague idea for a film but no structured way to explore where it could go. Every AI writing tool we tried output generic, formulaic slop. I didn't want to build another ChatGPT wrapper, so I went a different route.<p>The idea is simple: you input a rough concept, and the tool generates branching narrative paths visualized as a graph. You can sculpt those branches into a structured screenplay format and export to Fountain for use in professional screenwriting software.<p>Most AI writing tools are trained on generic internet text, which is why they output generic results. I wanted something that understood actual cinematic storytelling—not plot summaries or Wikipedia synopses, but the actual structural DNA of films. So I spent a month curating 100 films I consider high-quality cinema. Not just popular films, but works with distinctive narrative structures: Godard's jump cuts and essay-film digressions, Kurosawa's parallel character arcs, Brakhage's non-linear visual poetry, Tarkovsky's slow-burn temporal structures. The selection was deliberately eclectic because I wanted the model to learn that \"story\" can mean many things.<p>Getting useful training data from films is harder than it sounds. I built a 1000+ line Python pipeline using Qwen3-VL to analyze each film with subtitles enabled. The pipeline extracts scene-level narrative beats, character relationships and how they evolve, thematic threads, and dialogue patterns. The tricky part was getting Qwen3-VL to understand cinematic structure rather than just summarizing plot. I had to iterate on the prompts extensively to get it to identify things like \"this scene functions as a mirror to the opening\" or \"this character's arc inverts the protagonist's.\" That took weeks and I'm still not fully satisfied with it, but it's good enough to produce useful training data.<p>From those extractions I generated a 10K example dataset of prompt-to-branching-narrative pairs, then fine-tuned Qwen2.5-7B-Instruct with a LoRA optimized for probabilistic story branching. The LoRA handles the graph generation—exploring possible narrative directions—while the full 7B model generates the actual technical screenplay format when you export. I chose the 7B model because I wanted something that could run affordably at scale while still being capable enough for nuanced generation. The whole thing is served on a single 4090 GPU using vLLM. The frontend uses React Flow for the graph visualization. The key insight was that screenwriting is fundamentally about making choices—what if the character goes left instead of right?—but most writing tools force you into a linear document too early. The graph structure lets you explore multiple paths before committing, which matches how writers actually think in early development.<p>The biggest surprise was how much the film selection mattered. Early versions trained on more mainstream films produced much more formulaic outputs. Adding experimental and international cinema dramatically improved the variety and interestingness of the generations. The model seemed to learn that narrative structure is a design space, not a formula.<p>We've been using it ourselves to break through second-act problems—when you know where you want to end up but can't figure out how to get there. The branching format forces you to think in possibilities rather than committing too early.<p>You can try it at <a href=\"https://cinegraphs.ai/\" rel=\"nofollow\">https://cinegraphs.ai/</a> — no signup required to test it out. You get a full project with up to 50 branches without registering, though you'll need to create an account to save it. Registered users get 3 free projects. I'd love feedback on whether the generation quality feels meaningfully different from generic AI tools, and whether the graph interface adds va",
      "content_text": "Sculpt your screenplay Select the branches that resonate, combine elements, and iterate. When you're ready, export to Fountain format for final polishing in your favorite screenwriting software.",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "The Shoes and Brooms Transforming Curling at the 2026 Winter Olympics",
      "url": "https://www.wired.com/story/the-shoes-and-brooms-transforming-curling-at-the-2026-winter-olympics/",
      "published": "2026-02-08T12:00:00+00:00",
      "summary": "Halfway between chess and bocce, curling is experiencing an evolution thanks to technology. From brooms to stones to footwear, here’s everything you need to know about the game’s gadgets.",
      "content_text": "The Winter Olympic Games have begun, and once again the sport of curling is set to draw in scores of new converts . Although dominated by Sweden, Canada, Switzerland, and Scotland, many eyes during the 2026 Winter Olympics will be on the team from host country Italy thanks to Stefania Constantini and Amos Mosaner, the reigning Olympic and world curling champions in mixed doubles. Regardless of which country takes home the gold, the real attention during the Olympics this year might be on the cool gadgets curlers use. Somewhat similar to a game of shuffleboard played with brooms and stones, curling has seen some pretty interesting advances in the gear that’s used on the ice. In addition to raw skill and strategy, here’s everything you need to know about the state of the sport. Scottish Stones Nearly every curling stone—the round rock that slides down the ice—comes from the same place: Ailsa Craig. The 99-hectare island site in the Firth of Clyde inlet on Scotland’s west coast is known for its granite, and by extension its ability to provide enough of it to outfit curlers the world over. Each stone must weigh between 19.96 and 17.24 kilograms and is made from one of two varieties of Scottish granite, common green and blue hone. These two types are the most resistant to heat and humidity and to the cracks and condensation that can form thanks to the 28 meters of ice the stones slide on during competitions. The stones used at the Olympics, as well as the World Championships, are produced by Kays of Scotland. Many curling stones also come from Canada Curling Stone . (The sport has seen a recent spike in popularity in Canada.) Both companies produce the stones using a meticulous process of grinding and polishing. Broom Boom In addition to the stones, the main tools necessary to curl are a broom and shoes—this is where advancements in gear really come to the fore. For one, there are scores of sensors and microchips that allow players to manage the power of their throws. For another, there are new-and-improved brooms that allow sweepers to maximize their skills. More than anything, what curlers need to work a broom are dexterity, physicality, and coordination. But beyond that, good tools don’t hurt. “Broom technology continues to be a major focus because the physical demands of the sport continue to evolve, and one of the biggest challenges is finding the right balance between weight, strength, and effective energy transfer,” says Dale Matchett, general manager at curling equipment company BalancePlus. As with any kind of sporting equipment, quality depends on how much a team or player is willing to spend. Carbon fiber brooms are best for their combination of strength and lightness. Composite fiber works well for midrange players. Fiberglass is the cheapest option. The broom’s handle and bearing factor into its weight and sweeping efficiency.",
      "cover_image_url": "https://media.wired.com/photos/69824a425ca72a25a7df77d5/191:100/w_1280,c_limit/olympics_curling.jpg"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "4 Best AI Notetakers (2026), Tested and Reviewed",
      "url": "https://www.wired.com/gallery/best-ai-notetakers/",
      "published": "2026-02-08T12:00:00+00:00",
      "summary": "A growing collection of pocket-sized gadgets lets you record your meetings and extract value from them. Here are our favorites.",
      "content_text": "I had low expectations for the rather generic Comulytic Note Pro, but it surprised me as not only the most useful all-around notetaker on available but also the cheapest after you consider the cost of a premium subscription. The slim device, at 28 grams, is small enough to fit in a wallet or attach unobtrusively with the included magnetic ring to the back of your handset (note: it requires a special USB dongle to charge). The 64 GB of storage space and a 45-hour battery life aren’t massive, but both should be more than enough to handle a full week of interviews without offloading or recharging, all processed through OpenAI's GPT-5 and Google's Gemini. The small LCD is helpful (and rare in this market), indicating when you’re recording and offering a recording duration. This makes it a lot more foolproof than other notetakers, which offer nothing more than a colored LED to tell you if it’s on. The Note Pro supports 113 languages—sort of. It will record in a foreign tongue and offer a verbatim transcript in the native language, but insights and summaries are delivered in your language of choice. It’s not a full solution if you need a complete, direct translation, but if you just need the gist of a foreign news story or speech, Comulytic can uniquely handle it. The proof is in the quality of the abstracts and insights provided. Of all the devices I tested, Comulytic’s summaries were the most insightful and least rambling (though better than its transcripts), effectively picking out the most relevant portions of interviews and pulling the best quotes from my conversations (perhaps too many at times). It was also the only device to correctly transcribe a punny product nickname mentioned in passing in one interview, indicating that a more sophisticated language model may be behind the scenes. Comulytic isn’t perfect. It doesn’t transcribe in real time, it’s one of the slowest products at completing analyses, and I never got its “fast transfer” mode working, which meant all recordings had to be sent to my phone via a pokey Bluetooth connection, but these are minor dings against an otherwise solid solution. Best of all, for a limited time, the company includes a generous three months of premium service at no charge. Even if you don’t want to subscribe, the free plan, which offers three “deep dives” and 10 abstracts a month, is better than nothing. Subscription costs $15 per month or $120 per year",
      "cover_image_url": "https://media.wired.com/photos/6987b1c6829bf2e80f43c31b/191:100/w_1280,c_limit/The%20Best%20AI%20Notetakers%20to%20Record%20Your%20Meetings,%20Interviews,%20or%20Classes.png"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Fwd: [cherry.heiyui@keio.jp: Sad news: Dave Farber has passed away]",
      "url": "https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/TSNPJVFH4DKLINIKSMRIIVNHDG5XKJCM/",
      "published": "2026-02-08T11:38:57+00:00",
      "summary": "<p>Article URL: <a href=\"https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/TSNPJVFH4DKLINIKSMRIIVNHDG5XKJCM/\">https://lists.nanog.org/archives/list/nanog@lists.nanog.org/thread/TSNPJVFH4DKLINIKSMRIIVNHDG5XKJCM/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46933401\">https://news.ycombinator.com/item?id=46933401</a></p> <p>Points: 110</p> <p># Comments: 17</p>",
      "content_text": "----- Forwarded message from \"Cherry, Hei Yui WONG\" <cherry.heiyui@keio.jp> ----- From: \"Cherry, Hei Yui WONG\" <cherry.heiyui@keio.jp> Date: Sun, 8 Feb 2026 11:06:40 +0900 Subject: Sad news: Dave Farber has passed away We are heartbroken to report that our colleague -- our mentor, friend, and conscience -- David J. Farber passed away suddenly at his home in Roppongi, Tokyo. He left us on Saturday, Feb. 7, 2026, at the too-young age of 91. To his son Manny, he was simply ???Dad???, his bedrock whom he will miss immeasurably. They spoke almost daily by video throughout his time in Japan, and shared special times on numerous visits. He is survived by son Manny Farber and daughter-in-law Mei Xu, daughter-in-law Carol Hagan and grandsons Nate Farber and Sam Farber. He was preceded in death by his wife Gloria (G.G.) and son Joe Farber. Dave???s career began with his education at Stevens Institute of Technology, which he loved deeply and served as a Trustee. He joined the legendary Bell Labs during its heyday, and worked at the Rand Corporation. Along the way, among countless other activities, he served as Chief Technologist of the U.S. Federal Communications Commission; became a proficient (instrument-rated) pilot; and was an active board member of the Electronic Frontier Foundation, a digital civil-liberties organization. His professional accomplishments and impact are almost endless, but often captured by one moniker: ???grandfather of the Internet,??? acknowledging the foundational contributions made by his many students at the University of California, Irvine; the University of Delaware; the University of Pennsylvania; and Carnegie Mellon University In 2018, at the age of 83, Dave moved to Japan to become Distinguished Professor at Keio University and Co-Director of the Keio Cyber Civilization Research Center (CCRC). He loved teaching, and taught his final class on January 22, 2026. At CCRC, one of his most enjoyable activities was co-hosting the IP-Asia online gathering, which has met every Monday for more than five years and has addressed many aspects of the impact of technology on civilization. Dave thrived in Japan in every way. We, the IP-Asia community, will gather for an online remembrance of Dave at the usual time and place, 2100 JST on Monday, February 9, 2026. It???s impossible to summarize a life and career as rich and long as Dave???s in our few words here. And each of us, even those who knew him for decades, represent just one facet of his life. But because we are here at its end, we have the sad duty of sharing this news. Further information and a more formal obituary are forthcoming. With condolences to Manny and the rest of the family, Jiro Kokuryo Cherry Wong Kaori Suzuki Rodney Van Meter Dan Gillmor Manny can be reached at manny.farber@gmail.com.",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Last Week on My Mac: Why E cores make Apple silicon fast",
      "url": "https://eclecticlight.co/2026/02/08/last-week-on-my-mac-why-e-cores-make-apple-silicon-fast/",
      "published": "2026-02-08T11:31:49+00:00",
      "summary": "<p>Article URL: <a href=\"https://eclecticlight.co/2026/02/08/last-week-on-my-mac-why-e-cores-make-apple-silicon-fast/\">https://eclecticlight.co/2026/02/08/last-week-on-my-mac-why-e-cores-make-apple-silicon-fast/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46933365\">https://news.ycombinator.com/item?id=46933365</a></p> <p>Points: 127</p> <p># Comments: 137</p>",
      "content_text": "If you use an Apple silicon Mac I’m sure you have been impressed by its performance. Whether you’re working with images, audio, video or building software, we’ve enjoyed a new turn of speed since the M1 on day 1. While most attribute this to their Performance cores, as it goes with the name, much is in truth the result of the unsung Efficiency cores, and how they keep background tasks where they should be. To see what I mean, start your Apple silicon Mac up from the cold, and open Activity Monitor in its CPU view, with its CPU History window open as well. For the first five to ten minutes you’ll see its E cores are a wall of red and green with Spotlight’s indexing services, CGPDFService, mediaanalysisd, BackgroundShortcutRunner, Siri components, its initial Time Machine backup, and often an XProtect Remediator scan. Meanwhile its P cores are largely idle, and if you were to dive straight into using your working apps, there’s plenty of capacity for them to run unaffected by all that background mayhem. It’s this stage that scares those who are still accustomed to using Intel Macs. Seeing processes using more than 100% CPU is terrifying, because they know that Intel cores can struggle under so much load, affecting user apps. But on an Apple silicon Mac, who notices or cares that there’s over a dozen mdworker processes each taking a good 50% CPU simultaneously? After all, this is what the Apple silicon architecture is designed for. Admittedly the impression isn’t helped by a dreadful piece of psychology, as those E cores at 100% are probably running at a frequency a quarter of those of P cores shown at the same 100%, making visual comparison completely false . This is nothing new. Apple brought it to the iPhone 7 in 2016, in its first SoC with separate P and E cores. That’s an implementation of Arm’s big.LITTLE announced in 2011, and development work at Cray and elsewhere in the previous decade. What makes the difference in Apple silicon Macs is how threads are allocated to the two different CPU core types on the basis of a metric known as Quality of Service , or QoS. As with so much in today’s Macs, QoS has been around since OS X 10.10 Yosemite , six years before it became so central in performance. When all CPU cores are the same, it has limited usefulness over more traditional controls like Posix’s nice scheduling priority. All those background tasks still have to be completed, and giving them a lower priority only prolongs the time they take on the CPU cores, and the period in which the user’s apps are competing with them for CPU cycles. With the experience gained from its iPhones and other devices, Apple’s engineers had a better solution for future Macs. In addition to providing priority-based queues, QoS makes a fundamental distinction between those threads run in the foreground, and those of the background. While foreground threads will be run on P cores when they’re available, they can also be scheduled on E cores when necessary. But background threads aren’t normally allowed to run on P cores, even if they’re delayed by the load on the E cores they’re restricted to. We know this from our inability to promote existing background threads to run on P cores using St. Clair Software’s App Tamer and the command tool taskpolicy . This is why, even if you sit and watch all those background processes loading the E cores immediately after starting up, leaving the P cores mostly idle, macOS won’t try running them on its P cores. If it did, even if you wanted it to, the distinction between foreground and background, P and E cores would start to fall apart, our apps would suffer as a consequence, and battery endurance would decline. Gone are the days of crashing mdworker processes bringing our Macs to their knees with a spinning beachball every few seconds. If seeing all those processes using high % CPU can look scary, the inevitable consequence in terms of software architecture might seem terrifying. Rather than building monolithic apps, many of their tasks are now broken out into discrete processes run in the background on demand, on the E cores when appropriate. The fact that an idle Mac has over 2,000 threads running in over 600 processes is good news, and the more of those that are run on the E cores, the faster our apps will be. The first and last M-series chips to have only two E cores were the M1 Pro and Max, since when every one has had at least four E cores, and some as many as six or eight. Because Efficiency cores get the background threads off the cores we need for performance.",
      "cover_image_url": "https://eclecticlight.co/wp-content/uploads/2024/11/handecpuhistory.jpg"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "I Have Fallen in Love With Open Earbuds (and You Should Too)",
      "url": "https://www.wired.com/story/why-open-earbuds-are-my-favorite-new-category/",
      "published": "2026-02-08T11:30:00+00:00",
      "summary": "From jogging and cycling to multitasking or puttering around the house, open earbuds are an excellent way to jam out in the real world.",
      "content_text": "If you’ve done any wireless earbuds shopping lately, you’ve likely noticed a new design category cropping up everywhere. They’re called open earbuds (or open-ear buds, depending on the brand), and just about every audio brand has a pair (or three). They come in a slew of styles, but most either loop around your ears like older Beats buds , or clip on like funky-futuristic earrings. Whatever the style, they're designed to deliver satisfying sound while keeping your ear canals open to the sounds of the world around you. Open earbuds are a natural fit for staying aware during outdoor activities like jogging, hiking, and especially cycling, where the tiny microphones in traditional buds are rendered useless by wind. They don't sound as full or detailed as regular earbuds, but the best open earbuds can sound quite good. Buying such a specified item might seem extravagant when buds with noise-canceling and transparency modes work in the vast majority of scenarios. That was my stance at first, too. Like many things in life: sometimes you need to try something in real life to see if you'll like it. Over the last year or so, I’ve gone from open earbuds skeptic to evangilizer—and now I can’t imagine living without them. That New Sound Photograph: Ryan Waniata “Occlusion” is mostly a foreign word outside audio circles, but it describes that plugged-up feeling you get from traditional earbuds. The best wireless earbuds counter occlusion with venting and other design factors, but you can’t fully outswerve physics, and most of us get tired of blocking our ear canals after a few hours. Open earbuds (along with solutions like bone conducting headphones ) fix the occlusion problem, with sound that seems to pop into your head like magic. The airy designs of my favorite pairs from brands like Bose and Soundcore are so comfy I can wear them all day, often forgetting they’re on. Comfort alone wasn’t enough to sell me on an entire genre of buds you can’t use in loud places, but as it turns out, that’s rarely a problem. As WIRED’s primary open earbuds reviewer, the more time I spend with these buds, the more use cases seem to unfold before me. From the complications of life to my ever-fraying attention span, open earbuds meet me where I live. My main use case is probably also yours: I love using them for outdoor activities, from keeping in touch with my neighborhood while enjoying Comedy Bang Bang on a dog walk to blissfully grooving to my favorite Yacht Rock playlist on an ebike test ride. But that’s actually just the beginning.",
      "cover_image_url": "https://media.wired.com/photos/6987bace169b47a250342742/191:100/w_1280,c_limit/I%20Have%20Fallen%20in%20Love%20With%20Open%20Earbuds%20(and%20You%20Should%20Too).png"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "Best Vacuum Cleaner (2026): Cordless Vacuums, Robot Vacuums, Dysons",
      "url": "https://www.wired.com/gallery/best-vacuum-cleaner/",
      "published": "2026-02-08T11:09:00+00:00",
      "summary": "Looking for all our top recommended vacuums? Here are our favorites in every style we’ve tested, from stick vacs to robot vacuums.",
      "content_text": "Comparing Our Favorite Vacuum Cleaners Honorable Mentions Bissell PowerClean FurFinder for $210 : This was our previous top pick for cordless vacuums, and it's still a great affordable stick vacuum. But if you're looking for a cheap option, the regular Bissell PowerClean ($200) is a touch cheaper since it doesn't come with the FurFinder upholstery attachment, while Dyson and Ryobi's vacuums have more powerful suction for pet hair. Black and Decker Dustbuster Flex for $95 : This is another cool handheld vacuum that's great for cars, or even indoor areas like staircases. It has a 4-foot hose, longer than most compact vacuums, and has a handy little charging mount that the accessories clip into. And thank goodness for the charging mount, since the battery only lasts 15 minutes. Dyson Car+Boat Handheld Vacuum for $290 : Dyson's latest handheld vacuum was designed specifically for cars (and boats!) in mind, so if you have a vehicle to clean, this is made for it. It's got a fantastic battery life compared to other handheld vacuums. Dyson Gen5 Detect Cordless Vacuum for $800 : This is Dyson's current top-of-the-line stick vacuum, and it's fantastic, especially for homes with a lot of pet hair. But it's expensive and rarely on sale, making it a hard upgrade when you'll still get a great experience with the Dyson V15 Detect. But this vacuum does have a HEPA filter, while the V15 Detect does not. Ecovacs Deebot X11 Omnicyclone for $999 : If you want a newer robot vacuum, the Ecovacs Deebot X11 Omnicyclone has a unique design with no dust bag. Instead, it has a rounded canister like a Dyson or stick vacuum, circling the debris to keep it from tangling. It's a good design and this is overall a great robot vacuum, especially if you don't want to buy dust bags over and over. Roborock Qrevo S for $350 (used): This was our previous top robot vacuum pick, but Roborock updated the Qrevo line with new models that aren't shipping to the United States, and the model we liked best is only available secondhand. Tineco Pure One Station 5 for $459 : If you want a cordless stick vacuum but don't want to deal with emptying it all the time, this Tineco vacuum comes with a self-emptying docking station. You'll eventually have to empty the station, but it's a great bonus feature and keeps the vacuum from falling over around your home since it's stored safely in the docking station. FAQs Which Style Vacuum Is Right for You? AccordionItemContainerButton Here's what makes each style of vacuum great to help you choose which one you should buy. Cordless Vacuums or Stick Vacuums: These vacuums look like the latter name suggests, with a long, sticklike arm that connects the vacuum head to the canister and controls. You'll need to hold this up in a way you wouldn't have to with an upright vacuum, but these are powerful and super mobile. They make for a great main vacuum, and are especially great if you have multiple floors to vacuum since it's easy to carry these up and down stairs. Robot Vacuums: Robot vacuums are great for cleaning for you, and are controlled with an app. There are several models that double as a mop, too. You'll have to spend time moving furniture for the best clean possible, and you usually still want a regular vacuum of some kind in your home. But these are great for frequent cleans with kids and pets. Handheld Vacuums: Handheld vacuums are great for targeted cleans, or cleaning specific places like stairs and cars. Most stick vacuums can transform into a handheld vacuum, but true handhelds are much lighter and have a more compact design (but also sacrifice battery power and dustbin capacity). What About Upright Vacuums? AccordionItemContainerButton An upright vacuum is the classic, original vacuum style that sits straight up on its own and is much heavier than a cordless stick vacuum, and requires an outlet connection to work. We currently don't have an upright vacuum we recommend, since cordless stick vacuums have become the main focus for most shoppers (and as frequent vacuumers ourselves, we usually reach for cordless and robot vacuums anyway). We're considering upright vacuums to test in the future, however, so feel free to comment on this guide with models we should consider. Do You Need a Stick Vacuum and a Handheld Vacuum? AccordionItemContainerButton Do you need a handheld vacuum if you already have a cordless vacuum? Likely no, because most stick vacuums can transform into a handheld vacuum already. Stick or cordless vacuums usually allow you to remove the stick part from between the vacuum head and canister base and instead connect those two pieces directly, making it into a handheld vacuum. It'll be much heavier than a vacuum designed to always be handheld, and might be irritating if you have a specific use case you want it for, but you don't need both unless there's a specific reason. A handheld is a good add-on if you already have an upright vacuum you love that doesn't need replacing. How Often Should You Replace Your Vacuum? AccordionItemContainerButton Vacuums last about five years, depending on the use frequency and build quality. Some cheaper stick vacuums might only last about a year or two, though, so it's worth investing in a better vacuum than finding a cheap dupe. If you're curious what signs might indicate your vacuum needs replacing, check out our guide to how long vacuums can last . Power up with unlimited access to WIRED . Get best-in-class reporting and exclusive subscriber content that's too important to ignore. Subscribe Today .",
      "cover_image_url": "https://media.wired.com/photos/6987b3b03f3860972bce84f2/191:100/w_1280,c_limit/Update-%20All%20the%20Best%20Vacuum%20Cleaners%20We've%20Ever%20Tried.png"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "For $4,550, Would You Buy a Single Premium Watch or a Swarm of Affordable Ones?",
      "url": "https://www.wired.com/story/for-4550-would-you-buy-single-premium-watch-or-swarm-of-affordable-ones/",
      "published": "2026-02-08T11:00:00+00:00",
      "summary": "You could go all in on one pricey, luxe watch or assemble a collection of lower-budget timepieces. Let’s crunch the numbers.",
      "content_text": "To be a viable alternative to our GADA Tudor, the value collection has to include a travel-time watch. We looked at Farer’s 36-mm Lander IV , with its preppy color scheme and distinctive character, but ultimately we went for another cult favorite from the affordable end of the Swatch Group stable. The Mido Ocean Star Decompression Worldtimer costs $5 less than the Farer, at $1,490, and brings its own eye-catching dial to the table, as well as a 200-meter water resistance rating and a version of the same 80-hour movement as in the Hamilton. Perhaps the clincher was the world-time bezel, which shouldn’t be confused with a true mechanical world-time complication, but does give at-a-glance timekeeping around the world. So far we’ve spent $3,905, which means we still have $645 burning a hole in our pocket. The obvious gap in this collection is a chronograph of some kind. It would give us the decisive edge over the Black Bay, but for this budget most mechanical chronographs are out of reach. We could buy a MoonSwatch —in fact, at $285 we could buy two and have enough left for the Uber home—but we’re on our mission to find something more substantial, more interesting, and (let’s face it) more likely to stand the test of time. And that something is the Brew Super Metric ($475), a hybrid mecha-quartz chrono from a New York microbrand with more personality than every MoonSwatch put together. The unashamedly loud retro styling isn’t for everyone, but we think that the cushion-shaped case and steel bracelet help broaden our stylistic options, and although it’s not a pedigree mechanical chronograph, it costs less than $500 while looking and feeling like no one’s idea of a compromise. That brings the challengers to a grand total of $4,380, which means we’d be able to buy a six-watch case to keep our collection in (of course it’s got space for one more …) and maybe even a couple of spare straps. There’s no doubt the Tudor is in a different league, but could a crack squad of specialists tempt you to part with $4,550? Or will the lure of singular luxe prove too tempting? Over to you. It's decision time.",
      "cover_image_url": "https://media.wired.com/photos/698093a5fc89418254fc4e19/191:100/w_1280,c_limit/013026_GEAR-TIME-Collection-Top-Art.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "(AI) Slop Terrifies Me",
      "url": "https://ezhik.jp/ai-slop-terrifies-me/",
      "published": "2026-02-08T10:31:35+00:00",
      "summary": "<p>Article URL: <a href=\"https://ezhik.jp/ai-slop-terrifies-me/\">https://ezhik.jp/ai-slop-terrifies-me/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46933067\">https://news.ycombinator.com/item?id=46933067</a></p> <p>Points: 165</p> <p># Comments: 146</p>",
      "content_text": "(AI) Slop Terrifies Me ðŸ¦” ðŸ¦” ðŸ¦” What if this is as good as software is ever going to be? What if AI stops getting better and what if people stop caring? All em dashes in this post are organically-made. Imagine if this is as good as AI gets. If this is where it stops, you'd still have models that can almost code a web browser, almost code a compilerâ€”and can even present a pretty cool demo if allowed to take a few shortcuts. You'd still get models that can kinda-sorta simulate worlds and write kinda-sorta engaging stories. You'd still get self-driving cars that almost work, except when they don't. You get AI that can make you like 90% of a thing! 90% is a lot. Will you care about the last 10%? I'm terrified that you won't. I'm terrified of the good enough to ship â€”and I'm terrified of nobody else caring. I'm less afraid of AI agents writing apps that they will never experience than I am of the AI herders who won't care enough to actually learn what they ship. And I sure as hell am afraid of the people who will experience the slop and will be fine with it. As a woodworking enthusiast I am slowly making my peace with standing in the middle of an IKEA. But at the rate things are going in this dropshipping hell, IKEA would be the dream. Software temufication stings much more than software commoditization. Are these the same needles in my heart that older programmers had when IDEs became mainstream? I think Claude and friends can help with crafting good software and with learning new technologies and programming languagesâ€”though I sure as hell move slower when I stop to learn and understand than the guy playing Dwarf Fortress with 17 agents. But at the same time AI models seem to constantly nudge towards that same median Next-React-Tailwind, good enough app. These things just don't handle going off the beaten path well. Spend all the tokens you want, trying to make something unique like Paper by FiftyThree with AI tools will just end up looking normal and uninspired. Mind you, it's not like slop is anything new. A lot of human decisions had to happen before your backside ended up in an extremely uncomfortable chair, your search results got polluted by poorly-written SEO-optimized articles, and your brain had to deal with a ticket booking website with a user interface so poorly designed that it made you cry. So it's a people problem. Incentives just don't seem to align to make good software. Move fast and break things, etc, etc. You'll make a little artisan app, and if it's any good, Google will come along with a free clone, kill you, then kill its cloneâ€”and the world will be left with net zero new good software. And now, with AI agents, it gets even worse as agent herders can do the same thing much faster. Developers aside, there's also the users. AI models can't be imaginative, and the developers can't afford to, but surely with AI tools, the gap between users and developers will be bridged, ChatGPT will become the new HyperCard and people will turn their ideas into reality with just a few sentences? There's so many people out there who are coding without knowing it, from Carol in Accounting making insane Excel spreadsheets to all the kids on TikTok automating their phones with Apple Shortcuts and hacking up cool Notion notebooks. But what if those people are an aberration? What if this state of tech learned helplessness cannot be fixed? What if people really do just want a glorified little TV in their pocket? What if most people truly just don't care about tech problems, about privacy, about Liquid Glass, about Microsoft's upsells, about constantly dealing with apps and features which just don't work ? What if there will be nobody left to carry the torch? What if the future of computing belongs not to artisan developers or Carol from Accounting, but to whoever can churn out the most software out the fastest? What if good enough really is good enough for most people? I'm terrified that our craft will die, and nobody will even care to mourn it. ðŸ¦” ðŸ¦” ðŸ¦” 2026-02-08 â€¢ Discuss on Mastodon â€¢ Discuss on Bluesky",
      "cover_image_url": "https://ezhik.jp/assets/thumbnails/bro-you-had-chatgpt-write-the-get-well-card-for-your-grandma.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Curating a Show on My Ineffable Mother, Ursula K. Le Guin",
      "url": "https://hyperallergic.com/curating-a-show-on-my-ineffable-mother-ursula-k-le-guin/",
      "published": "2026-02-08T10:13:00+00:00",
      "summary": "<p>Article URL: <a href=\"https://hyperallergic.com/curating-a-show-on-my-ineffable-mother-ursula-k-le-guin/\">https://hyperallergic.com/curating-a-show-on-my-ineffable-mother-ursula-k-le-guin/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46932985\">https://news.ycombinator.com/item?id=46932985</a></p> <p>Points: 69</p> <p># Comments: 18</p>",
      "content_text": "PORTLAND — Under an acrylic case in an exhibition I curated about my mother, the writer Ursula K. Le Guin (1929–2018), sits the first typewriter she purchased. Compact and impossibly heavy, the machine comes from an era of word production so distant as to feel alien. The keyboard has no exclamation point. To create the favorite punctuation of tyrants and optimists, one must type an apostrophe, then backspace and type a period. The Underwood waited in my parents’ attic for decades as Ursula and the world moved on to electronic typewriters and eventually to computers. I hoped visitors to A Larger Reality , at Oregon Contemporary through February 8, could experience a little of the residual magic that I find clings to it, pecking out whatever they please, taking home the original and leaving a carbon copy for posterity. Ursula K. Le Guin's Underwood typewriter (photo by Mario Gallucci, courtesy Oregon Contemporary) I’m happiest when the case is removed and the gallery is filled with the sound of metal meeting paper. Visitors who’ve never used a manual typewriter, or who don’t touch type, peck tentatively. Others engage physically, producing the familiar percussive clack-clack sound of my childhood. Either way, I feel I’m sharing not just a machine but a sacred trust with strangers who love my mother’s writing and words in general . People type poetry, memoir, fiction, epistles, articles, political statements, and fan mail on the Underwood. Some offer short tributes to Ursula or variations on “I can’t believe I’m typing on Ursula K. Le Guin’s typewriter.” Others compose prose or poetry on the spot. A few write nothing, go home to draft several pages, and return later to type something polished. A scan of one of Le Guin's replies to fan mail (image courtesy Ursula K. Le Guin Foundation) One visitor’s letter wondered how Ursula would feel knowing that her writing and cultural presence are no longer her own after death. The question is apt for me as curator and literary executor. Even a very private writer, while she is alive, exercises a restraining influence on people’s ability to misinterpret her words or life story. I can take comfort in my mother’s respect for the agency and necessity of readers in creating literature. For many years, her stock fan mail reply was a thank-you note, in her handwriting, acknowledging that “a book is just a box of words until a reader opens it.” Over the past year, I’ve experienced cycles of grief and joy as I pored over my mother’s letters, manuscripts, and drawings to exhibit. I listened to hours of her voice, recreated an oak tree from her childhood and the room she wrote in from my childhood home. Curating an exhibition about your parent is a strange experience. Many visitors intuit this; the most common question I’m asked about the exhibition is what my mother would think about it. Muralist Ursula Barton's 38-foot-long (~11.6-meter-long) painting of a dragon on the gallery walls (photo by Mario Gallucci, courtesy Oregon Contemporary) Honestly, I have no idea. I’ve learned not to second-guess my decisions by constantly asking myself, “What would Ursula do?” I would never have proposed this exhibition in her lifetime, for fear that she might see it as reductionist. This is, after all, a writer who said in an interview , “Don’t shove me into your damn pigeonhole, where I don’t fit, because I’m all over. My tentacles are coming out of the pigeonhole in all directions.” Biographical and retrospective exhibitions exist in large part to assert and codify who an artist is. That is, at some level, a type of pigeon-holing. This icon-production takes various forms, from hagiography to “objective” centrism to critique. True, if anyone is going to codify my mother, I prefer it to be me. I’m granted an advantage due to proximity and memory. But my version of Ursula is just one version. Even her version of herself was not authoritative. My mother remade herself, through her art, constantly and over decades. She revised everything from her early centering of male characters, to her use of he/him as the default pronoun in an imagined ambisexual world, to her critique of a Kazuo Ishiguro novel. Rather than worship an immutable icon, we should aspire to her willingness to learn and change. Installation view of A Larger Reality at Oregon Contemporary (photo by Mario Gallucci, courtesy Oregon Contemporary) From a technical, curatorial perspective, however, the mandate of narrative was my greatest hindrance. We’ve had it drummed into us that humans learn through stories, so anyone in an educative role must tell a story. For biographical exhibitions, however, linearity flattens the subject and condescends to the audience. I would go so far as to say this may be true for linearity imposed on any kind of exhibition. My mother had something useful to say on this subject. Her essay The Carrier Bag Theory of Fiction (1986) , long a touchstone for writers, has recently become one for curators as well. Ursula posits, to simplify, that the reduction of narrative to linear, techno-heroic stories of conflict and conquest doesn’t serve us well. The hero’s journey remains a default model for storytelling in our culture, including for exhibitions. Ursula argues that the carrier bag, a humble yet capacious tool for gathering, is a better model for storytelling. The scales on Barton's dragon mural contain snippets of photos, book covers, and other visual ephemera from Le Guin's life. (photo by Mario Gallucci, courtesy Oregon Contemporary) Exhibitions can be superb carrier bags for culture and knowledge. Few experiences offer so many chances for discursion and recursion, negative space and introspection. A carrier bag can expand to make room for the needs of the moment, for participation, spectacle, and immersion. In a carrier bag, none of these qualities, in balance, is antithetical. For my part, releasing myself from the need to tell a tidy story about my mother led to an exhibition that is wordy, baggy, and inconclusive — but also, I believe, engaging and true to the subject.",
      "cover_image_url": "https://hyperallergic.com/content/images/2026/01/0315_ORE_70s_uklwtheo-1.JPG"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "joshuanwalker/Raiders2600: Reverse Engineering Raiders of the Lost Ark for the Atari 2600",
      "url": "https://github.com/joshuanwalker/Raiders2600",
      "published": "2026-02-08T09:10:18+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.com/joshuanwalker/Raiders2600\">https://github.com/joshuanwalker/Raiders2600</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46932678\">https://news.ycombinator.com/item?id=46932678</a></p> <p>Points: 49</p> <p># Comments: 1</p>",
      "content_text": "joshuanwalker/Raiders2600 You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/17522e46d925595d1ad56039c713c3e047d265b4ac893abe7db4acf7cb2fe600/joshuanwalker/Raiders2600"
    }
  ]
}