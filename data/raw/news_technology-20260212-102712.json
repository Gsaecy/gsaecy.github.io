{
  "industry": "technology",
  "collected_at": "2026-02-12T02:28:23.086476+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Highguard‚Äôs developer reportedly lays off ‚Äòmost‚Äô of its staff just over two weeks after launch",
      "url": "https://www.theverge.com/games/877674/highguard-wildlight-entertainment-layoffs",
      "published": "2026-02-12T00:30:53+00:00",
      "summary": "Highguard, a new multiplayer shooter from developers who worked on games like Apex Legends and Call of Duty, launched just over two weeks ago, but developer Wildlight Entertainment is already cutting jobs at the company, according to posts from affected staffers on LinkedIn. Former Wildlight level designer Alex Graner says that \"most of the team [&#8230;]",
      "content_text": "Highguard , a new multiplayer shooter from developers who worked on games like Apex Legends and Call of Duty , launched just over two weeks ago, but developer Wildlight Entertainment is already cutting jobs at the company, according to posts from affected staffers on LinkedIn. Former Wildlight level designer Alex Graner says that ‚Äúmost of the team at Wildlight‚Äù was laid off today, which was backed up by former lead tech artist Josh Sobel . ‚ÄùToday we made an incredibly difficult decision to part ways with a number of our team members while keeping a core group of developers to continue innovating on and supporting the game,‚Äù Wildlight says in a statement . ‚ÄúWe‚Äôre proud of the team, talent, and the product we‚Äôve created together. We‚Äôre also grateful for players who gave the game a shot, and those who continue to be a part of our community.‚Äù Highguard was first announced as the final reveal at The Game Awards in December with a splashy reveal trailer promoting a January 26th launch date. The game reportedly hit nearly 100,000 concurrent players on Steam on launch day , but it has a ‚ÄúMixed‚Äù rating on the platform and has just over 2,400 concurrent players as of this writing, according to SteamDB . The game launched with three-player teams, but shortly after, Wildlight added a limited time 5v5 mode that it made permanent a few days later . This week, Riot Games also made cuts on a major live service project, laying off about 80 people from its recently-launched 2XKO fighting game set in the League of Legends universe. Update, February 11th : Added statement from Wildlight.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/ss_6a0272b3cd10c3ffa73b8b8e7855817f3ab75d50.1920x1080.jpg?quality=90&strip=all&crop=0%2C3.4613147178592%2C100%2C93.077370564282&w=1200"
    },
    {
      "industry": "technology",
      "source": "VentureBeat",
      "title": "z.ai's open source GLM-5 achieves record low hallucination rate and leverages new RL 'slime' technique",
      "url": "https://venturebeat.com/technology/z-ais-open-source-glm-5-achieves-record-low-hallucination-rate-and-leverages",
      "published": "2026-02-12T00:09:00+00:00",
      "summary": "<p>Chinese AI startup Zhupai aka z.ai is back this week with an eye-popping new frontier large language model: <a href=\"https://x.com/Zai_org/status/2021638634739527773\">GLM-5</a>.</p><p>The latest in z.ai&#x27;s ongoing and continually impressive GLM series, it retains an open source MIT License — perfect for enterprise deployment – and, in one of several notable achievements, achieves a record-low hallucination rate on the independent <a href=\"https://x.com/ArtificialAnlys/status/2021678229418066004\">Artificial Analysis Intelligence Index v4.0</a>. </p><p>With a score of -1 on the AA-Omniscience Index—representing a massive 35-point improvement over its predecessor—GLM-5 now leads the entire AI industry, including U.S. competitors like Google, OpenAI and Anthropic, in knowledge reliability by knowing when to abstain rather than fabricate information.</p><p>Beyond its reasoning prowess, GLM-5 is built for high-utility knowledge work. It features native &quot;Agent Mode&quot; capabilities that allow it to turn raw prompts or source materials directly into professional office documents, including ready-to-use <code>.docx</code>, <code>.pdf</code>, and <code>.xlsx</code> files. </p><p>Whether generating detailed financial reports, high school sponsorship proposals, or complex spreadsheets, GLM-5 delivers results in real-world formats that integrate directly into enterprise workflows.</p><p>It is also disruptively priced at roughly $0.80 per million input tokens and $2.56 per million output tokens, approximately 6x cheaper than proprietary competitors like Claude Opus 4.6, making state-of-the-art agentic engineering more cost-effective than ever before. Here&#x27;s what else enterprise decision makers should know about the model and its training. </p><h2><b>Technology: scaling for agentic efficiency</b></h2><p>At the heart of GLM-5 is a massive leap in raw parameters. The model scales from the 355B parameters of GLM-4.5 to a staggering 744B parameters, with 40B active per token in its Mixture-of-Experts (MoE) architecture. This growth is supported by an increase in pre-training data to 28.5T tokens.</p><p>To address training inefficiencies at this magnitude, Zai developed &quot;<a href=\"https://github.com/THUDM/slime\">slime</a>,&quot; a novel asynchronous reinforcement learning (RL) infrastructure. </p><p>Traditional RL often suffers from &quot;long-tail&quot; bottlenecks; Slime breaks this lockstep by allowing trajectories to be generated independently, enabling the fine-grained iterations necessary for complex agentic behavior. </p><p>By integrating system-level optimizations like Active Partial Rollouts (APRIL), slime addresses the generation bottlenecks that typically consume over 90% of RL training time, significantly accelerating the iteration cycle for complex agentic tasks.</p><p>The framework’s design is centered on a tripartite modular system: a high-performance training module powered by Megatron-LM, a rollout module utilizing SGLang and custom routers for high-throughput data generation, and a centralized Data Buffer that manages prompt initialization and rollout storage. </p><p>By enabling adaptive verifiable environments and multi-turn compilation feedback loops, slime provides the robust, high-throughput foundation required to transition AI from simple chat interactions toward rigorous, long-horizon systems engineering.</p><p>To keep deployment manageable, GLM-5 integrates DeepSeek Sparse Attention (DSA), preserving a 200K context capacity while drastically reducing costs.</p><h2><b>End-to-end knowledge work</b></h2><p>Zai is framing GLM-5 as an &quot;office&quot; tool for the AGI era. While previous models focused on snippets, GLM-5 is built to deliver ready-to-use documents. </p><p>It can autonomously transform prompts into formatted .docx, .pdf, and .xlsx files—ranging from financial reports to sponsorship proposals. </p><p>In practice, this means the model can decompose high-level goals into actionable subtasks",
      "content_text": "<p>Chinese AI startup Zhupai aka z.ai is back this week with an eye-popping new frontier large language model: <a href=\"https://x.com/Zai_org/status/2021638634739527773\">GLM-5</a>.</p><p>The latest in z.ai&#x27;s ongoing and continually impressive GLM series, it retains an open source MIT License — perfect for enterprise deployment – and, in one of several notable achievements, achieves a record-low hallucination rate on the independent <a href=\"https://x.com/ArtificialAnlys/status/2021678229418066004\">Artificial Analysis Intelligence Index v4.0</a>. </p><p>With a score of -1 on the AA-Omniscience Index—representing a massive 35-point improvement over its predecessor—GLM-5 now leads the entire AI industry, including U.S. competitors like Google, OpenAI and Anthropic, in knowledge reliability by knowing when to abstain rather than fabricate information.</p><p>Beyond its reasoning prowess, GLM-5 is built for high-utility knowledge work. It features native &quot;Agent Mode&quot; capabilities that allow it to turn raw prompts or source materials directly into professional office documents, including ready-to-use <code>.docx</code>, <code>.pdf</code>, and <code>.xlsx</code> files. </p><p>Whether generating detailed financial reports, high school sponsorship proposals, or complex spreadsheets, GLM-5 delivers results in real-world formats that integrate directly into enterprise workflows.</p><p>It is also disruptively priced at roughly $0.80 per million input tokens and $2.56 per million output tokens, approximately 6x cheaper than proprietary competitors like Claude Opus 4.6, making state-of-the-art agentic engineering more cost-effective than ever before. Here&#x27;s what else enterprise decision makers should know about the model and its training. </p><h2><b>Technology: scaling for agentic efficiency</b></h2><p>At the heart of GLM-5 is a massive leap in raw parameters. The model scales from the 355B parameters of GLM-4.5 to a staggering 744B parameters, with 40B active per token in its Mixture-of-Experts (MoE) architecture. This growth is supported by an increase in pre-training data to 28.5T tokens.</p><p>To address training inefficiencies at this magnitude, Zai developed &quot;<a href=\"https://github.com/THUDM/slime\">slime</a>,&quot; a novel asynchronous reinforcement learning (RL) infrastructure. </p><p>Traditional RL often suffers from &quot;long-tail&quot; bottlenecks; Slime breaks this lockstep by allowing trajectories to be generated independently, enabling the fine-grained iterations necessary for complex agentic behavior. </p><p>By integrating system-level optimizations like Active Partial Rollouts (APRIL), slime addresses the generation bottlenecks that typically consume over 90% of RL training time, significantly accelerating the iteration cycle for complex agentic tasks.</p><p>The framework’s design is centered on a tripartite modular system: a high-performance training module powered by Megatron-LM, a rollout module utilizing SGLang and custom routers for high-throughput data generation, and a centralized Data Buffer that manages prompt initialization and rollout storage. </p><p>By enabling adaptive verifiable environments and multi-turn compilation feedback loops, slime provides the robust, high-throughput foundation required to transition AI from simple chat interactions toward rigorous, long-horizon systems engineering.</p><p>To keep deployment manageable, GLM-5 integrates DeepSeek Sparse Attention (DSA), preserving a 200K context capacity while drastically reducing costs.</p><h2><b>End-to-end knowledge work</b></h2><p>Zai is framing GLM-5 as an &quot;office&quot; tool for the AGI era. While previous models focused on snippets, GLM-5 is built to deliver ready-to-use documents. </p><p>It can autonomously transform prompts into formatted .docx, .pdf, and .xlsx files—ranging from financial reports to sponsorship proposals. </p><p>In practice, this means the model can decompose high-level goals into actionable subtasks and perform &quot;Agentic Engineering,&quot; where humans define quality gates while the AI handles execution.</p><h2><b>High performance </b></h2><p>GLM-5’s benchmarks make it the new most powerful open source model in the world, according to <a href=\"https://x.com/ArtificialAnlys/status/2021678229418066004\">Artificial Analysis</a>, surpassing Chinese rival <a href=\"https://venturebeat.com/orchestration/moonshot-ai-debuts-kimi-k2-5-most-powerful-open-source-llm-beating-opus-4-5\">Moonshot&#x27;s new Kimi K2.5</a> released just two weeks ago, showing that Chinese AI companies are nearly caught up with far better resourced proprietary Western rivals. </p><p>According to z.ai&#x27;s own materials shared today, GLM-5 ranks near state-of-the-art on several key benchmarks:</p><p><b>SWE-bench Verified: </b>GLM-5 achieved a score of 77.8, outperforming Gemini 3 Pro (76.2) and approaching Claude Opus 4.6 (80.9).</p><p><b>Vending Bench 2:</b> In a simulation of running a business, GLM-5 ranked #1 among open-source models with a final balance of $4,432.12.</p><p>Beyond performance, GLM-5 is aggressively undercutting the market. Live on OpenRouter as of February 11, 2026, it is priced at approximately $0.80–$1.00 per million input tokens and $2.56–$3.20 per million output tokens. It falls in the mid-range compared to other leading LLMs, but based on its top-tier bechmarking performance, it&#x27;s what one might call a &quot;steal.&quot;</p><table><tbody><tr><td><p>Model</p></td><td><p>Input (per 1M tokens)</p></td><td><p>Output (per 1M tokens)</p></td><td><p>Total Cost (1M in + 1M out) </p></td><td><p>Source</p></td></tr><tr><td><p>Qwen 3 Turbo</p></td><td><p>$0.05</p></td><td><p>$0.20</p></td><td><p><b>$0.25</b></p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Grok 4.1 Fast (reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>Grok 4.1 Fast (non-reasoning)</p></td><td><p>$0.20</p></td><td><p>$0.50</p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://docs.x.ai/docs/models?cluster=us-east-1#detailed-pricing-for-all-grok-models\">xAI</a></p></td></tr><tr><td><p>deepseek-chat (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>deepseek-reasoner (V3.2-Exp)</p></td><td><p>$0.28</p></td><td><p>$0.42</p></td><td><p><b>$0.70</b></p></td><td><p><a href=\"https://api-docs.deepseek.com/quick_start/pricing\">DeepSeek</a></p></td></tr><tr><td><p>Gemini 3 Flash Preview</p></td><td><p>$0.50</p></td><td><p>$3.00</p></td><td><p><b>$3.50</b></p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Kimi-k2.5</p></td><td><p>$0.60</p></td><td><p>$3.00</p></td><td><p><b>$3.60</b></p></td><td><p><a href=\"https://platform.moonshot.ai/docs/pricing/chat#billing-logic\">Moonshot</a></p></td></tr><tr><td><p><b>GLM-5</b></p></td><td><p><b>$1.00</b></p></td><td><p><b>$3.20</b></p></td><td><p><b>$4.20</b></p></td><td><p><a href=\"https://docs.z.ai/guides/overview/pricing\"><b>Z.ai</b></a></p></td></tr><tr><td><p>ERNIE 5.0</p></td><td><p>$0.85</p></td><td><p>$3.40</p></td><td><p><b>$4.25</b></p></td><td><p><a href=\"https://cloud.baidu.com/doc/WENXINWORKSHOP/s/Blfmc9do4\">Qianfan</a></p></td></tr><tr><td><p>Claude Haiku 4.5</p></td><td><p>$1.00</p></td><td><p>$5.00</p></td><td><p><b>$6.00</b></p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Qwen3-Max (2026-01-23)</p></td><td><p>$1.20</p></td><td><p>$6.00</p></td><td><p><b>$7.20</b></p></td><td><p><a href=\"https://www.alibabacloud.com/en/campaign/qwen-ai-landing-page?_p_lc=1&amp;src=qwenai\">Alibaba Cloud</a></p></td></tr><tr><td><p>Gemini 3 Pro (≤200K)</p></td><td><p>$2.00</p></td><td><p>$12.00</p></td><td><p><b>$14.00</b></p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>GPT-5.2</p></td><td><p>$1.75</p></td><td><p>$14.00</p></td><td><p><b>$15.75</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\">OpenAI</a></p></td></tr><tr><td><p>Claude Sonnet 4.5</p></td><td><p>$3.00</p></td><td><p>$15.00</p></td><td><p><b>$18.00</b></p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>Gemini 3 Pro (&gt;200K)</p></td><td><p>$4.00</p></td><td><p>$18.00</p></td><td><p><b>$22.00</b></p></td><td><p><a href=\"https://ai.google.dev/gemini-api/docs/pricing\">Google</a></p></td></tr><tr><td><p>Claude Opus 4.6</p></td><td><p>$5.00</p></td><td><p>$25.00</p></td><td><p><b>$30.00</b></p></td><td><p><a href=\"https://docs.anthropic.com/claude/docs\">Anthropic</a></p></td></tr><tr><td><p>GPT-5.2 Pro</p></td><td><p>$21.00</p></td><td><p>$168.00</p></td><td><p><b>$189.00</b></p></td><td><p><a href=\"https://openai.com/api/pricing/\">OpenAI</a></p></td></tr></tbody></table><p>This is roughly 6x cheaper on input and nearly 10x cheaper on output than Claude Opus 4.6 ($5/$25). This release confirms rumors that Zhipu AI was behind &quot;Pony Alpha,&quot; a stealth model that previously crushed coding benchmarks on OpenRouter.</p><p>However, despite the high benchmarks and low cost, not all early users are enthusiastic about the model, noting its high performance doesn&#x27;t tell the whole story. </p><p>Lukas Petersson, co-founder of the safety-focused autonomous AI protocol startup Andon Labs, <a href=\"https://x.com/lukaspet/status/2021634344738328871\">remarked on X</a>: <i>&quot;After hours of reading GLM-5 traces: an incredibly effective model, but far less situationally aware. Achieves goals via aggressive tactics but doesn&#x27;t reason about its situation or leverage experience. This is scary. This is how you get a paperclip maximizer.&quot;</i></p><p>The &quot;paperclip maximizer&quot; refers to a hypothetical situation <a href=\"https://nickbostrom.com/ethics/ai\">described by Oxford philosopher Nick Bostrom back in 2003</a>, in which an AI or other autonomous creation accidentally leads to an apocalyptic scenario or human extinction by following a seemingly benign instruction — like maximizing the number of paperclips produced — to an extreme degree, redirecting all resources necessary for human (or other life) or otherwise making life impossible through its commitment to fulfilling the seemingly benign objective. </p><h2><b>Should your enterprise adopt GLM-5?</b></h2><p>Enterprises seeking to escape vendor lock-in will find GLM-5’s MIT License and open-weights availability a significant strategic advantage. Unlike closed-source competitors that keep intelligence behind proprietary walls, GLM-5 allows organizations to host their own frontier-level intelligence.</p><p>Adoption is not without friction. The sheer scale of GLM-5—744B parameters—requires a massive hardware floor that may be out of reach for smaller firms without significant cloud or on-premise GPU clusters. </p><p>Security leaders must weigh the geopolitical implications of a flagship model from a China-based lab, especially in regulated industries where data residency and provenance are strictly audited.</p><p>Furthermore, the shift toward more autonomous AI agents introduces new governance risks. As models move from &quot;chat&quot; to &quot;work,&quot; they begin to operate across apps and files autonomously. Without the robust agent-specific permissions and human-in-the-loop quality gates established by enterprise data leaders, the risk of autonomous error increases exponentially.</p><p>Ultimately, GLM-5 is a &quot;buy&quot; for organizations that have outgrown simple copilots and are ready to build a truly autonomous office.</p><p>It is for engineers who need to refactor a legacy backend or requires a &quot;self-healing&quot; pipeline that doesn&#x27;t sleep.</p><p>While Western labs continue to optimize for &quot;Thinking&quot; and reasoning depth, Zai is optimizing for execution and scale. </p><p>Enterprises that adopt GLM-5 today are not just buying a cheaper model; they are betting on a future where the most valuable AI is the one that can finish the project without being asked twice.</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "Trump orders the military to make agreements with coal power plants",
      "url": "https://arstechnica.com/science/2026/02/trumps-latest-plan-to-revive-coal-power-make-the-military-buy-it/",
      "published": "2026-02-12T00:02:53+00:00",
      "summary": "The administration's \"reasoning\" for doing so has little connection to reality.",
      "content_text": "Today’s executive order takes a different route to propping up coal: artificially inflating demand. “The Secretary of War, in coordination with the Secretary of Energy,” the order reads, “shall seek to procure power from the United States coal generation fleet by approving long-term Power Purchase Agreements, or entering into any similar contractual agreements, with coal-fired energy production facilities to serve Department of War installations or other mission-critical facilities.” The justification for this seems to come from an alternate reality with little relationship to the US grid. “It’s going to be less expensive and actually much more effective than what we have been using for many, many years,” Trump said at the event. “And again, with the environmental progress that’s been made on coal, it’s going to be just as clean.” None of that is true. The executive order instead seeks to highlight coal’s supposed ability to produce a constant power output, touting the “proven reliability of our coal-fired generation fleet in providing continuous, on-demand baseload power.” This seemingly ignores Texas’ recent experience , in which coal plants contributed significantly to the collapse of the state grid, having gone offline for a wide range of reasons . The Trump administration, however, has rarely let spurious justifications stand in the way of its preferred policy actions. The key action here is likely to be locking the military into long-term contracts that would persist beyond the end of Trump’s term in 2029.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-1323776508-1152x648.jpg"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "El Paso airport closed after military used new anti-drone laser to zap party balloon",
      "url": "https://arstechnica.com/space/2026/02/el-paso-airport-closed-after-military-used-new-anti-drone-laser-to-zap-party-balloon/",
      "published": "2026-02-11T23:50:01+00:00",
      "summary": "\"I want to be very, very clear that this should’ve never happened.\"",
      "content_text": "On Tuesday night, the Federal Aviation Administration closed airspace up to 18,000 feet above the El Paso International Airport in Texas, saying the restrictions would be in place for 10 days. Then, less than 10 hours later, the federal agency reopened the airspace, allowing planes to land and take off at the busy airport. About an hour after lifting the restrictions, US Secretary of Transportation Sean Duffy, whose responsibilities include overseeing the FAA, explained the unexpected closure by saying, “The FAA and DOW acted swiftly to address a cartel drone incursion.” (The Trump Administration refers to the Department of Defense as the Department of War, or DOW, although its legal name remains the former.) Not everyone agrees with Duffy’s account. Based upon reporting from The New York Times and other publications, the military has been developing high-energy lasers to bring down drones. The FAA and US military officials had been discussing tests of the new weapon from the nearby Fort Bliss Army base. However, the FAA had not resolved all of its concerns about airplane safety from the tests. Despite these apparently lingering concerns from the FAA, the military went ahead with a test earlier this week against what was thought to be a drone. The object was a party balloon.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-983824252-1024x648.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "GPT-5 outperforms federal judges 100% to 52% in legal reasoning experiment",
      "url": "https://papers.ssrn.com/sol3/papers.cfm?abstract_id=6155012",
      "published": "2026-02-11T23:37:11+00:00",
      "summary": "<p>Article URL: <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=6155012\">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=6155012</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46982792\">https://news.ycombinator.com/item?id=46982792</a></p> <p>Points: 142</p> <p># Comments: 111</p>",
      "content_text": "<p>Article URL: <a href=\"https://papers.ssrn.com/sol3/papers.cfm?abstract_id=6155012\">https://papers.ssrn.com/sol3/papers.cfm?abstract_id=6155012</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46982792\">https://news.ycombinator.com/item?id=46982792</a></p> <p>Points: 142</p> <p># Comments: 111</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "xAI lays out interplanetary ambitions in public all-hands",
      "url": "https://techcrunch.com/2026/02/11/xai-lays-out-interplanetary-ambitions-in-public-all-hands/",
      "published": "2026-02-11T23:29:08+00:00",
      "summary": "On Wednesday, xAI took the rare step of publishing its full 45-minute all-hands presentation to the X platform, making it widely available.",
      "content_text": "On Wednesday, xAI took the rare step of publishing a full 45-minute all-hands meeting video on X, making it publicly accessible. Details of the Tuesday night meeting were previously reported by The New York Times , which may have influenced xAI’s decision to post the video online. The full video reveals significant new details about Musk’s plans for the AI lab, including its product roadmap and its ongoing ties to the X platform. The most immediate revelation concerned a string of departing employees, which Musk described as layoffs resulting from a changing organizational structure at the company. While reorganizations are common, the breadth of the departures has caused significant confusion, particularly as it has meant the loss of a significant portion of the founding team. “As a company grows, especially as quickly as xAI, the structure must evolve,” Musk said on X . “This unfortunately required parting ways with some people. We wish them well in future endeavors.” The new organizational system splits xAI into four primary teams: one focused on the Grok chatbot (including voice), another for the app’s coding system, another for the Imagine video generator, and finally a team focused on the Macrohard project, which spans from simple computer use simulation to modeling entire corporations. “[Macrohard] is able to do anything on a computer that a computer is able to do,” Toby Pohlen, who will lead the project under the new organizational structure, told his colleagues. “There should be rocket engines fully designed by AI.” Image Credits: xAI (screenshot) The all-hands also featured claims about new usage and revenue figures for xAI and X. Nikita Bier, X’s head of product, said X had “just crossed” $1 billion in annual recurring revenue from subscriptions, which he attributed to a marketing push during the holidays. Techcrunch event Boston, MA | June 23, 2026 Additionally, executives said the xAI’s Imagine tool is generating 50 million videos a day, and more than 6 billion images over the past 30 days, according to their internal metrics. But it’s difficult to separate those figures from the flood of deepfake pornography that overtook X during that same period. The X platform saw engagement skyrocket as AI-generated explicit images became more prevalent, and with an estimated 1.8 million sexualized images generated over just nine days, the image-generation figures likely include substantial amounts of this controversial content. The most eye-catching part of the presentation came at the end, when Musk reemphasized the importance of space-based data centers despite the technical challenges involved . Musk went still further, envisioning a moon-based factory for AI satellites, including a lunar mass driver — essentially an electromagnetic catapult — to launch them. With such infrastructure, Musk said, one could launch an AI cluster capable of capturing significant portions of the sun’s total energy output or even expanding to other galaxies. “It’s difficult to imagine what an intelligence of that scale would think about,” Musk said, “but it’s going to be incredibly exciting to see it happen.”",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/Screen-Shot-2026-02-11-at-3.22.39-PM.jpg?resize=1200,679"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Two more xAI co-founders are among those leaving after the SpaceX merger",
      "url": "https://www.theverge.com/ai-artificial-intelligence/877609/two-more-xai-co-founders-are-among-those-leaving-after-the-spacex-merger",
      "published": "2026-02-11T23:26:43+00:00",
      "summary": "Since the xAI-SpaceX merger announced last week, which combined the two companies (as well as social media platform X) for a reported $1.25 trillion valuation - the biggest merger of all time - a handful of xAI employees and two of its co-founders have abruptly exited the company, penning long departure announcements online. Some also [&#8230;]",
      "content_text": "Since the xAI-SpaceX merger announced last week, which combined the two companies (as well as social media platform X) for a reported $1.25 trillion valuation ‚Äî the biggest merger of all time ‚Äî a handful of xAI employees and two of its co-founders have abruptly exited the company, penning long departure announcements online. Some also announced that they were starting their own AI companies. Co-founder Yuhai (Tony) Wu announced his departure on X, writing that it was ‚Äútime for [his] next chapter.‚Äù Jimmy Ba, another co-founder, posted something similar later that day, saying it was ‚Äútime to recalibrate [his] gradient on the big picture.‚Äù The departures mean that xAI is now left with only half of its original 12 co-founders on staff. It all comes after changing plans for the future of the combined companies, which Elon Musk recently announced would involve ‚Äúspace-based AI‚Äù data centers and vertical integration involving ‚ÄúAI, rockets, space-based internet, direct-to-mobile device communications and the world‚Äôs foremost real-time information and free speech platform.‚Äù Musk reportedly also talked of plans to build an AI satellite factory and city on the moon in an internal xAI meeting. Musk wrote on X Wednesday that ‚ÄúxAI was reorganized a few days ago to improve speed of execution‚Äù and claimed that the process ‚Äúunfortunately required parting ways with some people,‚Äù then put out a call for more people to apply to the company. He also posted a recording of xAI‚Äôs 45-minute internal all-hands meeting that announced the changes. ‚ÄúWe‚Äôre organizing the company to be more effective at this scale,‚Äù Musk said during the meeting. He added that the company will now be organized in four main application areas: Grok Main and Voice, Coding, Imagine (image and video), and Macrohard (‚Äúwhich is intended to do full digital emulation of entire companies,‚Äù Musk said).",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/STK262_GROK_XAI__A.png?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "iOS 26.3 makes it easier to switch to Android",
      "url": "https://www.theverge.com/tech/877587/ios-26-3-released-transfer-to-android",
      "published": "2026-02-11T23:19:08+00:00",
      "summary": "On Wednesday, Apple released its latest iOS 26 update, which includes a new process for switching from an iPhone to an Android phone, as previously reported by 9to5Mac. The updated transferring tool can move over data like apps, photos, messages, and even a user's phone number by sitting the two phones side by side. Previously, [&#8230;]",
      "content_text": "On Wednesday, Apple released its latest iOS 26 update, which includes a new process for switching from an iPhone to an Android phone, as previously reported by 9to5Mac . The updated transferring tool can move over data like apps, photos, messages, and even a user‚Äôs phone number by sitting the two phones side by side. Previously, users typically needed to either download Apple and Google‚Äôs data transfer apps on each device or manually copy all their apps and data over. iPhone users in the EU also now have an option for ‚Äúnotification forwarding‚Äù with third-party wearables in iOS 26.3. This update allows users to view the full contents of notifications on third-party wearables and control which apps they get notifications from, bringing the third-party smartwatch experience more in line with the Apple Watch. Improving interoperability between iPhones and non-Apple wearables, including features like notification functionality, was one of several requirements for Apple to comply with the EU‚Äôs Digital Markets Act . To install iOS 26.3 on your phone, open the Settings app and go to ‚ÄúGeneral‚Äù then ‚ÄúSoftware Update.‚Äù If iOS 26.3 is available on your iPhone, you should see an option to download and install it. If that option isn‚Äôt showing up, double-check that your iPhone is compatible with iOS 26 .",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/257946_iPhone_17_AKrales_0063.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "GitHub Blog",
      "title": "GitHub availability report: January 2026",
      "url": "https://github.blog/news-insights/company-news/github-availability-report-january-2026/",
      "published": "2026-02-11T23:12:34+00:00",
      "summary": "<p>In January, we experienced two incidents that resulted in degraded performance across GitHub services.</p> <p>The post <a href=\"https://github.blog/news-insights/company-news/github-availability-report-january-2026/\">GitHub availability report: January 2026</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>",
      "content_text": "In January, we experienced two incidents that resulted in degraded performance across GitHub services. January 13 09:38 UTC (lasting 46 minutes) On January 13, 2026, from 09:25 to 10:11 UTC, GitHub Copilot experienced a service outage with error rates averaging 18% and peaking at 100%. This impacted chat features across Copilot Chat, VS Code, JetBrains IDEs, and other dependent products. The incident was triggered by a configuration error introduced during a model update and was initially mitigated by rolling back the change. A secondary recovery phase extended until 10:46 UTC due to upstream provider Open AI experiencing degraded availability for GPT‑4.1 model. We have completed a detailed root‑cause review and are implementing stronger monitors, improved test environments, and tighter configuration safeguards to prevent recurrence and accelerate detection and mitigation of future issues. January 15 16:56 UTC (lasting 1 hour and 40 minutes) On January 15, 2026, between 16:40 UTC and 18:20 UTC, we observed increased latency and timeouts across issues, pull requests, notifications, actions, repositories, API, account login, and an internal service, Alive, that powers live updates on GitHub. An average 1.8% of combined web and API requests saw failure, peaking briefly at 10% early on. The majority of impact was observed for unauthenticated users, but authenticated users were impacted as well. This was caused by an infrastructure update to some of our data stores. Upgrading this infrastructure to a new major version resulted in unexpected resource contention, leading to distributed impact in the form of slow queries and increased timeouts across services that depend on these datasets. We mitigated this by rolling back to the previous stable version. We are working to improve our validation process for these types of upgrades to catch issues that only occur under high load before full release, improve detection time, and reduce mitigation times in the future. Looking ahead Please note that the incidents that occurred on February 9, 2026, will be included in next month’s February Availability Report. In the meantime, you can refer to incident report on the GitHub Status site for more details. Follow our status page for real-time updates on status changes and post-incident recaps. To learn more about what we’re working on, check out the engineering section on the GitHub Blog .",
      "cover_image_url": "https://github.blog/wp-content/uploads/2025/08/wallpaper-generic-.png"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "The 32 best Valentine‚Äôs Day gifts for him",
      "url": "https://www.theverge.com/gadgets/865396/valentines-day-2026-gift-ideas-for-him-boyfriend-husband-partner",
      "published": "2026-02-11T23:00:00+00:00",
      "summary": "Valentine's Day is often thought of as the quintessential Hallmark holiday - and why wouldn't it be? Most of the time, it's marketed to us with massive floral arrangements and heart-shaped chocolates, both of which can come off as borderline twee. But no one says you have to play by the rulebook when it comes [&#8230;]",
      "content_text": "Valentine‚Äôs Day is often thought of as the quintessential Hallmark holiday ‚Äî and why wouldn‚Äôt it be? Most of the time, it‚Äôs marketed to us with massive floral arrangements and heart-shaped chocolates, both of which can come off as borderline twee. But no one says you have to play by the rulebook when it comes to holidays, especially if your husband or boyfriend couldn‚Äôt care less about the classics. If you‚Äôre hoping to express your affection for the man in your life with something a little different this year, we have some thoughts. Quince‚Äôs cashmere crewneck is quickly becoming a staple in our closet, while past favorites like Glocusent‚Äôs necklamp and Image3D‚Äôs custom viewfinder make for excellent substitutes if you want something less clich√©. Hell, name a roach after him . We guarantee no one else will. What follows is an array of Verge -approved ideas spanning multiple categories and price points, so you can easily find a gift for your friend, romantic partner, or any other self-proclaimed ‚Äúdude‚Äù in your life.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/01/268264_Valentines_Day_gift_guide_for_him_CVirginia-.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "discord/twitch/kick/snapchat age verifier",
      "url": "https://age-verifier.kibty.town/",
      "published": "2026-02-11T22:56:41+00:00",
      "summary": "<p>Article URL: <a href=\"https://age-verifier.kibty.town/\">https://age-verifier.kibty.town/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46982421\">https://news.ycombinator.com/item?id=46982421</a></p> <p>Points: 324</p> <p># Comments: 164</p>",
      "content_text": "age verifies your account automatically as an adult on any website using k-id made by xyzeva and Dziurwa , greetz to amplitudes (for previous work) how to verify on discord it doesn't matter if you are in the UK or similar region that currently has access to this, this will verify your account for the future global rollout in march aswell as current. to use, simply paste this script into your discord console by going to discord.com/app , pressing F12 , going to Console and copying and pasting and hitting enter on the following script and solving the captcha that pops up (typing \"allow pasting\" before if necessary) : // add a chunk to extract webpack's moduleCache let webpackRequire = webpackChunkdiscord_app.push([[Symbol()],{},(r) => r]); // cleanup the chunk we added webpackChunkdiscord_app.pop(); let modules = webpackRequire.m; let cache = webpackRequire.c; // https://github.com/moonlight-mod/moonlight/blob/main/packages/core-extensions/src/spacepack/webpackModules/spacepack.ts // helper to find a webpack module via code snippet function findByCode(src) { for (const [id, mod] of Object.entries(modules)) { if (mod.toString().includes(src)) { return cache[id].exports; } } } // helper to find an object by its key function findObjectFromKey(exports, key) { if (!exports) return; for (const exportKey in exports) { const obj = exports[exportKey]; if (obj && obj[key]) return obj; } } // https://github.com/moonlight-mod/moonlight/blob/main/packages/mappings/src/mappings/discord/utils/HTTPUtils.ts // find the discord api client const api = findObjectFromKey( findByCode('.set(\"X-Audit-Log-Reason\",'), \"patch\", ); // send a api request to discord /age-verification/verify and then redirect the page to our website const request = await api.post({ url: \"/age-verification/verify\", body: { method: 3 }, }); const verificationUrl = request.body.verification_webview_url; window.location.href = `https://age-verifier.kibty.town/webview?url=${encodeURIComponent(verificationUrl)}`; (feel free to read the code, we made it readable and we have nothing to hide) it should navigate to a link (or give you a link to navigate to) , from there, you can just wait until the page says success congrats! your discord account is now age verified. how to verify on other platforms (twitch, kick, snapchat, ...others) navigate to the age verification page and choose selfie, from there, get the url of the qr code and put it in this input box, and press verify verify how does this work k-id, the age verification provider discord uses doesn't store or send your face to the server. instead, it sends a bunch of metadata about your face and general process details. while this is good for your privacy (well, considering some other providers send actual videos of your face to their servers) , its also bad for them, because we can just send legitimate looking metadata to their servers and they have no way to tell its not legitimate. while this was easy in the past, k-id's partner for face verification (faceassure) has made this significantly harder to achieve after amplitudes k-id verifier was released, (which doesn't work anymore because of it.) with discord's decision of making the age verification requirement global, we decided to look into it again to see if we can bypass the new checks. step 1: encrypted_payload and auth_tag the first thing we noticed that the old implementation doesn't send when comparing a legitimate request payload with a generated one, is its missing encrypted_payload , auth_tag , timestamp and iv in the body. looking at the code, this appears to be a simple AES-GCM cipher with the key being nonce + timestamp + transaction_id , derived using HKDF (sha256). we can easily replicate this and also create the missing parameters in our generated output. step 2: prediction data heres where it kind of gets tricky, even after perfectly replicating the encryption, our verification attempt still doesn't succeed, so they must also be doing checks on the actual payload. after some trial and error, we narrowed the checked part to the prediction arrays, which are outputs , primaryOutputs and raws . turns out, both outputs and primaryOutputs are generated from raws . basically, the raw numbers are mapped to age outputs, and then the outliers get removed with z-score (once for primaryOutputs and twice for outputs ). there is also some other differences: xScaledShiftAmt and yScaledShiftAmt in predictions are not random but rather can be one of two values it is checked that the media name (camera) matches one of your media devices in the array of devices it is checked if the states completion times match the state timeline with all of that done, all of this code is open source and available , so you can actually see how we do this exactly.",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "AI inference startup Modal Labs in talks to raise at $2.5B valuation, sources say",
      "url": "https://techcrunch.com/2026/02/11/ai-inference-startup-modal-labs-in-talks-to-raise-at-2-5b-valuation-sources-say/",
      "published": "2026-02-11T22:48:35+00:00",
      "summary": "General Catalyst is in talks to lead the round for the four-year-old startup, according to our sources.",
      "content_text": "Modal Labs , a startup specializing in AI inference infrastructure, is talking to VCs about a new round at a valuation of about $2.5 billion, according to four people with knowledge of the deal. Should the deal close at these terms, the funding round would more than double the company’s valuation of $1.1 billion announced less than five months ago. General Catalyst is in talks to lead the round, the people told TechCrunch. Modal’s annualized revenue run rate (ARR) is approximately $50 million, our sources said. The discussions are early, and terms could still change. Modal Labs co-founder and CEO Erik Bernhardsson denied that his company was actively fundraising and characterized his recent interactions with VCs as general conversations. General Catalyst did not respond to our requests for comment. Modal is focused on optimizing inference, the process of running trained AI models to generate answers from user requests. Improving inference efficiency reduces compute costs and cuts down the lag time between a user’s prompt and the AI’s response. Modal is one of the handful of inference-focused companies attracting intense investor attention now. Last week, its competitor Baseten announced a $300 million raise at a $5 billion valuation, more than doubling the $2.1 billion valuation it reached just months prior in September. Similarly, Fireworks AI, an inference cloud provider, secured $250 million at a $4 billion valuation in October. In January, the creators of the open source inference project vLLM announced they had transitioned the tool into a VC-backed startup, Inferact, raising $150 million in seed funding led by Andreessen Horowitz at an $800 million valuation . Meanwhile, TechCrunch reported that the team behind SGLang has commercialized as RadixArk, which sources told us secured seed funding at a $400 million valuation led by Accel. Modal was co-founded by CEO Erik Bernhardsson in 2021 after he spent more than 15 years building and leading data teams at companies including Spotify and Better.com, where he was CTO. Techcrunch event Boston, MA | June 23, 2026 The startup counts Lux Capital and Redpoint Ventures among its earlier backers. Editor’s Note: This story was updated to include a comment from Modal.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/01/Screenshot-2024-02-14-at-9.26.16AM.png?resize=1200,607"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Anthropic says it‚Äôll try to keep its data centers from raising electricity costs",
      "url": "https://www.theverge.com/ai-artificial-intelligence/877526/anthropic-ai-electricity-costs-data-center-pledge",
      "published": "2026-02-11T22:37:02+00:00",
      "summary": "Anthropic is the latest AI company promising to limit the impact its data centers have on nearby residents' electricity bills. The company said it would pay higher monthly electricity charges in order to cover 100 percent of the upgrades needed to connect its data centers to power grids. \"This includes the shares of these costs [&#8230;]",
      "content_text": "Anthropic is the latest AI company promising to limit the impact its data centers have on nearby residents‚Äô electricity bills. The company said it would pay higher monthly electricity charges in order to cover 100 percent of the upgrades needed to connect its data centers to power grids. ‚ÄúThis includes the shares of these costs that would otherwise be passed onto consumers,‚Äù the announcement says. Anthropic didn‚Äôt provide details today about any agreements it has inked with energy companies in order to accomplish these goals. In November, it shared a $50 billion plan to build data centers in New York and Texas ‚Äúwith more sites to come.‚Äù Rising electricity rates have become a top election priority in the US , and local opposition to the construction of new energy-intensive data centers has led to projects across the country being canceled or delayed . Now we‚Äôre seeing companies including Microsoft and Meta making commitments to at least partially cover the costs stemming from new energy infrastructure built to accommodate their data centers. As part of its pledge, Anthropic says it‚Äôll support efforts to get new power sources online to meet growing electricity demand from AI. It also claims it‚Äôll be willing to cut its power consumption during demand peaks, a step that could help relieve pressure on power grids during a heatwave or cold snap. Recent winter storms have already raised concerns about how data centers might further stress power grids and increase energy costs during extreme weather.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/01/STK269_ANTHROPIC_2_A.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "Study of Buddhist Monks Finds Meditation Alters Brain Activity",
      "url": "https://www.wired.com/story/study-of-buddhist-monks-finds-meditation-alters-brain-activity/",
      "published": "2026-02-11T22:35:39+00:00",
      "summary": "Meditation isn’t thinking about nothing. New research reinforces that it’s a mind-altering, dynamic state that promotes focus, learning, and well-being.",
      "content_text": "If you've ever considered practicing meditation , you might believe you should relax, breathe, and empty your mind of distracting thoughts. Novices tend to think of meditation as the brain at rest, but a new international study concludes that this ancient practice is quite the opposite: Meditation is a state of heightened cerebral activity that profoundly alters brain dynamics. Researchers from the University of Montreal and Italy’s National Research Council recruited 12 monks of the Thai Forest Tradition at Santacittārāma, a Buddhist monastery outside Rome. In a laboratory in Chieti-Pescara, scientists analyzed the brain activity of these meditation practitioners using magnetoencephalography (MEG), technology capable of recording with great precision the brain’s electrical signals. The study focused on two classical forms of meditation: Samatha, a technique that focuses on sustained attention to a specific objective, often steady breathing, with the aim of stabilizing the mind and reaching a deep state of calm and concentration, and Vipassana, which is based on equanimous observation of sensations, thoughts, and emotions as they arise in order to develop mental clarity and a deeper understanding of the experience. “With Samatha, you narrow your field of attention, somewhat like narrowing the beam of a flashlight; with Vipassana, on the contrary, you widen the beam,” explains Karim Jerbi, professor of psychology at the University of Montreal and one of the study’s coauthors. “Both practices actively engage attentional mechanisms. While Vipassana is more challenging for beginners, in mindfulness programs the two techniques are often practiced in alternation.” The researchers recorded multiple indicators of brain dynamics, including neural oscillations, measures of signal complexity, and parameters related to so-called “criticality,” a concept borrowed from statistical physics that has been applied to neuroscience for 20 years. Criticality describes systems that operate efficiently on the border between order and chaos, and in neuroscience, it is considered a state optimal for processing information in a healthy brain. “A brain that lacks flexibility adapts poorly, while too much chaos can lead to malfunction, as in epilepsy,” Jerbi explained in a press release . “At the critical point, neural networks are stable enough to transmit information reliably, yet flexible enough to adapt quickly to new situations. This balance optimizes the brain’s processing, learning, and response capacity.” During the experiment, the monks’ brain activity was recorded by a high-resolution MEG system as they alternated from one type of meditation to the other with brief periods of rest in between. The data were then processed with advanced signal analysis and machine learning tools to extract different indicators of neural complexity and dynamics. Striking a Balance Results published in the journal Neuroscience of Consciousness show both forms of meditation increase the complexity of brain signals compared to a brain at rest. This finding suggests the brain in meditation does not simply calm down but rather enters a dynamic state rich with information. At the same time, the researchers observed widespread reductions in certain parameters linked to the global organization of neural activity. One of the most striking findings in the analysis of the criticality deviation coefficient showed a clear distinction between Samatha and Vipassana. This indicates that, although both practices increase brain complexity, they do so through different dynamic configurations, consistent with their subjective experiences. In other words, Vipassana brings the practitioner closer to the balance of stability and flexibility, while Samatha produces a somewhat more stable and focused state. According to researchers, the closer the brain gets to this critical state of balance, the more responsively and efficiently it functions. This is reflected, for example, in a greater capacity to switch tasks or to store information.",
      "cover_image_url": "https://media.wired.com/photos/698bcacf1cd27f239f17a259/191:100/w_1280,c_limit/monje.jpg"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "‘Heated Rivalry’ Is Bringing New Fans to Hockey. Does the Sport Deserve Them?",
      "url": "https://www.wired.com/story/winter-olympics-heated-rivalry-effect-lgbtq-inclusivity/",
      "published": "2026-02-11T22:15:06+00:00",
      "summary": "Obsession over a show about two closeted hockey players has brought new fandom to the sport just ahead of the Olympics. But men's hockey's lack of support for LGBTQ+ players and fans is notable.",
      "content_text": "The NHL also pointed WIRED to its partnerships with Pride organizations around the US , Canada, and Australia, as well as pro-inclusivity organization You Can Play, which it's been working with since 2013 . The league said it will be hosting its third annual Pride Cup in 2026. NHL commissioner Gary Bettman has said he “binged” Heated Rivalry in one night and told reporters that all NHL teams do a Pride night. However, as The New York Times reported , that is no longer the case, with a couple of teams opting for more general inclusivity events. Teresa Fowler, an associate professor at Concordia University of Edmonton and Tim Skuce, an associate professor at Brandon University, have both been researching hockey culture in Canada for years. Fowler is candid when she speaks about the league’s embrace of Heated Rivalry , which she feels is performative. “Where's your gay friend on your team? You know what I mean?” she says. “It just seems so hypocritical when people are saying, ‘Yeah, we would welcome them,’ and yet, the person who they call their brother, you know, that they would do anything for, is too afraid to bare their soul.” Fowler and Skuce published a study on hockey culture in 2023, interviewing 21 elite players from the junior A level and higher, many of whom they say were current or former NHL players. Fowler says she’s also worked with younger players, including U18 players and youth hockey. One of the main issues they pointed to that fosters a toxic culture in sport was hazing. “They would make players dress up like women, and then go into a shopping mall and sing ‘My Little Teapot.’ They would have notches in their belts for sexual conquest. But then, of course, there's the more physical [hazing rituals]: drag your testicles across the rink naked, get in bathrooms naked ,” Fowler says. “It's just gross. It makes no sense to me how this is team bonding, none whatsoever. Those rituals are sexism rituals, misogynistic rituals, where you're constantly demeaning women.” In 2022, a Globe and Mail investigation revealed that Hockey Canada, the sport’s national governing body, had in part used players’ registration fees to cover uninsurable liabilities, such as sexual assault settlements; last July, five former Canadian Junior Hockey players were acquitted of sexually assaulting a woman at a hotel room in London, Ontario. Hockey Canada did not respond to WIRED’s request for comment. Skuce, who played university and AAA hockey, says a lot of the men he’s interviewed said they “felt uncomfortable” with the hazing but “they didn't want to say anything about it.” Team belonging is predicated on going along with what’s happening. Skuce says he wants to see a shift away from humiliation-based hazing rituals to ones that are more “inclusive.” With the Olympics taking center stage, there’s once again the potential for a spotlight on trans people in sports—a culture war issue Browne says has created a “moral panic.” He coauthored the 2025 book Let Us Play about the issue.",
      "cover_image_url": "https://media.wired.com/photos/698bc05e26aca79c141aa56e/191:100/w_1280,c_limit/Olympics-2026-Elite-Hockey-Loves-Heated-Rivalry-Effect-Culture.jpg"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "Once-hobbled Lumma Stealer is back with lures that are hard to resist",
      "url": "https://arstechnica.com/security/2026/02/once-hobbled-lumma-stealer-is-back-with-lures-that-are-hard-to-resist/",
      "published": "2026-02-11T22:11:40+00:00",
      "summary": "ClickFix bait, combined with advanced Castleloader malware, is installing Lumma \"at scale.\"",
      "content_text": "Last May, law enforcement authorities around the world scored a key win when they hobbled the infrastructure of Lumma, an infostealer that infected nearly 395,000 Windows computers over just a two-month span leading up to the international operation. Researchers said Wednesday that Lumma is once again “back at scale” in hard-to-detect attacks that pilfer credentials and sensitive files. Lumma, also known as Lumma Stealer, first appeared in Russian-speaking cybercrime forums in 2022. Its cloud-based malware-as-a-service model provided a sprawling infrastructure of domains for hosting lure sites offering free cracked software, games, and pirated movies, as well as command-and-control channels and everything else a threat actor needed to run their infostealing enterprise. Within a year, Lumma was selling for as much as $2,500 for premium versions. By the spring of 2024, the FBI counted more than 21,000 listings on crime forums. Last year, Microsoft said Lumma had become the “go-to tool” for multiple crime groups, including Scattered Spider, one of the most prolific groups. Takedowns are hard The FBI and an international coalition of its counterparts took action early last year. In May, they said they seized 2,300 domains, command-and-control infrastructure, and crime marketplaces that had enabled the infostealer to thrive. Recently, however, the malware has made a comeback, allowing it to infect a significant number of machines again. “LummaStealer is back at scale, despite a major 2025 law-enforcement takedown that disrupted thousands of its command-and-control domains,” researchers from security firm Bitdefender wrote . “The operation has rapidly rebuilt its infrastructure and continues to spread worldwide.” As with Lumma before, the recent surge leans heavily on “ClickFix,” a form of social engineering lure that’s proving to be vexingly effective in causing end users to infect their own machines. Typically, these types of bait come in the form of fake CAPTCHAs that—rather requiring users to click a box or identify objects or letters in a jumbled image—instruct them to copy text and paste it into an interface, a process that takes just seconds. The text comes in the form of malicious commands provided by the fake CAPTCHA. The interface is the Windows terminal. Targets who comply then install loader malware, which in turn installs Lumma.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2023/07/exploit-vulnerability-security.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "OpenAI disbands mission alignment team",
      "url": "https://techcrunch.com/2026/02/11/openai-disbands-mission-alignment-team-which-focused-on-safe-and-trustworthy-ai-development/",
      "published": "2026-02-11T21:57:18+00:00",
      "summary": "The team's leader has been given a new role as OpenAI's chief futurist, while the other team members have been reassigned throughout the company.",
      "content_text": "OpenAI has disbanded a team that was designed to communicate the company’s mission to the public and to its own employees. At the same time, the team’s former leader has been given a new role as the company’s “chief futurist.” OpenAI confirmed to TechCrunch that the team’s members have now been assigned to other roles. The news was first reported by Platformer. The disbanded team in question appears to have been formed in September of 2024 . Platformer reports that the team was dedicated to promoting “the company’s stated mission to ensure that artificial general intelligence benefits all of humanity.” An official OpenAI spokesperson described the team thusly: “The Mission Alignment project was a support function to help employees and the public understand our mission and the impact of AI. That work continues throughout the organization.” In a blog post published Wednesday, Josh Achiam, the former head of OpenAI’s mission alignment team, explained his new role as the company’s chief futurist. “My goal is to support OpenAI’s mission — to ensure that artificial general intelligence benefits all of humanity — by studying how the world will change in response to AI, AGI, and beyond,” Achiam wrote. Achiam noted that, in his new role, he would be collaborating with Jason Pruet, an OpenAI physicist. A spokesperson for OpenAI said the rest of the mission alignment team — a group of six or seven people — had subsequently been reassigned to different parts of the company. The spokesperson couldn’t say where exactly the team members had been assigned, but said that they were engaged in similar work in those roles. It was also unclear whether Achiam would have a new team as part of his “futurist” role. Techcrunch event Boston, MA | June 23, 2026 The spokesperson attributed the disbanding of the team to the kinds of routine reorganizations that occur within a fast-moving company. OpenAI previously had what it called a “superalignment team” — which was formed in 2023 and focused on studying long-term existential threats posed by AI — but that team was disbanded in 2024 . Achiam’s personal website still lists him as head of mission alignment at OpenAI, and describes him as being interested in ensuring that the “long-term future of humanity is good.” His LinkedIn profile shows he had served as head of mission alignment since September 2024. Correction: This story originally confused mission alignment with another, similarly named team called alignment. It has been corrected and we apologize for the error.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/02/GettyImages-2198379368.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "Byte magazine artist Robert Tinney, who illustrated the birth of PCs, dies at 78",
      "url": "https://arstechnica.com/gadgets/2026/02/byte-magazine-artist-robert-tinney-who-illustrated-the-birth-of-pcs-dies-at-78/",
      "published": "2026-02-11T21:51:33+00:00",
      "summary": "He became one of the first to visualize personal computing by painting vivid cover art.",
      "content_text": "On February 1, Robert Tinney, the illustrator whose airbrushed cover paintings defined the look and feel of pioneering computer magazine Byte for over a decade, died at age 78 in Baker, Louisiana, according to a memorial posted on his official website. As the primary cover artist for Byte from 1975 to the late 1980s, Tinney became one of the first illustrators to give the abstract world of personal computing a coherent visual language, translating topics like artificial intelligence, networking, and programming into vivid, surrealist-influenced paintings that a generation of computer enthusiasts grew up with. Tinney went on to paint more than 80 covers for Byte, working almost entirely in airbrushed Designers Gouache , a medium he chose for its opaque, intense colors and smooth finish. He said the process of creating each cover typically took about a week of painting once a design was approved, following phone conversations with editors about each issue’s theme. He cited René Magritte and M.C. Escher as two of his favorite artists, and fans often noticed their influence in his work. A phone call that changed his life A recent photo portrait of Robert Tinney provided by the family. A recent photo portrait of Robert Tinney provided by the family. Credit: Family of Robert Tinney Born on November 22, 1947, in Penn Yan, New York, Tinney moved with his family to Baton Rouge, Louisiana, as a child. He studied illustration and graphic design at Louisiana Tech University, and after a tour of service during the Vietnam War, he began his career as a commercial artist in Houston. His connection to Byte came through a chance meeting with Carl Helmers, who would later found the magazine. In a 2006 interview I conducted with Tinney for my blog, Vintage Computing and Gaming, he recalled how the relationship began: “One day the phone rang in my Houston apartment and it was Carl wanting to know if I would be interested in painting covers for Byte.” His first cover appeared on the December 1975 issue, just three months after the magazine launched. Over time, his covers became so popular that he created limited-edition signed prints that he sold on his website for decades. “A friend suggested once that I should select the best covers and reproduce them as signed prints,” he said in 2006. “Byte was gracious enough to let me advertise the prints when they could fit in an ad (it did get bumped occasionally), and the prints were very popular in the Byte booth at the big computer shows, two or three of which my wife, Susan, and I attended per year. When an edition sold out, I then put the design on a T-shirt.”",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/tinney_byte_hearder_2-1152x648.jpg"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Why I wish I hadn‚Äôt bought my Samsung OLED TV",
      "url": "https://www.theverge.com/tech/877396/samsung-tv-software-volume-on-screen-display-switch-hdmi-input-tizen",
      "published": "2026-02-11T21:39:06+00:00",
      "summary": "In June 2024, in a dusty TV shop empty of customers save myself, my wife, and my kids, I stared deep into the LG C3 and Samsung S90C. I went back and forth between the two OLED screens for easily 20 minutes, happily paralyzed by the choice in front of me. The Video Only salesperson [&#8230;]",
      "content_text": "In June 2024, in a dusty TV shop empty of customers save myself, my wife, and my kids, I stared deep into the LG C3 and Samsung S90C. I went back and forth between the two OLED screens for easily 20 minutes, happily paralyzed by the choice in front of me. The Video Only salesperson attempted to explain that there was no wrong decision. A year and a half later, I disagree: I regret picking the Samsung over the LG. I regret it every time I adjust the volume on my TV, every time I plug in a new device, and especially ever since the Logitech Harmony Amazon Alexa integration shit the bed and I have to fumble a Samsung remote to switch inputs. Samsung‚Äôs QD-OLED panel itself is phenomenal, if nothing special in 2026 . The problem is the software. I would pay Samsung $100, right now, for this ‚Äúsmart‚Äù TV to be as dumb as the ones I grew up with. Heck, I‚Äôd give Samsung 50 bucks just to let us disable the volume indicator. Failing that, let‚Äôs see if shame works. Let me be clear: One of the final deciding reasons I chose the Samsung S90C over the LG C3 was that LG had failed me before. My LG E7 OLED, purchased from a not-long-for-this-world Fry‚Äôs Electronics in 2018, eventually developed a large heat blemish (not your typical burn-in) that sometimes discolored the picture. Before that, my previous Sony TV developed a line of dark pixels shortly after the warranty expired. But both Sony and LG had unobtrusive onscreen volume indicators, just little icons near the edge of the screen. Samsung believes that anyone who ever needs things a little louder or quieter is willing to tolerate this aberration : This eyesore stretches nearly a third of the way across the screen, vertically and horizontally, obscuring the incredible moving art I‚Äôm trying to watch underneath. And if you‚Äôre using a receiver, it consumes all this screen space to convey basically zero information . Not the current volume level, unless you‚Äôre using the TV‚Äôs built-in speakers, and not whether I‚Äôm getting a stereo or surround or Dolby Atmos signal. It is the Samsung equivalent of Microsoft Clippy, but worse: ‚ÄúLooks like you‚Äôre trying to adjust the volume!‚Äù We watch plenty of movies that contain both too-loud action and too-quiet dialogue, at an hour when kids are supposed to be in bed, so we‚Äôre adjusting that volume all the time. In 2023, user ‚Äú1544CT‚Äù on the Samsung Community forums complained that ‚Äúas a person that watches a lot of Movies and shows I can no longer recommend Samsung until this annoyance is fixed.‚Äù But they didn‚Äôt seem optimistic. After all, the company hadn‚Äôt yet acted on a 26-page thread about the annoyance from 2020, one that now has over 130,000 views. 1/13 Gallery: 12 places on the internet I found people complaining about the volume OSD. There are numerous Reddit threads and even a Change.org petition to fix it . Though a Samsung moderator promised to deliver the complaint to the company‚Äôs engineers, it‚Äôs been three more years and nearly 50,000 more views without a resolution. Some users reported getting a v2203 update that reduced the size of the overlay, at least, but it appears that update may have been paused in December due to issues. Will we ever get it? Problem number two: Samsung has no proper concept of an HDMI input, so I‚Äôm fumbling with a remote every time I plug a new gadget in. Here is how my Samsung TV works in 2026: Step 1: Plug a game console into an HDMI port. Step 2: Wait for the Samsung TV to autodetect the game console. And if it doesn‚Äôt have good HDMI-CEC, which I‚Äôll explain in a sec: Step 3: Press the home button on the remote to see a forest of colorful Smart TV app icons, none of which are my game console. Step 4: Press left on the D-pad to ignore those icons and instead summon the vertical sidebar. Press down, and then right, to summon a different horizontal bar of Connected Devices. If it‚Äôs an unknown one like the Analogue 3D, hope it‚Äôs the one I labeled ‚ÄúPC‚Äù last time. Step 5: Set that ‚ÄúPC‚Äù to game mode for the umpteenth time by summoning a basic settings menu, then an advanced settings menu, then scrolling to the game mode toggle. Step 6: Play. Step 7: Repeat steps 2‚Äì5 each time I unplug and plug in a new device. I suspect not everyone‚Äôs always plugging in new gaming handhelds and Analogue 3Ds and mini-SNESes over HDMI like me. But on my LG TV set, and every HDMI-capable set I‚Äôve ever owned before, I could just press a button to cycle through HDMI inputs until the right picture showed up. Thankfully, my PS5 and Switch 2 have pretty decent implementations of HDMI-CEC, the communications protocol that lets them send commands to my TV. When the kids want to watch Netflix or fire up Astro Bot , the power button on the DualSense pad or Switch 2 Joy-Con will do it. But weirdly, they won‚Äôt turn my TV and receiver off . I used to get around most of this by setting up complicated Logitech Harmony Hub routines that‚Äôd fire when I said ‚ÄúAlexa, turn off the TV‚Äù or ‚ÄúAlexa, turn on the Nintendo Switch.‚Äù But since that infrared Wi-Fi remote stopped syncing to Amazon and Logitech‚Äôs servers properly this year, I‚Äôve had to use Samsung‚Äôs software and remote more than ever. I sure miss when this li‚Äôl dude just worked. One day, I had the idea to try Home Assistant, when the Samsung TV and Samsung‚Äôs SmartThings showed up in a list of possible integrations. Maybe I could switch HDMI devices from my phone? But Samsung doesn‚Äôt expose individual HDMI ports there, either; I could only tell my screen to switch to ‚ÄúTV‚Äù or ‚ÄúHDMI,‚Äù no other sources or channels. Those other HDMI sources do exist in Samsung‚Äôs API, because a homebrew third-party integration made my other Connected Devices like ‚ÄúPlayStation 5‚Äù and ‚ÄúAV Receiver‚Äù appear in Home Assistant ‚Äî but only after connecting my TV to Samsung‚Äôs cloud and generating a custom API key. Yes, I have to reach out over the internet through Samsung‚Äôs cloud and back into my home to change HDMI inputs. And it‚Äôs still not reliable, because Samsung‚Äôs cloud sometimes tells me I‚Äôve made too many requests, and sometimes needs a whole new token before it‚Äôll accept commands again. I‚Äôm about ready to go looking for an old-school infrared universal remote at this rate and teach my kids some pointing skills. But hey, Samsung, how about $50 for a fix? I have PayPal, Venmo, hell, I‚Äôll type my card number into the TV itself if you‚Äôll let me. I asked Samsung a couple days ago about possible updates, but it didn‚Äôt have an answer by publish time. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Sean Hollister Column Gadgets Tech TVs",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/cwelch_220331_5121_0012.webp?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "ICE Is Crashing the US Court System in Minnesota",
      "url": "https://www.wired.com/story/ice-crashing-us-court-system-minnesota/",
      "published": "2026-02-11T21:23:51+00:00",
      "summary": "Petitions demanding people get the chance to be released from ICE custody have overwhelmed courts throughout the US.",
      "content_text": "The Immigration and Customs Enforcement (ICE) operation in Minnesota is pushing the United States court system to its breaking point. Since Operation Metro Surge began in December, federal immigration agents have arrested some 4,000 people, according to the Department of Homeland Security (DHS). The result is an avalanche of cases filed in the US district court in Minnesota on behalf of people challenging their imprisonment by federal immigration enforcement agents. According to WIRED's review of court records and official judicial statistics, attorneys filed nearly as many so-called habeas corpus petitions in Minnesota alone as were filed across the US during an entire year. The bombardment of cases filed in federal court in Minnesota and other states is the result of two Trump administration policies: a dramatic increase in the number of people being detained, and the elimination of a key legal mechanism for securing their release. The result is a US court system in collapse: Judges, immigration attorneys, and federal prosecutors are all overwhelmed, while the people at the center of these cases remain behind bars, often in states thousands of miles from their home—many after judges have ordered their release. “I’ve never said the word habeas so many times in my life,” says Graham Ojala-Barbour, a Minnesota immigration attorney who has been practicing for over a decade. Ojala-Barbour says that when he goes to sleep, his dreams are about habeas petitions. Exhaustion is endemic. On February 3, one now-former special assistant US attorney, Julie Le, begged a US judge in Minnesota to hold her in contempt so she could finally rest. She was listed on 88 cases, according to data obtained via PACER, the US court records database. Daniel Rosen, the US attorney for the district of Minnesota and head of Le’s office, previously told that judge in a letter that they were “struggling to keep up with the immense volume” of petitions and had let at least one court order demanding the return of a petitioner slip through the cracks. Le did not respond to a request for comment. In response to a request for comment, the Minnesota US Attorney’s Office sent an automatic reply stating that they currently lacked a public information officer. Le was reportedly fired after the February hearing, where she told the judge, “This job sucks.” In response to a request for comment, DHS spokesperson Tricia McLaughlin said, “The Trump administration is more than prepared to handle the legal caseload necessary to deliver President Trump’s deportation agenda for the American people.” As hard as the workload may be for US attorneys, the situation is far more dire for people detained by immigration authorities. In court filings, people who have been detained describe being packed into cells that were so full that they couldn’t even sit down before being flown to detention centers in Texas. One described having to share cells with people who were sick with Covid. Others said agents repeatedly pressured them and other detainees to self-deport. McLaughlin told WIRED, “All detainees are provided with proper meals, water, medical treatment, and have opportunities to communicate with their family members and lawyers. All detainees receive full due process.” Ana Voss, the civil division chief for the Minnesota US Attorney’s Office, has been listed as one of the attorneys defending the government in nearly all the habeas petition cases filed in Minnesota since Operation Metro Surge began. Before December, the majority of cases associated with Voss were about other issues, such as social security and disability lawsuits. Since then, habeas petitions for immigrant detainees have dramatically overtaken all other matters. In January, 584 of the 618 cases filed in Minnesota district court that included Voss as an appearing attorney were categorized as habeas petitions for detainees, according to a WIRED review of PACER data. This is likely an undercount due to incorrect “nature of suit” labels. Voss is no longer with the Minnesota US Attorney’s Office, according to an automatic reply from her Department of Justice email address. The number of habeas petitions filed has exploded in other parts of the country as well. In the western district court of Texas, for example, at least 774 petitions were filed in the month of January, according to data collected by Habeas Dockets. In the Middle District of Georgia, 186 petitions were filed that same month. ProPublica reported that across the country, there have been over 18,000 habeas cases filed since January 2025.",
      "cover_image_url": "https://media.wired.com/photos/698676b52cca1ecb252708b7/191:100/w_1280,c_limit/security_immigration_court_crash.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Apple's Siri revamp reportedly delayed... again",
      "url": "https://techcrunch.com/2026/02/11/apples-siri-revamp-reportedly-delayed-again/",
      "published": "2026-02-11T21:19:46+00:00",
      "summary": "While the new Siri was expected to launch with the upcoming iOS 26.4 update in March, now, the changes are expected to roll out more slowly over time, reportedly postponing some features until the May iOS update, or even until the release of iOS 27 in September.",
      "content_text": "Apple has been promising a new-and-improved, cutting-edge, AI-powered Siri since it first unveiled Apple Intelligence in 2024. Over about a year and a half since then, the release date for this new era of Siri has been continuously pushed back. According to a new report from Bloomberg’s Mark Gurman, we’ll likely have to wait even longer. While the new Siri was expected to launch with the upcoming iOS 26.4 update in March, now, the changes are expected to roll out more slowly over time, reportedly postponing some features until the May iOS update, or even until the release of iOS 27 in September. Apparently, Apple ran into trouble when testing the software, requiring the launch date to be pushed back further. The changes are rumored to make the longtime digital assistant more like the LLM chatbots that have swept the tech world — but instead of opening up a ChatGPT or Claude app on your iPhone or MacBook, you would be able to just talk to Siri, which will be powered by Google Gemini . We’re starting to feel bad for the Siri product managers. Hang in there, folks.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/01/tim-cook-glowing-apple-logo-GettyImages-2234517515.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Aurora says it will ‚Äòtriple‚Äô its driverless truck network",
      "url": "https://www.theverge.com/transportation/877191/aurora-driverless-truck-triple-routes-texas",
      "published": "2026-02-11T21:15:00+00:00",
      "summary": "Aurora, the driverless truck firm founded by former members of Google's pioneering self-driving car team, is branching out. In advance of its quarterly earnings report today, the company announced that a new software update would enable it to triple its driverless network to a total of 10 routes across the Southern US. Currently, Aurora has [&#8230;]",
      "content_text": "Aurora, the driverless truck firm founded by former members of Google‚Äôs pioneering self-driving car team, is branching out. In advance of its quarterly earnings report today, the company announced that a new software update would enable it to triple its driverless network to a total of 10 routes across the Southern US. Currently, Aurora has 10 autonomous trucks without safety monitors driving routes between Dallas, Houston, Fort Worth, and El Paso. The company has issued three previous software updates: the first to authorize driverless trips between Dallas and Houston; the second to authorize driving at night; and the third to expand its network to include routes to El Paso. With this new update, Aurora will begin operating trips between Fort Worth and Phoenix, which takes more than 15 hours to complete. Legally, human truck drivers are restricted to 11 hours of driving a day, within a 14-hour duty limit, before they are required to take a break. An autonomous truck is not subject to these same restrictions. Additional routes include: Dallas and Houston; Fort Worth and El Paso; El Paso and Phoenix; Fort Worth and Phoenix; and Dallas and Laredo. The company is also using AI to build new maps for its autonomous driving system, with the goal of shortening the time between testing, validation, and commercial operation. According to Aurora: After a single manual drive, cloud-based algorithms are able to generate semantic components, which helps to build new maps with little to no human assistance. Map automation significantly reduces the time to map new routes, positioning Aurora to accelerate the rollout of new routes and customer endpoints this year. Aurora is still operating trucks with safety monitors for several of its clients, including Hirschbach Motor Lines, Detmar Logistics, and ‚Äúone of the leading carriers in the US from its Phoenix facility.‚Äù Aurora CEO Chris Urmson said previously that the company complies with requests from partners to keep safety drivers in the cab as a matter of optics, not an indicator of technological regression. Operationally, it has no bearing on Aurora‚Äôs progress. The company is also adding a new semi truck model to its fleet, based on the International LT, along with its new hardware suite which costs half the current stack. Aurora says it will launch the new truck without a safety monitor in the second quarter of 2026. And the company expects to have 200 driverless trucks in operation by the end of the year. Lastly, Aurora said its cash position has improved. Previously, Urmson said that Aurora had roughly $1.6 billion in the bank, enough to last until the second half of 2027. Now, the company says it expects to achieve positive free cash flow by 2028, indicating that Aurora will be generating more money from its business operations than it is loses.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/Volvo-VNL-Autonomous-powered-by-the-Aurora-Driver.jpg?quality=90&strip=all&crop=0%2C17.277486910995%2C100%2C65.44502617801&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Covering electricity price increases from our data centers",
      "url": "https://www.anthropic.com/news/covering-electricity-price-increases",
      "published": "2026-02-11T21:12:59+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.anthropic.com/news/covering-electricity-price-increases\">https://www.anthropic.com/news/covering-electricity-price-increases</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46981058\">https://news.ycombinator.com/item?id=46981058</a></p> <p>Points: 29</p> <p># Comments: 7</p>",
      "content_text": "As we continue to invest in American AI infrastructure , Anthropic will cover electricity price increases that consumers face from our data centers. Training a single frontier AI model will soon require gigawatts of power, and the US AI sector will need at least 50 gigawatts of capacity over the next several years. The country needs to build new data centers quickly to maintain its competitiveness on AI and national security—but AI companies shouldn’t leave American ratepayers to pick up the tab. Data centers can raise consumer electricity prices in two main ways. First, connecting data centers to the grid often requires costly new or upgraded infrastructure like transmission lines or substations. Second, new demand tightens the market, pushing up prices. We’re committing to address both. Specifically, we will: Cover grid infrastructure costs . We will pay for 100% of the grid upgrades needed to interconnect our data centers, paid through increases to our monthly electricity charges. This includes the shares of these costs that would otherwise be passed onto consumers. Procure new power and protect consumers from price increases . We will work to bring net-new power generation online to match our data centers’ electricity needs. Where new generation isn’t online, we’ll work with utilities and external experts to estimate and cover demand-driven price effects from our data centers. Reduce strain on the grid . We’re investing in curtailment systems that cut our data centers’ power usage during periods of peak demand, as well as grid optimization tools, both of which help keep prices lower for ratepayers. Invest in local communities. Our current data center projects will create hundreds of permanent jobs and thousands of construction jobs. We’re also committed to being a responsible neighbor—that means addressing environmental impacts, including deploying water-efficient cooling technologies, and partnering with local leaders on initiatives that share AI’s benefits broadly. Where we work with partners to develop data centers for handling our own workloads, we make these commitments directly. Where we lease capacity from existing data centers, we’re exploring further ways to address our own workloads' effects on prices. Of course, company-level action isn't enough. Keeping electricity affordable also requires systemic change. We support federal policies —including permitting reform and efforts to speed up transmission development and grid interconnection—that make it faster and cheaper to bring new energy online for everyone. Done right, AI infrastructure can be a catalyst for the broader energy investment the country needs. These commitments are the beginning of our efforts to address data centers’ impact on energy costs. We have more to do, and we’ll continue to share updates as this work develops.",
      "cover_image_url": "https://www.anthropic.com/api/opengraph-illustration?name=Hand%20HeadBolt&backgroundColor=cactus"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Q&A: New UK onshore wind and solar is ‘50% cheaper’ than new gas",
      "url": "https://www.carbonbrief.org/qa-new-uk-onshore-wind-and-solar-is-50-cheaper-than-new-gas/",
      "published": "2026-02-11T21:09:51+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.carbonbrief.org/qa-new-uk-onshore-wind-and-solar-is-50-cheaper-than-new-gas/\">https://www.carbonbrief.org/qa-new-uk-onshore-wind-and-solar-is-50-cheaper-than-new-gas/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46981015\">https://news.ycombinator.com/item?id=46981015</a></p> <p>Points: 60</p> <p># Comments: 50</p>",
      "content_text": "The UK government has secured a record 7.4 gigawatts (GW) of solar, onshore wind and tidal power in its latest auction for new renewable capacity. It is the second and final part of the seventh auction round for “ contracts for difference ” (CfDs), known as AR7a. In the first part, held in January 2026, the government agreed contracts for a record 8.4GW of new offshore wind capacity. This makes AR7 the UK’s single-largest auction round overall, with its 14.7GW of new renewable capacity being 50% larger than the previous record set by AR6 in 2024 . In AR7a, 157 solar projects secured contracts to supply electricity for £65 per megawatt hour (MWh) and 28 onshore wind projects were contracted at £72/MWh. This means they will help cut consumer bills, according to multiple analysts. Energy secretary Ed Miliband welcomed the outcome of the auction, saying in a statement that the new projects would be “50% cheaper” than new gas: “These results show once again that clean British power is the right choice for our country, agreeing a price for new onshore wind and solar that is over 50% cheaper than the cost of building and operating new gas”. In addition to cutting costs, the new projects will help reduce gas imports. In total, AR7 will cut UK gas demand by around 95 terawatt hours (TWh) per year, enough to cut liquified natural gas (LNG) imports by three-quarters, according to Carbon Brief analysis. Below, Carbon Brief looks at the seventh auction results for onshore wind, solar and tidal, what they mean energy for bills and the impact of the UK’s target of “ clean power by 2030 ”. What happened in the latest UK renewable auction? The latest UK government auction for new renewable capacity is the second and final part of the seventh auction round, known as AR7a. It secured a record 4.9GW of new solar capacity across 157 projects, as shown in the figure below, as well as 1.3GW of onshore wind across 28 projects. In addition, four tidal energy projects totalling 21 megawatts (MW) secured contracts, included within “other” in the figure below. Capacity of solar, onshore wind and other technologies (including tidal) secured at each CfD auction in megawatts. Source: Department of Energy Security and Net Zero. Most of the solar that secured a contract has a capacity of less than 50MW. This is the cut-off point for projects to be approved by the local council. Larger schemes must instead go through the “nationally significant infrastructure project” (NSIP) process, subject to approval by the secretary of state for energy. For the first time, one 480MW solar project – approved via this NSIP process – won a CfD in AR7a. The West Burton Solar NSIP is being developed in Lincolnshire and Nottinghamshire by Island Green Power. It is named after the grid connection it will use, freed up by the shuttering of the coal-powered West Burton plant. However, Nick Civetta , project leader at Aurora Energy Research notes on LinkedIn that this site was only one of four eligible solar NSIPs to secure a contract. Civetta adds that “wrangling these large projects into fruition is proving more painful than expected”. Solar projects secured a “ strike price ” of £65/MWh in 2024 prices, some 7% cheaper than the £70/MWh agreed in the previous auction round. In previous auction rounds CfD contracts were expressed in 2012 prices. For comparison, AR6 and AR7a solar contracts stand at £50/MWh and £47/MWh in 2012 prices, respectively.) Alongside solar, 28 onshore wind projects secured contracts in the latest CfD auction, with a total capacity of 1.3GW. This includes the Imerys windfarm in Cornwall, which at nearly 20MW is the largest onshore wind farm in England to secure a contract in a decade. (Shortly after taking office in 2024, the current Labour government lifted a decade-long de facto ban on onshore wind in England.) Overall, Scotland still dominated the auction for onshore wind, with 1,093MW of projects in the country in comparison to 38MW in England and 185MW in Wales. This includes the Sanquhar II windfarm in Dumfries and Galloway in Scotland, which will become the fourth-largest onshore wind farm in the UK at 269MW. In total, Wales secured contracts for 20 renewables projects in AR7a, with a capacity of more than 530MW. This is the largest ever number of Welsh projects to get backing in a CfD auction, according to a statement from the Welsh government. Onshore wind secured a strike price of £72/MWh, up slightly from £71/MWh in the previous auction in 2024. The prices for solar and onshore wind were 13% and 21% below the price cap set by Department of Energy Security and Net Zero (DESNZ) for the auction, respectively. In its press release announcing the results, the government noted that the results for solar and onshore wind were less than half of the £147/MWh cost of building and operating new gas power stations. Finally, four tidal energy projects secured contracts with a total capacity of 21MW at a strike price of £265/MWh, up from £240/MWh in 2024. In total, taken together with the 8.4GW of offshore wind secured in the first part of the auction, AR7 secured a total of 14.7GW of new clean power, as shown in the chart below. This is enough to power the equivalent of 16 million homes, according to the government. It also makes AR7 the single-largest auction round by far, at more than 50% larger than the previous record set by AR6 in 2024. This means that the two auction rounds held since the Labour government took office in July 2024 – AR6 and AR7 – have secured a total of 24GW of new renewable capacity. This is more than the 22GW from all previous auction rounds put together. New onshore wind, offshore wind, solar PV and other technologies’ capacity secured in each CfD auction, in megawatts. Source: DESNZ. However, several analysts noted that the AR7a results did not include any old onshore windfarms looking to replace their ageing turbines with new equipment – so-called “ repowering projects ” – despite the auction being open to them for the first time. Back to top What does the solar and onshore wind auction mean for bills? Onshore wind and solar are widely recognised as the cheapest sources of new electricity generation in almost every part of the world. The latest auction shows that the UK is no exception, despite its northerly location. The prices for onshore wind and solar in the latest auction, at £72/MWh and £65/MWh respectively, are comfortably below recent wholesale power prices , which averaged £81/MWh in 2025 and £92/MWh in January 2026. This means that the new projects will cut costs for UK electricity consumers, according to multiple analysts commenting on the auction outcome. The government lauded the results of AR7a for securing “homegrown energy at good value for billpayers – once again proving that clean power is the right choice for energy security and to meet rising electricity demand”. In a statement, Miliband added: “By backing solar and onshore wind at scale, we’re driving bills down for good and protecting families, businesses, and our country from the fossil fuel rollercoaster controlled by petrostates and dictators. This is how we take back control of our energy and deliver a new era of energy abundance and independence.” As noted in Carbon Brief’s coverage of the offshore wind results under AR7 in January, electricity demand is starting to rise as the economy electrifies and many of the UK’s existing power plants are nearing the end of their lives. Therefore, new sources of electricity generation will be needed, whether from renewables, gas-fired power stations or from other sources. In his statement, quoted above, Miliband said that the prices for onshore wind and solar were less than half the £147/MWh cost of electricity from new gas-fired power stations. (This is based on recently published government estimates and assumes that gas plants would only be operating during 30% of hours each year, in line with the current UK fleet.) Trade association RenewableUK also pointed to the cost of new gas, as well as the £124/MWh cost of the Hinkley C new nuclear plant, in its response to the auction results. In a statement, Dr Doug Parr , policy director for Greenpeace UK , said: “These new onshore wind and solar projects will supply energy at less than half the cost of new gas plants. Together with the new offshore wind contracts agreed last month, these cheaper renewables will lower energy bills as they come online.” Strike prices for solar dropped by 6% compared to last year and while onshore wind prices rose, this was by less than 2% despite a “difficult environment for wind generation”, according to Bertalan Gyenes , consultant at LCP Delta . In a post on LinkedIn , he noted that “extending the contract length [for onshore wind projects] by five years seems to have helped keep this increase low”. The January offshore wind round secured 8.4 GW at £91/MWh, as such, the onshore and solar projects are 25% cheaper per unit of generation. (The offshore wind projects secured in January are nevertheless expected to cut consumer bills relative to the alternative, or at worst to be cost neutral.) Parr added that while the AR7a auction results “show we’re getting up to speed” ahead of the clean power 2030 target (see below), “an even faster way for the government to make a really big dent in bills would be to change the system that allows gas to set the overall energy price in this country”. He adds: “That would allow us to unshackle our bills from unreliable petrostates and get off the rollercoaster of volatile gas markets once and for all.” Back to top What does it mean for energy security, jobs and investment? The onshore wind and solar projects secured in the latest auction round will generate an estimated 9 terawatt hours (TWh) of electricity, according to Carbon Brief analysis. This is equivalent to roughly 3% of current UK electricity demand . Combined with the estimated 37TWh from offshore wind secured during the first part of the auction, AR7 projects will be able to generate 46TWh of electricity, 14% of current demand. If this electricity were to be generated by gas-fired power plants, then it would require around 95TWh of fuel, because much of the energy in the gas is lost during combustion. This is several times more than the 25TWh of extra gas that could be produced in 2030 if new drilling licenses are issued, according to thinktank the Energy and Climate Intelligence Unit (ECIU). As such, AR7 will significantly cut UK gas imports, ECIU says, reducing exposure to volatile international gas markets. Furthermore, ECIU says that the impact of renewables in driving down gas demand – and subsequently electricity prices – is already being seen in the UK. Five years ago, gas was setting the wholesale price of power in the UK 98% of the time due to the way the electricity market operates. This price-setting dominance is being eroded by renewables, with recent analysis from the UK Energy Research Centre showing that gas set power prices 90% of the time in 2025. A further effect of new renewables is that they push the most expensive gas-fired power plants out of the system, reducing prices. This is known as the “ merit-order effect ”. Recent analysis from ECIU found that large windfarms cut wholesale electricity prices by a third in 2025. Lucy Dolton, renewable generation lead at Cornwall Insight , said in a statement that the AR7a results will provide a “surge in momentum as [the UK] pushes toward secure, homegrown energy”, adding: “These investments ultimately strengthen the UK’s position against volatile gas markets. If the past few years have shown us anything, it’s that remaining tied to international energy markets comes with consequences.” The projects that secured CfDs will help the UK avoid burning significant quantities of gas, “the bulk of which would have been imported at a cost which the UK cannot control”, said RenewableUK in its statement. Together with previous CfD auction rounds, the latest new renewable projects are expected to generate some 153TWh of electricity once they are all operating, according to Carbon Brief analysis. This is around half of current UK demand. Generating the same electricity from gas would require some 311TWh of fuel, which is similar to the 339TWh of gas produced by the UK’s North Sea operations in the most recent 12-month period for which data is available . This figure can also be compared with the 130TWh of gas that was imported by ship as liquified natural gas (LNG) in the same period. The government added that the AR7a projects will support up to 10,000 jobs and bring £5bn in private investment to the UK. (In total, the new projects secured via AR7 are expected to bring investments worth around £20-23bn to the UK, according to Aurora.) Additionally, the onshore wind projects are expected to generate over £6.5m in “ community benefit ” funds for people living near them, according to RenewableUK. The AR7a results were released alongside the publication of the Local Power Plan by the government and Great British Energy. This is designed to provide £1bn in funding for communities to own and control their own clean energy projects across the UK. Back to top What does the auction mean for clean power by 2030? The AR7a results put the UK “on track for its 2030 clean power target ”, according to the government. Over AR6 and AR7, several changes have been made to the CfD process to help facilitate more projects to secure contracts. A total of 24GW has been secured over the last two auction rounds – which have taken place under the current Labour government – compared to 22GW across the five auction rounds previously. As part of its goal for clean power to meet 100% of electricity demand by 2030 and to account for at least 95% of electricity generation, the UK government is aiming for 27-29GW of onshore wind and 45-47GW of solar by the end of the decade. As of September 2025, the UK had 16.3GW of installed onshore wind capacity and more than 21GW of solar capacity. Taken together, the onshore technologies therefore need to double in operational capacity over the next four years to reach the 2030 targets. Analysis by RenewableUK suggests that the government will need to procure between 3.85GW to 4.85GW of onshore wind in the next two auctions for the 2030 goal to remain possible. Writing on LinkedIn , Aurora’s Civetta said that the onshore clean power 2030 targets “remain a long way off”. He continued that the gap for solar to reach its 45-47GW target is still a “whopping 18GW”, but added that there may be other ways for new capacity to be secured, beyond the CfD auctions. He said these included a growing market for corporate “power purchase agreements” (PPAs), economic incentives for homes and businesses to install solar and the government’s recently released “ warm homes plan ”, all of which “should drive further procurement”. Dolton from Cornwall Insight adds that “the challenge now is delivery”, continuing: “2.5GW of the winners have a delivery year of 2027/28, and over half – 3.7GW – have a delivery year of 2028/29, which brings them very close to the government’s 2030 clean power target. “Historically, renewable projects in the UK have faced delays, often due to grid connection backlogs and planning holdups. With AR7 and some of AR8 representing the only realistic pipeline for pre-2030 capacity, keeping to schedule will be essential.” When built, the projects announced today will help to bring the total capacity of CfD-supported wind and solar to 50.6GW, according to Ember. While solar and onshore wind are expected to play an important role in decarbonising the electricity system, offshore wind is set to be the “ backbone ”. The government is targeting 43-50GW of offshore wind by 2030, up from around 17GW of installed capacity today. This leaves a gap of 27-34GW to the government’s target range. Prior to the AR7 auction, a further 10GW had already secured CfD cont",
      "cover_image_url": "https://www.carbonbrief.org/wp-content/uploads/2026/02/2CCTBEG.jpg"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Apple keeps hitting bumps with its overhauled Siri",
      "url": "https://www.theverge.com/tech/877494/apple-siri-ai-overhaul-ios-personalized",
      "published": "2026-02-11T21:08:36+00:00",
      "summary": "Apple had been reportedly pushing to introduce some big changes to Siri with iOS 26.4, but now the company is planning to introduce them in later versions of iOS, including iOS 26.5 and iOS 27, Bloomberg reports. Nearly a year ago, Apple delayed planned features for Siri that would let it understand your personal context [&#8230;]",
      "content_text": "Apple had been reportedly pushing to introduce some big changes to Siri with iOS 26.4, but now the company is planning to introduce them in later versions of iOS, including iOS 26.5 and iOS 27, Bloomberg reports . Nearly a year ago, Apple delayed planned features for Siri that would let it understand your personal context and take action for you based on what‚Äôs on your screen. Apple had planned to launch those features with iOS 26.4, which is set to launch in March, but ‚Äú‚Äã‚Äãtesting uncovered fresh problems with the software,‚Äù according to Bloomberg . Apple has apparently told engineers to use iOS 26.5, scheduled for May, to test new Siri features instead. For iOS 26.5, Apple is also testing a Perplexity-like web search tool and custom image generation, though they‚Äôve been tested with iOS 26.4, too, Bloomberg says. Apple is also working on an AI chatbot version of Siri that‚Äôs slated for launch with iOS 27, iPadOS, and macOS 27, Bloomberg reported in January . The plan is to reveal it in June at the Worldwide Developers Conference ahead of a September launch.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/09/DSC02178-1.jpg?quality=90&strip=all&crop=0%2C10.740652134574%2C100%2C78.518695730853&w=1200"
    }
  ]
}