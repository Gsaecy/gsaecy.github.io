{
  "industry": "technology",
  "collected_at": "2026-02-13T01:52:57.746738+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Can You Escape the Tip Screen?",
      "url": "https://skipthe.tips/",
      "published": "2026-02-13T00:54:51+00:00",
      "summary": "<p>Article URL: <a href=\"https://skipthe.tips/\">https://skipthe.tips/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46997519\">https://news.ycombinator.com/item?id=46997519</a></p> <p>Points: 9</p> <p># Comments: 2</p>",
      "content_text": "Skip the Tips A free browser game that challenges you to press \"No Tip\" while dark patterns try to trick you into tipping. From tiny buttons and guilt-trip modals to fake loading screens and rigged sliders — can you escape the tip screen? Skip the Tips is a satirical take on modern tipping culture. Every checkout screen has become a guilt machine. This game lets you practice saying no — if you can find the button. Features over 30 dark patterns inspired by real-world tipping screens, progressive difficulty, and a timer that keeps shrinking. Play free in your browser — no downloads, no sign-ups, no tip required.",
      "cover_image_url": "https://skipthe.tips/og-image.png"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "When Amazon badly needed a ride, Europe's Ariane 6 rocket delivered",
      "url": "https://arstechnica.com/space/2026/02/when-amazon-badly-needed-a-ride-europes-ariane-6-rocket-delivered/",
      "published": "2026-02-13T00:34:29+00:00",
      "summary": "This was the first launch of the Ariane 64, the most powerful rocket in European space history.",
      "content_text": "The Ariane 64 flew with an extended payload shroud to fit all 32 Amazon Leo satellites. Combined, the payload totaled around 20 metric tons, or about 44,000 pounds, according to Arianespace. This is close to maxing out the Ariane 64’s lift capability. Amazon has booked more than 100 missions across four launch providers to populate the company’s planned fleet of more than 3,200 satellites. With Thursday’s launch, Amazon has launched 214 production satellites on eight missions with United Launch Alliance, SpaceX, and now Arianespace. The Amazon Leo constellation is a competitor with SpaceX’s Starlink Internet network. SpaceX now has more than 9,000 satellites in orbit beaming broadband to more than 9 million subscribers, and all have launched on the company’s own Falcon 9 rockets. Amazon, meanwhile, initially bypassed SpaceX when selecting which companies would launch satellites for the Amazon Leo program, formerly known as Project Kuiper. Amazon booked the last nine launches on ULA’s soon-to-retire Atlas V, five of which have now flown, and reserved the rest of its launches in 2022 on rockets that had never launched before: 38 flights on ULA’s new Vulcan rocket, 24 launches on Blue Origin’s New Glenn, and 18 on Europe’s Ariane 6. An artist’s illustration of the Ariane 6’s upper stage in orbit with a stack of Amazon Leo satellites awaiting deployment. Credit: Arianespace An artist’s illustration of the Ariane 6’s upper stage in orbit with a stack of Amazon Leo satellites awaiting deployment. Credit: Arianespace Meanwhile, in Florida All three new rockets suffered delays but are now in service. The Ariane 6 has enjoyed the fastest ramp-up in launch cadence, with six flights under its belt after Thursday’s mission from French Guiana. ULA’s Vulcan rocket has flown four times, and Amazon says its first batch of satellites to fly on Vulcan is now complete. But a malfunction with one of the Vulcan launcher’s solid rocket boosters on a military launch from Florida early Thursday —the second such anomaly in three flights —raises questions about when Amazon will get its first ride on Vulcan. Blue Origin, owned by Amazon founder Jeff Bezos, is gearing up for the third flight of its heavy-lift New Glenn rocket from Florida as soon as next month. Amazon and Blue Origin have not announced when the first group of Amazon Leo satellites will launch on New Glenn.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/HA-evg8WgAAY3tl-1152x648.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Release 2026-02-12 · aws/aws-sdk-go-v2@3dca5e4 · GitHub",
      "url": "https://github.com/aws/aws-sdk-go-v2/commit/3dca5e45d5ad05460b93410087833cbaa624754e",
      "published": "2026-02-13T00:07:57+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.com/aws/aws-sdk-go-v2/commit/3dca5e45d5ad05460b93410087833cbaa624754e\">https://github.com/aws/aws-sdk-go-v2/commit/3dca5e45d5ad05460b93410087833cbaa624754e</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46997133\">https://news.ycombinator.com/item?id=46997133</a></p> <p>Points: 47</p> <p># Comments: 17</p>",
      "content_text": "* ** Feature ** : R8i instances powered by custom Intel Xeon 6 processors available only on AWS with sustained all-core 3.9 GHz turbo frequency",
      "cover_image_url": "https://opengraph.githubassets.com/7ba3578fdea8f386aa3ff7a7ae036df2f6f368e811b7f55067e23ebab3421810/aws/aws-sdk-go-v2/commit/3dca5e45d5ad05460b93410087833cbaa624754e"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Resizing windows on macOS Tahoe - the saga continues",
      "url": "https://noheger.at/blog/2026/02/12/resizing-windows-on-macos-tahoe-the-saga-continues/",
      "published": "2026-02-12T23:52:24+00:00",
      "summary": "<p>Article URL: <a href=\"https://noheger.at/blog/2026/02/12/resizing-windows-on-macos-tahoe-the-saga-continues/\">https://noheger.at/blog/2026/02/12/resizing-windows-on-macos-tahoe-the-saga-continues/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46997008\">https://news.ycombinator.com/item?id=46997008</a></p> <p>Points: 93</p> <p># Comments: 55</p>",
      "content_text": "macOS 26.3, Release Candidate In the release notes for macOS 26.3 RC, Apple stated that the window-resizing issue I demonstrated in my recent blog post had been resolved. I was happy to read that, but also curious about what had actually changed. So I wrote a little test app. It performs a pixel-by-pixel scan in the area around the bottom-right corner of the window, hammering it with simulated mouse clicks to detect exactly where it responds to those clicks (red), where it’s about to resize (green), where it’s about to resize vertically or horizontally only (yellow), and where it doesn’t receive any mouse events at all (blue). And indeed, the window resize areas now follow the corner radius instead of using square regions: So that’s definitely better! But unfortunately, as you can see, the thickness of the yellow area – used for resizing the window only vertically or horizontally – also became thinner. The portion that lies inside the window frame is now only 2 pixels instead of 3. In total the thickness went down from 7 to 6 pixels, which is a 14% decrease, making it 14% more likely to miss it. macOS 26.3, Final Release When the final version of macOS 26 was released I was curious if Apple might have further refined the implementation. So I performed the scan once again. But to my big surprise, the fix was not only unrefined – it was completely removed! So we are now back to the previous square regions: And in fact, the release notes have also been updated: the problem went from a “Resolved Issue” to a “Known Issue”.",
      "cover_image_url": "https://noheger.at/blog/wp-content/uploads/2026/02/resolved-issues.webp"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Ring cancels its partnership with Flock Safety after surveillance backlash",
      "url": "https://www.theverge.com/news/878447/ring-flock-partnership-canceled",
      "published": "2026-02-12T23:51:16+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.theverge.com/news/878447/ring-flock-partnership-canceled\">https://www.theverge.com/news/878447/ring-flock-partnership-canceled</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46996999\">https://news.ycombinator.com/item?id=46996999</a></p> <p>Points: 134</p> <p># Comments: 53</p>",
      "content_text": "Following intense backlash to its partnership with Flock Safety , a surveillance technology company that works with law enforcement agencies, Ring has announced it is canceling the integration. In a statement published on Ring’s blog and provided to The Verge ahead of publication, the company said: “Following a comprehensive review, we determined the planned Flock Safety integration would require significantly more time and resources than anticipated. We therefore made the joint decision to cancel the integration and continue with our current partners … The integration never launched, so no Ring customer videos were ever sent to Flock Safety.” The statement goes on to say that Ring’s mission to make neighborhoods safer “comes with significant responsibility — to our customers, to the communities we serve, and to the trust you place in our products and features.” Trust is the big one there. Over the last few weeks, the company has faced significant public anger over its connection to Flock, with Ring users being encouraged to smash their cameras , and some announcing on social media that they are throwing away their Ring devices. The Flock partnership was announced last October , but following recent unrest across the country related to ICE activities, public pressure against the Amazon-owned Ring’s involvement with the company started to mount. Flock has reportedly allowed ICE and other federal agencies to access its network of surveillance cameras , and influencers across social media have been claiming that Ring is providing a direct link to ICE. While that claim is not accurate, as the Flock integration has never gone live, Ring has a history of partnering with police , and the new partnership quickly came under intense criticism. Ring’s ad for Search Party showed cameras scanning a neighborhood. Screenshot from Ring video Adding fuel to the fire, this weekend Ring aired a Super Bowl ad for its new AI-powered Search Party feature. While the company says the feature is designed to find lost dogs and maintains it’s not capable of finding people , the ad raised fears that Ring cameras were being used for mass surveillance. The ad shows dozens of Ring cameras in a neighborhood scanning the streets. On top of this, the company recently launched a new facial recognition feature, Familiar Faces . Combined with Search Party, the technological leap to using neighborhood cameras to search for people through a mass-surveillance network suddenly seems very small. Sen. Ed Markey (D-MA) – a longtime critic of Ring – sent an open letter this week calling on Amazon to cancel the company’s facial recognition feature. Ring spokesperson Yassi Yarger said in an email that its products are purpose-driven tech, “not tools for mass surveillance.” She added that “Familiar Faces is an opt-in feature designed to give customers more control over the alerts they receive (e.g., ‘Mom at front door’ instead of ‘Someone at front door’) while keeping their data protected.” Why did Ring partner with Flock? Ring’s partnership with Flock was announced in October 2025 as part of Ring’s Community Requests program , which launched last September. It was designed to allow local law enforcement agencies that use Flock’s software to integrate directly with the program. Community Requests launched after Ring ended its controversial Requests for Assistance (RFA) program , which consumer advocacy groups criticized for allowing video to be provided to police without a warrant, calling it a threat to civil liberties . In its statement about the Flock cancellation, Ring maintains that Community Requests will continue, claiming it helped authorities locate a suspect during the recent Brown University shooting: “When a shooting occurred near Brown University in December 2025, every second mattered. The Providence Police Department turned to their community for help, putting out a Community Request. Within hours, 7 neighbors responded, sharing 168 videos that captured critical moments from the incident. One video identified a new key witness, helping lead police to identify the suspect’s vehicle and solve the case. With a shooter at large, the community faced uncertainty about their safety. Neighbors who chose to share footage played a crucial role in neutralizing the threat and restoring safety to their community.” As with RFA, Community Requests still allows public safety agencies to request video footage from users in a certain area during an active investigation, but it differs from the previous program because law enforcement agencies are required to partner with a third-party evidence management system – such as Flock – to use the service. Ring says this is to better maintain the chain of custody. The previous system allowed police to request footage directly from a user. Flock was the second partner Ring announced for Community Requests, the first being Axon , a law enforcement technology company known for making Tasers. With the new service, only law enforcement agencies that use these companies’ software can submit requests. But the end result is the same: law enforcement gets video from users if they choose to share it. Ring spokesperson Yassi Yarger says the Axon partnership is unaffected by the end of the Flock integration. Additionally, she says no other integrations are currently being explored. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Jennifer Pattison Tuohy Amazon Exclusive News Report Smart Home Tech",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/STKS525_MASS_SURVEILLANCE.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "For $1M, you can pay Bryan Johnson (or BryanAI?) to teach you how to live longer",
      "url": "https://techcrunch.com/2026/02/12/for-1-million-you-can-pay-bryan-johnson-or-bryanai-to-teach-you-how-to-live-longer/",
      "published": "2026-02-12T23:43:47+00:00",
      "summary": "The longevity-obsessed investor Bryan Johnson is charging $1 million to sign up for his \"Immortals\" program.",
      "content_text": "It’s the middle of February, and the air is dry. There are fine lines emerging on my forehead, maybe because I don’t moisturize enough, but maybe as a harbinger of something greater: Each day I grow closer to my own death. Soon, I will be 30. I will never be younger than I am right now. Fintech-founder-turned-longevity-guru Bryan Johnson has an offer that has caught my attention. For the low, low price of $1 million per year, I can pay him to show me the ropes of the “exact protocol” he’s followed for the last five years. He calls the program “Immortals.” Yes, a guy who has received botox injections in his genitals will teach me how to supposedly reverse the process of aging. Why shouldn’t I believe that Bryan Johnson has uncovered the secrets to living longer than any other human? No, he has not yet proven his capacity to outlive all other humans. He was born in 1977, a year in which many current humans were born. But why would I doubt the judgment of a guy who fortified his constitution with blood from his teenage son ? When have the tech elite ever misled us? Should I also question when Elon Musk says that saving for retirement is irrelevant because AGI will create an economic abundance so great that no one will ever know poverty again? According to Johnson’s post on X, this exclusive service — only three spots are available! — will include “a dedicated concierge team, BryanAI 24/7, extensive testing, millions of biological data points, continuous tracking, best skin and hair protocols, and access to the best therapies on market.” I can talk to the AI version of a guy who livestreams himself doing shrooms for “science”? Sign me up! Except I can’t. Because I do not have $1 million. Those like me will have to settle for buying Johnson’s overpriced olive oil in our pursuit of immortality (it’s peppery and smooth !). Techcrunch event Boston, MA | June 23, 2026 My emergent forehead wrinkle intensifies with the knowledge that Johnson will likely have an easy time filling up those three $1 million spots. Among the ultrawealthy, longevity has become an increasingly hot pursuit. John Hering, who has given Musk billions of dollars in backing, co-founded Biograph , which describes itself as a preventative health and diagnostics clinic. Its most premium membership costs $15,000 a year (next to Johnson’s offering, it almost seems like a good deal … almost). A similar startup, Fountain Life , has raised $108 million to fund its “ultimate longevity program,” which charges a $21,500 annual fee. Sure, Johnson’s program is a lot more expensive, but remember, there’s only three spots! And if you’re still not ready to shell out seven figures, well, you can access a vague “supported tier” for $60,000. There’s nothing wrong with wanting to live a longer, healthier life, but longevity influencers like Johnson take this to an extreme that’s unattainable and (common sense would say) totally unnecessary for the average person. In his defense, Johnson isn’t trying to proselytize us all into taking 100 pills a day and subsisting largely on boiled vegetables. But he’s also not depriving us of the chance to make him richer in exchange for his “secrets.”",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/03/Screenshot-2025-03-13-at-6.23.04PM.png?resize=1200,670"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "A surprise God of War prequel is out on the PS5 right now",
      "url": "https://www.theverge.com/games/878375/god-of-war-sons-of-sparta-trilogy-sony-playstation-ps5-release-date-trailer",
      "published": "2026-02-12T23:30:36+00:00",
      "summary": "To close out its February 2026 State of Play presentation, Sony revealed God of War Sons of Sparta, a new prequel 2D side scroller in the God of War franchise, and announced that it's out right now on PlayStation 5. \"God of War Sons of Sparta is a 2D action platformer with a canon story [&#8230;]",
      "content_text": "To close out its February 2026 State of Play presentation, Sony revealed God of War Sons of Sparta , a new prequel 2D side scroller in the God of War franchise, and announced that it’s out right now on PlayStation 5. ” God of War Sons of Sparta is a 2D action platformer with a canon story set in Kratos’ youth during his harsh training at the Agoge alongside his brother Deimos,” Sony says . Over the course of the game, Kratos will “learn deadly skills using his spear and shield, as well as harness powerful divine artifacts known as the Gifts of Olympus to take on a wide array of foes.” Sony’s Santa Monica Studio collaborated on the game with Mega Cat Studios . It costs $29.99, with a Digital Deluxe version available for $39.99. Sony also announced that it’s working on a remake of the original God of War trilogy , with TC Carson set to return as the voice of Kratos. However, the project is “still very early in development, so we ask for your patience as it will be a while before anything else can be shared,” according to Sony. “When we can come back with an update, we aim to make it a big one!”",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/videoframe_36946.png?quality=90&strip=all&crop=0%2C3.4613147178592%2C100%2C93.077370564282&w=1200"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Amid disappointing earnings, Pinterest claims it sees more searches than ChatGPT",
      "url": "https://techcrunch.com/2026/02/12/amid-disappointing-earnings-pinterest-claims-it-sees-more-searches-than-chatgpt/",
      "published": "2026-02-12T23:26:56+00:00",
      "summary": "Pinterest's stock tumbles after an earnings miss, with higher-than-expected usage its only bright spot.",
      "content_text": "After a particularly poor performance on its fourth-quarter earnings, Pinterest CEO Bill Ready attempted to favorably compare the digital pinboarding site to the popular AI chatbot ChatGPT. Trying to highlight its potential as a unique search destination, Ready asserted that the site sees larger search volume than ChatGPT. According to third-party data, ChatGPT sees 75 billion searches per month, while Pinterest sees 80 billion searches and generates 1.7 billion monthly clicks, he said. “That makes us one of the largest search destinations in the world. And importantly, more than half of those searches are commercial in nature, compared to, I think . . . approximately 2% [of ChatGPT searches],” Ready added. Pinterest in the fourth quarter missed expectations on both revenue and earnings per share, reporting $1.32 billion in revenue versus $1.33 billion expected, and earnings per share of 67 cents, compared to the 69 cents projected. It also forecast that first-quarter 2026 sales will come in between $951 million to $971 million, below the $980 million expected. The company blamed its shortfall on larger advertisers pulling back on spend, particularly in Europe, and a new furniture tariff implemented in October that caused issues within the home category. It said those trends could worsen in the first quarter. Surprisingly, Pinterest missed on earnings despite a user base that’s growing faster than expected. The company reported monthly active users were up 12% year-over-year to 619 million, when Wall Street had forecast 613 million users. Shares dropped 20% in after-hours trading. Techcrunch event Boston, MA | June 23, 2026 Pinterest has long struggled to translate the high usage of its platform into ad dollars, as its users often go to Pinterest to plan and dream, not shop and buy. That challenge could become even more acute in the AI era, especially if advertisers shift their dollars to platforms where intent to buy is clearer — such as chatbot requests that ask for product recommendations. When asked about how Pinterest will navigate the shift toward AI-powered shopping, Ready pointed to the company’s visual search, discovery, and personalization features, which he said would point users to relevant products when they open the app. “We’re helping them complete those commercial journeys without having to type in a single prompt,” he said, also noting that Pinterest had benefited from an easier checkout flow that came from its partnership with Amazon. He said customers didn’t yet seem ready to allow an AI to make a purchase on their behalf, but said Pinterest would be ready if that time came. “That’ll actually be one of the easiest parts of the commercial journey to solve,” he claimed.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/01/pinterest-header.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "IBM will hire your entry-level talent in the age of AI",
      "url": "https://techcrunch.com/2026/02/12/ibm-will-hire-your-entry-level-talent-in-the-age-of-ai/",
      "published": "2026-02-12T23:23:17+00:00",
      "summary": "IBM plans to triple its entry-level hiring in the U.S. in 2026, but these jobs will have different tasks than in previous years.",
      "content_text": "While the artificial intelligence industry touts that AI will replace entry-level jobs, not every company is scaling back hiring these positions. In IBM’s case, it’s going all in. Hardware giant IBM plans to triple entry-level hiring in the U.S. in 2026, according to reporting from Bloomberg . Nickle LaMoreaux, IBM’s chief human resource officer, announced the initiative at Charter’s Leading with AI Summit on Tuesday. “And yes, it’s for all these jobs that we’re being told AI can do,” LaMoreaux said. These jobs will look different than the entry-level jobs IBM used to offer, she explained. According to LaMoreaux, she went through and changed the descriptions for these entry-level jobs so they were less focused on areas AI can actually automate — like coding — and more focused on people-forward areas like engaging with customers. This strategy makes sense. Even if an enterprise like IBM doesn’t necessarily need the same amount of entry-level talent that it did before, fostering less experienced workers helps ensure these employees have the skills needed for the higher-level roles down the road. IBM didn’t specify how many people they would be hiring in this initiative. TechCrunch reached out to IBM for more information on the hiring plans. This year could be a pivotal one regarding what the impact of AI on the hiring market will look like. An MIT study in 2025 estimated that 11.7% of jobs could likely already be automated by AI . A TechCrunch survey found that multiple investors think 2026 will start to show AI’s potential impact on the labor market — despite not being asked about labor specifically. Techcrunch event Boston, MA | June 23, 2026",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2022/04/GettyImages-1254279163.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "The Asus Zenbook S 16 Is $500 Off and Has Never Been This Cheap",
      "url": "https://www.wired.com/story/asus-zenbook-s-16-presidents-day-sale/",
      "published": "2026-02-12T23:20:21+00:00",
      "summary": "The Asus Zenbook S 16 was a favorite of ours last year, but the price was always too high. Now it has dropped to $1,000, and it’s a total steal.",
      "content_text": "After a long time of resisting significant price drops, the Asus Zenbook S 16 has finally dropped down to $1,000 , which is $500 off its retail price. It's normal for laptops to dip in price toward the end of their lifespan, close to when an update comes out. But the Asus Zenbook S 16 has held on. To be fair, it's an extremely high-end Windows laptop , one of the prettiest to come out last year. It's sleek, portable, and has a striking design. It even gets fantastic battery life, on par with a MacBook. Speaking of MacBooks, this Zenbook is the laptop I saw tech journalists traveling with more than anything else. Given how much tech they review, that's quite an endorsement. But the S 16 has always been hard for me to recommend when the cheapest model available was $1,500. I was always on the lookout for a more significant price cut, but it never dropped more than a couple hundred bucks. And even though it always came with 24 GB of RAM and a terabyte of storage, the price was a hard pill to swallow. Well, the day has finally come. It's now down to $1,000 over at Best Buy as part of the store's Presidents’ Day sale. That's an incredible price for this much laptop. Photograph: Christopher Null Asus Zenbook S 16 (UM5606) The previously mentioned memory and storage still apply here, along with the 2880 x 1800 OLED display with a 120-Hz refresh rate. This laptop basically has every high-end feature you could imagine, but one of my favorite aspects is the ports. Despite the thin profile, the S 16 keeps all the legacy ports you might want, including HDMI, USB-A, and even a full-size SD card slot. There is also a smaller, 14-inch model, but its discount is not as strong as the 16-inch model. It comes in at $1,300 right now , which is still a solid price for this configuration. I should say that Asus has an update in the works for 2026 with the latest Intel chips , but it's only coming to the 14-inch model. I won't lie: Based on my testing, these CPUs will make a significant difference in performance—especially on the graphics front. But I have a feeling Asus will be selling this device for an even higher price for much longer, especially with the recent development around memory shortage. While the Zenbook S 16 is certainly the best deal at Best Buy for its Presidents' Day sale , I would also recommend the Asus Zephyrus G14, which is also $500 off . This configuration comes with a powerful RTX 5070 Ti graphics card and is one of our favorite gaming laptops .",
      "cover_image_url": "https://media.wired.com/photos/698e5f58e6079eaf3eb8e384/191:100/w_1280,c_limit/This%20$500%20Price%20Cut%20Just%20Made%20the%20Prettiest%20Laptop%20of%20Last%20Year%20Worth%20Buying.png"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Rivian was saved by software in 2025",
      "url": "https://techcrunch.com/2026/02/12/rivian-was-saved-by-software-in-2025/",
      "published": "2026-02-12T23:17:32+00:00",
      "summary": "The company's annual revenue was boosted by its technology joint venture with Volkswagen Group.",
      "content_text": "Rivian is, by every measure, a maker and seller of EVs. But in 2025, it was the company’s software and services that helped its annual revenue grow by 8%. Rivian reported Thursday $5.38 billion in total revenue in 2025, up from $4.97 billion from the prior year. That rosy picture dulls a bit when looking just at its automotive revenue, which fell 15% to $3.8 billion in 2025. The fall was fueled by a $134 million drop in regulatory credit sales and lower vehicle deliveries, which were partially offset by higher average selling prices, according to Rivian. Meanwhile, software and services revenue grew more than threefold to $1.55 billion for the year. And the joint venture with Volkswagen Group was behind most of that growth, according to Rivian. The “services” component of this line item, which Rivian doesn’t break out, includes a variety of items, including vehicle repair, vehicle trade-ins, and maintenance services. The remainder, and the bulk of the revenue, is from software, and specifically due to the joint venture with VW Group. VW and Rivian formed a technology joint venture in 2024 that is worth up to $5.8 billion. The joint venture is milestone-based and in 2025 Rivian hit the mark, which meant a $1 billion payout in the form of a share sale. Under the terms of the JV, Rivian will supply VW Group with its existing electrical architecture and software technology stack. Rivian received an initial $1 billion convertible note in 2024 and another $1 billion payment in July 2025. Rivian is expected to continue to receive payments from VW Group through 2027. Rivian is expected to receive an additional $2 billion of capital as part of the joint venture in 2026, CFO Claire McDonough said Thursday on the company earnings call. About $1 billion of that is subject to the successful completion of winter testing, which is underway. The remaining $1 billion is nonrecourse debt, which is expected to be received in October. And while the funds provide a hefty stopgap, Rivian’s financial success in 2026 will hinge largely on the rollout of its next EV, the R2. Techcrunch event Boston, MA | June 23, 2026 Rivian confirmed in its earnings report Thursday that the R2 SUV, which is designed to be cheaper to build and less expensive for customers, will come to market by June 2026. That “cheaper to build” line item is particularly crucial for Rivian, which has historically lost money on every vehicle it makes. Rivian has spent years trying to push the cost of goods sold figure down. And it has made progress with the rollout of its second-generation flagship R1T truck and R1S SUV. For instance, McDonough said “in the fourth quarter it was able to deliver $92,000 of cogs per unit and that was about a $4,000 per unit improvement relative to the third quarter.” Rivian’s cogs per unit was $99,000 in the fourth quarter of 2024. The company saw its total automotive cost of revenue decrease year-over-year from $1.4 billion in the fourth quarter of 2024 to $898 million in the same quarter in 2025. Notably, the company’s cost of revenue for software steadily inched up throughout 2025. The R2 SUV, which will initially launch as a dual motor all-wheel-drive model, is an opportunity to further reduce costs. The company is expected to release more information about the R2, including final specs, on March 12. Rivian’s guidance for 2026 suggests that it is banking on demand for R2 and its ability to ramp up production. The company said Thursday it expects to deliver between 62,000 and 67,000 vehicles in 2026 — which could provide up to a 59% bump from last year. Rivian delivered 42,247 vehicles in 2025, which includes its two R1 consumer vehicles and the electric delivery van (EDV). Rivian CEO RJ Scaringe noted that the company expects some growth in EDV sales in 2026. Rivian plans to produce an all-wheel-drive version and a larger battery pack variant of the EDV, for which Amazon is its primary customer. “Both of those are to help unlock specific use cases within the Amazon network,” Scaringe said. “We’re working really closely with Amazon in defining the requirements of those and excited to get those launched.” The company isn’t signaling profitability — on an adjusted basis — just yet. But it is offering up considerable improvement on that front. Rivian reported a $3.6 billion net loss in 2025; it expects an adjusted net loss of between $1.8 billion and $2.1 billion for 2026. Rivian also projects capital expenditures will be between $1.95 billion and $2.05 billion this year.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/07/250522-ANASTASIA-BENSON-GOOGLE-MAPS-AEB08056-FINAL.jpg?resize=1200,790"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Recoverable and irrecoverable decisions",
      "url": "https://herbertlui.net/recoverable-and-irrecoverable-decisions/",
      "published": "2026-02-12T23:08:01+00:00",
      "summary": "<p>Article URL: <a href=\"https://herbertlui.net/recoverable-and-irrecoverable-decisions/\">https://herbertlui.net/recoverable-and-irrecoverable-decisions/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46996569\">https://news.ycombinator.com/item?id=46996569</a></p> <p>Points: 29</p> <p># Comments: 8</p>",
      "content_text": "When you need to make an anxiety-inducing decision, ask yourself: What is the worst realistic outcome? Will you be able to recover from it? Let’s say you want to make a product and sell it, and you need to invest in inventory. The manufacturer needs you to order $1,000 worth to meet their minimum. The worst outcome: you only sell to a few friends. Can you recover from spending nearly $1,000? If not, how do you put yourself in a position to recover from it? In other words, how can you make this decision more recoverable? Or, can you make an irrecoverable outcome less likely or drastic (by taking pre-orders, earning extra with a part-time job or freelancing, or selling some old devices or clothes you don’t use—amongst many other ideas)? Keep in mind: when you’re in a good position, you can win in all sorts of ways . Here’s a day-to-day example: A haircut is recoverable because it grows back. Yes, a bad haircut can feel mortifying, but it won’t be permanent. It’s still a decision—and for some, anxiety-inducing—but it’s one you will recover from. Conventional leadership advice suggests looking at decisions as reversible or non-reversible . Many important, non-reversible, decisions are recoverable, though. The more recoverable a decision is, the more useful it is to bias for action . Entrepreneurship involves the skill of making more decisions recoverable. Thanks to my partner Bernice Liu for the idea.",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "OpenAI sidesteps Nvidia with unusually fast coding model on plate-sized chips",
      "url": "https://arstechnica.com/ai/2026/02/openai-sidesteps-nvidia-with-unusually-fast-coding-model-on-plate-sized-chips/",
      "published": "2026-02-12T22:56:02+00:00",
      "summary": "OpenAI's new GPT‑5.3‑Codex‑Spark is 15 times faster at coding than its predecessor.",
      "content_text": "On Thursday, OpenAI released its first production AI model to run on non-Nvidia hardware, deploying the new GPT-5.3-Codex-Spark coding model on chips from Cerebras. The model delivers code at more than 1,000 tokens (chunks of data) per second, which is reported to be roughly 15 times faster than its predecessor. To compare, Anthropic’s Claude Opus 4.6 in its new premium-priced fast mode reaches about 2.5 times its standard speed of 68.2 tokens per second , although it is a larger and more capable model than Spark. “Cerebras has been a great engineering partner, and we’re excited about adding fast inference as a new platform capability,” Sachin Katti, head of compute at OpenAI, said in a statement. Codex-Spark is a research preview available to ChatGPT Pro subscribers ($200/month) through the Codex app, command-line interface, and VS Code extension. OpenAI is rolling out API access to select design partners. The model ships with a 128,000-token context window and handles text only at launch. The release builds on the full GPT-5.3-Codex model that OpenAI launched earlier this month. Where the full model handles heavyweight agentic coding tasks, OpenAI tuned Spark for speed over depth of knowledge. OpenAI built it as a text-only model and tuned it specifically for coding, not for the general-purpose tasks that the larger version of GPT-5.3 handles. On SWE-Bench Pro and Terminal-Bench 2.0, two benchmarks for evaluating software engineering ability, Spark reportedly outperforms the older GPT-5.1-Codex-mini while completing tasks in a fraction of the time, according to OpenAI. The company did not share independent validation of those numbers. Anecdotally, Codex’s speed has been a sore spot; when Ars tested four AI coding agents building Minesweeper clones in December, Codex took roughly twice as long as Anthropic’s Claude Code to produce a working game. The coding agent arms race For context, GPT-5.3-Codex-Spark’s 1,000 tokens per second represents a fairly dramatic leap over anything OpenAI has previously served through its own infrastructure. According to independent benchmarks from Artificial Analysis, OpenAI’s fastest models on Nvidia hardware top out well below that mark: GPT-4o delivers roughly 147 tokens per second, o3-mini hits about 167, and GPT-4o mini clocks around 52.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2225076517_resize-1152x648.jpg"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "Trump official overruled FDA scientists to reject Moderna's flu shot",
      "url": "https://arstechnica.com/health/2026/02/trump-official-overruled-fda-scientists-to-reject-modernas-flu-shot/",
      "published": "2026-02-12T22:36:33+00:00",
      "summary": "FDA's top vaccine regulator, Vinay Prasad, is known for overruling scientists.",
      "content_text": "Still, while Moderna largely stuck with its plan to use a standard dose for all participants, it altered its plans based on the feedback. Specifically, it added a comparison of a high-dose vaccine to some older participants and provided the FDA with an additional analysis. This wasn’t enough for Prasad, who, according to the Journal’s sources, told FDA staff that he wants to send more such refusal letters that appear to blindside drug developers. The review staff apparently pushed back, noting that such moves break with the agency’s practices and could open it up to being sued. Prasad reportedly dismissed concern over possible litigation. Trump’s FDA Commissioner Marty Makary seemed similarly unconcerned, suggesting on Fox News that Moderna’s trial may be “unethical.” A senior FDA official suggested to Stat, meanwhile, that the door might not be entirely closed for Moderna’s flu vaccine. The official said that the company could toss the data for the 65 and up participants and, perhaps, grovel. “It is entirely feasible that if they come back, maybe even show some humility and say, ‘Yes, we didn’t follow your recommendation. Just take a look at the 50 to 65 group, where there’s a little more equipoise,’” the official told Stat. “Then the review team could say, ‘We’ll consider that cohort.’” The Journal notes that Moderna is at least the ninth company to have received a surprise rejection from Prasad and his team. The unpredictability is raising fears about the industry’s ability to obtain investments and innovate. Prasad, a blood cancer specialist who has no expertise or experience in vaccine regulation, is also facing internal problems at the agency. His management style has created an environment “rife with mistrust and paranoia,” according to Stat. The Journal reports that several complaints have been filed against him, including some involving sexual harassment, retaliation against subordinates, and verbally berating staﬀ.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/05/GettyImages-628879332-2560x1440.jpg"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "Spider-Noir teaser comes in colorized \"True Hue\" and black and white",
      "url": "https://arstechnica.com/culture/2026/02/spider-noir-teaser-comes-in-colorized-true-hue-and-black-and-white/",
      "published": "2026-02-12T22:14:53+00:00",
      "summary": "Nicolas Cage described his character as \"70 percent Humphrey Bogart and 30 percent Bugs Bunny.\"",
      "content_text": "Nicolas Cage stars as Ben Reilly/The Spider. YouTube/Prime Video Nicolas Cage stars as Ben Reilly/The Spider. YouTube/Prime Video Lamorne Morris plays freelance journalist Robbie Robertson. YouTube/Prime Video Lamorne Morris plays freelance journalist Robbie Robertson. YouTube/Prime Video Nicolas Cage stars as Ben Reilly/The Spider. YouTube/Prime Video Lamorne Morris plays freelance journalist Robbie Robertson. YouTube/Prime Video Li Jun Li plays sultry femme fatale nightclub singer Cat Hardy. YouTube/Prime Video Li Jun Li plays sultry femme fatale nightclub singer Cat Hardy. YouTube/Prime Video Karen Rodriguez plays Reilly’s secretary and fellow investigator Janet. YouTube/Prime Video Karen Rodriguez plays Reilly’s secretary and fellow investigator Janet. YouTube/Prime Video Li Jun Li plays sultry femme fatale nightclub singer Cat Hardy. YouTube/Prime Video Karen Rodriguez plays Reilly’s secretary and fellow investigator Janet. YouTube/Prime Video The footage was shot digitally and processed separately to create the black-and-white and color versions. The team coined the term “True Hue” for the latter, since the intent was to create something that looked supersaturated, like classic Technicolor. (Cage compared the feel to the 1944 Edward Hopper painting Nighthawks .) Per the official premise: “ Spider-Noir tells the story of Ben Reilly (Nicolas Cage), a seasoned, down on his luck private investigator in 1930s New York, who is forced to grapple with his past life, following a deeply personal tragedy, as the city’s one and only superhero.” In addition to Cage’s Ben Reilly/The Spider, the cast includes Lamorne Morris as Reilly’s friend Robbie Robertson, a freelance journalist who clings to optimism in the face of his buddy’s cynicism; Li Jun Li as nightclub singer Cat Hardy, the classic underworld femme fatale (Li based her portrayal on Anna May Wong, Rita Hayworth, and Lauren Bacall); Karen Rodriguez as Reilly’s secretary, Janet; Abraham Popoola as a World War I veteran; Jack Huston as a bodyguard named Flint Marko; Brendan Gleeson as New York mob boss Silvermane, who is being targeted for assassination; Lukas Haas as one of Silvermane’s subordinates; Richard Robichaux as the editor of the Daily Bugle; and Kai Caster. Frankly, we’re digging the black and white, but here’s the True Hue color version of the teaser for good measure: VIDEO Spider-Noir premieres on May 25, 2026, on MGM+, with all episodes becoming available on Prime Video on May 27, 2026. Viewers can choose to watch in black and white or True Hue.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/noirTOP-1152x648-1770930363.jpg"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "‘Uncanny Valley’: ICE’s Secret Expansion Plans, Palantir Workers’ Ethical Concerns, and AI Assistants",
      "url": "https://www.wired.com/story/uncanny-valley-podcast-ice-expansion-palantir-workers-ethical-concerns-openclaw-ai-assistants/",
      "published": "2026-02-12T22:12:42+00:00",
      "summary": "In this episode of Uncanny Valley, our hosts dive into WIRED’s scoop about a secret Trump administration campaign extending right into your backyard.",
      "content_text": "Brian Barrett: They've got 80 billion or so to spend 75 billion of that I think they have to spend in the next four years. So yeah, they're going to keep expanding. And when you think of how much of an impact 3000 agents officers had in Minneapolis alone, that's like an eighth of the, they can repeat some version of that in a lot of different spots. Leah Feiger: And I've been fielding, honestly, shout out to the many local reporters around the country who've been contacting me in the last day or so, just to ask questions about the locations that we named that are near them or in their states or cities. And the thing to me that keeps coming up is that in addition to new buildings, they're getting put into preexisting government buildings, preexisting leases, or that that appears to be the plan. And then we've also found that a bunch of these ICE offices are being located near plans for giant immigration detention warehouses, and we're looking at offices being set up, say 20 minutes, an hour and 20 minutes away for these. Yeah. So we're looking at different, the triangulation of this around you have to have your lawyers, your agents, have a place to get their orders and put their computers and do in some ways very mundane things that are required of an operation like this one. Brian Barrett: Well, Leah, that's a good point. I think when people hear ICE offices or when I do just instinctively, I think of ICE as guys with guns and masks and all that, but that's not exactly what we're saying here. Do you mind talking through what these offices seem to be queued up to be used for and by whom? Because ICE is not just the masked guys with bad tattoos. Leah Feiger: Yes, absolutely. So what we reported in this story as well was some of the specific parts of ICE that actually reached out to GSA and asked them to expedite the process of getting new leases, et cetera, included in that, for example, where representatives from Ola, Ola is ICE's office of the principal legal advisor. So that's the lawyers, those are the ICE lawyers that are working with the courts and arguing back or deportation orders saying yes, no, et cetera, signing the documents, putting everything in front of judges. This is a really important part of this entire operation that we're not talking about a ton. There's a lot of focus on the DOJ. There's a lot of focus. There was an excellent article this week in Politico talking about all of these federal judges that are really, really upset that DHS and ICE are ignoring their requests for immigrants to not be detained anymore. The missing level of that is the lawyers that are part of this that are representing ICE to the US government here, and that's ola. So they've reached out to GSA extensively as we report to get these leasing locations, specifically with the OLA legal request. I just want to get across how big this is. How massive is this ICE repeatedly outlined its expansion to cities around the us And this one piece of memorandum that we got from Ola stated that ICE will be expanding its legal operations into Birmingham, Alabama, Fort Lauderdale, Fort Myers, Jacksonville, and Tampa, Des Moines, Iowa, Boise, Idaho, Louisville, Kentucky, Baton Rouge, Louisiana, grand Rapids, Michigan, St. Louis, Missouri, rally, North Carolina, long Island, New York, Columbus, Ohio, Oklahoma City, Oklahoma, Pittsburgh, Pennsylvania, Charleston and Columbia, South Carolina, Nashville, Tennessee, Richmond, Virginia, Spokane, Washington and Cord Delaine, Idaho and Milwaukee, Wisconsin. We have other locations as well throughout the rest of the article, but those are the requests from OLA.",
      "cover_image_url": "https://media.wired.com/photos/698d17a4fbe49e3e4a648a71/191:100/w_1280,c_limit/Uncanny-Valley-Ice-Expansion-2235818079.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Musk needed a new vision for SpaceX and xAI. He landed on Moonbase Alpha.",
      "url": "https://techcrunch.com/2026/02/12/musk-needed-a-new-vision-for-spacex-and-xai-he-landed-on-moonbase-alpha/",
      "published": "2026-02-12T22:10:55+00:00",
      "summary": "\"I really want to see a mass driver on the moon that is shooting AI satellites into deep space.\"",
      "content_text": "“Join xAI if the idea of mass drivers on the Moon appeals to you,” CEO Elon Musk proclaimed yesterday following a restructuring that saw a stream of former executives exit the AI lab . This is an interesting recruitment strategy after the company’s merger with Musk’s rocket maker, SpaceX, and the combined company’s anticipated IPO. You might think that xAI employees ought to be fascinated with achieving AGI, using deep learning models to disrupt traditional software companies, or simply bad wordplay like “Macrohard.” But instead, Elon is going to the moon. After outlining plans to build AI data centers in orbit , the primary synergy between the two companies, Musk took the idea further. “What if you want to go beyond a mere terawatt per year?” Musk asked. “To do that, you have to go to the moon…I really want to see a mass driver on the moon that is shooting AI satellites into deep space.” New year, new dream Image Credits: SpaceX In Musk’s telling, the step beyond data centers orbiting Earth is even larger computers in deep space. And furthermore, Musk says the best way to achieve that is to build a city on the moon to manufacture space computers and hurl them into the solar system using a big maglev train. If that all feels a bit much, veteran Musk watchers know there’s a clue about where the discussion appears in a video of an all-hands meeting xAI shared with the public. The slide describing the moon base comes at the end of the presentation deck, where, during SpaceX pep talks, Musk typically shares renderings of SpaceX rockets landing on Mars and waxes rhapsodic about the future of multi-planetary humanity. Notably, the moon base comes just after SpaceX has publicly backed away from its long-held goal of colonizing Mars. Now, with xAI in the corporate fold, Musk needs a new science fiction metaphor for the future: In this case, the Kardashev Scale , a theoretical measure of galactic civilizations coined by the eponymous Soviet astronomer in the 1960s. The idea is climbing the scale of energy usage — early civilizations figure out how to leverage all the power sources on their planets, and then (hypothetically) go to space and build infrastructure to capture the energy of the sun. With the moon base, Musk says the company could harness “maybe even a few percent of the sun’s energy” to train and operate AI models. “It’s difficult to imagine what an intelligence of that scale would think about,” he told his staff, “but it’s going to be incredibly exciting to see it happen.” Techcrunch event Boston, MA | June 23, 2026 In the nine years since Musk unveiled his plan for Martian exploration and colonization, the vision has been an effective hiring tool for SpaceX: The founding tale of Musk’s interest in the Red Planet offered a long-term vision that united the company’s various development efforts, and signaled the company’s ambition among other space contractors that settled for incremental work on government priorities. “Occupy Mars” t-shirts offered a visible symbol of SpaceX’s aspirations. That’s where the hypothetical moon base fits in — part of a long history of Musk wrapping his companies in a powerful narrative. It’s one million people living on Mars, but now catering to a future where AI is the most interesting thing. Martian mission creep became apparent less in Musk’s May 2025 Starship update , when the presentation ended with a now-cancelled vision of Tesla Optimus robots clomping across the Red Planet. Poor robot Image Credits: SpaceX There was just one problem with SpaceX and Mars: No one wanted to pay them to go there. Plans announced in 2016 to repurpose the company’s Dragon spacecraft as a Mars lander were abandoned the next year after the technical challenges became too costly. And since Musk unveiled the vehicle that would become Starship in 2016, its capabilities, initially intended for Mars colonization, have been scaled back to focus on two more remunerative tasks: launching satellites for the Starlink comms network and $4 billion worth of contracts to land astronauts on the moon for NASA. Unlike a multi-planetary civilization, there may be some logic in having SpaceX purchase a money-burning AI and social media to build data centers in Earth orbit, particularly if forecasts of rising demand and costs on the ground come true. Experts suggest that it might be possible in the 2030s. Hypothetically, building satellites on the moon would require a lot more of Musk’s other dreams coming true first. Scientists and startups are experimenting with building chips and other precision components in space. But mass-producing many tons of advanced computers on the moon means we’re living in a universe where it is dramatically cheaper to get to space, which is the central requirement for those technologies, getting all the raw materials for such an effort to the moon, plus whatever is required for a “self-sustaining city.” In a sense, that’s the point: This is the, uh, stretch goal. If meme-happy retail investors buy the argument, they could turn SpaceX shares into the next Tesla. The engineers, AI or aerospace, who Musk needs to achieve his goals may find the shift jarring. But the vision is one way to explain what xAI is about, other than an LLM perhaps best known as a pervert . As one of the company’s departing executives said on his way out the door, “all AI labs are building the exact same thing, and it’s boring.” Mass-producing a solar system-scale supercomputer on the moon is many things (I’m going to get emails for not using the word “insane”), but it is not the exact same thing, and it is not boring.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/Screenshot-2026-02-12-at-10.37.51-AM.png?resize=1200,666"
    },
    {
      "industry": "technology",
      "source": "VentureBeat",
      "title": "Nvidia’s new technique cuts LLM reasoning costs by 8x without losing accuracy",
      "url": "https://venturebeat.com/orchestration/nvidias-new-technique-cuts-llm-reasoning-costs-by-8x-without-losing-accuracy",
      "published": "2026-02-12T22:00:00+00:00",
      "summary": "<p>Researchers at Nvidia have developed a technique that can reduce the memory costs of large language model reasoning by up to eight times. Their technique, called <a href=\"https://arxiv.org/abs/2506.05345\"><u>dynamic memory sparsification</u></a> (DMS), compresses the key value (KV) cache, the temporary memory LLMs generate and store as they process prompts and reason through problems and documents.</p><p>While researchers have proposed various methods to compress this cache before, most struggle to do so without degrading the model&#x27;s intelligence. Nvidia&#x27;s approach manages to discard much of the cache while maintaining (and in some cases improving) the model&#x27;s reasoning capabilities.</p><p>Experiments show that DMS enables LLMs to &quot;think&quot; longer and explore more solutions without the usual penalty in speed or memory costs.</p><h2>The bottleneck of reasoning</h2><p>LLMs improve their performance on complex tasks by generating &quot;<a href=\"https://venturebeat.com/ai/dont-believe-reasoning-models-chains-of-thought-says-anthropic\"><u>chain-of-thought</u></a>&quot; tokens, essentially writing out their reasoning steps before arriving at a final answer. Inference-time scaling techniques leverage this by giving the model a larger budget to generate these thinking tokens or to explore multiple potential reasoning paths in parallel.</p><p>However, this improved reasoning comes with a significant computational cost. As the model generates more tokens, it builds up a <a href=\"https://venturebeat.com/ai/mixture-of-recursions-delivers-2x-faster-inference-heres-how-to-implement-it\"><u>KV cache</u></a>. </p><p>For real-world applications, the KV cache is a major bottleneck. As the reasoning chain grows, the cache grows linearly, consuming vast amounts of memory on GPUs. This forces the hardware to spend more time reading data from memory than actually computing, which slows down generation and increases latency. It also caps the number of users a system can serve simultaneously, as running out of VRAM causes the system to crash or slow to a crawl.</p><p>Nvidia researchers frame this not just as a technical hurdle, but as a fundamental economic one for the enterprise.</p><p>&quot;The question isn&#x27;t just about hardware quantity; it&#x27;s about whether your infrastructure is processing 100 reasoning threads or 800 threads for the same cost,&quot; Piotr Nawrot, Senior Deep Learning Engineer at Nvidia, told VentureBeat.</p><p>Previous attempts to solve this focused on heuristics-based approaches. These methods use rigid rules, such as a &quot;sliding window&quot; that only caches the most recent tokens and deletes the rest. While this reduces memory usage, it often forces the model to discard critical information required for solving the problem, degrading the accuracy of the output.</p><p>&quot;Standard eviction methods attempt to select old and unused tokens for eviction using heuristics,&quot; the researchers said. &quot;They simplify the problem, hoping that if they approximate the model&#x27;s internal mechanics, the answer will remain correct.&quot;</p><p>Other solutions use paging to offload the unused parts of the KV cache to slower memory, but the constant swapping of data introduces latency overhead that makes real-time applications sluggish.</p><h2>Dynamic memory sparsification</h2><p>DMS takes a different approach by &quot;retrofitting&quot; existing LLMs to intelligently manage their own memory. Rather than applying a fixed rule for what to delete, DMS trains the model to identify which tokens are essential for future reasoning and which are disposable.</p><p>&quot;It doesn&#x27;t just guess importance; it learns a policy that explicitly preserves the model&#x27;s final output distribution,&quot; Nawrot said.</p><p>The process transforms a standard, pre-trained LLM such as Llama 3 or Qwen 3 into a self-compressing model. Crucially, this does not require training the model from scratch, which would ",
      "content_text": "<p>Researchers at Nvidia have developed a technique that can reduce the memory costs of large language model reasoning by up to eight times. Their technique, called <a href=\"https://arxiv.org/abs/2506.05345\"><u>dynamic memory sparsification</u></a> (DMS), compresses the key value (KV) cache, the temporary memory LLMs generate and store as they process prompts and reason through problems and documents.</p><p>While researchers have proposed various methods to compress this cache before, most struggle to do so without degrading the model&#x27;s intelligence. Nvidia&#x27;s approach manages to discard much of the cache while maintaining (and in some cases improving) the model&#x27;s reasoning capabilities.</p><p>Experiments show that DMS enables LLMs to &quot;think&quot; longer and explore more solutions without the usual penalty in speed or memory costs.</p><h2>The bottleneck of reasoning</h2><p>LLMs improve their performance on complex tasks by generating &quot;<a href=\"https://venturebeat.com/ai/dont-believe-reasoning-models-chains-of-thought-says-anthropic\"><u>chain-of-thought</u></a>&quot; tokens, essentially writing out their reasoning steps before arriving at a final answer. Inference-time scaling techniques leverage this by giving the model a larger budget to generate these thinking tokens or to explore multiple potential reasoning paths in parallel.</p><p>However, this improved reasoning comes with a significant computational cost. As the model generates more tokens, it builds up a <a href=\"https://venturebeat.com/ai/mixture-of-recursions-delivers-2x-faster-inference-heres-how-to-implement-it\"><u>KV cache</u></a>. </p><p>For real-world applications, the KV cache is a major bottleneck. As the reasoning chain grows, the cache grows linearly, consuming vast amounts of memory on GPUs. This forces the hardware to spend more time reading data from memory than actually computing, which slows down generation and increases latency. It also caps the number of users a system can serve simultaneously, as running out of VRAM causes the system to crash or slow to a crawl.</p><p>Nvidia researchers frame this not just as a technical hurdle, but as a fundamental economic one for the enterprise.</p><p>&quot;The question isn&#x27;t just about hardware quantity; it&#x27;s about whether your infrastructure is processing 100 reasoning threads or 800 threads for the same cost,&quot; Piotr Nawrot, Senior Deep Learning Engineer at Nvidia, told VentureBeat.</p><p>Previous attempts to solve this focused on heuristics-based approaches. These methods use rigid rules, such as a &quot;sliding window&quot; that only caches the most recent tokens and deletes the rest. While this reduces memory usage, it often forces the model to discard critical information required for solving the problem, degrading the accuracy of the output.</p><p>&quot;Standard eviction methods attempt to select old and unused tokens for eviction using heuristics,&quot; the researchers said. &quot;They simplify the problem, hoping that if they approximate the model&#x27;s internal mechanics, the answer will remain correct.&quot;</p><p>Other solutions use paging to offload the unused parts of the KV cache to slower memory, but the constant swapping of data introduces latency overhead that makes real-time applications sluggish.</p><h2>Dynamic memory sparsification</h2><p>DMS takes a different approach by &quot;retrofitting&quot; existing LLMs to intelligently manage their own memory. Rather than applying a fixed rule for what to delete, DMS trains the model to identify which tokens are essential for future reasoning and which are disposable.</p><p>&quot;It doesn&#x27;t just guess importance; it learns a policy that explicitly preserves the model&#x27;s final output distribution,&quot; Nawrot said.</p><p>The process transforms a standard, pre-trained LLM such as Llama 3 or Qwen 3 into a self-compressing model. Crucially, this does not require training the model from scratch, which would be prohibitively expensive. Instead, DMS repurposes existing neurons within the model’s attention layers to output a &quot;keep&quot; or &quot;evict&quot; signal for each token.</p><p>For teams worried about the complexity of retrofitting, the researchers noted that the process is designed to be lightweight. &quot;To improve the efficiency of this process, the model&#x27;s weights can be frozen, which makes the process similar to Low-Rank Adaptation (LoRA),&quot; Nawrot said. This means a standard enterprise model like Qwen3-8B &quot;can be retrofitted with DMS within hours on a single DGX H100.&quot;</p><p>One of the important parts of DMS is a mechanism called &quot;delayed eviction.&quot; In standard sparsification, if a token is deemed unimportant, it is deleted immediately. This is risky because the model might need a split second to integrate that token&#x27;s context into its current state.</p><p>DMS mitigates this by flagging a token for eviction but keeping it accessible for a short window of time (e.g., a few hundred steps). This delay allows the model to &quot;extract&quot; any remaining necessary information from the token and merge it into the current context before the token is wiped from the KV cache.</p><p>“The ‘delayed eviction’ mechanism is crucial because not all tokens are simply ‘important’ (keep forever) or ‘useless’ (delete immediately). Many fall in between — they carry some information, but not enough to justify occupying an entire slot in memory,” Nawrot said. “This is where the redundancy lies. By keeping these tokens in a local window for a short time before eviction, we allow the model to attend to them and redistribute their information into future tokens.”</p><p>The researchers found that this retrofitting process is highly efficient. They could equip a pre-trained LLM with DMS in just 1,000 training steps, a tiny fraction of the compute required for the original training. The resulting models use standard kernels and can drop directly into existing high-performance inference stacks without custom hardware or complex software rewriting.</p><h2>DMS in action</h2><p>To validate the technique, the researchers applied DMS to several reasoning models, including the Qwen-R1 series (distilled from DeepSeek R1) and Llama 3.2, and tested them on difficult benchmarks like AIME 24 (math), GPQA Diamond (science), and LiveCodeBench (coding).</p><p>The results show that DMS effectively moves the Pareto frontier, the optimal trade-off between cost and performance. On the AIME 24 math benchmark, a Qwen-R1 32B model equipped with DMS achieved a score 12.0 points higher than a standard model when constrained to the same memory bandwidth budget. By compressing the cache, the model could afford to &quot;think&quot; much deeper and wider than the standard model could for the same memory and compute budget.</p><p>Perhaps most surprisingly, DMS defied the common wisdom that compression hurts long-context understanding. In &quot;needle-in-a-haystack&quot; tests, which measure a model&#x27;s ability to find a specific piece of information buried in a large document, DMS variants actually outperformed the standard models. By actively managing its memory rather than passively accumulating noise, the model maintained a cleaner, more useful context.</p><p>For enterprise infrastructure, the efficiency gains translate directly to throughput and hardware savings. Because the memory cache is significantly smaller, the GPU spends less time fetching data, reducing the wait time for users. In tests with the Qwen3-8B model, DMS matched the accuracy of the vanilla model while delivering up to 5x higher throughput. This means a single server can handle five times as many customer queries per second without a drop in quality.</p><h2>The future of memory</h2><p>Nvidia has released DMS as part of its <a href=\"https://github.com/NVIDIA/kvpress\"><u>KVPress library</u></a>. Regarding how enterprises can get started with DMS, Nawrot emphasized that the barrier to entry is low. &quot;The &#x27;minimum viable infrastructure&#x27; is standard Hugging Face pipelines — no custom CUDA kernels are required,&quot; Nawrot said, noting that the code is fully compatible with standard FlashAttention. </p><p>Looking ahead, the team views DMS as part of a larger shift where memory management becomes a distinct, intelligent layer of the AI stack. Nawrot also confirmed that DMS is &quot;fully compatible&quot; with newer architectures like the <a href=\"https://bdtechtalks.com/2025/04/07/deepseek-innovations/\"><u>Multi-Head Latent Attention</u></a> (MLA) used in DeepSeek’s models, suggesting that combining these approaches could yield even greater efficiency gains.</p><p>As enterprises move from simple chatbots to complex agentic systems that require extended reasoning, the cost of inference is becoming a primary concern. Techniques like DMS provide a path to scale these capabilities sustainably.</p><p>&quot;We’ve barely scratched the surface of what is possible,&quot; Nawrot said, &quot;and we expect inference-time scaling to further evolve.&quot; </p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "PlayStation State of Play February 2026: all the news and trailers",
      "url": "https://www.theverge.com/games/877875/playstation-state-of-play-february-2026-ps5-news-trailers",
      "published": "2026-02-12T21:45:00+00:00",
      "summary": "Strap in, because the next PlayStation event is going to be a long one. Sony&#8217;s latest State of Play — a showcase event for upcoming PS5 games — kicks off on February 12th at 5PM ET and it&#8217;ll last more than an hour. We don&#8217;t know what exactly will be shown. Sony says that the [&#8230;]",
      "content_text": "Strap in, because the next PlayStation event is going to be a long one . Sony‚Äôs latest State of Play ‚Äî a showcase event for upcoming PS5 games ‚Äî kicks off on February 12th at 5PM ET and it‚Äôll last more than an hour. We don‚Äôt know what exactly will be shown. Sony says that the event will include ‚Äúnews, gameplay updates, and announcements from game studios across the globe.‚Äù However, it sounds like one of the biggest upcoming PS5 games, Insomniac‚Äôs bloody take on Wolverine , might not make an appearance . Most likely the event will feature a mixture of some of Sony‚Äôs tentpole single-player experiences from studios like Naughty Dog , along with its continued ( albeit scaled back ) push into live-service games through upcoming titles like Horizon Hunters Gathering and Bungie‚Äôs return to Marathon . You can watch the event live on both Twitch and YouTube , and stay tuned here for all of the most important and interesting reveals and announcements.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/22015304/vpavic_4278_20201030_0247.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "ULA's Vulcan rocket suffers another booster problem on the way to orbit",
      "url": "https://arstechnica.com/space/2026/02/ulas-vulcan-launcher-still-has-a-solid-rocket-booster-problem/",
      "published": "2026-02-12T21:33:13+00:00",
      "summary": "Vulcan's Blue Origin-made BE-4 engines appear to have saved the rocket from failure.",
      "content_text": "Moments after liftoff from Florida’s Space Coast early Thursday morning, a shower of sparks emerged in the exhaust plume of United Launch Alliance’s Vulcan rocket. Seconds later, the rocket twisted on its axis before recovering and continuing the climb into orbit with a batch of US military satellites. The sight may have appeared familiar to seasoned rocket watchers. Sixteen months ago, a Vulcan rocket lost one of its booster nozzles shortly after launch from Cape Canaveral Space Force Station. The rocket recovered from the malfunction and still reached the mission’s planned orbit. Details of Thursday’s booster problem remain unclear. An investigation into the matter is underway, according to ULA, a 50-50 joint venture between Boeing and Lockheed Martin. But the circumstances resemble those of the booster malfunction in October 2024 . Closeup video from Thursday’s launch shows a fiery plume near the throat of one of the rocket’s four solid-fueled boosters, the area where the motor’s propellant casing connects to its bell-shaped exhaust nozzle. The throat drives super-hot gas from the burning solid propellant through the nozzle to generate thrust. Anomalous plume The plume first appeared less than 30 seconds after liftoff at 4:22 am EST (09:22 UTC) on Thursday. The rocket later released a cloud of sparks and debris a little more than a minute into the flight. That was followed by a sudden rolling motion along the long axis of the Vulcan launcher. Finally, the rocket’s four strap-on boosters burned out and were jettisoned, falling into the Atlantic Ocean, and ULA said the rest of the mission continued without incident. “Early during flight, the team observed a significant performance anomaly on one of the four solid rocket motors. Despite the observation, the Vulcan booster and Centaur performed nominally and delivered the spacecraft directly to geosynchronous orbit,” said Gary Wentz, ULA’s vice president of Atlas and Vulcan programs. “The integrated US government and contractor team is reviewing the technical data, available imagery, and establishing a recovery team to collect any debris. We will conduct a thorough investigation, identify root cause, and implement any corrective action necessary before the next Vulcan mission.”",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/v004plume-1152x648-1770930283.jpg"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "EPA kills foundation of greenhouse gas regulations",
      "url": "https://arstechnica.com/tech-policy/2026/02/as-expected-trumps-epa-guts-climate-endangerment-finding/",
      "published": "2026-02-12T21:04:22+00:00",
      "summary": "The agency is betting the the Supreme Court will reverse a prior ruling.",
      "content_text": "In a widely expected move, the Environmental Protection Agency has announced that it is revoking an analysis of greenhouse gases that laid the foundation for regulating their emissions by cars, power plants, and industrial sources. The analysis, called an endangerment finding, was initially ordered by the US Supreme Court in 2007 and completed during the Obama administration; it has, in theory, served as the basis of all government regulations of carbon dioxide emissions since. In practice, lawsuits and policy changes between Democratic and Republican administrations have meant it has had little impact. In fact, the first Trump administration left the endangerment finding in place, deciding it was easier to respond to it with weak regulations than it was to challenge its scientific foundations, given the strength of the evidence for human-driven climate change. Legal tactics The second Trump administration, however, was prepared to tackle the science head-on, gathering a group of contrarians to write a report questioning that evidence. It did not go well, either scientifically or legally . Today’s announcement ignores the scientific foundations of the endangerment finding and argues that it’s legally flawed. “The Trump EPA’s final rule dismantles the tactics and legal fictions used by the Obama and Biden Administrations to backdoor their ideological agendas on the American people,” the EPA claims. The claim is awkward, given that the “legal fictions” referenced include a Supreme Court decision ordering the EPA to conduct an endangerment analysis.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2020/03/sad-epa-smog.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Welcoming Discord users amidst the challenge of Age Verification",
      "url": "https://matrix.org/blog/2026/02/welcome-discord/",
      "published": "2026-02-12T20:57:33+00:00",
      "summary": "<p>Article URL: <a href=\"https://matrix.org/blog/2026/02/welcome-discord/\">https://matrix.org/blog/2026/02/welcome-discord/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46995046\">https://news.ycombinator.com/item?id=46995046</a></p> <p>Points: 218</p> <p># Comments: 109</p>",
      "content_text": "Hi all, We’ve seen a huge spike of signups on the matrix.org homeserver over the last few days due to Discord announcing its plans to age-verify all users as of next month . We’d like to give a warm welcome to the massive influx of users currently trying Matrix as an open decentralised alternative to centralised platforms like Discord. We wish we had more time and resources to develop all the features needed for mainstream adoption (see The Road To Mainstream Matrix from last year’s FOSDEM), but we're happy to welcome you anyway! The biggest difference between Matrix and Discord is that Matrix is an open standard, like email or the Web. There’s a wide range of both clients and servers, and anyone can run their own server on their own terms while participating in the global Matrix network. However, it’s important to note that server admins are still subject to the law in the jurisdiction where they operate. Practically speaking, that means that people and organisations running a Matrix server with open registration must verify the ages of users in countries which require it. Last summer we announced a series of changes to the terms and conditions of the Matrix.org homeserver instance, to ensure UK-based users are handled in alignment with the UK’s Online Safety Act (OSA). Since then Australia, New Zealand and the EU have introduced similar legislation, with movement in the US and Canada too. If you’ve been around for a while, you will have seen that we started raising the alarm about the dangers and potential risks of the OSA back in 2021 - but the reality is that these laws already apply, and the consequences of getting it wrong are serious. From our perspective, the matrix.org homeserver instance has never been a service aimed at children, which our terms of use reflect by making it clear that users need to be at least 18 years old to use the server. However, the various age-verification laws require stricter forms of age verification measures than a self-declaration. Our Safety team and DPO are evaluating options that preserve your privacy while satisfying the age verification requirements in the jurisdictions where we have users. As a free service, we also have to be mindful of the cost of age-verification compliance. Paying for a matrix.org Premium account with a credit card is one approach which would verify your account and support our work. Premium accounts are currently going through a phased roll out, so if you’re on an older account you might not see the option to convert your account yet, you can mail [email protected] if you wish to be upgraded. We also want to make it easy for users to move their account to another server with a feature called account portability. Account portability would give users more freedom to choose a server that matches their needs, and it would reduce the load on our matrix.org server. This takes significant work, but there should be some new Matrix Spec Change proposals (MSCs) in the coming weeks showing the direction of travel. Finally: we’re painfully aware that none of the Matrix clients available today provide a full drop-in replacement for Discord yet. All the ingredients are there, and the initial goal for the project was always to provide a decentralised, secure, open platform where communities and organisations could communicate together. However, the reality is that the team at Element who originally created Matrix have had to focus on providing deployments for the public sector (see here or here ) to be able to pay developers working on Matrix. Some of the key features expected by Discord users have yet to be prioritised (game streaming, push-to-talk, voice channels, custom emoji, extensible presence, richer hierarchical moderation, etc). Meanwhile no other organisation stepped up to focus on the “communication tool for communities” use case and provide a production ready Discord alternative, but clients like Cinny or Commet may feel much closer to Discord. On the other hand, Matrix goes far beyond Discord in other areas: both messages, files and calls are end-to-end-encrypted; we have read receipts; Matrix is an open protocol everyone can extend, and in the end, most Matrix clients are open source; there is nothing stopping developers from starting their own project based on existing ones and adding the missing features themselves. They may even eventually get accepted in the original projects! Anyway, TL;DR: Welcome to everyone trying Matrix for the first time; please understand that public Matrix servers will also have to uphold age verification laws, as misguided as they might be. However, at least in Matrix you have the opportunity to run your own servers as you wish: we actively encourage you to make your own assessments and seek legal advice where needed. The Foundation needs you The Matrix.org Foundation is a non-profit and only relies on donations to operate. Its core mission is to maintain the Matrix Specification, but it does much more than that. It maintains the matrix.org homeserver and hosts several bridges for free. It fights for our collective rights to digital privacy and dignity. Support us",
      "cover_image_url": "https://matrix.org/blog/img/matrix-logo.png"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "ICE, CBP Knew Facial Recognition App Couldn’t Do What DHS Says It Could, Deployed It Anyway",
      "url": "https://www.techdirt.com/2026/02/12/ice-cbp-knew-facial-recognition-app-couldnt-do-what-dhs-says-it-could-deployed-it-anyway/",
      "published": "2026-02-12T20:53:30+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.techdirt.com/2026/02/12/ice-cbp-knew-facial-recognition-app-couldnt-do-what-dhs-says-it-could-deployed-it-anyway/\">https://www.techdirt.com/2026/02/12/ice-cbp-knew-facial-recognition-app-couldnt-do-what-dhs-says-it-could-deployed-it-anyway/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46995001\">https://news.ycombinator.com/item?id=46995001</a></p> <p>Points: 147</p> <p># Comments: 39</p>",
      "content_text": "ICE, CBP Knew Facial Recognition App Couldn’t Do What DHS Says It Could, Deployed It Anyway from the fuck-everyone-but-us-policy-still-in-play dept The DHS and its components want to find non-white people to deport by any means necessary. Of course, “necessary” is something that’s on a continually sliding scale with Trump back in office, which means everything (legal or not) is “necessary” if it can help White House advisor Stephen Miller hit his self-imposed 3,000 arrests per day goal. As was reported last week, DHS components (ICE, CBP) are using a web app that supposedly can identify people and link them with citizenship documents. As has always been the case with DHS components (dating back to the Obama era), the rule of thumb is “deploy first, compile legally-required paperwork later.” The pattern has never changed. ICE, CBP, etc. acquire new tech, hand it out to agents, and much later — if ever — the agencies compile and publish their legally-required Privacy Impact Assessments (PIAs). PIAs are supposed to precede deployments of new tech that might have an impact on privacy rights and other civil liberties. In almost every case, the tech has been deployed far ahead of the precedential paperwork. As one would expect, the Trump administration was never going to be the one to ensure the paperwork arrived ahead of the deployment. As we covered recently , both ICE and CBP are using tech provided by NEC called “Mobile Fortify” to identify migrants who are possibly subject to removal, even though neither agency has bothered to publish a Privacy Impact Assessment. As Wired reported , the app is being used widely by officers working with both agencies, despite both agencies making it clear they don’t have the proper paperwork in place to justify these deployments. While CBP says there are “sufficient monitoring protocols” in place for the app, ICE says that the development of monitoring protocols is in progress, and that it will identify potential impacts during an AI impact assessment. According to guidance from the Office of Management and Budget, which was issued before the inventory says the app was deployed for either CBP or ICE, agencies are supposed to complete an AI impact assessment before deploying any high-impact use case. Both CBP and ICE say the app is “high-impact” and “deployed.” While this is obviously concerning, it would be far less concerning if we weren’t dealing with an administration that has told immigration officers that they don’t need warrants to enter houses or effect arrests . And it would be insanely less concerning if we weren’t dealing with an administration that has claimed that simply observing or reporting on immigration enforcement efforts is an act of terrorism. Officers working for the combined forces of bigotry d/b/a/ “immigration enforcement” know they’re safe. The Supreme Court has ensured they’re safe by making it impossible to sue federal officers. And the people running immigration-related agencies have made it clear they don’t even care if the ends justify the means. These facts make what’s reported here even worse , especially when officers are using the app to “identify” pretty much anyone they can point a smartphone at. Despite DHS repeatedly framing Mobile Fortify as a tool for identifying people through facial recognition, however, the app does not actually “verify” the identities of people stopped by federal immigration agents—a well-known limitation of the technology and a function of how Mobile Fortify is designed and used. […] Records reviewed by WIRED also show that DHS’s hasty approval of Fortify last May was enabled by dismantling centralized privacy reviews and quietly removing department-wide limits on facial recognition—changes overseen by a former Heritage Foundation lawyer and Project 2025 contributor, who now serves in a senior DHS privacy role. Even if you’re the sort of prick who thinks whatever happens to non-citizens is deserved due to their alleged violation of civil statutes, one would hope you’d actually care what happens to your fellow citizens. I mean, one would hope, but even the federal government doesn’t care what happens to US citizens if they happen to be unsupportive of Trump’s migrant-targeting crime wave. DHS—which has declined to detail the methods and tools that agents are using, despite repeated calls from oversight officials and nonprofit privacy watchdogs —has used Mobile Fortify to scan the faces not only of “targeted individuals,” but also people later confirmed to be US citizens and others who were observing or protesting enforcement activity. TLDR and all that: DHS knows this tool performs worst in the situations where it’s used most. DHS and its components also knew they were supposed to produce PIAs before deploying privacy-impacting tech. And DHS knows its agencies are not only misusing the tech to convert AI shrugs into probable cause, but are using it to identify people protesting or observing their efforts, which means this tech is also a potential tool of unlawful retribution. There’s nothing left to be discussed. This tech will continue to be used because it can turn bad photos into migrant arrests. And its off-label use is just as effective: it allows ICE and CBP agents to identify protesters and observers, even as DHS officials continue to claim doxing should be a federal offense if they’re not the ones doing it. Everything about this is bullshit. But bullshit is all this administration has. Filed Under: border patrol , cbp , dhs , facial recognition tech , ice , privacy impact assessment , surveillance , trump administration Companies: mobile fortify , nec",
      "cover_image_url": "https://www.techdirt.com/wp-content/themes/techdirt/assets/images/td-rect-logo-white.png"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Fixing retail with land value capture",
      "url": "https://worksinprogress.co/issue/fixing-retail-with-land-value-capture/",
      "published": "2026-02-12T20:44:17+00:00",
      "summary": "<p>Article URL: <a href=\"https://worksinprogress.co/issue/fixing-retail-with-land-value-capture/\">https://worksinprogress.co/issue/fixing-retail-with-land-value-capture/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=46994869\">https://news.ycombinator.com/item?id=46994869</a></p> <p>Points: 56</p> <p># Comments: 98</p>",
      "content_text": "A lot of what we find interesting about cities is the retail within them. We lean on retail – shops, cafes, restaurants and so on – to make cities what they are. Urban economist Ed Glaeser called this the rise of the consumer city , showing how consumption agglomeration was becoming increasingly important, as well as production agglomeration , in driving up urban rents. When people say Hayes Valley in San Francisco or Williamsburg in Brooklyn are interesting neighborhoods, what they often mean is that they have interesting retail. Hayes Street is Hayes Street because of stores and restaurants, rather than something inherent about the streetscape. Williamsburg is Williamsburg because of its wine bars, taco trucks, and fancy coffee shops. Get the print magazine Subscribe for $100 to receive six beautiful issues per year. Subscribe Yet the retail operating environment is as hard as it’s ever been. Online shopping continues to capture market share , remote work reduces foot traffic , and crime eats into already-small margins . Almost half of stores shuttered within four years in one San Francisco shopping district. We risk losing something that makes cities what they are, because we don’t have a good model for letting retail capture the value it creates. Retail suffers from leaky value capture Hayes Valley has some of the most interesting retail in San Francisco – clothes shops like Marine Layer, Lisa Says Gah and Faherty; some of SF’s best coffee at Ritual; the best bagels in the city at Wise Sons; and some of its best ice cream at Salt + Straw. But the shops there go in and out of business all the time. They barely survive. The neighborhood thrives, the rents go up, the stores struggle. This is because a big fraction of the value created by these retailers is not captured by them. Consider how you enjoy going into interesting shops – often independent, or quirky, from which you are unlikely to buy something. Going there is a leisure value in itself. Compare to a Walmart where the value is largely in getting food and household items that directly benefit you, and people rarely walk around the shop without buying things. When an interesting new store, cafe, bar, or restaurant opens up, as well as it profiting from selling its products (if it does), others benefit too: owners of other commercial properties on the street benefit because potential customers are attracted to the area, and owners of homes nearby benefit because their house is now near a nice thing to do. This means that the value of commercial and residential properties go up. A substantial part of the efforts of the retailers on Hayes Street gets realized through the home values of the folks owning Victorians on Fell Street two blocks away. Home prices near Hayes Valley commercial corridor. In American cities, there is an issue with value capture. One party creates the value (in this case retailers), another party (landowners or homeowners) captures it. Of course retailers would love to capture more value. But homeowners would likely be willing to share value too: the homeowners like having the retailers there, yet those retailers often go out of business, making the homeowners worse off. They’d be better off if there was an institution to support them, but it doesn’t exist. Large single family lots outside of Menlo Park Caltrain Station. You see a similar dynamic with public transportation infrastructure. The government spent billions building Caltrain’s regional rail service to the Bay Area Peninsula. Unfortunately, most of those stations are surrounded by low density housing. The few hundred homes within walking distance of a station capture a large amount of the value from the infrastructure. Meanwhile, the train system runs unprofitably and needs to be propped up by taxpayers across the whole region. If you like having shops, parks and trains in your city, the fact that these institutions are failing to capture so much of the value they create should alarm you. The less they capture, the less of it will be created in the first place. As a result, we will have empty storefronts, fewer parks, and less public transit. Thankfully, history and international practice show us quite a few examples of doing this much better. Internal cross-subsidization (within big developments) The first model, which has been widely used historically, is unified ownership . When ownership of a main street is splintered, a large spillover from ‘cool retail’ leaks away to unaffiliated parties. The failure of splintered pedestrian main streets in the 1960s and 1970s led to the rise of destination shopping malls and strip malls. Both make use of ‘anchor stores’ to bring in customers, plus regulated signage, and usually pick a diverse set of interesting shops. A single entity can capture the resulting spillover. The single owners captured enough of the benefit from policing them with private security, and from excluding cars, that they could survive where the splintered outdoor main streets could not. Regulated signage and an interesting range of shops in Old Spitalfields Market. Supermarkets and department stores are classic anchor tenants. They make lower profits, and are often charged lower rents, but bring in customers that benefit all the other shops. Effectively they raise land values. Single ownership allows them to capture some of the land value appreciation, usually by being charged lower rents from the unified owner. Leadenhall Market, also in London. Image Third Eye Traveller. But shopping malls only go so far, mostly capturing only the spillover benefits between businesses, and not the spillovers that all the businesses taken together give the rest of the community, such as to the homeowners who live nearby. Developers are beginning to try this, returning to a historic model by having a single entity own both housing and retail, in order to sell the housing for more. One of the authors of this piece helped start Culdesac , where we selected commercial tenants not only on the rents we anticipated the tenant would pay, but also the value they would provide to residents in the surrounding apartment units. For developers building at a sufficient scale and where zoning permits it (a big if in the USA, where zoning has historically favored separated uses), this approach is fairly common around the world. This requires single entities that control a large swath of land. It’s part of the reason why large planned communities such as Seaside and Celebration in Florida are able to have nice common amenities. They are in a position to do this cross-subsidization. It’s also why shopping malls from the past few decades as far apart as Bay Street Emeryville in the East Bay or Coal Drops Yard in Kings Cross, London increasingly have housing included. Transit is another classic example where unified ownership can capture spillover effects. The Hong Kong Mass Transit Railway buys up the land around new station sites before they start building them. This rail-plus-property model makes them one of the few profitable transit services in the world. Japan goes even further: Tokyo’s metros, trams, and buses are private, and fund their investment into infrastructure by speculating on property they expect to rise in value as a result of their investment. How could we get cities without unified ownership blocks to create them? One way to encourage this comes from Donald Shoup: graduated density zoning . This gives properties the right to build more on their plots if they are part of a larger assembled plot. This is effectively how the old light plane–based zoning of 1916–1961 New York City worked as well. The larger the plot, the more externalities internalized. A still further way to enable consolidation might be to give local governments more power to plan for it where they think it will maximize value for the public, for example by letting them waive transfer taxes (like the UK’s stamp duty ), in exchange for a bigger property tax (or in the UK, business rates) take. Hyperlocal taxes, hyperlocal authorities Local taxing authorities can tax the increase in the land value and funnel it back into supporting retail or common infrastructure. Something like this is happening when local authorities in the UK refuse to let commercial landlords convert their commercial properties into residential ones. They argue that, although it is a benefit considered on its own terms (because it uses the land for something more in demand), it deprives the area of valuable amenities. But typical local governments are often too big to do this well, in a way that really does achieve the optimal use of the land. Individual local government units – like cities or counties in the US – often have hundreds of thousands of residents, spread over hundreds of square miles. It is very difficult to track where land value is spilling over from, and where it should be funneled back, and residents thus have no faith that this is what will happen. By contrast, this sort of value capture can work when the taxing authority is very local. Two thirds of new American homes are in some sort of community association, typically homeowners’ associations, but also co-ops, and condominium associations, and 30 percent of American homes overall. Buyers opt into these associations, pay annual fees in the thousands of dollars, and suffer their annoying restrictions and demands because they create amenities: quiet, cleanliness/tidiness, safety, or things like public pools and parks. But so far, the community association model has been applied almost exclusively to purely residential areas. Business Improvement Districts are one way of trying to bring this sort of institution to a high street. Businesses opt into charging themselves higher taxes or fees to support projects that make local businesses more successful like planting trees, improving streets, and tackling local crime or antisocial behavior. But while these districts can help internalize externalities that spill over among businesses, they haven’t so far been applied to capture value that spills over to nearby residents. Given that there is more residential real estate than commercial, a BID that could capture the residential interest too could be an interesting avenue for capturing value and funding public goods. Special Purpose Bonds, like the one raised to fund the Golden Gate Bridge and this example from New Zealand are a variation where voters approved bond-funded investments, usually infrastructure, that will be paid back through their property taxes. We can imagine an example where voters are approving not a bridge, but a neighborhood organization that raised a small tax to keep the most interesting shops in business, the streets clean, and the plants fed. Really bringing this system alive would require creating an institution, like special purpose bonds, or a mixed homeowners’ association-business improvement district that would allow hyperlocal taxes to part-subsidize valued community retail assets. Providing the commons We are asking a lot of retail in cities. We want it to be entertainment, a gathering spot or third space, and we want it to help form a city’s culture. We also want it to pay its rent. Delivering on all of those goals may be too much to ask of our retail base, without some help. We offer a prediction: as the ‘selling stuff’ model of retail becomes less viable due to internet-based alternatives, the ‘commons’ or ‘third space’ version of it may rise up instead. There are already examples: The Commons in San Francisco took over a former clothing shop and runs a member-based ‘home outside of home’. These models can work for private spaces, but they won’t fully capture spillovers, meaning they will be underprovided. These value capture models could help neighborhoods more directly provide the thing people actually want without having a shoehorn a high-margin retail business model alongside it. And they may provide a path to capturing, in a more direct way, the benefits a space gives to its surrounding community.",
      "cover_image_url": "https://wip.gatspress.com/wp-content/uploads/2026/01/Issue-19-onwards-share-cards-17.png"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Didero lands $30M to put manufacturing procurement on 'agentic' autopilot",
      "url": "https://techcrunch.com/2026/02/12/didero-lands-30m-to-put-manufacturing-procurement-on-agentic-autopilot/",
      "published": "2026-02-12T20:31:47+00:00",
      "summary": "Didero functions as an agentic AI layer that sits on top of a company’s existing ERP, acting as a coordinator that reads incoming communications and automatically executes the necessary updates and tasks.",
      "content_text": "Tim Spencer realized just how complicated manufacturing procurement can be while running Markai, an e-commerce startup in Asia, during the pandemic. “We had thousands of suppliers, and we were distributing products into dozens of countries around the world,” Spencer (pictured left) told TechCrunch. His staff was overwhelmed by the manual complexity of sourcing suppliers, negotiating pricing, tracking orders, and managing payments. “I found myself running this big team that was not really set up for success,” he said. He sold Markai in 2023, just as it was becoming clear that generative AI could streamline the most time-consuming procurement hurdles for manufacturers and distributors. Later that year, Spencer launched Didero with Lorenz Pallhuber (pictured center), a veteran of McKinsey’s procurement practice, and Tom Petit, the former technical co-founder of Landis . Didero, whose mission is to automate many of the complexities of global procurement, just raised a $30 million Series A co-led by Chemistry and Headline, with participation from Microsoft’s venture fund M12. “Global trade runs on natural language communication,” Spencer said. “It’s emails, WeChat, phone calls, purchase orders, and packing lists.” Until the advent of generative AI, these fragmented pieces had to be tracked by humans who spent their days chasing suppliers and manually updating systems of record. Didero claims its platform can ingest that communication, putting a significant portion of the procurement workflow on autopilot. Techcrunch event Boston, MA | June 23, 2026 Didero functions as an agentic AI layer that sits on top of a company’s existing ERP, acting as a coordinator that reads incoming communications and automatically executes the necessary updates and tasks. “The goal is to go from ‘I need a good’ to payment without having to lift a finger,” Spencer said. Unlike Levelpath, Zip, or Oro Labs, which use AI to streamline corporate purchasing, Didero focuses on the supply chain. Its platform is designed for manufacturers and distributors who need to source raw materials and inputs required to build or sell their products. Didero has a few smaller competitors that can handle some of the tasks that the company does. For instance, Cavela and Pietra help brands source and negotiate pricing with manufacturers, but according to Spencer, these companies serve small and medium-sized companies and don’t handle the full procurement process, from the first quote to the final payment. Didero has dozens of customers but named only one, Footprint , a provider of sustainable, plant-based packaging.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/Founders_Exterior_Mid-3.jpg?resize=1200,800"
    }
  ]
}