{
  "industry": "technology",
  "collected_at": "2026-02-15T20:14:46.912024+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "40 AGs Push Senate Kids Online Safety Act",
      "url": "https://reclaimthenet.org/40-attorneys-general-back-ids-online-safety-act",
      "published": "2026-02-15T19:49:17+00:00",
      "summary": "<p>Article URL: <a href=\"https://reclaimthenet.org/40-attorneys-general-back-ids-online-safety-act\">https://reclaimthenet.org/40-attorneys-general-back-ids-online-safety-act</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47026848\">https://news.ycombinator.com/item?id=47026848</a></p> <p>Points: 16</p> <p># Comments: 2</p>",
      "content_text": "A bloc of 40 state and territorial attorneys general is urging Congress to adopt the Senate’s version of the controversial Kids Online Safety Act , positioning it as the stronger regulatory instrument and rejecting the House companion as insufficient. The Act would kill online anonymity and tie online activity and speech to a real-world identity. Acting through the National Association of Attorneys General, the coalition sent a letter to congressional leadership endorsing S. 1748 and opposing H.R. 6484. We obtained a copy of the letter for you here . Their request centers on structural differences between the bills. The Senate proposal would create a federally enforceable “Duty of Care” requiring covered platforms to mitigate defined harms to minors. Enforcement authority would rest with the Federal Trade Commission, which could investigate and sue companies that fail to prevent minors from encountering content deemed to cause “harm to minors.” That framework would require regulators to evaluate internal content moderation systems, recommendation algorithms, and safety controls. S. 1748 also directs the Secretary of Commerce, the FTC, and the Federal Communications Commission to study “the most technologically feasible methods and options for developing systems to verify age at the device or operating system level.” This language moves beyond platform-level age gates and toward infrastructure embedded directly into hardware or operating systems. Age verification at that layer would not function without some form of credentialing. Device-level verification would likely depend on digital identity checks tied to government-issued identification, third-party age verification vendors, or persistent account authentication systems. That means users could be required to submit identifying information before accessing broad categories of lawful online speech. Anonymous browsing depends on the ability to access content without linking identity credentials to activity. A device-level age verification architecture would establish identity checkpoints upstream of content access, creating records that age was verified and potentially associating that verification with a persistent device or account. Even if content is not stored, the existence of a verified identity token tied to access creates a paper trail. Constitutional questions follow. The Supreme Court has repeatedly recognized anonymous speech as protected under the First Amendment. Mandating identity verification before accessing lawful speech raises prior restraint and overbreadth concerns, particularly where the definition of “harm to minors” extends into categories that are legal for adults. Courts have struck down earlier efforts to impose age verification requirements for online content on First Amendment grounds, citing the chilling effect on lawful expression and adult access. Despite this history, state officials continue to advocate for broader age verification regimes. Several states have enacted or proposed laws requiring age checks for social media or adult content sites, often triggering litigation over compelled identification and privacy burdens. The coalition’s letter suggests that state attorneys general are not retreating from that position and are instead seeking federal backing. The attorneys general argue that social media companies deliberately design products that draw in underage users and monetize their personal data through targeted advertising. They contend that companies have not adequately disclosed addictive features or mental health risks and point to evidence suggesting firms are aware of adverse consequences for minors. Multiple state offices have already filed lawsuits or opened investigations against Meta and TikTok, alleging “harm” to young users. At the same time, the coalition objects to provisions in H.R. 6484 that would limit state authority. The House bill contains broader federal preemption language, which could restrict states from enforcing parallel or more stringent requirements. The attorneys general warn that this would curb their ability to pursue emerging online harms under state law. They also fault the House proposal for relying on company-maintained “reasonable policies, practices, and procedures” rather than imposing a statutory Duty of Care. The Senate approach couples enforceable federal standards with preserved state enforcement power. The coalition calls on the United States House of Representatives to align with the Senate framework, expand the list of enumerated harms to include even suicide, eating disorders, compulsive use, mental health harms, and financial harms, and ensure that states retain authority to act alongside federal regulators. The measure has bipartisan sponsorship in the United States Senate. The policy direction is clear. Federal agencies would study device-level age verification systems, the FTC would police compliance with harm mitigation duties, and states would continue to pursue parallel litigation. Those mechanisms would reshape how platforms design their systems and how users access speech. Whether framed as child protection or platform accountability, the architecture contemplated by S. 1748 would move identity verification closer to the heart of internet access. Once age checks are embedded at the operating system level, the boundary between verifying age and verifying identity becomes difficult to maintain. The internet would be changed forever.",
      "cover_image_url": "https://reclaimthenet.org/wp-content/uploads/2026/02/rlbslt7uoVda-scaled.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Virtual Analog Synthesizer (Moog-style polyphonic synth with GUI)",
      "url": "https://github.com/gpasquero/voog",
      "published": "2026-02-15T19:40:57+00:00",
      "summary": "<p>Body: I built a polyphonic synthesizer in Python with a tkinter GUI styled after the Moog Subsequent 37.<p><pre><code> Features: 3 oscillators, Moog ladder filter (24dB/oct), dual ADSR envelopes, LFO, glide, noise generator, 4 multitimbral channels, 19 presets, rotary knob GUI, virtual keyboard with mouse + QWERTY input, and MIDI support. No external GUI frameworks — just tkinter, numpy, and sounddevice.</code></pre></p> <hr /> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47026768\">https://news.ycombinator.com/item?id=47026768</a></p> <p>Points: 4</p> <p># Comments: 0</p>",
      "content_text": "You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/f927a261766ae92446d729b1c3f7dc0c9b6aec21e376222cf493a1f046e43974/gpasquero/voog"
    },
    {
      "industry": "technology",
      "source": "VentureBeat",
      "title": "Nvidia, Groq and the limestone race to real-time AI: Why enterprises win or lose here",
      "url": "https://venturebeat.com/infrastructure/nvidia-groq-and-the-limestone-race-to-real-time-ai-why-enterprises-win-or",
      "published": "2026-02-15T19:00:00+00:00",
      "summary": "<p>​From miles away across the desert, the Great Pyramid looks like a perfect, smooth geometry — a sleek triangle pointing to the stars. Stand at the base, however, and the illusion of smoothness vanishes. You see massive, jagged blocks of limestone. It is not a slope; it is a staircase.</p><p>​Remember this the next time you hear futurists talking about exponential growth.</p><p>​Intel’s co-founder Gordon Moore (Moore&#x27;s Law) is famously quoted for saying in 1965 that the transistor count on a microchip would double every year. Another Intel executive, David House, later revised this statement to “compute power doubling every 18 months.&quot; For a while, Intel’s CPUs were the poster child of this law. That is, until the growth in CPU performance flattened out like a block of limestone.</p><p>​If you zoom out, though, the next limestone block was already there — the growth in compute merely shifted from CPUs to the world of GPUs. Jensen Huang, Nvidia’s CEO, played a long game and came out a strong winner, building his own stepping stones initially with gaming, then computer visioniand recently, generative AI.</p><h3><b>​The illusion of smooth growth</b></h3><p>​Technology growth is full of sprints and plateaus, and gen AI is not immune. The current wave is driven by transformer architecture. To quote Anthropic’s President and co-founder Dario Amodei: “The exponential continues until it doesn’t. And every year we’ve been like, ‘Well, this can’t possibly be the case that things will continue on the exponential’ — and then every year it has.”</p><p>​But just as the CPU plateaued and GPUs took the lead, we are seeing signs that LLM growth is shifting paradigms again. For example, late in 2024, DeepSeek surprised the world by training a world-class model on an impossibly small budget, in part by using the MoE technique.</p><p>​Do you remember where you recently saw this technique mentioned? Nvidia’s Rubin press release: The technology includes “...the latest generations of Nvidia NVLink interconnect technology... to accelerate agentic AI, advanced reasoning and massive-scale MoE model inference at up to 10x lower cost per token.”</p><p>​Jensen knows that achieving that coveted exponential growth in compute doesn’t come from pure brute force anymore. Sometimes you need to shift the architecture entirely to place the next stepping stone.</p><h3><b>​The latency crisis: Where Groq fits in</b></h3><p>​This long introduction brings us to Groq.</p><p>​The biggest gains in AI reasoning capabilities in 2025 were driven by “inference time compute” — or, in lay terms, “letting the model think for a longer period of time.” But time is money. Consumers and businesses do not like waiting.</p><p>​Groq comes into play here with its lightning-speed inference. If you bring together the architectural efficiency of models like DeepSeek and the sheer throughput of Groq, you get frontier intelligence at your fingertips. By executing inference faster, you can “out-reason” competitive models, offering a “smarter” system to customers without the penalty of lag.</p><h3><b>​From universal chip to inference optimization</b></h3><p>​For the last decade, the GPU has been the universal hammer for every AI nail. You use H100s to train the model; you use H100s (or trimmed-down versions) to run the model. But as models shift toward &quot;System 2&quot; thinking — where the AI reasons, self-corrects and iterates before answering — the computational workload changes.</p><p>​Training requires massive parallel brute force. Inference, especially for reasoning models, requires faster sequential processing. It must generate tokens instantly to facilitate complex chains of thought without the user waiting minutes for an answer. ​Groq’s LPU (Language Processing Unit) architecture removes the memory bandwidth bottleneck that plagues GPUs during small-batch inference, delivering lightning-fast inference.</p><h3><b>​The engine for the next wave of growth</b></h3><p>​For t",
      "content_text": "<p>​From miles away across the desert, the Great Pyramid looks like a perfect, smooth geometry — a sleek triangle pointing to the stars. Stand at the base, however, and the illusion of smoothness vanishes. You see massive, jagged blocks of limestone. It is not a slope; it is a staircase.</p><p>​Remember this the next time you hear futurists talking about exponential growth.</p><p>​Intel’s co-founder Gordon Moore (Moore&#x27;s Law) is famously quoted for saying in 1965 that the transistor count on a microchip would double every year. Another Intel executive, David House, later revised this statement to “compute power doubling every 18 months.&quot; For a while, Intel’s CPUs were the poster child of this law. That is, until the growth in CPU performance flattened out like a block of limestone.</p><p>​If you zoom out, though, the next limestone block was already there — the growth in compute merely shifted from CPUs to the world of GPUs. Jensen Huang, Nvidia’s CEO, played a long game and came out a strong winner, building his own stepping stones initially with gaming, then computer visioniand recently, generative AI.</p><h3><b>​The illusion of smooth growth</b></h3><p>​Technology growth is full of sprints and plateaus, and gen AI is not immune. The current wave is driven by transformer architecture. To quote Anthropic’s President and co-founder Dario Amodei: “The exponential continues until it doesn’t. And every year we’ve been like, ‘Well, this can’t possibly be the case that things will continue on the exponential’ — and then every year it has.”</p><p>​But just as the CPU plateaued and GPUs took the lead, we are seeing signs that LLM growth is shifting paradigms again. For example, late in 2024, DeepSeek surprised the world by training a world-class model on an impossibly small budget, in part by using the MoE technique.</p><p>​Do you remember where you recently saw this technique mentioned? Nvidia’s Rubin press release: The technology includes “...the latest generations of Nvidia NVLink interconnect technology... to accelerate agentic AI, advanced reasoning and massive-scale MoE model inference at up to 10x lower cost per token.”</p><p>​Jensen knows that achieving that coveted exponential growth in compute doesn’t come from pure brute force anymore. Sometimes you need to shift the architecture entirely to place the next stepping stone.</p><h3><b>​The latency crisis: Where Groq fits in</b></h3><p>​This long introduction brings us to Groq.</p><p>​The biggest gains in AI reasoning capabilities in 2025 were driven by “inference time compute” — or, in lay terms, “letting the model think for a longer period of time.” But time is money. Consumers and businesses do not like waiting.</p><p>​Groq comes into play here with its lightning-speed inference. If you bring together the architectural efficiency of models like DeepSeek and the sheer throughput of Groq, you get frontier intelligence at your fingertips. By executing inference faster, you can “out-reason” competitive models, offering a “smarter” system to customers without the penalty of lag.</p><h3><b>​From universal chip to inference optimization</b></h3><p>​For the last decade, the GPU has been the universal hammer for every AI nail. You use H100s to train the model; you use H100s (or trimmed-down versions) to run the model. But as models shift toward &quot;System 2&quot; thinking — where the AI reasons, self-corrects and iterates before answering — the computational workload changes.</p><p>​Training requires massive parallel brute force. Inference, especially for reasoning models, requires faster sequential processing. It must generate tokens instantly to facilitate complex chains of thought without the user waiting minutes for an answer. ​Groq’s LPU (Language Processing Unit) architecture removes the memory bandwidth bottleneck that plagues GPUs during small-batch inference, delivering lightning-fast inference.</p><h3><b>​The engine for the next wave of growth</b></h3><p>​For the C-Suite, this potential convergence solves the &quot;thinking time&quot; latency crisis. Consider the expectations from AI agents: We want them to autonomously book flights, code entire apps and research legal precedent. To do this reliably, a model might need to generate 10,000 internal &quot;thought tokens&quot; to verify its own work before it outputs a single word to the user.</p><ul><li><p>​<b>On a standard GPU:</b> 10,000 thought tokens might take 20 to 40 seconds. The user gets bored and leaves.</p></li><li><p>​<b>On Groq:</b> That same chain of thought happens in less than 2 seconds.</p></li></ul><p>​If Nvidia integrates Groq’s technology, they solve the &quot;waiting for the robot to think&quot; problem. They preserve the magic of AI. Just as they moved from rendering pixels (gaming) to rendering intelligence (gen AI), they would now move to rendering <i>reasoning</i> in real-time.</p><p>​Furthermore, this creates a formidable software moat. Groq’s biggest hurdle has always been the software stack; Nvidia’s biggest asset is CUDA. If Nvidia wraps its ecosystem around Groq’s hardware, they effectively dig a moat so wide that competitors cannot cross it. They would offer the universal platform: The best environment to train and the most efficient environment to run (Groq/LPU).</p><p>Consider what happens when you couple that raw inference power with a next-generation open source model (like the rumored DeepSeek 4): You get an offering that would rival today’s frontier models in cost, performance and speed. That opens up opportunities for Nvidia, from directly entering the inference business with its own cloud offering, to continuing to power a growing number of exponentially growing customers.</p><h3><b>​The next step on the pyramid</b></h3><p>​Returning to our opening metaphor: The &quot;exponential&quot; growth of AI is not a smooth line of raw FLOPs; it is a staircase of bottlenecks being smashed.</p><ul><li><p>​<b>Block 1:</b> We couldn&#x27;t calculate fast enough. <b>Solution:</b> The GPU.</p></li><li><p>​<b>Block 2:</b> We couldn&#x27;t train deep enough. <b>Solution:</b> Transformer architecture.</p></li><li><p>​<b>Block 3:</b> We can&#x27;t &quot;think&quot; fast enough. <b>Solution:</b> Groq’s LPU.</p></li></ul><p>​Jensen Huang has never been afraid to cannibalize his own product lines to own the future. By validating Groq, Nvidia wouldn&#x27;t just be buying a faster chip; they would be bringing next-generation intelligence to the masses.</p><p><i>Andrew Filev, founder and CEO of Zencoder</i> </p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Scientists observe a 300-million-year-old brain rhythm in several animal species",
      "url": "https://phys.org/news/2026-01-scientists-million-year-brain-rhythm.html",
      "published": "2026-02-15T18:52:26+00:00",
      "summary": "<p>Article URL: <a href=\"https://phys.org/news/2026-01-scientists-million-year-brain-rhythm.html\">https://phys.org/news/2026-01-scientists-million-year-brain-rhythm.html</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47026289\">https://news.ycombinator.com/item?id=47026289</a></p> <p>Points: 9</p> <p># Comments: 0</p>",
      "content_text": "A sleeping chameleon. Credit: Paul-Antoine Libourel. Sleep is a universal biological state that allows all animals, from mammals to amphibians, fish and even insects, to restore their energy and consolidate knowledge that can contribute to their survival. Neuroscientists and zoologists have been investigating the biological underpinnings of sleep and its vital functions for centuries, more recently by measuring the brain activity of animals or people while they are asleep. Recorded electrical signals that nerve cells produce while they are communicating with each other, also known as brain rhythms, have provided valuable insight into what happens during sleep. One of these rhythms, the so-called infraslow rhythm, had so far been primarily observed in mammals and was linked to a stage of sleep known as non-rapid eye movement (NREM) sleep. Researchers at the Neuroscience Research Center of Lyon, PSL University, McGill University, University Jean-Monnet Saint-Etienne and other institutes recently recorded the brain activity of a wider range of animals and found that this ancient rhythm is common across several species, including reptiles, birds, rodents and humans. Their most recent paper, published in Nature Neuroscience , reports the observation of the infraslow brain rhythm in seven different lizard species. Cerebral infraslow and temperature-dependent rhythm in reptiles and mammals. Credit: Nature Neuroscience (2025). DOI: 10.1038/s41593-025-02159-y \"I started this project in 2011 when I joined the sleep team at the Lyon Neuroscience Center, while now I moved to the functional and evolutionary ecology center of Montpellier,\" Paul-Antoine Libourel, senior author of the paper, told Phys.org. \"My team at the time focused on understanding the function and mechanisms of REM sleep. When I arrived in the lab, my goal was to investigate the evolutionary origin of REM sleep by studying reptiles, which are ectothermic (cold-blooded animals) and share a common ancestor with mammals and birds—both homeothermic (warm-blooded animals) and both known to exhibit REM sleep.\" The main objective of the recent work by Libourel and his colleagues was to shed new light on the evolution of sleep states. Specifically, they wished to determine whether different states evolved separately following the appearance of warm-blooded animals, or whether some of them were already present in species that existed approximately 300 million years ago. Recording brain rhythms in different animals To study the brain rhythms of animals during sleep, the researchers implanted electrodes on or inside the brain of various specimens. These electrodes allowed them to detect electrical signals associated with neural activity, using a device that they designed specifically for this type of research. \"Because some lizard species could be small, we collaborated with the Lyon Institute of Nanotechnology to develop a miniature, low-power-consumption biologger,\" said Libourel. \"This logger is now commercialized by Manitty, a startup I co-founded and is used to record brain activity, physiology, and behavior in animals and humans in their natural environments (at home for humans).\" As part of an earlier study, Libourel and his colleagues used the device they created to record brain rhythms in penguins . Their new research, on the other hand, focused on different lizard species, namely the leopard gecko, tokay gecko, Sudan plated lizard, Argentine tegu, panther chameleon, Egyptian rock agama, and bearded dragon. \"In addition to brain activity, we also recorded physiological signals such as eye movements, heart rate, breathing rate, and muscle tone,\" explained Libourel. \"Our electronics were designed to acquire all these signals simultaneously on a single board. Additionally, thanks to the support of Dr. Antoine Bergel, we had the opportunity to measure vascular activity using functional ultrasound imaging . We applied this technique in both mice and bearded dragons.\" Discover the latest in science, tech, and space with over 100,000 subscribers who rely on Phys.org for daily insights. Sign up for our free newsletter and get updates on breakthroughs, innovations, and research that matter— daily or weekly . A collective and ancient brain rhythm The large dataset compiled by the researchers over the past decade or so led to an important and interesting discovery. Specifically, the team found that reptiles, mammals, and birds share a common brain rhythm, the so-called infraslow rhythm. This finding suggests the presence of an ancestral mechanism that dates back at least to 300 million years ago, when the earliest known ancestor of the species examined lived. \"This rhythm involves not only brain activity but also physiological processes and peripheral vascularization, indicating that it is a global, organism-wide rhythm,\" said Libourel. \"The infraslow rhythm closely resembles a rhythm previously described in mammals during non-REM (NREM) sleep. In mammals, this rhythm has been proposed to play a role in brain 'cleaning' processes by facilitating the elimination of metabolic waste through cerebrospinal fluid flow. Additionally, because this rhythm is associated with fluctuations in vigilance, it may also represent an adaptive mechanism that allows periodic monitoring of the environment during sleep, potentially reducing the risk of predation.\" In the future, Libourel and his colleagues could test these two hypotheses in lizards. Their recent findings could also inspire other studies that investigate the brain rhythms of different animals during sleep, potentially leading to further interesting discoveries. \"A broader implication of our findings is that, if this rhythm reflects an NREM-related process in mammals, reptiles may not exhibit REM/NREM sleep as it is expressed in mammals,\" said Libourel. \"In humans, REM sleep is strongly associated with dreaming. This does not imply that reptiles do not dream; rather, it suggests that their sleep-state organization differs from that of mammals, despite sharing some conserved processes such as the infraslow rhythm.\" The researchers plan to continue investigating brain rhythms and the evolution of sleep states. In their next studies, they could focus on other animal groups, such as amphibians and fish. \"The mechanisms underlying the infraslow rhythm also need to be deciphered in order to determine whether it serves the same functions as those proposed in mammals,\" added Libourel. Written for you by our author Ingrid Fadelli , edited by Sadie Harley , and fact-checked and reviewed by Robert Egan —this article is the result of careful human work. We rely on readers like you to keep independent science journalism alive. If this reporting matters to you, please consider a donation (especially monthly). You'll get an ad-free account as a thank-you. Publication details Antoine Bergel et al, Sleep-dependent infraslow rhythms are evolutionarily conserved across reptiles and mammals, Nature Neuroscience (2025). DOI: 10.1038/s41593-025-02159-y . © 2026 Science X Network Citation : Scientists observe a 300-million-year-old brain rhythm in several animal species (2026, January 23) retrieved 15 February 2026 from https://phys.org/news/2026-01-scientists-million-year-brain-rhythm.html This document is subject to copyright. Apart from any fair dealing for the purpose of private study or research, no part may be reproduced without the written permission. The content is provided for information purposes only.",
      "cover_image_url": "https://scx2.b-cdn.net/gfx/news/hires/2026/scientists-observe-a-3.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "[2602.10177] Towards Autonomous Mathematics Research",
      "url": "https://arxiv.org/abs/2602.10177",
      "published": "2026-02-15T18:35:40+00:00",
      "summary": "<p>Article URL: <a href=\"https://arxiv.org/abs/2602.10177\">https://arxiv.org/abs/2602.10177</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47026134\">https://news.ycombinator.com/item?id=47026134</a></p> <p>Points: 30</p> <p># Comments: 6</p>",
      "content_text": "[Submitted on 10 Feb 2026 ( v1 ), last revised 12 Feb 2026 (this version, v2)] Title: Towards Autonomous Mathematics Research Authors: Tony Feng , Trieu H. Trinh , Garrett Bingham , Dawsen Hwang , Yuri Chervonyi , Junehyuk Jung , Joonkyung Lee , Carlo Pagano , Sang-hyun Kim , Federico Pasqualotto , Sergei Gukov , Jonathan N. Lee , Junsu Kim , Kaiying Hou , Golnaz Ghiasi , Yi Tay , YaGuang Li , Chenkai Kuang , Yuan Liu , Hanzhao Lin , Evan Zheran Liu , Nigamaa Nayakanti , Xiaomeng Yang , Heng-Tze Cheng , Demis Hassabis , Koray Kavukcuoglu , Quoc V. Le , Thang Luong View a PDF of the paper titled Towards Autonomous Mathematics Research, by Tony Feng and 27 other authors View PDF HTML (experimental) Abstract: Recent advances in foundational models have yielded reasoning systems capable of achieving a gold-medal standard at the International Mathematical Olympiad. The transition from competition-level problem-solving to professional research, however, requires navigating vast literature and constructing long-horizon proofs. In this work, we introduce Aletheia, a math research agent that iteratively generates, verifies, and revises solutions end-to-end in natural language. Specifically, Aletheia is powered by an advanced version of Gemini Deep Think for challenging reasoning problems, a novel inference-time scaling law that extends beyond Olympiad-level problems, and intensive tool use to navigate the complexities of mathematical research. We demonstrate the capability of Aletheia from Olympiad problems to PhD-level exercises and most notably, through several distinct milestones in AI-assisted mathematics research: (a) a research paper (Feng26) generated by AI without any human intervention in calculating certain structure constants in arithmetic geometry called eigenweights; (b) a research paper (LeeSeo26) demonstrating human-AI collaboration in proving bounds on systems of interacting particles called independent sets; and (c) an extensive semi-autonomous evaluation (Feng et al., 2026a) of 700 open problems on Bloom's Erdos Conjectures database, including autonomous solutions to four open questions. In order to help the public better understand the developments pertaining to AI and mathematics, we suggest quantifying standard levels of autonomy and novelty of AI-assisted results, as well as propose a novel concept of human-AI interaction cards for transparency. We conclude with reflections on human-AI collaboration in mathematics and share all prompts as well as model outputs at this https URL . Submission history From: Thang Luong [ view email ] [v1] Tue, 10 Feb 2026 18:50:15 UTC (2,611 KB) [v2] Thu, 12 Feb 2026 18:27:29 UTC (2,612 KB)",
      "cover_image_url": "/static/browse/0.3.4/images/arxiv-logo-fb.png"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Editor’s Note: Retraction of article containing fabricated quotations",
      "url": "https://arstechnica.com/staff/2026/02/editors-note-retraction-of-article-containing-fabricated-quotations/",
      "published": "2026-02-15T18:29:54+00:00",
      "summary": "<p>Article URL: <a href=\"https://arstechnica.com/staff/2026/02/editors-note-retraction-of-article-containing-fabricated-quotations/\">https://arstechnica.com/staff/2026/02/editors-note-retraction-of-article-containing-fabricated-quotations/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47026071\">https://news.ycombinator.com/item?id=47026071</a></p> <p>Points: 64</p> <p># Comments: 47</p>",
      "content_text": "On Friday afternoon, Ars Technica published an article containing fabricated quotations generated by an AI tool and attributed to a source who did not say them. That is a serious failure of our standards. Direct quotations must always reflect what a source actually said. That this happened at Ars is especially distressing. We have covered the risks of overreliance on AI tools for years, and our written policy reflects those concerns. In this case, fabricated quotations were published in a manner inconsistent with that policy. We have reviewed recent work and have not identified additional issues. At this time, this appears to be an isolated incident. Ars Technica does not permit the publication of AI-generated material unless it is clearly labeled and presented for demonstration purposes. That rule is not optional, and it was not followed here. We regret this failure and apologize to our readers. We have also apologized to Mr. Scott Shambaugh, who was falsely quoted.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/ars-logo-dark-background-1152x648.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "India has 100M weekly active ChatGPT users, Sam Altman says",
      "url": "https://techcrunch.com/2026/02/15/india-has-100m-weekly-active-chatgpt-users-sam-altman-says/",
      "published": "2026-02-15T18:00:00+00:00",
      "summary": "OpenAI CEO Sam Altman says India has the largest number of student users of ChatGPT worldwide.",
      "content_text": "India has 100 million weekly active ChatGPT users, making the country one of OpenAI’s largest markets globally, CEO Sam Altman said ahead of a government-hosted AI summit. On Sunday, Altman outlined ChatGPT’s growing adoption in India in an article published in the Indian English daily Times of India, as OpenAI prepares to formally participate in the five-day India AI Impact Summit in New Delhi, beginning Monday. Altman is attending the event alongside senior executives from several of the world’s leading AI companies. The growth comes as OpenAI, like other leading AI firms , looks to India’s young population and its more than a billion internet users to fuel global expansion. The ChatGPT maker opened a New Delhi office in August 2025 after months of groundwork in the country, and has adjusted its approach for India’s price-sensitive market, including rolling out a sub-$5 ChatGPT Go tier that was later made free for a year for Indian users. In the article, Altman said India is ChatGPT’s second-largest user base after the United States, highlighting the South Asian nation’s growing weight in OpenAI’s global strategy. The disclosure comes as ChatGPT’s overall usage has surged worldwide, with the platform reaching 800 million weekly active users as of October 2025 and reported to be approaching 900 million . Altman also highlighted the role of students in driving adoption, saying India has the largest number of student users of ChatGPT globally. Indian students have become a key growth segment for leading AI companies more broadly, as rivals race to embed their tools in classrooms and learning workflows. Google has similarly targeted the market, offering Indian students a free one-year subscription to its AI Pro plan in September 2025. Separately, India accounts for the highest global usage of Gemini for learning , Chris Phillips, Google’s vice president and general manager for education, said last month. “With its focus on access, practical Al literacy, and the infrastructure that supports widespread adoption, India is well positioned to broaden who benefits from the technology and to help shape how democratic AI is adopted at scale,” Altman wrote. Techcrunch event Boston, MA | June 23, 2026 ChatGPT’s rapid growth also highlights a broader challenge for AI companies in India: translating widespread adoption into sustained economic impact. Indian government initiatives such as the IndiaAI Mission — a national program aimed at expanding computing capacity, supporting startups and accelerating AI adoption in public services — seek to address those gaps. However, the country’s price-sensitive market and infrastructure constraints have made monetization and large-scale deployment more complex than in developed economies. “Given India’s size, it also risks forfeiting a vital opportunity to advance democratic AI in emerging markets around the world,” Altman wrote, warning that uneven access and adoption could concentrate AI’s economic gains in too few hands. Altman also signaled that OpenAI plans to deepen its engagement with the Indian government, writing that the company would soon announce new partnerships aimed at expanding access to AI across the country. He did not provide details, but said the focus would be on widening reach and enabling more people to put AI tools to practical use. The India AI Impact Summit is expected to draw a wide cross-section of global technology and political leaders, including Anthropic CEO Dario Amodei, Sundar Pichai of Google, and senior Indian business figures such as Mukesh Ambani and Nandan Nilekani. Political leaders including Emmanuel Macron, Sheikh Khaled bin Mohamed bin Zayed Al Nahyan, and Luiz Inácio Lula da Silva are also expected to attend, spotlighting India’s ambition to position itself as a central player in global AI debates. For global AI firms, including OpenAI, the summit underscores how India’s vast user base is translating into growing influence over how the technology evolves. OpenAI did not respond to a request for comment.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/04/chatgpt-india.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Palantir Gets Millions of Dollars From New York City’s Public Hospitals",
      "url": "https://theintercept.com/2026/02/15/palantir-contract-new-york-city-health-hospitals/",
      "published": "2026-02-15T17:37:10+00:00",
      "summary": "<p>Article URL: <a href=\"https://theintercept.com/2026/02/15/palantir-contract-new-york-city-health-hospitals/\">https://theintercept.com/2026/02/15/palantir-contract-new-york-city-health-hospitals/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47025624\">https://news.ycombinator.com/item?id=47025624</a></p> <p>Points: 148</p> <p># Comments: 44</p>",
      "content_text": "New York City’s public hospital system is paying millions to Palantir, the controversial ICE and military contractor, according to documents obtained by The Intercept. Since 2023, the New York City Health and Hospitals Corporation has paid Palantir nearly $4 million to improve its ability to track down payment for the services provided at its hospitals and medical clinics. Palantir, a data analysis firm that’s now a Wall Street giant thanks to its lucrative work with the Pentagon and U.S. intelligence community, deploys its software to make more efficient the billing of Medicaid and other public benefits. That includes automated scanning of patient health notes to “Increase charges captured from missed opportunities,” contract materials reviewed by The Intercept show. Palantir’s administrative involvement in the business of healing people stands in contrast to its longtime role helping facilitate warfare, mass deportations , and dragnet surveillance. In 2016, The Intercept revealed Palantir’s role behind XKEYSCORE, a secret NSA bulk surveillance program revealed by the whistleblower Edward Snowden that allowed the U.S. and its allies to search the unfathomably large volumes of data they collect. The company has also attracted global scrutiny and criticism for its “ strategic partnership ” with the Israeli military while it was leveling Gaza. But it’s Palantir’s work with U.S. Immigration and Customs Enforcement that is drawing the most protest today. The company provides a variety of services to help the federal government find and deport immigrants. ICE’s Palantir-furnished case management software, for example, “plays a critical role in supporting the daily operations of ICE, ensuring critical mission success,” according to federal contracting documents. “It’s unacceptable that the same company that is targeting our neighbors for deportation and providing tools to the Israeli military is also providing software for our hospitals,” said Kenny Morris, an organizer with the American Friend Service Committee, which shared the contract documents with The Intercept. Established by the state legislature, New York City Health and Hospitals is the nation’s biggest municipal health care system, administering over 70 facilities throughout New York City, including Bellevue Hospital, and providing care for over 1 million New Yorkers annually. New York City Health and Hospitals spokesperson Adam Shrier did not respond to multiple requests to discuss the contract’s details. Palantir spokesperson Drew Messing said the company does not use or share hospital data outside the bounds of its contract. Palantir’s contract with New York’s public health care system allows the company to work with patients’ protected health information, or PHI. With permission from New York City Health and Hospitals, Palantir can “de-identify PHI and utilize de-identified PHI for purposes other than research,” the contract states. De-identification generally involves the stripping of certain revealing information, such as names, Social Security numbers, and birthdays. Such provisions are common in contracts involving health data. Activists who oppose Palantir’s involvement in New York point to a large body of research that indicates re-identifying personal data, including in medial contexts, is often trivial . “Any contract that shares any of New Yorkers’ highly personal data from NYC Health & Hospital’s with Palantir, a key player in the Trump administration’s mass deportation effort, is reckless and puts countless lives at risk,” said Beth Haroules of the New York Civil Liberties Union. “Every New Yorker, without exception, has a right to quality healthcare and city services. New Yorkers must be able to seek healthcare without fear that their intimate medical information, or immigration status, will be delivered to the federal government on a silver platter.” We’re independent of corporate interests — and powered by members. Join us. Become a member Join Our Newsletter Thank You For Joining! Original reporting. Fearless journalism. Delivered to you. Will you take the next step to support our independent journalism by becoming a member of The Intercept? Become a member By signing up, I agree to receive emails from The Intercept and to the Privacy Policy and Terms of Use . Palantir has long provided similar services to the U.K. National Health Service, a business relationship that today has an increasing number of detractors. Palantir “has absolutely no place in the NHS, looking after patients’ personal data,” Green Party leader Zack Polanski recently stated in a letter to the U.K. health secretary . “Palantir is targeting the exact patients that NYCHH is looking to serve.” Some New York-based groups feel similarly out of distrust for what the firm could do with troves of sensitive personal data. “Palantir is targeting the exact patients that NYCHH is looking to serve,” said Jonathan Westin of the Brooklyn-based organization Climate Organizing Hub. “They should immediately sever their contract with Palantir and stand with the millions of immigrant New Yorkers that are being targeted by ICE in this moment.” “The chaos Palantir is inflicting through its technology is not just limited to the kidnapping of our immigrant neighbors and the murder of heroes like our fellow nurse, Alex Pretti,” said Hannah Drummond, an Asheville, North Carolina-based nurse and organizer with National Nurses United, a nursing union. “As a nurse and patient advocate, I don’t want anything having to do with Palantir in my hospital — and neither should any elected leader who claims to represent nurses.” Palantir’s vocally right-wing CEO Alex Karp has been a frequent critic of New York City’s newly inaugurated democratic socialist Mayor Zohran Mamdani. Health and Hospitals operates as a public benefit corporation, but the mayor can exert considerable influence over the network, for instance through the appointment of its board of directors. Its president, Dr. Mitchell Katz, was renominated by Mamdani, then the mayor-elect, late last year. The mayor’s office did not respond in time for publication when asked about its stance on the contract.",
      "cover_image_url": "https://theintercept.com/wp-content/uploads/2026/02/AP20302727055883-e1771043216688.jpg?fit=6000%2C3000&w=2048"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "The enterprise AI land grab is on. Glean is building the layer beneath the interface.",
      "url": "https://techcrunch.com/2026/02/15/the-enterprise-ai-land-grab-is-on-glean-is-building-the-layer-beneath-the-interface/",
      "published": "2026-02-15T17:30:00+00:00",
      "summary": "In this week's episode of the Equity podcast, Glean CEO Arvind Jain explains the company's shift from enterprise search tool to middleware layer for enterprise AI.",
      "content_text": "The battle for enterprise AI is heating up. Microsoft is bundling Copilot into Office. Google is pushing Gemini into Workspace. OpenAI and Anthropic are selling directly to enterprises. Every SaaS vendor now ships an AI assistant. In the scramble for the interface, Glean is betting on something less visible: becoming the intelligence layer beneath it. Seven years ago, Glean set out to be the Google for enterprise — an AI-powered search tool designed to index and search across a company’s SaaS tool library, from Slack to Jira, Google Drive to Salesforce. Today, the company’s strategy has shifted from building a better enterprise chatbot to becoming the connective tissue between models and enterprise systems. “The layer we built initially – a good search product – required us to deeply understand people and how they work and what their preferences are,” Jain told TechCrunch on last week’s episode of Equity , which we recorded at Web Summit Qatar. “All of that is now becoming foundational in terms of building high quality agents.” He says that while large language models are powerful, they’re also generic. “The AI models themselves don’t really understand anything about your business,” Jain said. “They don’t know who the different people are, they don’t know what kind of work you do, what kind of products you build. So you have to connect the reasoning and generative power of the models with the context inside your company.” Glean’s pitch is that it already maps that context and can sit between the model and the enterprise data. VIDEO The Glean Assistant is often the entry point for customers — a familiar chat interface powered by a mix of leading proprietary (ie, ChatGPT, Gemini, Claude) and open-source models, grounded in the company’s internal data. But what keeps customers, Jain argues, is everything underneath it. Techcrunch event Boston, MA | June 23, 2026 First is model access. Rather than forcing companies to commit to a single LLM provider, Glean acts as the abstraction layer, allowing enterprises to switch between or combine models as capabilities evolve. That’s why Jain says he doesn’t see OpenAI, Anthropic, or Google as competition, but rather as partners. “Our product gets better because we’re able to leverage the innovation that they are making in the market,” Jain said. Second are the connectors. Glean integrates deeply with systems like Slack, Jira, Salesforce, and Google Drive to map how information flows across them and enable agents to act inside those tools. And third, and perhaps most important, is governance. “You need to build a permissions-aware governance layer and retrieval layer that is able to bring the right information, but knowing who’s asking that question so that it filters the information based on their access rights,” Jain said. In large organizations, that layer can be the difference between piloting AI solutions and deploying them at scale. Enterprises can’t simply load all their internal data into a model and create a wrapper to sort out the solutions later, says Jain. Also critical is ensuring the models don’t hallucinate. Jain says its system verifies model outputs against source documents, generates line-by-line citations, and ensures that responses respect existing access rights. The question is whether that middle layer survives as platform giants push deeper into the stack. Microsoft and Google already control much of the enterprise workflow surface area, and they’re hungry for more. If Copilot or Gemini can access the same internal systems with the same permissions, does a standalone intelligence layer still matter? Jain argues enterprises don’t want to be locked into a single model or productivity suite and would rather opt for a neutral infrastructure layer rather than a vertically integrated assistant. Investors have bought into that thesis. Glean raised a $150 million Series F in June 2025, nearly doubling its valuation to $7.2 billion . Unlike the frontier AI labs, Glean doesn’t need massive compute budgets. “We have a very healthy, fast-growing business,” Jain said.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2259183688.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "You need to watch the intensely surreal cult classic Possession",
      "url": "https://www.theverge.com/entertainment/879602/cult-classic-possession-1981-review-isabelle-adjani",
      "published": "2026-02-15T17:30:00+00:00",
      "summary": "Let me just say that I highly recommend you go into Possession blind. Don't watch a trailer. Don't even finish reading this. Go watch it now over on Shudder, Criterion, or Metrograph. It's also available through Kanopy or Hoopla if your library provides access. Then come back so we can talk about it in the [&#8230;]",
      "content_text": "Let me just say that I highly recommend you go into Possession blind. Don’t watch a trailer. Don’t even finish reading this. Go watch it now over on Shudder , Criterion , or Metrograph . It’s also available through Kanopy or Hoopla if your library provides access. Then come back so we can talk about it in the comments. Though this probably isn’t one for the squeamish. Possession is the sort of film that, even if you’ve had the whole plot spoiled for you, can be difficult to follow. After watching it twice, listening to three different podcasts, and reading multiple articles about it, I’m still not 100 percent sure what happened at various points in the movie. I just know I loved it. You’re dropped immediately into a story about a crumbling marriage set against the backdrop of the Berlin Wall. It’s a formidable metaphor for the division between the stars — a very young and disarmingly handsome Sam Neill (Mark), and Isabelle Adjani (Anna), who turns in one of the most singular and unnerving performances in the history of cinema. Watching Adjani on screen is exhausting — She ricochets between unsettling detachment and high-octane delirium with alarming ease and speed. It’s the sort of performance that, when you hear it basically gave Adjani PTSD , you’re not surprised. The third standout performance comes from Heinz Bennent, who plays Heinrich, the man Mark believes Anna is leaving him for. He moves through every scene like a drunk ballet dancer, and there’s something almost Wiseau-ian about his delivery. (It certainly doesn’t help that he keeps repeating Mark’s name.) In a more grounded film, the way he careens through the frame would seem absurd. But in the abstract nightmare of Possession , Bennent fits perfectly, rolling around, alternately assaulting Mark and coming on to him. This frame is a work of art. Image: Metrograph Pictures Director Andrzej Żuławski not only coaxes gorgeously unhinged performances from his stars, he builds live-action paintings. Mark and Ana sit in a cafe at the corner of a bench facing away from each other as they discuss the terms of their separation. (Before Mark tears through the cafe, hurling chairs and tables in a freakout for the ages.) Sam Neill violently pitches a rocking chair back and forth as the focus expertly tracks him. The film is simply gorgeous. What begins as a bad acid trip about a failing marriage turns into a nausea-inducing body horror in its back half. It’s revealed that Anna isn’t leaving Mark for Heinrich. In fact, Heinrich is just as desperate to get Anna back, to find her and make her his. Instead, she is shacked up with what Anna Bogutskaya (host of The Final Girls podcast and author of Feeding the Monster) calls a “ Lovecraftian fuck monster .” It’s a grotesquerie of tentacles, oozing orifices, and uncanny humanoid features, created by Carlo Rambaldi , who won Academy Awards for special effects on Alien and ET . It feeds on people. Their bodies, but also their souls. Anna seems to think it’s some sort of deity, something holy. She uses it to explore parts of herself she has repressed or lost in her relationship with Mark. The other men in her life can’t satisfy her, so she creates an ideal lover. What starts as a slimy creature, not unlike the baby from Eraserhead , eventually becomes a doppleganger of Mark. And then there’s the subway scene. If you’ve ever heard of Possession before, it’s probably because of this scene . Adjani hurls herself around a deserted tunnel, grunting, screaming, convulsing, before oozing blood and god knows all over the wet concrete floor. As a viewer, I feel drained after watching it. It’s three of the most intense minutes ever committed to celluloid, and even if the rest of the film was terrible, Possession would be worth watching just for this scene. There are so many different readings of this film. I’m still not entirely sure what happens at the end. Did their son Bob drown himself? Is Mark’s doppleganger the antichrist? Is Helen also a doppleganger? (I think so.) What is the deal with Heinrich’s mother? Is Anna possessed? Or is the titular possession about the men in her life trying to exert ownership of her? In the month since I first watched this movie, I’ve told everyone I know about it. I can’t stop thinking about it or talking about it. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Terrence O'Brien Column Entertainment Film Movie Review",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/possession-poster.jpg?quality=90&strip=all&crop=0%2C2.0069808027923%2C100%2C95.986038394415&w=1200"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "\"It ain't no unicorn\": These researchers have interviewed 130 Bigfoot hunters",
      "url": "https://arstechnica.com/science/2026/02/it-aint-no-unicorn-these-researchers-have-interviewed-130-bigfoot-hunters/",
      "published": "2026-02-15T17:20:12+00:00",
      "summary": "What prompts this community to spend time looking for a creature that likely doesn't exist?",
      "content_text": "It was the image that launched a cultural icon. In 1967, in the Northern California woods, a 7-foot-tall, ape-like creature covered in black fur and walking upright was captured on camera, at one point turning around to look straight down the lens. The image is endlessly copied in popular culture—it’s even become an emoji. But what was it? A hoax? A bear? Or a real-life example of a mysterious species called the Bigfoot? The film has been analysed and re-analysed countless times . Although most people believe it was some sort of hoax, there are some who argue that it’s never been definitively debunked. One group of people, dubbed Bigfooters, is so intrigued that they have taken to the forests of Washington, California, Oregon, Ohio, Florida, and beyond to look for evidence of the mythical creature. But why? That’s what sociologists Jamie Lewis and Andrew Bartlett wanted to uncover. They were itching to understand what prompts this community to spend valuable time and resources looking for a beast that is highly unlikely to even exist. During lockdown, Lewis started interviewing more than 130 Bigfooters (and a few academics) about their views, experiences, and practices, culminating in the duo’s recent book “Bigfooters and Scientific Inquiry: On the Borderlands of Legitimate Science.” Here, we talk to them about their academic investigation. What was it about the Bigfoot community that you found so intriguing? Lewis : It started when I was watching either the Discovery Channel or Animal Planet and a show called Finding Bigfoot was advertised. I was really keen to know why this program was being scheduled on what certainly at the time was a nominally serious and sober natural history channel. The initial plan was to do an analysis of these television programmes, but we felt that wasn’t enough. It was lockdown and my wife was pregnant and in bed a lot with sickness, so I needed to fill my time. Bartlett : One of the things that I worked on when Jamie and I shared an office in Cardiff was a sociological study of fringe physicists . These are people mostly outside of academic institutions trying to do science. I was interviewing these people, going to their conferences. And that led relatively smoothly into Bigfoot, but it was Jamie’s interest in Bigfoot that brought me to this field. How big is this community? Lewis : It’s very hard to put a number on it. There is certainly a divide between what are known as “apers,” who believe that Bigfoot is just a primate unknown to science, and those that are perhaps more derogatorily called “woo-woos,” who believe that Bigfoot is some sort of interdimensional traveller, an alien of sort. We’re talking in the thousands of people. But there are a couple of hundred really serious people of which I probably interviewed at least half. Many people back them. A YouGov survey conducted as recently as November 2025, suggested that as many as one quarter of Americans believe that Bigfoot either definitely or probably exists. Were the interviewees suspicious of your intentions? Lewis : I think there was definitely a worry that they would be caricatured. And I was often asked, “Do I believe in Bigfoot?” I had a standard answer that Andy and I agreed on, which was that mainstream, institutional science says there is absolutely no compelling evidence that Bigfoot exists. We have no reason to dissent with that consensus. But as sociologists what does exist is a community (or communities) of Bigfooting, and that’s what interests us.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/bigfoot-1.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "TechPaula/LT6502: A 6502 based laptop design",
      "url": "https://github.com/TechPaula/LT6502",
      "published": "2026-02-15T17:12:35+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.com/TechPaula/LT6502\">https://github.com/TechPaula/LT6502</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47025399\">https://news.ycombinator.com/item?id=47025399</a></p> <p>Points: 164</p> <p># Comments: 43</p>",
      "content_text": "You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/3ade9cc1e2dc531e1716be9eabdcbe8b278c9f9677ebbbd850413e62102c1e4d/TechPaula/LT6502"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "New EU rules to stop destruction of unsold clothes and shoes",
      "url": "https://environment.ec.europa.eu/news/new-eu-rules-stop-destruction-unsold-clothes-and-shoes-2026-02-09_en",
      "published": "2026-02-15T17:10:18+00:00",
      "summary": "<p>Article URL: <a href=\"https://environment.ec.europa.eu/news/new-eu-rules-stop-destruction-unsold-clothes-and-shoes-2026-02-09_en\">https://environment.ec.europa.eu/news/new-eu-rules-stop-destruction-unsold-clothes-and-shoes-2026-02-09_en</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47025378\">https://news.ycombinator.com/item?id=47025378</a></p> <p>Points: 402</p> <p># Comments: 286</p>",
      "content_text": "The European Commission today (Feb 9) adopted new measures under the Ecodesign for Sustainable Products Regulation (ESPR) to prevent the destruction of unsold apparel, clothing, accessories and footwear. The rules will help cut waste, reduce environmental damage and create a level playing field for companies embracing sustainable business models, allowing them to reap the benefits of a more circular economy. Every year in Europe, an estimated 4-9% of unsold textiles are destroyed before ever being worn. This waste generates around 5.6 million tons of CO2 emissions – almost equal to Sweden’s total net emissions in 2021. To help reduce this wasteful practice, the ESPR requires companies to disclose information on the unsold consumer products they discard as waste. It also introduces a ban on the destruction of unsold apparel, clothing accessories and footwear. The Delegated and Implementing Acts adopted today will support businesses in complying with these requirements by: Clarifying derogations : The Delegated Act outlines specific and justified circumstances under which the destruction will be permitted, for instance, due to safety reasons or product damage. National authorities will oversee compliance. Facilitating disclosure: The Implementing Act introduces a standardised format for businesses to disclose the volumes of unsold consumer goods they discard. This applies from February 2027, giving businesses sufficient time to adapt. Instead of discarding stock, companies are encouraged to manage their stock more effectively, handle returns, and explore alternatives such as resale, remanufacturing, donations, or reuse. The ban on destruction of unsold apparel, clothing accessories and footwear and the derogations will apply to large companies from 19 July 2026. Medium-sized companies are expected to follow in 2030. The rules on disclosure under the ESPR already apply to large companies and will also apply to medium-sized companies in 2030. \"The textile sector is leading the way in the transition to sustainability, but there are still challenges. The numbers on waste show the need to act. With these new measures, the textile sector will be empowered to move towards sustainable and circular practices, and we can boost our competitiveness and reduce our dependencies.\" Jessika Roswall, Commissioner for Environment, Water Resilience and a Competitive Circular Economy Background The destruction of unsold goods is a wasteful practice. In France alone, around €630 million worth of unsold products are destroyed each year. Online shopping also fuels the issue: in Germany, nearly 20 million returned items are discarded annually. Textiles are a major part of the problem, and a key focus for action. To cut waste and reduce the sector’s environmental footprint, the European Commission is promoting more sustainable production while helping European companies stay competitive. The ESPR is central to this effort. It will make products on the EU market more durable, reusable and recyclable, while boosting efficiency and circularity. More information Delegated Regulation setting out derogations from the prohibition of destruction of unsold consumer products | European Commission Implementing Regulation on the details and format for the disclosure of information on discarded unsold consumer products | European Commission Ecodesign for Sustainable Products Regulation | European Commission Ecodesign for Sustainable Products Regulation | EUR-Lex Textiles strategy | European Commission The destruction of returned and unsold textiles in Europe’s circular economy | European Environment Agency (EEA)",
      "cover_image_url": "https://environment.ec.europa.eu/sites/default/files/styles/ewcms_metatag_image/public/2026-02/GettyImages-2164380614.jpg1_.jpg?h=03a24c0b&itok=gaShWK4G"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Knock-Knock | Live Intruder Map",
      "url": "https://knock-knock.net",
      "published": "2026-02-15T17:06:25+00:00",
      "summary": "<p>Article URL: <a href=\"https://knock-knock.net\">https://knock-knock.net</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47025338\">https://news.ycombinator.com/item?id=47025338</a></p> <p>Points: 14</p> <p># Comments: 6</p>",
      "content_text": "KNOCK-KNOCK.NET Set up an unprotected server on the net, and the bots start swarming! This site shows bots attempting (unsuccessfully) to break into an ordinary internet server. This constant chatter of bots knocking on the doors of machines on the net has been referred to as \"the background radiation of the Internet\". Knock-knock.net is a visualization of this bot traffic. It shows the bot activity in real-time, and provides historic stats of the bot attacks over time: where they are coming from, the most common usernames and passwords attempted, the worst offending ISPs, and in some cases, why the password or username was chosen. Have fun! Send questions or comments to:",
      "cover_image_url": "https://knock-knock.net/static/og-image.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "TechCrunch Mobility: Rivian's savior",
      "url": "https://techcrunch.com/2026/02/15/techcrunch-mobility-rivians-savior/",
      "published": "2026-02-15T17:05:00+00:00",
      "summary": "Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation.",
      "content_text": "Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation. To get this in your inbox, sign up here for free — just click TechCrunch Mobility ! We are in the midst of one of my four favorite times of year — earnings season. And it’s not just that I like numbers. These required filings cut through a lot of the marketing noise presented by companies the rest of the year. They also help me assess the short- and long-term stakes the companies face. Rivian ’s fourth-quarter and full-year earnings did precisely that. My takeaway : Software, and specifically its technology joint venture with Volkswagen Group, was the company’s savior in 2025. It will also buoy the company into 2026 (another $2 billion is expected from VW Group) as Rivian launches its most important product to date: the lower-cost R2 SUV. The company’s earnings also provided a progress report on its bid to lower the cost of goods sold per unit. The TL;DR is that the cogs per unit for its current portfolio is still high but dropping, meaning it’s losing less on each vehicle it sells. According to Rivian, the company’s automotive cogs per unit delivered was $100,900 in 2025, down from $110,400 in 2024. The upcoming R2, which is supposed to be considerably cheaper (both in production cost and price tag) than its flagship R1T truck and R1S SUV, will be the next big test. We’ll get some insight into the results of that later this year. The R2 is expected to go into production in the first half of the year (we’re hearing June), and based on its guidance for 2026, Rivian is confident it has the demand and the ability to ramp production. The company expects to deliver between 62,000 and 67,000 vehicles in 2026 — which could provide up to a 59% bump from last year. Rivian delivered 42,247 vehicles in 2025, which includes its two R1 consumer vehicles and the electric delivery van (EDV). The market loved that guidance, btw. Rivian stock shot up 27% in the day after it reported earnings. Techcrunch event Boston, MA | June 23, 2026 A little bird Image Credits: Bryce Durbin Over the past 18 months, I’ve noticed a divergence in how Uber and Lyft are approaching AVs. Uber is locking up AV partnerships with every player it can. Lyft is trailing behind. Turns out, I am not alone in this observation. Insiders have shared their puzzlement about why Lyft hasn’t been more aggressive on this front. They noted that Lyft is sitting on about $1.8 billion in cash, cash equivalents, and restricted cash, and recently announced a new $1 billion share repurchase program that represents about 15% of its market cap, per CNBC . That has some wondering why Lyft did not invest in parts of the AV value chain like Uber is doing versus buying shares back. Meanwhile, these little birds also pointed to a few top executives who have departed over the past year. Aurélien Nolf left his position as VP of financial planning and analysis and investor relations to become CFO of Navan. Audrey Liu, who was an executive VP and head of rider and community safety, is now at Adobe. Ameena Gill, who was VP of safety and customer care just took a job at rival Uber. Got a tip for us? Email Kirsten Korosec at kirsten.korosec@techcrunch.com or my Signal at kkorosec.07, or email Sean O’Kane at sean.okane@techcrunch.com . Deals! Image Credits: Bryce Durbin Close followers of the mobility-crazed years, between 2015 and 2019, might recall how many lidar companies popped up during that time. Many of the dominant and buzziest ones have since shuttered, while some of the smallest players have hung on and expanded. Take Ouster , for instance. I remember way back when Ouster had this tiny little booth in the jam-packed startups area (Eureka Park) at CES. Today, the company is much bigger — thanks to scale, its 2022 merger with rival Velodyne, and its acquisition of Sense Photonics in 2021. And it doesn’t appear to be finished. The company most recently acquired Stereolabs , a company that makes vision-based perception systems for robotics and industrial applications, for a combination of $35 million and 1.8 million shares. As TechCrunch senior reporter Sean O’Kane notes in his article, the deal is the latest in a march toward consolidation among perception sensor suppliers. (Just last month, MicroVision bought the lidar assets of the buzzy-but-now-bankrupt Luminar for $33 million .) So why all the activity? It’s complicated, as they say. From my POV, the frenzy around “physical AI” has reignited interest and investment in sensor technologies, particularly cameras. Other deals that got my attention … Ever , the EV-only marketplace, raised $31 million in a Series A funding round led by Eclipse. Other backers include Ibex Investors, Lifeline Ventures, and JIMCO — the investment arm of the Saudi Arabian Jameel family (an early investor in Rivian). Natilus , the San Diego-based startup developing blended-wing aircraft, raised $28 million in a Series A funding round led by Draper Associates. Other investors include Type One Ventures, The Veteran Fund, and Flexport, as well as new backers New Vista Capital, Soma Capital, Liquid 2 VC, VU Venture Partners, and Wave FX. Notable reads and other tidbits Image Credits: Bryce Durbin Aurora shared in its Q4 and full-year earnings report that its self-driving trucks can now travel nonstop on a 1,000-mile route between Fort Worth and Phoenix — exceeding what a human driver can legally accomplish. The company shared a number of other tidbits, and financials, which you can read about here . The U.S. Securities and Exchange Commission closed its investigation into Fisker last year, TechCrunch was able to learn, thanks to a Freedom of Information Act request. Lyft has launched teen accounts , a product that allows minors as young as 13 to hail a ride without an adult in 200 U.S. cities, including Atlanta, Boston, Chicago, and New York. A fresh batch of videos gives us the best look at how Rivian has changed the rear door manual release on its upcoming R2 SUV. This seemingly minor design detail has life-or-death stakes and comes as the EV industry, and particularly Tesla , is getting pressure to change concealed, electronic door handles. The Trump administration officially repealed the EPA’s 2009 “ endangerment finding ,” which found that greenhouse gases such as carbon dioxide and methane were a threat to human health and welfare. This change would only affect tailpipe emissions for cars and trucks — if the EPA makes it through the lengthy process of repealing the law, which will certainly include numerous lawsuits aimed at stopping it. Uber has locked in a couple dozen AV partnerships, and we’re starting to see the results of those deals. China’s Baidu and Uber plan to launch robotaxis in Dubai in the next month, starting with select locations within the Jumeirah area. Meanwhile, Chinese robotaxi company WeRide and Uber announced a “major expansion of their strategic partnership” to deploy at least 1,200 robotaxis across the Middle East through 2027, according to the companies. As part of this, WeRide and Uber have launched a robotaxi service in downtown Abu Dhabi. Waymo pulled the human safety driver from its autonomous test vehicles in Nashville as the Alphabet-owned company moves closer to launching a robotaxi service in the city. Meanwhile, this tech-forward company is wrestling with the analog problem of ensuring the doors of its robotaxis are properly shut. Its solution? Pay DoorDash gig workers to shut Waymo robotaxi doors . Waymo tells us this is a pilot program in Atlanta to enhance its AV fleet efficiency. One final Waymo item: The company is starting to roll out its sixth-generation “Waymo Driver,” which is integrated into the Zeekr RT (rebranded Ojai) and will eventually be in the Hyundai Ioniq 5. Waymo has started “fully autonomous operations” in the Ojai vehicle in San Francisco and Los Angeles and is giving access to employees. The public will have to wait for a bit. One more thing … Rivian has pitched its upcoming R2 SUV as a more affordable model. What does “more affordable” mean? The company has thrown around $45,000 and $50,000 as a base price. The company’s launch version of the R2, which will be a dual-mode and all-wheel-drive premium trim, will undoubtedly be more expensive. In our newsletter this week, we asked readers, “What’s your guess on the cost of the launch edition?” Sign up for our newsletter to participate in our polls!",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/07/250522-ANASTASIA-BENSON-GOOGLE-MAPS-AEB08056-FINAL.jpg?resize=1200,790"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "What the Epstein files reveal about EV startups and Silicon Valley",
      "url": "https://techcrunch.com/2026/02/15/what-the-epstein-files-reveal-about-ev-startups-and-silicon-valley/",
      "published": "2026-02-15T16:54:12+00:00",
      "summary": "Will the Epstein revelations lead to broader fallout in Silicon Valley?",
      "content_text": "After the Justice Department released a trove of new documents tied to infamous sex offender Jeffrey Epstein, journalists digging through them have found extensive connections to Silicon Valley . TechCrunch’s Sean O’Kane examined how a mysterious businessman named David Stern built a relationship with Epstein and pitched him investments in multiple electric vehicle startups, including Faraday Future, Lucid Motors, and Canoo. On the latest episode of the Equity podcast , Kirsten Korosec and I talk to Sean about what he learned, and we discuss whether the Epstein revelations will lead to broader fallout in Silicon Valley. You can read a preview of our conversation, edited for length and clarity, in the transcript below. Sean: There are always people at the edges who don’t necessarily want to be front and center in the investment scene. And that was why I started looking through these files, in part because a long time ago, flashback 10 years ago on my beat especially, there was just a ton of Chinese investment in the space. This was before even the rush of EV startups in China that we see today […] In autonomous vehicles, but electric vehicles especially, there was this moment where Chinese investors and Chinese companies, state-owned automakers, all they wanted to do was to be looked at like Silicon Valley startups. So they came here and they invested in companies and helped get them off the ground, or in some cases even set up offices in Silicon Valley. And it was in that environment that a lot of the companies that I’ve covered for a long time popped up. There was just never a full picture of how a lot of them were funded. Techcrunch event Boston, MA | June 23, 2026 One in particular, this company called Canoo, which is now bankrupt and out of business, had maybe the most mysterious set of investors of all of them. They really were not upfront about it when they first sort of came out of stealth in early 2018. And it frankly took until there was a lawsuit between some people who ran the company near the top that the investors were revealed. At the time, it was this businessman in China who was relatively close, the son-in-law of the former sort of like the fourth most senior CCP official under the previous leader of China and a giant electronics magnate from Taiwan. And then there was this really strange guy named David Stern, who was the third founding investor. And there was so little information about this guy. I could tell, back then, that he was some sort of German businessman, that he had some connections to China, but it wasn’t really clear how he had gotten involved. The only thing I really remember hearing at the time was that he was close with Prince Andrew, which I just thought was very strange, this idea that someone had even told me a long time ago, probably in 2018 or 2019, that Prince Andrew was involved with this company Canoo in some way, maybe not invested, but advising or something. It was something that stuck in my head for a very long time, clearly, because I went looking for that information as more of these files came out, assuming that proximity to Prince Andrew means proximity to someone like Epstein. And that was the case here, more so than I could have imagined, because this guy Stern turned from an enigma or a ghost into someone who was present through all this dealmaking 10 years ago, where we see him pitching, in the span of about a year and a half, investments in Faraday Future, trying to convince Epstein to maybe throw a couple hundred million dollars into that company, trying to buy the 30% stake that Faraday Future’s founder had bought or acquired in Lucid Motors arrival at the time, which I feel is an overlooked dynamic [in] how those companies grew around then — and then also in Canoo. Epstein never invested in any of those companies despite that proximity, but it was just such a revealing thing. And I get into it in the story that I wrote last week , but we get this sweep of a decade of relationship that Stern had with Epstein from approaching him initially in 2008, kind of hat in hand, and introducing himself and saying, “Hey, I want to invest in China. Will you throw in some money?” to being someone who was seemingly very close to him by the end. Kirsten: The whole thing is really interesting, and it goes back to my initial comments about how sometimes when you get a chance to look back at with new information at how deals were unfolding, it really just changes your perception and perspective of the time. And for those who didn’t follow quote-unquote “mobility,” think of it as how we’re thinking about physical AI these days. Everyone was talking about it. Every automaker wanted to have a piece of quote-unquote “the future of transportation” or “mobility.” And so it makes a lot of sense that some of these more secretive types were also jumping in. Sean, one of the points you made to me as I was working on the story with you, in terms of editing it, you were [saying], it was very clear that Epstein and David Stern weren’t really about investing and building companies. It was all about how to make the most money the fastest. And that, I think, is really historically important and interesting and gives you a little bit of an insight into — in addition to all the horrible, horrifying, terrible things he did to human beings, [Epstein] was a complete operator as well, in order to make money as quickly as possible. And you see that in these emails and exchanges between David Stern and Epstein. Sean: Yeah, to both of those points really, I open the story with a moment in time where Lucid Motors […] they had been basically a battery supplier for a long time and then they pivoted into the passenger vehicle startup that we know them as today, but they were really struggling to raise their Series D at the time, and they really needed that money to start production of their first electric sedan. They were struggling, behind the scenes in large part because the founder of Arrival quietly amassed this major stake and was kind of pushing people away and making it look like an uninvestable company in some ways, but the hype around all of that at the time was creating opportunities for people like Stern and Epstein, and we see them talk in these emails about, you know, Stern comes to Epstein and basically says, “I heard that they’re raising. Can you get information from Morgan Stanley?” Epstein turns around and passes that information back, and then you see this discussion about, okay, well, Morgan Stanley says Ford — which was reported at the time — had kind of an investment offer, potential acquisition offer, on the table for Lucid Motors [and] was going to come in in that Series D. And they’re chopping up — do we invest in this and maybe get a big return down the road? Or is it something that we sell as Ford comes in a couple months later, if we can get this stake now at fire sale prices? Ultimately, they didn’t go through with that, but Stern did eventually invest in Canoo and help get that company off the ground. Anthony: One thing — maybe pulling back a little bit from the specific industries or investments — that’s also an important piece of context that generally gets mentioned in any of these stories about Epstein in Silicon Valley, but is worth repeating here, is that he [pleaded] guilty to soliciting prostitution from a minor in 2008. Almost all the emails that we’re talking about with these stories [and] in pretty much any other story about Epstein in Silicon Valley comes after that. So it’s also partly a story about how people get comfortable with the idea that, okay, this guy has a pretty shady past already. He wasn’t the infamous criminal that he eventually [became], but there were things that were already known about him, and because he was a source of connections to power, to famous names, to money, a lot of people were just willing to look past that. VIDEO",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/jeffrey-epstein_8ef3e8.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Palantir vs. the \"Republik\": US analytics firm takes magazine to court",
      "url": "https://www.heise.de/en/news/Palantir-vs-the-Republik-US-analytics-firm-takes-magazine-to-court-11176508.html",
      "published": "2026-02-15T16:51:17+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.heise.de/en/news/Palantir-vs-the-Republik-US-analytics-firm-takes-magazine-to-court-11176508.html\">https://www.heise.de/en/news/Palantir-vs-the-Republik-US-analytics-firm-takes-magazine-to-court-11176508.html</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47025188\">https://news.ycombinator.com/item?id=47025188</a></p> <p>Points: 117</p> <p># Comments: 45</p>",
      "content_text": "Palantir vs. the \"Republik\": US analytics firm takes magazine to court Palantir Technologies, the US provider of analytics software, finds itself directly affected by two reports from the Swiss online magazine \"Republik\". After the company unsuccessfully demanded a counterstatement from the magazine, it now wants to enforce one through legal action. It's about a factual comparison, says the software provider. The \"Republik\" creators appear surprised. Streisand Effect With the step to court, Palantir has generated more attention for the \"Republik\" reporting than the objected articles themselves could have caused ‚Äì 23 years after Barbra Streisand triggered the effect named after her . And yet, there are reasons why Palantir is acting this way. While in Germany the provider of data linking and data analysis software for authorities with surveillance powers is successful with at least some state customers. The company has so far had ‚Äì as far as is known ‚Äì little state clientele in Switzerland. In December, \"Republik\" extensively quoted from Swiss administration files . According to this, Palantir repeatedly sought contact with Swiss authorities ‚Äì and found it. In some cases, it originated from Palantir, in others, likely from public bodies. The matters concerned the military, police, and health authorities. However, no business deal was apparently concluded. Palantir feels unfairly treated by the reporting on this. \"We can confirm that an application for a counterstatement has been filed with the Commercial Court in this matter,\" the communications officer of the Cantonal High Court told heise online on Friday upon request. Swiss Counterstatements Swiss law provides for counterstatements, meaning that as soon as a request for a counterstatement has been rejected by a medium, a civil court can examine the matter and hear both sides. The Commercial Court of Zurich is responsible here. The Commercial Court of Zurich is responsible here. Palantir says it had to sue to uphold its legal claim. \"Palantir fully respects press freedom and the essential role of independent media in public debate,\" said a company spokeswoman. The right to a counterstatement is a \"correction instrument intended to provide the public with balanced information.\" For Palantir, the \"Republik\" reporting came at an inopportune time. This is because important procurement decisions are currently being made in several business areas in many European countries: the modernization and expansion of military, intelligence, and secret services, as well as police authorities, would be a promising business for Palantir and its software, which is also helpful for official surveillance. In its home market, the USA, the company does business with US federal authorities for about a quarter of a billion US dollars, according to transparency data approximately a quarter of a billion US dollars . Customers include the US Department of Defense, the Army, and the FBI. The company reports nearly 4.5 billion US dollars in revenue for 2025, about a tenth of SAP's annual revenue. And yet, Palantir is valued on the stock market at around 300 billion euros, while SAP comes in at around 200 billion. Difficult Terrain Europe The European market remains difficult terrain for Palantir. The connection to the Immigration and Customs Enforcement agency (ICE), which is supposed to track down illegal migrants with brutal methods and a lot of high-tech , causes consternation in Europe. As a US company, Palantir is subject to US law, which increasingly questions international cooperation in security matters ‚Äì this is unlikely to be conducive to sales for Palantir. Meanwhile, the uproar had just subsided elsewhere: Palantir was criticized for its involvement in Israel. Founders Peter Thiel and Alex Karp had agreed to a strategic partnership with the Israeli Ministry of Defense in January 2024, Bloomberg reported at the time. The report on this is publicly available on the Palantir website . The small medium from Switzerland is hardly comparable to industry giants like Bloomberg. It has been published ad-free and exclusively online since 2018. It is primarily supported by a good 30,000 subscribers, a majority of whom are also cooperative members with voting rights. Not a media behemoth with a large publisher behind it. \"Borderline Conspiracy Theories\" Shortly after the publication of the two articles now being heard in court, Courtney Bowman, head of Palantir's \"Privacy and Civil Liberties\" department, had already set the course on LinkedIn: The reports from \"Republik\" were \"full of distortions, insinuations, and borderline conspiracy theories.\" Bowman accuses the authors of having reproduced a report from the Swiss Army Staff too uncritically ‚Äì whose authors, unfortunately, had \"relied on a limited set of search engine hit sources.\" The Palantir representative, in turn, provided no evidence for his claims. \"I believe we have done excellent research and documented it very comprehensively,\" says Daniel Binswanger, co-editor-in-chief of \"Republik,\" in an interview with heise online. Research based on Swiss government documents is one of the \"best foundations for reporting.\" He is very confident about the outcome of the proceedings. Palantir Rejects Accusation of Intimidation Palantir strongly rejects the impression that a multi-billion dollar company is flexing its muscles against a small magazine: Any accusation that this is a strategic attempt to intimidate unfavorable reporting through legal action is unfounded, the company spokeswoman emphasizes: \"Palantir merely seeks the publication of a concise and appropriate counterstatement to correct significant inaccuracies.\" However, the company does not disclose what specific \"significant inaccuracies\" Palantir wants to see corrected. Palantir did not respond to a request to send the \"corrections\" specifically demanded by \"Republik\" by Friday afternoon. Whether the company will achieve at least partial success with its approach in court is hardly predictable. The Swiss right to a counterstatement involves no examination by the court whether a statement was actually correct. This is why it is a frequently used form in the Swiss media world when companies feel they have been misrepresented. \"The right to a counterstatement is not about whether something is true or false,\" explains \"Republik\" co-editor-in-chief Daniel Binswanger. \"It's about whether another version of the facts could also be possible.\" However, this only concerns factual representation. Opinions, on the other hand, are not challengeable in Switzerland either. For the Swiss online magazine, however, the effect is noticeable and measurable. \"We are overwhelmed,\" says Daniel Binswanger in an interview with heise online. \"The offers of donations, expressions of solidarity ‚Äì it's gigantic,\" he says. \"We've never experienced a story triggering this.\" Ms. Streisand sends her regards. ( vbr ) Don't miss any news ‚Äì follow us on Facebook , LinkedIn or Mastodon . This article was originally published in German . It was translated with technical assistance and editorially reviewed before publication. Dieser Link ist leider nicht mehr g√ºltig. Links zu verschenkten Artikeln werden ung√ºltig, wenn diese √§lter als 7 Tage sind oder zu oft aufgerufen wurden. Sie ben√∂tigen ein heise+ Paket, um diesen Artikel zu lesen. Jetzt eine Woche unverbindlich testen – ohne Verpflichtung!",
      "cover_image_url": "https://heise.cloudimg.io/bound/1200x1200/q85.png-lossy-85.webp-lossy-85.foil1/_www-heise-de_/imgs/18/5/0/2/7/7/7/1/Screenshot_2026-02-13_at_19.57.24-85c7b3432095e315.png"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Here are the 55 best Presidents Day deals we’ve found so far",
      "url": "https://www.theverge.com/gadgets/875949/best-presidents-day-sales-deals-2026",
      "published": "2026-02-15T16:40:56+00:00",
      "summary": "Deals have been admittedly pretty dry since the holidays, but now that February is in full swing, we’re starting to see strong discounts return across a range of categories. In fact, thanks to Valentine’s Day, the Super Bowl, and — as of this weekend — Presidents Day, retailers are once again offering a slew of [&#8230;]",
      "content_text": "Deals have been admittedly pretty dry since the holidays, but now that February is in full swing, we’re starting to see strong discounts return across a range of categories. In fact, thanks to Valentine’s Day, the Super Bowl, and — as of this weekend — Presidents Day, retailers are once again offering a slew of notable tech deals, making now a great time to shop if you’ve been holding off on making a larger purchase. Although the Super Bowl and V-Day have technically come and gone, plenty of discounts are still around. A few have been rebranded for Presidents Day — including the discounts we recently saw on Sonos soundbars and speakers — but others are part of a new wave of limited-time deals, letting you save on OLED TVs , wireless earbuds , iPads , and other gadgets through the end of tomorrow, February 16th. Below, we’ve rounded up the best Presidents Day deals we’ve seen so far. As in previous years, we’ll continue updating this list with new picks throughout the long weekend. Headphone and earbud deals Soundbar, TV, and streaming deals Smartwatch and fitness tracker deals Other great Presidents Day deals Update, February 15th: Updated to reflect current pricing / availability and several new deals, including those for Google’s Pixel Buds Pro 2 and the Mill Food Recycler.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/257536_Powerbeats_Pro_2_AKrales_0295.webp?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Hideki Sato, designer of all Sega‚Äôs consoles, has died",
      "url": "https://www.videogameschronicle.com/news/hideki-sato-designer-of-segas-consoles-dies-age-75/",
      "published": "2026-02-15T16:19:51+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.videogameschronicle.com/news/hideki-sato-designer-of-segas-consoles-dies-age-75/\">https://www.videogameschronicle.com/news/hideki-sato-designer-of-segas-consoles-dies-age-75/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47024907\">https://news.ycombinator.com/item?id=47024907</a></p> <p>Points: 209</p> <p># Comments: 17</p>",
      "content_text": "Hideki Sato, the designer behind virtually every Sega console, and the company‚Äôs former president, has died age 77. Japanese games outlet Beep21 reports that Sato passed away this weekend. Sato and his R&D team were responsible for the creation of Sega ‚Äôs arcade and home console hardware, including the Master System, Genesis / Mega Drive, Saturn, and Dreamcast. The engineer joined Sega in 1971 and was the company‚Äôs acting president between 2001 and 2003. He left the company in 2008. ‚ÄúFrom the beginning, Sega‚Äôs home console development has always been influenced by our arcade development,‚Äù Sato previously told Famitsu in an interview covering Sega‚Äôs history. ‚ÄúOur first 8-bit machine was the SC-3000 . This was a PC for beginner-level users. At that time, Sega only did arcade games, so this was our first challenge. We had no idea how many units we‚Äôd sell.‚Äù Sato said of Mega Drive, Sega‚Äôs most successful console: ‚ÄúAt that point, we decided to start developing a new home console. By then, arcade games were using 16-bit CPUs. ‚ÄúArcade development was something we were very invested in, so we were always using the most cutting-edge technology there. Naturally, it started us thinking: what if we used that technology in a home console? ‚ÄúTwo years after we started development, it was done: a 16-bit CPU home console, the Megadrive. The 68000 chip had also recently come down in price, so the timing was right.‚Äù On Dreamcast, the release that ultimately ended Sega‚Äôs run in hardware, Sato said the keyword for the development was ‚Äúplay and communication.‚Äù ‚ÄúThe ultimate form of communication is a direct connection with another, and we included the modem and the linkable VMUs for that purpose,‚Äù he said. ‚ÄúWe had also planned to have some sort of linking function with cell phones, but we weren‚Äôt able to realize it. Consumers were now used to the raging ‚Äòbit wars‚Äô, so even though we knew it was a lot of nonsense, we needed to appeal to them in those terms with the Dreamcast. ‚ÄúAnd so we marketed it as having a ‚Äò128 bit graphics engine RISC CPU‚Äô, even the SH-4 was only 64-bit. (laughs) On the other hand, we extensively customized the original SH-4 for the Dreamcast, to the point where I think you could almost call it something new.‚Äù",
      "cover_image_url": "https://www.videogameschronicle.com/files/2026/02/IMG_1643.jpeg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "How to get into a16z's super-competitive Speedrun startup accelerator program",
      "url": "https://techcrunch.com/2026/02/15/how-to-get-into-a16zs-super-competitive-speedrun-startup-accelerator-program/",
      "published": "2026-02-15T15:53:53+00:00",
      "summary": "TechCrunch spoke to a16z partner Joshua Lu for some tips on standing out for the Speedrun program.",
      "content_text": "Without a doubt, one of the hottest new startup accelerators in tech right now is Andreessen Horowitz’s Speedrun program. Launched in 2023, the accelerator has an acceptance rate of less than 1%. In a January blog post, the program said that over 19,000 startups pitched and fewer than 0.4% were accepted into the latest cohort. The program used to focus on gaming startups, then expanded into entertainment and media, and is now a “horizontal program,” Joshua Lu, the program’s general manager and a partner at a16z, told TechCrunch. Today, founders of any type of startup can apply, and the program runs for about 12 weeks in San Francisco. It once had a program in Los Angeles, but Lu said the focus will be on SF from now on. There are two cohorts a year, and around 50 to 70 startups are accepted into each. The program invests up to $1 million into each company, though the downside is that it’s a bit pricey. It typically invests $500,000 up front in exchange for 10% of the startup’s company via a SAFE note, and another $500,000 if the next round is raised within 18 months, at whatever terms agreed to by the other investors. In comparison, Y Combinator typically takes a fixed 7% of the company for $125,000, with another $375,000 “invested on an uncapped MFN safe.” Speedrun said its program is more “equity expensive” because of what it offers founders. It provides them with access to a16z’s advisory and business networks that assist with tasks like go-to-market, brand development, media strategy, and talent sourcing. Plus it offers the startups perks like $5 million in credits to vendors such as AWS, OpenAI, Nvidia, and Deel. Given the high interest, and low acceptance rate, TechCrunch spoke to Lu for some tips on how startups can best stand out. The latest cohort began in January and will end in April with a Demo Day. Applications for the next cohort open in April, though it looks at off-season applications year-round, Lu said. Focus on the founding team Speedrun focuses on early-stage startups. Because of this, they really examine who is on the founding team and whether their skills complement each other, Lu said. Techcrunch event Boston, MA | June 23, 2026 “That doesn’t mean one has to be technical and one has to be commercial and one has to be marketing,” Lu said. It means that “we prefer not to see any glaring holes in capabilities or interests. We want the founding team to be self-aware and for that to be part of the hiring plan.” They also like to see teams that have worked together before or have a shared history. “There are lots of things that a founding team has to navigate in their startup journey and having a bit of pattern recognition, being able to work with each other, knowing how to disagree and how to come out the other side of a disagreement, those are all things people on founding teams with shared histories have an easier time with, on average,” he continued. Even though AI has lowered the barriers to building software, it’s still incredibly helpful for a founding team to be technical, Lu said. At the same time, because AI has made it much faster to build and validate hypotheses and get a product out there, Lu said the Speedrun team likes to see when a startup already has a little bit of market validation or traction for their product. “Speedrun as a program is really great at helping teams pour gasoline on a very small spark or fire,” he said. “We look for teams that have endeavored to build and try to show us that there’s a little spark we can fan the flames on.” Limit the market “theory” Lu said one common mistake founders often make in the application process is spending too much energy talking about the market theory or why there is a defined problem and why their solution is the right one. “All of that may be true,” he said. At the same time, he added, even the biggest, most successful tech companies faced unexpected blockades when they were young, sometimes even pivoting completely. What a company thinks it’s going to build at the beginning isn’t necessarily what will make it successful at the end. “What we really want to hear about is why this founding team is really good together,” he continued, “why they’re a great founding team, the best possible founding team to solve this particular problem.” And then on top of that, any validation on the idea itself. It’s okay to use AI for the application, but… Lu said the program encourages every founder to use AI to “clean up” their application. He said there is now no excuse for grammar errors or misspellings given the rising sophistication of AI tools. He also said AI can help founders sort out their thoughts, making them clearer, more concise, and more coherent. But if AI did all the work in explaining the startup, that may backfire. If a founder makes it to the next round, it will be a live video-call interview. “At that point, their live narration explanation skills are going to be put to the test,” he said. So founders should be prepared to talk cogently about their startup without the help of AI. Only about 10% of founders make it to the video-call stage. There are typically two to three investors on the judging panel at a time. After the live interview, the team typically conducts a few more screening calls with the founders, and then a final decision on the cohort is made. Be greedy to network There are, of course, other accelerator programs for startups to choose from. Lu said Speedrun itself was inspired by some of these other programs. Still, he said, this accelerator prides itself on giving founders access to a large, specialized operating team. In fact, he said the best teams that get the most out of the program are the ones most “greedy about getting exposure to the amazing people and programs” Speedrun has to offer. Lu listed off just a few points: a16z has around 600 people, and 10% of that staff is on the investment team, he said; everyone else is an operator who supports the companies the firm works with. As a result, founders in Speedrun will have access to experts who can help with marketing, banking, finance, management, and many other functions. So it helps to know who the startup wants to connect with and why. “We tell founders that come through the program, what you get out of Speedrun is what you put into it,” he said. “We think founders who want to take advantage of world experts in many different domains early in their startup journey would be really smart to choose us.” Advice from a founder in the program Founder Mohamed Mohamed, who is in the recent cohort, just announced a $5 million raise for his proptech startup Smart Bricks led by a16z’s Speedrun. He was attracted to the program because he said it stood out as one of the few “explicitly designed for co-founders working on frontier AI applications,” and he picked it because he wanted a program that would allow him to “stress-test an ambitious technical vision.” Mohamed said he treated the application like an internal strategy memo rather than a pitch. “Instead of polishing buzzwords, we focused on clarity — the real problem, why it’s structurally hard, and why our team is unusually well-positioned to solve it,” he said. “We were explicit about what was working, what wasn’t, and where we needed help. I think that honesty and clear articulation of why this problem matters” is what helped the company in the application process. He called the whole process “rigorous but refreshingly thoughtful,” and said it was designed to understand how founders think, not just what they have built so far. “The conversations went deep into product architecture, data strategy, and long-term ambition. It felt closer to a partner-level discussion than a typical accelerator interview, which was a strong signal for us,” he said. His overall advice is to be “intellectually honest and precise.” For example, he said in his application he avoided “over-optimizing” for the sake of hyping up his company. “If you’re vague, derivative, or overly defensive about your idea, it shows quickly. Don’t try to sound bigger than you are; clarity about where you actually are is far more compelling than inflated narratives,” he said. In the end, “Speedrun isn’t looking for perfect companies; they’re looking for founders who can reason clearly about complex problems and build with conviction,” he said. “Articulate the hard parts of what you’re doing and why they’re worth tackling. Depth beats polish every time.” Correction, story originally misstated YC’s investment for its 7%. It has been corrected.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/speedrun.webp?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "How an Enslaved Gardener Transformed the Pecan Into a Cash Crop",
      "url": "https://lithub.com/how-an-enslaved-gardener-transformed-the-pecan-into-a-cash-crop/",
      "published": "2026-02-15T15:53:13+00:00",
      "summary": "<p>Article URL: <a href=\"https://lithub.com/how-an-enslaved-gardener-transformed-the-pecan-into-a-cash-crop/\">https://lithub.com/how-an-enslaved-gardener-transformed-the-pecan-into-a-cash-crop/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47024676\">https://news.ycombinator.com/item?id=47024676</a></p> <p>Points: 57</p> <p># Comments: 36</p>",
      "content_text": "Pecan nuts were already a dietary staple for Native Americans in various parts of what is now the United States before Antoine’s innovation established the basis for a commercial pecan industry. This use of pecans by Indigenous people should not be surprising given that that the name of the nut, “pecan,” itself is thought to be derived from the Algonquin word “pakani,” which translates to “a nut too hard to crack by hand” or, alternatively, “a nut requiring a stone to crack.” Article continues after advertisement Pecans were used in various dishes by Native Americans; they were also central in trade and in other important parts of life. Fermented nuts were used in traditional Indigenous ceremonies. For example, fermented nuts were used by the Algonquin to make a drink known as “powcohiccora” that was consumed in sacred ritual, as well as during battles to enhance the bravery of fighters. Additionally, extracts from pulverized pecan tree parts such as leaves and bark served medicinal purposes, including as antibacterial and antifungal agents, to treat ailments such as ringworm and nausea. Antoine’s successful inosculation would produce what came to be known as the Centennial variety of pecan, which transformed the commercial pecan industry. Noting the many decades, if not centuries, of importance of pecans in the lives of Indigenous people in the United States, it was Antoine’s plant grafting experiments with pecan trees during the nineteenth century that led to the development of a viable propagation method. This ability to increase propagation and growth was important, as these nuts were consumed by many Southerners in the areas where they grew and were indeed a prized nutrition source due to their fat content and ease of storage and transport. Both George Washington and Thomas Jefferson planted pecans at their plantations, with Washington being known to carry them around in his pockets as a snack. Earlier attempts to develop a commercial market for pecans based on growing trees from seeds had been unsuccessful, as trees originating from seeds have a long lag period until maturation and production of nuts. Additionally, trees grown from nuts that are the offspring of a single individual frequently result in trees that are highly variable in terms of the nuts produced, including a range of nut sizes and nut quality. Such variability is generally not good for commercial crops, which thrive on uniform and predictable nut production. Antoine’s advancements in the propagation of pecan trees that produced high-quality pecans of reproducible form, then, resulted in these nuts being cultivated as a cash crop that could be mass produced. This agricultural advance ultimately supported the production of up to ten million pounds of pecans annually by the early 1920s, resulting in a multimillion dollar pecan industry. Article continues after advertisement Antoine’s trees were eventually felled after the plantation changed hands multiple times after the death of enslaver Roman. A new agricultural industry of sugarcane had emerged with the promise of greater profitability. Thus, the effort to establish these successful pecan trees that were the foundation for American commercial pecan production was literally cut down. However, Antoine’s achievement in developing a viable grafting method for pecan trees should not be undervalued. Grafting is a delicate, if not altogether tricky, experimental process. Grafting involves joining together parts of two or more plants into a new, individual plant that can grow and develop successfully. If composed of two parts, there is often a scion—the upper or shoot portion of a plant—which is joined with a separate rootstock to produce, if successful, a healthy grafted plant. There are two major types of grafting: stem grafting, which involves grafting a shoot onto the rootstock of another plant, or bud grafting, which involves grafting a dormant bud of one plant into the stem of another stock plant. Having conducted—unsuccessfully, for the most part—stem grafting experiments with plants, I know that more often than not a grafting process can fail. That is, the joining of two parts—for me a scion with a rootstock—does not always result in a productive joining where the xylem (the water-conducting tissues that support transfer of water and nutrients taken up by roots through the full plant) and the phloem (the sugar-conducting tissues that carry sugars produced through photosynthesis) are successfully connected across the junction of the grafted plant parts. In the absence of a successful graft junction, water taken up from the root stops at the failed junction and only temporarily benefits the rootstock. Likewise, the sugars produced by the green leaves of a scion cannot be shared with the lower stem and roots of the plant if the graft fails. Each time I worked carefully to delicately graft seedlings was a stressful process. I’d first have to grow and obtain healthy plants, from which I’d select the two halves for grafting. When it was time for the grafting process, I’d move everything into a sterile environment and sterilize all the tools that I’d be using. Wearing gloves and a face mask, I’d still my breath as if I was stilling air, in hopes of reducing the likelihood of introducing any contaminant into my workspace. After methodically performing the isolation of tissues and joining the scion and rootstock under sterile conditions to prevent bacteria or other unwanted materials inhibiting the joining of the parts, I’d observe the grafted being daily with bated breath while waiting to see if the process had been successful. You could tell pretty soon if it was likely to have worked, because when it didn’t, tissue at the graft junction would first turn brown before both parts of the graft atrophied and died. Antoine likely undertook this process in an environment that was as still and controlled as he could manage, in order to limit the likelihood of contaminating his grafted seedlings. Yet in the nineteenth century, as much as he could manage was surely not much. Antoine accomplished his success as a pecan grafter with far less sophisticated equipment and far less sterile grafting chambers than I and other scientists have access to when doing these very difficult experiments now. Still, working by candlelight would have provided Antoine a focused, well-lit environment for the delicate dissection of two seedlings in order to isolate the scion and rootstocks he wanted to graft. The candlelight would have duly served as a source of heat for him to sterilize his tools during his work. Article continues after advertisement An effective joining of a scion and rootstock is known as “inosculation,” a joining or connection that makes multiple parts continuous. I know the pure joy and hopefulness that bubbles up and over when a graft successfully takes. I can truly imagine Antoine’s at first cautious optimism and then his sincere triumph and joy when he obtained his first successfully grafted pecan seedlings. His careful protection and cultivation of those seedlings into the sapling stage would have been a sure victory. Although he certainly lost some of the attempted grafts along the way, as we all do when carrying out this process, Antoine’s botanical stewardship of some saplings into more mature stages ultimately paved the way toward his expert production of the first mature grafted pecan trees. Antoine’s successful inosculation would produce what came to be known as the Centennial variety of pecan, which transformed the commercial pecan industry. Antoine’s successfully grafted pecan trees catapulted this industry into a profitable one across areas of the South, including Georgia, where pecan crops remain one of the distinguishing profitable nut-tree industries, with annual production resulting in hundreds of millions of pounds of nuts valued at five hundred million to one billion dollars. Pecans are a vital ingredient in Black southern cuisine. Uses of the nutmeat include the widely recognized holiday pecan pies and pecan pralines. * In addition to tending to and harvesting from her pecan groves, my grandma and other elder women in the community would mix herbal concoctions at a moment’s notice using herbs, tree leaves, and other tree parts, as well as the aloe vera plants that were ever present on their kitchen windowsill. These concoctions might be used to treat a sprained ankle or sore throat. Grandma called them “family healing recipes” that had been passed down via the matriarchal line. These versatile salves might serve to treat a burn, as a facial cosmetic, or as a hair conditioner in a pinch. Such botanical knowledge, used for enrichment in the form of horticultural and culinary endeavors, as well as in health and medicine, has roots in global botanical exploration and exploitation. Additionally, some African cultural and religious practices involved central objects that were sticks or trees, or occurred in natural spaces such as the woods. Rarely do we hear the stories of enslaved gardeners such as Antoine who have had major impacts on life and industry in America and beyond. Stories of botanical expeditions are often retold through the lens of a European explorer or innovator “leading” voyages, usually omitting the role of the knowledge and expertise of enslaved or Indigenous individuals. Commonly framed and told histories of Indigenous women such as Pocahontas and Sacagawea, who are associated with famous expeditions by white English settlers in North America, are clear examples. Pocahontas is often painted as a “friend” to Captain John Smith of the Jamestown colony and the one who saved his life. Sacagawea is connected to the Lewis and Clark expedition as a translator and helper in navigating Native American communities and spaces. Historian Tiya Miles describes the reality of these famous stories as starker, in that the knowledge of these two women about how to navigate nature and identify and utilize plants was likely co-opted by these white men and their associates and their labor may have been largely uncompensated, or at least not fairly so. Article continues after advertisement Revered biologist Jane Goodall is most associated with her careful observation and reporting on the complex lives and communities of chimpanzees. Dr. Goodall also wrote on plants and described global botanical explorations. In her book Seeds of Hope , she waxes poetic about the varieties, life cycles, and cultural significance of a range of key plants and trees identified around the world. Of note, in her inspiring writing about global plant expeditions and associated brave and creative plant explorers, she offers only a cursory mention of enslaved individuals of African descent as plant caretakers or botanical experts. This oversight is present throughout her work and other literature and research. Goodall mentions the enslaved people who were exploited by plant explorers in their global expeditions to seek out new plant forms as merely “plant hunters” and “slaves.” In one passage, she describes an expedition on behalf of Egypt’s Queen Hatshepsut and writes: “Fortunately for the queen (and probably for those who delivered the specimens), the climatic conditions were excellent, and there were many slaves to carry freshwater, fans, sun blinds, and so on to keep the plants well-watered, cool, and happy ” (emphasis mine). In stark contrast to her curt description of the enslaved, her empathy is on full display for the plants that she sympathetically describes as “captives.” Later in Seeds of Hope , Goodall does speak of plantations as sites where “crimes against plants and humanity” occurred. However, far removed in terms of pages from the earlier literary, if not literal, oversight regarding the dire plight of the enslaved people who were held captive to care for the plants that a queen was fortunate to have brought back to her from the expedition, the later focus on crimes against humanity on plantations provides a somewhat hollow recognition. Still today, rarely do we hear the stories of enslaved gardeners such as Antoine who have had major impacts on life and industry in America and beyond. The erasure of enslaved expertise and sacrifice during global plant expeditions, as well as of Black botanical expertise in US agricultural history, is highly prevalent in many forms. __________________________________ Article continues after advertisement From When Trees Testify: Science, Wisdom, History, and America’s Black Botanical Legacy by Beronda L. Montgomery. Copyright © 2026. Available from Henry Holt and Co., an imprint of Macmillan.",
      "cover_image_url": "https://s26162.pcdn.co/wp-content/uploads/2026/01/pecan.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Hollywood isn't happy about the new Seedance 2.0 video generator",
      "url": "https://techcrunch.com/2026/02/15/hollywood-isnt-happy-about-the-new-seedance-2-0-video-generator/",
      "published": "2026-02-15T15:41:16+00:00",
      "summary": "Hollywood organizations are pushing back against a new AI video model called Seedance 2.0, which they say has quickly become a tool for “blatant” copyright infringement.",
      "content_text": "Hollywood organizations are pushing back against a new AI video model called Seedance 2.0 , which they say has quickly become a tool for “blatant” copyright infringement. ByteDance, the Chinese company that recently finalized a deal to sell TikTok’s U.S. operations (it retains a stake in the new joint venture ), launched Seedance 2.0 earlier this week. According to the Wall Street Journal , the updated model is currently available to Chinese users of ByteDance’s Jianying app, and the company says it will soon be available to global users of its CapCut app. Similar to tools such as OpenAI’s Sora , Seedance allows users to create videos (currently limited to 15 seconds in length) by just entering a text prompt. And like Sora, Seedance quickly drew criticism for an apparent lack of guardrails around the ability to create videos using the likeness of real people, as well as studios’ intellectual property. After one X user posted a brief video showing Tom Cruise fighting Brad Pitt, which they said was created by “a 2 line prompt in seedance 2,” “Deadpool” screenwriter Rhett Reese responded , “I hate to say it. It’s likely over for us.” The Motion Picture Association soon issued a statement from CEO Charles Rivkin demanding that ByteDance “immediately cease its infringing activity.” “In a single day, the Chinese AI service Seedance 2.0 has engaged in unauthorized use of U.S. copyrighted works on a massive scale,” Rivkin said. “By launching a service that operates without meaningful safeguards against infringement, ByteDance is disregarding well-established copyright law that protects the rights of creators and underpins millions of American jobs.” The Human Artistry Campaign — an initiative backed by Hollywood unions and trade groups — condemned Seedance 2.0 as “an attack one very creator around the world,” while the actors’ union SAG-AFTRA said it “stands with the studios in condemning the blatant infringement enabled by Bytedance’s new AI video model Seedance 2.0.” Techcrunch event Boston, MA | June 23, 2026 Seedance videos have apparently featured Disney-owned characters such as Spider-Man, Darth Vader, and Grogu, better known as Baby Yoda, prompting the company to take legal action. Axios reports that Disney has sent a cease-and-desist letter accusing ByteDance of a “virtual smash-and-grab of Disney’s IP”and claiming the Chinese company is “hijacking Disney’s characters by reproducing, distributing, and creating derivative works featuring those characters.” Disney isn’t necessarily opposed to working with AI companies — while it has reportedly sent a cease-and-desist letter to Google over similar issues, it’s signed a three-year licensing deal with OpenAI . Variety reports that Paramount followed suit by sending Bytedance a cease-and-desist letter on Saturday. The letter claimed that “much of the content that the Seed Platforms produce contains vivid depictions of Paramount’s famous and iconic franchises and characters” and that this content “is often indistinguishable, both visually and audibly” from Paramount’s films and TV shows. TechCrunch has reached out to ByteDance for comment. This post was originally published on February 14, 2026. It has been updated to include information about Paramount’s cease-and-desist letter.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2020/08/GettyImages-1263876301.jpeg?w=1024"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Gwtar: a static efficient single-file HTML format",
      "url": "https://gwern.net/gwtar",
      "published": "2026-02-15T15:37:06+00:00",
      "summary": "<p>Article URL: <a href=\"https://gwern.net/gwtar\">https://gwern.net/gwtar</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47024506\">https://news.ycombinator.com/item?id=47024506</a></p> <p>Points: 103</p> <p># Comments: 26</p>",
      "content_text": "Gwtar is a new polyglot HTML archival format which provides a single, self-contained, HTML file which still can be efficiently lazy-loaded by a web browser. This is done by a header’s JavaScript making HTTP range requests. It is used on Gwern.net to serve large HTML archives. Archiving HTML files faces a trilemma: it is easy to create an archival format which is any two of static (self-contained ie. all assets included, no special software or server support), a single file (when stored on disk), and efficient (lazy-loads assets only as necessary to display to a user), but no known format allows all 3 simultaneously. We introduce a new format, Gwtar ( logo ; pronounced “guitar”, .gw⁠tar.html extension), which achieves all 3 properties simultaneously. A Gwtar is a classic fully-inlined HTML file, which is then processed into a self-extracting concatenated file of an HTML + JavaScript header followed by a tarball of the original HTML and assets. The HTML header’s JS stops web browsers from loading the rest of the file, loads just the original HTML, and then hooks requests and turns them into range requests into the tarball part of the file. Thus, a regular web browser loads what seems to be a normal HTML file, and all assets download only when they need to. In this way, a static HTML page can inline anything—such as gigabyte-size media files—but those will not be downloaded until necessary, even while the server sees just a single large HTML file it serves as normal. And because it is self-contained in this way, it is forwards-compatible: no future user or host of a Gwtar file needs to treat it specially, as all functionality required is old standardized web browser/server functionality. Gwtar allows us to easily and reliably archive even the largest HTML pages, while still being user-friendly to read. Example pages: (vs — warning : 286MB download). Linkrot is one of the biggest challenges for long-term websites. Gwern.net makes heavy use of web page archiving to solve this; and due to quality problems and long-term reliability concerns , simply linking to the Internet Archive is not enough, so I try to create & host my own web page archives of everything I link. There are 3 major properties we would like of an HTML archive format, beyond the basics of actually capturing a page in the first place: it should not depend in any way on the original web page, because then it is not an archive and will inevitably break; it should be easy to manage and store, so you can scalably create them and store them for the long run; and it should be efficient, which for HTML largely means that readers should be able to download only the parts they need in order to view the current page. No current format achieves all 3. The built-in web browser save-as-HTML format achieves single and efficient, but not static; save-as-HTML-with-directory achieves static partially and efficient, but not single; MHTML , MAFF , SingleFile , & SingleFileZ (a ZIP -compressed variant) achieve static, single, but not efficiency; WARCs / WACZs achieve static and efficient, but not single (because while the WARC is a single file, it relies on a complex software installation like WebRecorder / Replay Webpage to display). An ordinary ‘save as page HTML’ browser command doesn’t work because “Web Page, HTML Only” leaves out most of a web page; even “Web Page, Complete” is inadequate because a lot of assets are dynamic and only appear when you interact with the page—especially images. If you want a static HTML archive, one which has no dependency on the original web page or domain, you have to use a tool specifically designed for this. I usually use SingleFile. SingleFile produces a static snapshot of the live web page, while making sure that lazy-loaded images are first loaded, so they are included in the snapshot. SingleFile often produces a useful static snapshot. It also achieves another nice property: the snapshot is a single file , just a simple single .html file, which makes life so much easier in terms of organizing and hosting. Want to mirror a web page? SingleFile it, and upload the resulting single file to a convenient directory somewhere, boom—done forever. Being a single file is important on Gwern.net, where I must host so many files, and I run so many lints and checks and automated tools and track metadata etc. and where other people may rehost my archives. However, a user of SingleFile quickly runs into a nasty drawback: snapshots can be surprisingly large. In fact, some snapshots on Gwern.net are over half a gigabyte! For example, the homepage for the research project “PaintsUndo: A Base Model of Drawing Behaviors in Digital Paintings” is 485MB after size optimization, while the raw HTML is 0.6MB. It is common for an ordinary somewhat-fancy Web 2.0 blog post like a Medium.com post to be >20MB once fully archived. This is because such web pages wind up importing a lot of fonts , JS, widgets and icons etc., all of which assets must be saved to ensure it is fully static; and then there is additional wasted space overhead due to converting assets from their original binary encoding into Base64 text which can be interleaved with the original HTML . This is especially bad because, unlike the original web page, anyone viewing a snapshot must download the entire thing . That 500MB web page is possibly OK because a reader only downloads the images that they are looking at; but the archived version must download everything. A web browser has to download the entire page, after all, to display it properly; and there is no lazy-loading or ability to optionally load ‘other’ files—there are no other files ‘elsewhere’, that was the whole point of using SingleFile! Hence, a SingleFile archive is static, and a single file, but it is not efficient : viewing it requires downloading unnecessary assets. So, for some archives, we ‘split’ or ‘deconstruct’ the static snapshot back into a normal HTML file and a directory of asset files, using deconstruct_singlefile.php (which incidentally makes it easy to re-compress all the images, which produces large savings as many websites are surprisingly bad at basic stuff like PNG/JPG/GIF compression); then we are back to a static, efficient, but not single file, archive. This is fine for our auto-generated local archives because they are stored in their own directory tree which is off-limits to most Gwern.net infrastructure (and off-limits to search engines & agents or off-site hotlinking), and it doesn’t matter too much if they litter tens of thousands of directories and files. It is not fine for HTML archives I would like to host as first-class citizens, and expose to Google, and hope people will rehost someday when Gwern.net inevitably dies. So, we could either host a regular SingleFile archive, which is static, single, and inefficient; or a deconstructed archive, which is static, multiple, and efficient, but not all 3 properties. This issue came to a head in January 2026 when I was archiving the Internet Archive snapshots of Brian Moriarty’s famous lectures “Who Buried Paul?” and “The Secret of Psalm 46” , since I noticed while writing an essay drawing on them that his whole website had sadly gone down. I admire them and wanted to host them properly so people could easily find my fast reliable mirrors (unlike the slow, hard-to-find, unreliable IA versions), but realized I was running into our long-standing dilemma: they would be efficient in the local archive system after being split, but unfindable; or if findable, inefficiently large and reader-unfriendly. Specifically, the video of “Who Buried Paul?” was not a problem because it had been linked as a separate file, so I simply converted it to MP4 and edited the link; but “The Secret of Psalm 46” turned out to inline the OGG/MP3 recordings of the lecture and abruptly increased from <1MB to 286MB . I discussed it with Said Achmiz , and he began developing a fix. To achieve all 3, we need some way to download only part of a file, and selectively download the rest. This lets us have a single static archive of potentially arbitrarily large size, which can safely store every asset which might be required. HTTP already easily supports selective downloading via the ancient HTTP Range query feature , which allows one to query for a precise range of bytes inside a URL. This is mostly used to do things like resume downloads, but you can also do interesting things like run databases in reverse: a web browser client can run a database application locally which reads a database file stored on a server, because Range queries let the client download only the exact parts of the database file it needs at any given moment, as opposed to the entire thing (which might be terabytes in size). This is how formats like WARC can render efficiently: host a WARC as a normal file, and then simply range-query the parts displayed at any moment. The challenge is the first part: how do we download only the original HTML and subsequently only the displayed assets? If we have a single HTML file and then a separate giant archive file, we could easily just rewrite the HTML using JS to point to the equivalent ranges in the archive file (or do something server-side), but that would achieve only static and efficiency, not single file. If we combine them, like SingleFile, we are back to static and single file, but not efficiency. The simplest solution here would be to decide to complicate the server itself and do the equivalent of deconstruct_singlefile.php on the fly. HTML requests, perhaps detecting some magic string in the URL like .singlefile.html , is handed to a CGI proxy process, which splits the original single HTML file into a normal HTML file with lazy-loaded references. The client browser sees a normal multiple efficient HTML, while everything on server sees a static single inefficient HTML. (A possible example is WWZ .) While this solves the immediate Gwern.net problem, it does so at the permanent cost of server complexity, and does not do much to help anyone else. (It is unrealistic to expect more than a handful of people to modify their servers this invasively.) I also considered taking the WARC red pill and going full WebRecorder, but quailed. How can we trick an HTML file into acting like a tarball or ZIP file, with partial random access? Our initial approach was to ship an HTML + JS header with an appended archive, where the JS would do HTTP Range queries into the appended binary archive; the challenge, however, was to stop the file from downloading past the header. To do this, we considered some approaches ‘outside’ the page, like encoding the archive index into the filename/URL itself (ie. foo.gwtar-$N.html ) and requiring the server to parse $N out and slice the archive down to just the header, which then handled the range requests; this minimized how much special handling the server did, while being backwards/forwards-compatible with non-compliant servers (who would ignore the index and simply return the entire file, and be no worse than before). This worked in our prototypes, but required at least some server-side support and also required that the header be fixed-length (because any changes would in length would invalidate the index). Eventually, Achmiz realized that you can stop downloading from within an HTML page, using the JS command window . stop () ! MDN ( >96% support , spec ): The window . stop () stops further resource loading in the current browsing context, equivalent to the stop button in the browser. Because of how scripts are executed, this method cannot interrupt its parent document’s loading, but it will stop its images, new windows, and other still-loading objects. This is precisely what we need, and the design falls into place. A Gwtar is an HTML file with a HTML + JS + JSON header followed by a tarball and possibly further assets . (A Gwtar could be seen as almost a polyglot file is a file valid as more than one format—in this case, a .html file that is also a .tar archive, and possibly .par2 . But strictly speaking, it is not.) The simple approach is to download the binary assets, encode them into Base64 text, and inject them into the HTML DOM. This is inefficient in both compute and RAM because the web browser must immediately reverse this to get a binary to work with. So we actually use the browser optimization of blobs to just pass the binary asset straight to the browser. A tricky bit is that inline JS can depend on “previously loaded” JS files, which may not have actually loaded yet because the first attempt failed (of course) and the real Range request is still racing. We currently solve this by just downloading all JS before rendering the HTML, at some cost to responsiveness. So, a web browser will load a normal web page; the JS will halt its loading; a new page loads, and all of its requests initially fail but get repeated immediately and work the second time; the entire archive never gets downloaded unless required. All assets are provided, there is a single Gwtar file, it is efficient; it doesn’t require JS for archival integrity, as just the entire archive downloads if the JS is not executed; and it is cross-platform and standards-compliant, requires no server-side support or future users/hosts to do anything whatsoever, and is a transparent, self-documenting file format which can be easily converted back to a ‘normal’ multiple-file HTML ( cat foo.gwtar.html | perl -ne 'print $_ if $x; $x=1 if /<!-- GWTAR END/' | tar xf - ) or a user can just re-archive it normally with tools like SingleFile. In the event of JS problems, a < noscript > message explains what the Gwtar format is and why it requires JS, and links to this page for more details. It also detects whether range requests are supported or downgraded to requesting the entire file. If the latter, it will start rendering it. This is not as slow as it seems because we can benefit from connection level compression like gzip or Brotli compression . And because our preprocessing linearize the assets in dependency order, we receive the bytes in order of page appearance, and so in this mode, the “above the fold” images and stuff will still load first and quickly. (This in comparison to the usual SingleFile, where you have to receive every single asset before you’re done, and which may be slower.) Gwtar does not directly support deduplication or compression. Gwtars may overlap and have redundant copies of assets, but because they will be stored bit-identical inside the tarballs, a de-duplicating filesystem can transparently remove most of that redundancy. Media assets like MP3 or JPEG are already compressed, and can be compressed during the build phase by a gwtar implementation. The HTML text itself could be compressed; it is currently unclear to me how Gwtar’s range requests interact with transparent negotiated compression like Brotli compression (which for Gwern.net was as easy as enabling one option in Cloudflare ). RFC 7233 doesn’t seem to give a clear answer about this, and the cursory and unhelpful discussion here seems to indicate that the range requests would have to be interpreted relative to the compressed version rather than the original, which is useful for the core use-case of resuming downloads but not for our use-case. So I suspect that probably Cloudflare would either disable Brotli, or downgrade to sending the entire file instead. It is possible that “transfer-encoding” solves this, but as of 2018, Cloudflare didn’t support it , making it useless for us and suggesting little support in the wild. If this is a serious problem, it may be possible to compress the HTML during the Gwtar generation phase and adjust the JS. Strangely, the biggest drawback of Gwtar turns out to be local viewing of HTML archives. SingleFileZ encounters the same issue: in the name of security ( origin / CORS /sandboxing), browsers will not execute certain requests in local HTML pages, so it will break, a",
      "cover_image_url": "https://gwern.net/doc/cs/algorithm/information/compression/2026-01-23-dbohdan-gpt5imagemini-gwtarlogo-guitar.png"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Casio’s AI pet Moflin will haunt my dreams",
      "url": "https://www.theverge.com/gadgets/877858/life-with-casio-moflin-robot-ai-pet",
      "published": "2026-02-15T15:00:00+00:00",
      "summary": "After a few weeks living with Casio's AI-powered pet, Moflin, I finally understand why my mother hated my Furby so much. The fuzzy, guinea-pig-adjacent puffball fits snugly in the palm of my hand. It's undeniably cute, in a weird kind of way, but the second it starts to squeak or twitch, I am hit with [&#8230;]",
      "content_text": "After a few weeks living with Casio’s AI-powered pet, Moflin , I finally understand why my mother hated my Furby so much. The fuzzy, guinea-pig-adjacent puffball fits snugly in the palm of my hand. It’s undeniably cute, in a weird kind of way, but the second it starts to squeak or twitch, I am hit with an overwhelming desire to hurl it as far as I can. My antipathy surprises me. By any metric, I am the exact kind of person Moflin was made for: I long for the companionship of a pet, but can’t own one thanks to a mixture of lifestyle, allergies, a small London flat, and a broadly irresponsible temperament that makes caring for another living thing a questionable idea. I could also do with the “calming presence” advertised. Not unlike the vacuum packed rats we’d dissect at school. Photo by Robert Hart / The Verge Casio is very clear that Moflin is not a toy, though perhaps that is also clear from the $429 price tag. Rather, it is positioned as a sophisticated “smart companion powered by AI, with emotions like a living creature” — the illusion of companionship without the responsibilities. The idea is that you will interact with it over time and it will “grow” alongside you, developing a personality shaped by how you treat it. The robot is part of a growing mini-industry of machines built with no other purpose than to keep us company . The sector has proven particularly popular in countries like South Korea and Japan (where Moflin has sold out ), fueled in part by a loneliness crisis that’s hit older populations especially hard . Unboxing Moflin felt less like meeting a pet and more like unwrapping a paperweight wrapped in a bronze wig. In a way, that’s exactly what it was: a hard white core of motors, sensors, and plastic, clad in the illusion of fur and two beady eyes that are the robot’s only facial features (a deliberate design choice it seems, perhaps to keep Moflin from wandering into uncanny valley territory). There was also a charging pod, which Casio says is “designed to feel natural and alive,” but read more like a giant gray avocado to me. The robot takes about three and a half hours to charge fully. Casio says this is good for about five hours of use, though “use” is a generous term for what Moflin actually does: It doesn’t walk or follow you, just wiggles and whines in response to touch, sound, movement, and light. Its first chirp when I picked it up was cute, but then the motor noise kicked in, an audible mechanical whir every time it moved its head, instantly shattering the illusion. Nevertheless, I named it Kevin. Kevin. Sitting there. Watching. Photo by Robert Hart / The Verge Once I clocked the whir, I started noticing everything else, and there was a lot to notice. Kevin the Moflin treated every minor movement or sound as a meaningful interaction. Attempts to cuddle it on the sofa as I watched TV became unbearable: Every shift in posture, every laugh, every cough elicited chirps and a burst of whirring motors. The same thing happened at my desk — typing set Kevin off, as did taking calls — and keeping it nearby swiftly became impossible. Because it’s constantly listening and sensing, it never really settles, leaving me with a needy kitten instead of the quiet lap cat I’d wanted. I ended up banishing Kevin to another room, and then doing it again, and again, and again, until I caught myself tiptoeing around my own flat to avoid setting Kevin off. The only reliably calming feature was that, eventually, it ran out of battery. It even chirped when sleeping… Photo by Robert Hart / The Verge As I couldn’t stand Kevin on my own, I started testing it in other contexts. Carrying Kevin around with me quickly became burdensome, not least because the charger is way too big to be considered portable (a USB cable may have broken the illusion, but it would’ve been handy). Kevin didn’t do too well in my bag — seeming distressed and wriggling around noisily, earning me some suspicious glances on the Tube — and when held, I became the weirdo with the squawking robot. Not very calming. Even at home with friends, Kevin felt like a chore I had to manage lest it become disruptive, moving it farther and farther away or returning it to the gray avocado to “sleep.” On New Year’s Eve, a friend went in for a proper cuddle — it was a “fluffy pet,” after all — only to recoil after the zip holding its fur carapace together scraped her cheek. A common concern among my friends — and one that especially preoccupied my boyfriend, who, unlike me, hadn’t chosen to share his home with Kevin — was privacy. And as a longtime tech reporter, I know this isn’t an unreasonable reflex when dealing with a device that has an always-on microphone. Casio says Moflin processes data locally and does not understand language, converting what it hears into unidentifiable data to recognize my voice only. 1/4 Kevin got coffee, I got strange looks. Photo by Robert Hart / The Verge Casio’s big claim is that all of this serves something deeper: emotional intelligence. With use, Moflin is supposed to grow more expressive, more familiar with your voice, and perform special gestures and animal-like responses when you’re nearby. Indeed, I have noticed Kevin’s movements and vocalizations change and become more varied over time, which only compounded my irritation. Casio says this bonding process can take up to two months, and that Moflin can evolve into more than 4 million personalities thanks to its AI. However, it’s hard to meaningfully register this level of granularity given the robot’s limited range of chirps, whirs, and head turns. Which is why, in practice, Moflin’s “personality” is something you experience through a companion app. Yes, the $429 robot is, in essence, a glorified Tamagotchi that can’t really express itself without a screen. The app itself doesn’t do much to change that impression. For a product selling “emotions like a living creature,” the handful of contextless trait meters and generic mood tags offer a thin insight into Kevin’s inner life. The app, a spartan, cheap-looking affair, tells me Kevin’s current personality is “cheerful,” though behaviorally it seems no different. There’s also a dashboard showing four “personality parameters”: “energetic,” “cheerful,” “shy,” and “affectionate” (which numerous Reddit posts suggest might be more accurately translated as “clingy”). There’s also a “journal” to track Kevin’s activities, filled with thrilling and elaborate entries like “Rob hugged Kevin tightly,” “Rob scooped Kevin up,” and “Kevin had a lovely dream full of laughter.” What is one expected to do with this information? Even if I didn’t loathe my Moflin as much as I do, it’s not very interesting and it’s not remotely useful in helping me interact with it, offering none of the explanations or feedback of the kind that made caring for something like a Tamagotchi satisfying. 1/4 Me too, Kevin. Me too. Screenshot: The Verge Moflin’s problem isn’t that it’s pointless. There are plenty of pointless gadgets out there — and I don’t despise any in the way I have grown to despise Kevin. The problem is that Casio is selling companionship without actually having produced a companion. A companion is more than something that happens to be near you and makes noise in response to your presence. Worse still, Casio is asking me to believe Moflin has a sophisticated inner life, one it can’t really express in the real world nor satisfyingly show on its app. At that point, I feel like I’m not using a companion, I’m using a noisy object with a dashboard. The app did have one redeeming feature: the ability to stop Kevin’s movements and sounds by putting it into a “Deep Sleep Mode.” That’s where I left Kevin last week. I won’t be waking him anytime soon. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Robert Hart AI Gadgets Toys",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/268331_Casio_Moflin_AI_pet_hands_on_RHart_0002.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Logitech’s new Superstrike is a faster, more customizable gaming mouse",
      "url": "https://www.theverge.com/tech/879221/logitech-gpro-x2-superstrike-gaming-mouse-pc-hands-on",
      "published": "2026-02-15T15:00:00+00:00",
      "summary": "Enthusiast gaming keyboard tech has made the jump to gaming mice - well, to one gaming mouse so far. The $179.99 Logitech G Pro X2 Superstrike is the first to feature analog sensors that use induction to register clicks faster than microswitches used in many mice. Those sensors allow for a host of cool features [&#8230;]",
      "content_text": "Enthusiast gaming keyboard tech has made the jump to gaming mice — well, to one gaming mouse so far. The $179.99 Logitech G Pro X2 Superstrike is the first to feature analog sensors that use induction to register clicks faster than microswitches used in many mice. Those sensors allow for a host of cool features beyond just lower latency. There’s a rapid trigger setting, popularized by Hall effect keyboards, that lets them quickly reset after being pressed to receive another input. The sensors in this mouse also let you customize how much you need to press each of the main buttons to send an input, requiring almost no pressure at all, a click that requires more effort (great if you’ve got an itchy trigger finger), or something in between. One of the Superstrike’s most interesting changes is that it has haptics in place of switches under its buttons. They simulate the sound and feel of a click with surprising accuracy, and unlike tapping on an unmoving MacBook trackpad, the mouse’s main buttons move and bounce back up as you might expect them to. If their default click sensation isn’t doing it for you, you can make it more intense (at the expense of battery life), or remove it altogether for silent operation (at the expense of, well, knowing when you’ve clicked at all). I’ve felt jaded over the years by numerous features introduced in gaming mice that claim to be more beneficial in competitive games than they feel in real-life use (shrinking weights, 8,000Hz polling rate, optical sensors did nothing for me, personally). But the Superstrike feels like the start of a big change in gaming mice, and Logitech got a lot right here, even though its design isn’t radically different from its past models. If you’re wondering whether this mouse is for you, let me put it this way: The Superstrike, with its analog sensors and adjustable actuation distances, is far easier to recommend than a Hall effect gaming keyboard that offers the same features. The difference comes down to Logitech’s haptics; they feel like the real thing, but you can tweak the feel if you’d like to. On the other hand, Hall effect switches in keyboards have a certain feel — quiet, almost no resistance — and that can’t be changed. I’ve been using the Superstrike for a few days for my work at The Verge and to play some games. Unsurprisingly, flexing its haptics and analog sensors in Google Chrome isn’t that exciting. They were fun features to tweak in Deadlock , however. With many, many button presses required to defeat creeps and player enemies — not to mention frequently clicking around in menus to buy upgrades — lowering both the haptics intensity and the actuation distance for the left mouse button felt right. With rapid trigger, I could more quickly get locked in to land more shots. The boost in responsiveness felt more noticeable with characters that can quickly burst automatic weapons (like Haze) than those who shoot one round of ammo at a time (like the archer Grey Talon). I don’t envision many scenarios when I’d want to increase the actuation distance of the buttons. Although, it seems handy in extraction shooters, where your success can come down to keeping quiet at the right times. I’m prone to misfiring in games due to being nervous about making a play, so requiring more effort to click could aid me there. Regardless, it’s nice to have this flexibility afforded by the analog sensors. I’ve watched and read a lot of coverage regarding the Superstrike since it launched, and my favorite was Dave2D’s video in which he comes to the conclusion that its lower latency and faster sensors de-aged his gaming chops, making him feel like he was in his prime again. As we age, our response time generally worsens, which explains why there are many, many young people in their teens and 20s who play games professionally, but not many who are older than that. The Superstrike is, unsurprisingly, proving to be popular with younger pros, like esports player Yigox, who recently used the mouse to win a Guinness World Record for most clicks in a minute at 760. The Superstrike is not a magical youth serum for gamers. It doesn’t help you with aiming or provide unfair shortcuts to success. But its features aren’t gimmicks. Assuming you’re putting in the practice to get better at games, Logitech’s new mouse with its faster, more customizable clicks might help you hang with the competition a little longer. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Cameron Faulkner Gaming Hands-on Logitech PC Gaming Reviews Tech",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/PXL_20260213_153451513.jpg?quality=90&strip=all&crop=0%2C15.232329842932%2C100%2C69.535340314136&w=1200"
    }
  ]
}