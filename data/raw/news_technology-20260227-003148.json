{
  "industry": "technology",
  "collected_at": "2026-02-26T16:33:11.301174+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "VentureBeat",
      "title": "8 billion tokens a day forced AT&T to rethink AI orchestration — and cut costs by 90%",
      "url": "https://venturebeat.com/orchestration/8-billion-tokens-a-day-forced-at-and-t-to-rethink-ai-orchestration-and-cut",
      "published": "2026-02-26T21:30:00+00:00",
      "summary": "<p>When your average daily token usage is 8 billion a day, you have a massive scale problem. This was the case at AT&amp;T, and chief data officer Andy Markus and his team recognized that it simply wasn’t feasible (or economical) to push everything through large reasoning models. So, when building out an internal Ask AT&amp;T personal assistant, they reconstructed the orchestration layer. The result: A multi-agent stack built on LangChain where large language model “super agents” direct smaller, underlying “worker” agents performing more concise, purpose-driven work. This flexible orchestration layer has dramatically improved latency, speed and response times, Markus told VentureBeat. Most notably, his team has seen up to 90% cost savings. “I believe the future of agentic AI is many, many, many small language models (SLMs),” he said. “We find small language models to be just about as accurate, if not as accurate, as a large language model on a given domain area.”</p><p>Most recently, Markus and his team used this re-architected stack along with Microsoft Azure to build and deploy Ask AT&amp;T Workflows, a graphical drag-and-drop agent builder for employees to automate tasks. </p><p>The agents pull from a suite of proprietary AT&amp;T tools that handle document processing, natural language-to-SQL conversion, and image analysis. “As the workflow is executed, it&#x27;s AT&amp;T’s data that&#x27;s really driving the decisions,” Markus said. Rather than asking general questions, “we&#x27;re asking questions of our data, and we bring our data to bear to make sure it focuses on our information as it makes decisions.” Still, a human always oversees the “chain reaction” of agents. All agent actions are logged, data is isolated throughout the process, and role-based access is enforced when agents pass workloads off to one another. “Things do happen autonomously, but the human on the loop still provides a check and balance of the entire process,” Markus said.</p><h2>Not overbuilding, using ‘interchangeable and selectable’ models</h2><p>AT&amp;T doesn’t take a &quot;build everything from scratch&quot; mindset, Markus noted; it’s more relying on models that are “interchangeable and selectable” and “never rebuilding a commodity.” As functionality matures across the industry, they’ll deprecate homegrown tools in lieu of off the shelf options, he explained. “Because in this space, things change every week, if we&#x27;re lucky, sometimes multiple times a week,” he said. “We need to be able to pilot, plug in and plug out different components.” They do “really rigorous” evaluations of available options as well as their own; for instance, their Ask Data with Relational Knowledge Graph has topped the Spider 2.0 text to SQL accuracy leaderboard, and other tools have scored highly on the BERT SQL benchmark. In the case of homegrown agentic tools, his team uses LangChain as a core framework, fine-tunes models with standard retrieval-augmented generation (RAG) and other in-house algorithms, and partners closely with Microsoft, using the tech giant’s search functionality for their vector store. Ultimately, though, it’s important not to just fuse agentic AI or other advanced tools into everything for the sake of it, Markus advised. “Sometimes we over complicate things,” he said. “Sometimes I&#x27;ve seen a solution over engineered.” Instead, builders should ask themselves whether a given tool actually needs to be agentic. This could include questions like: What accuracy level could be achieved if it was a simpler, single-turn generative solution? How could they break it down into smaller pieces where each piece could be delivered “way more accurately”?, as Markus put it. Accuracy, cost and tool responsiveness should be core principles. “Even as the solutions have gotten more complicated, those three pretty basic principles still give us a lot of direction,” he said. </p><h2>How 100,000 employees are actually using it</h2><p>Ask AT&amp;T Workflows has be",
      "content_text": "<p>When your average daily token usage is 8 billion a day, you have a massive scale problem. This was the case at AT&amp;T, and chief data officer Andy Markus and his team recognized that it simply wasn’t feasible (or economical) to push everything through large reasoning models. So, when building out an internal Ask AT&amp;T personal assistant, they reconstructed the orchestration layer. The result: A multi-agent stack built on LangChain where large language model “super agents” direct smaller, underlying “worker” agents performing more concise, purpose-driven work. This flexible orchestration layer has dramatically improved latency, speed and response times, Markus told VentureBeat. Most notably, his team has seen up to 90% cost savings. “I believe the future of agentic AI is many, many, many small language models (SLMs),” he said. “We find small language models to be just about as accurate, if not as accurate, as a large language model on a given domain area.”</p><p>Most recently, Markus and his team used this re-architected stack along with Microsoft Azure to build and deploy Ask AT&amp;T Workflows, a graphical drag-and-drop agent builder for employees to automate tasks. </p><p>The agents pull from a suite of proprietary AT&amp;T tools that handle document processing, natural language-to-SQL conversion, and image analysis. “As the workflow is executed, it&#x27;s AT&amp;T’s data that&#x27;s really driving the decisions,” Markus said. Rather than asking general questions, “we&#x27;re asking questions of our data, and we bring our data to bear to make sure it focuses on our information as it makes decisions.” Still, a human always oversees the “chain reaction” of agents. All agent actions are logged, data is isolated throughout the process, and role-based access is enforced when agents pass workloads off to one another. “Things do happen autonomously, but the human on the loop still provides a check and balance of the entire process,” Markus said.</p><h2>Not overbuilding, using ‘interchangeable and selectable’ models</h2><p>AT&amp;T doesn’t take a &quot;build everything from scratch&quot; mindset, Markus noted; it’s more relying on models that are “interchangeable and selectable” and “never rebuilding a commodity.” As functionality matures across the industry, they’ll deprecate homegrown tools in lieu of off the shelf options, he explained. “Because in this space, things change every week, if we&#x27;re lucky, sometimes multiple times a week,” he said. “We need to be able to pilot, plug in and plug out different components.” They do “really rigorous” evaluations of available options as well as their own; for instance, their Ask Data with Relational Knowledge Graph has topped the Spider 2.0 text to SQL accuracy leaderboard, and other tools have scored highly on the BERT SQL benchmark. In the case of homegrown agentic tools, his team uses LangChain as a core framework, fine-tunes models with standard retrieval-augmented generation (RAG) and other in-house algorithms, and partners closely with Microsoft, using the tech giant’s search functionality for their vector store. Ultimately, though, it’s important not to just fuse agentic AI or other advanced tools into everything for the sake of it, Markus advised. “Sometimes we over complicate things,” he said. “Sometimes I&#x27;ve seen a solution over engineered.” Instead, builders should ask themselves whether a given tool actually needs to be agentic. This could include questions like: What accuracy level could be achieved if it was a simpler, single-turn generative solution? How could they break it down into smaller pieces where each piece could be delivered “way more accurately”?, as Markus put it. Accuracy, cost and tool responsiveness should be core principles. “Even as the solutions have gotten more complicated, those three pretty basic principles still give us a lot of direction,” he said. </p><h2>How 100,000 employees are actually using it</h2><p>Ask AT&amp;T Workflows has been rolled out to 100,000-plus employees. More than half say they use it every day, and active adopters report productivity gains as high as 90%, Markus said. “We&#x27;re looking at, are they using the system repeatedly? Because stickiness is a good indicator of success,” he said. The agent builder offers “two journeys” for employees. One is pro-code, where users can program Python behind the scenes, dictating rules for how agents should work. The other is no-code, featuring a drag-and-drop visual interface for a “pretty light user experience,” Markus said. Interestingly, even proficient users are gravitating toward the latter option. At a recent hackathon geared to a technical audience, participants were given a choice of both, and more than half chose low code. “This was a surprise to us, because these people were all very competent in the programming aspect,” Markus said. Employees are using agents across a variety of functions; for instance, a network engineer may build a series of them to address alerts and reconnect customers when they lose connectivity. In this scenario, one agent can correlate telemetry to identify the network issue and its location, pull change logs and check for known issues. Then, it can open a trouble ticket. Another agent could then come up with ways to solve the issue and even write new code to patch it. Once the problem is resolved, a third agent can then write up a summary with preventative measures for the future. “The [human] engineer would watch over all of it, making sure the agents are performing as expected and taking the right actions,” Markus said. </p><h2>AI-fueled coding is the future</h2><p>That same engineering discipline — breaking work into smaller, purpose-built pieces — is now reshaping how AT&amp;T writes code itself, through what Markus calls &quot;AI-fueled coding.&quot; He compared the process to RAG; devs use agile coding methods in an integrated development environment (IDE) along with “function-specific” build archetypes that dictates how code should interact. The output is not loose code; the code is “very close to production grade,” and could reach that quality in one turn. “We&#x27;ve all worked with vibe coding, where we have an agentic kind of code editor,” Markus noted. But AI-fueled coding “eliminates a lot of the back and forth iterations that you might see in vibe coding.” He sees this coding technique as “tangibly redefining” the software development cycle, ultimately shortening development timelines and increasing output of production-grade code. Non-technical teams can also get in on the action, using plain language prompts to build software prototypes. His team, for instance, has used the technique to build an internal curated data product in 20 minutes; without AI, building it would have taken six weeks. “We develop software with it, modify software with it, do data science with it, do data analytics with it, do data engineering with it,” Markus said. “So it&#x27;s a game changer.”</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Self-driving truck startup Einride raises $113M PIPE ahead of public debut",
      "url": "https://techcrunch.com/2026/02/26/self-driving-truck-startup-einride-raises-113m-pipe-ahead-of-public-debut/",
      "published": "2026-02-26T16:32:31+00:00",
      "summary": "Self-driving trucks startup Einride has raised an oversubscribed $113 million PIPE in advance of its SPAC merger scheduled for early 2026.",
      "content_text": "Einride has secured an oversubscribed $113 million PIPE (private investment in public equity) ahead of its public debut that’s expected for the first half of 2026. The Swedish startup is most well-known for building both electric trucks and autonomous pods that are designed to carry freight with no room for a human driver. Einride announced its plans to go public via a merger with a special purpose acquisition company, Legato Merger Corp., last November. The deal values Einride at a pre-money valuation of $1.35 billion — down from the $1.8 billion figure initially attached to the SPAC deal. Despite a drop in valuation, there’s still clearly investor appetite for the firm. The PIPE exceeded the company’s earlier target of up to $100 million. Einride’s PIPE comes from new and existing investors, including a global asset management company based on the West Coast of the United States, and Stockholm-based EQT Ventures. In total, Einride has secured around $213 million tied to this transaction, including $100 million previously announced crossover financing. The SPAC, which will see Einride trading on the New York Stock Exchange, had been expected to deliver roughly $220 million from Legato’s trust account. With the addition of the $113 million PIPE, the companies now project total gross proceeds of about $333 million before redemptions and expenses. Though they say they may seek additional capital before closing. The proceeds will support Einride’s technology roadmap, global expansion, and autonomous deployments in North America, Europe, and the Middle East. Outside of Sweden, Einride operates a fleet of 200 heavy-duty electric trucks in Europe, North America, and the UAE for companies like Heineken, PepsiCo, Carlsberg Sweden, and DP World. The company has also done limited deployments of its autonomous pod-like trucks with customers including Apotea in Sweden and GE Appliances in the U.S. Einride is not the first autonomous vehicle company to have pursued a SPAC merger in recent years for additional funding. Aurora Innovation went public via a SPAC merger valued at $13 billion in 2021 and has since launched a commercial self-driving trucks operation (with a human observer on board). Kodiak AI also took the SPAC road to the public market in 2025.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-1239352244.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Your smart TV may be crawling the web for AI",
      "url": "https://www.theverge.com/column/885244/smart-tv-web-crawler-ai",
      "published": "2026-02-26T16:30:00+00:00",
      "summary": "This is Lowpass by Janko Roettgers, a newsletter on the ever-evolving intersection of tech and entertainment, syndicated just for The Verge subscribers once a week. These days, if you sign up for a new streaming service, you generally have two options: Either pay a massive premium for an ad-free experience, or endure frequent commercial breaks [&#8230;]",
      "content_text": "This is Lowpass by Janko Roettgers , a newsletter on the ever-evolving intersection of tech and entertainment, syndicated just for The Verge subscribers once a week. These days, if you sign up for a new streaming service, you generally have two options: Either pay a massive premium for an ad-free experience, or endure frequent commercial breaks and all the sneaky tracking that comes with ad targeting. Web data aggregator Bright Data has been pitching streaming service operators on an alternative approach for apps running on Samsung’s Tizen and LG’s webOS platform — one that comes without ads and sky-high fees. All publishers have to do to unlock a new revenue source is integrate the company’s Bright SDK into their TV apps and convince viewers to opt into Bright’s monetization network. “We don’t do any kind of tracking,” explained Bright Data’s chief product officer, Ariel Shulman, during a webinar for streaming industry insiders two years ago. “We work silently in the background, and completely anonymously. Users don’t actually see or don’t feel anything.” The catch? With Bright’s SDK, a viewer’s smart TV becomes part of a massive global proxy network that crawls and scrapes the web. Including apps running on desktop PCs and mobile devices, the company claims to operate 150 million such residential proxies worldwide. Together, these devices gather petabytes of public web data from a wide range of different locations and IP addresses. This approach allows the company to capture localized versions of websites, but also helps to circumvent web crawler blacklists. The gathered data is then resold to companies to train AI models , among other things. Here’s how Bright’s smart TV partnerships work: When a consumer downloads and installs a participating app, they’ll see an opt-in screen asking them to confirm their willingness to participate in Bright’s proxy network. For instance, for an app called Petflix that was until recently available on the Roku app store, the note reads: “To enjoy Petflix for free with fewer ads, you are allowing Bright Data to occasionally use your device’s free resources and IP address to download public web data from the internet. Bright Data will only use your IP address for approved business-related use cases. None of your personal information is accessed or collected except your IP address. Period.” “Our network is based on consensual individual participation,” explains Bright Data spokesperson Jennifer Burns. “All users can opt-out at any time via a fast two-click process.” Once a consumer opts in to Bright Data’s network, their smart TV starts downloading publicly available webpages as well as audio and video data, which is then forwarded to Bright’s cloud servers. The company claims to only do so when it doesn’t impact the device’s bandwidth or processing capacities, with Shulman saying that individual devices download only around 50MB of data per day. In reality, there is no way for a user to know whether the SDK downloads web data at any given moment. In some cases, your smart TV may even crawl the web for Bright as soon as you turn it on. “On some operating systems, [...] our SDK is given permissions by the user to run in the background,” Shulman explained during his webinar. “This means that our monetization continues even if the app itself is not running.” All it takes for consumers is to run the app once and opt in to Bright’s network, and the device will keep crawling the web every day until they opt out again or uninstall the app. Bright Data is not the only company operating such residential proxy networks. Some of its competitors have come under fire for unsavory business practices. Last month, Google took action against the IPIDEA network, which Google’s Threat Intelligence Group called “the world’s largest proxy network.” IPIDEA worked with a number of SDK providers to distribute its code in third-party apps, including on smart TVs. Once devices were enrolled in its network, IPIDEA’s operators allegedly rented out those resources to hacking groups in China, North Korea, Iran, and Russia. “We [...] observe IPIDEA being leveraged by a vast array of espionage, crime, and information operations threat actors,” Google’s Threat Intelligence Group wrote in a January blog post . To be clear: Google’s security researchers did not draw any connection whatsoever between IPIDEA and Bright Data, and Bright goes to great lengths to set itself apart from bad actors. “Our SDK, along with all of our technology, is reviewed by Apesteem, Google, McAfee, and more, and audited regularly, most recently by PwC,” says Burns. “Bright SDK implements rigorous partner selection criteria and vets every application through strict compliance processes.” The company has nonetheless been impacted by a broader backlash against residential proxy activities. Google has adopted policies against proxy SDKs running in the background, and is now telling developers that they’re only allowed to use proxy services “in apps where that is the primary, user-facing core purpose of the app.” Amazon added a provision to its developer policies that outright bans “apps that facilitate proxy services to third parties.” Roku also bars developers from using Bright SDK and similar proxy services. All those changes have made it more difficult to figure out how widespread the use of the SDK on smart TVs actually is. A few dozen Fire TV apps still mention the SDK on Amazon’s app store, but don’t appear to make use of it anymore. I was able to download a few apps from Roku’s store that were still using the SDK, including the aforementioned Petflix app. However, those apps disappeared from the store after I contacted Roku for this story. New restrictions against proxy SDKs have had a direct impact on Bright’s addressable market in the smart TV space. The company used to pitch its solution to Roku, Android TV, and Fire TV app developers, but Burns tells me that it no longer supports these platforms. Bright does still list Samsung’s Tizen OS and LG’s webOS as supported smart TV platforms, and has published more than 200 first-party apps to LG’s app store alone. LG spokesperson Léa Lee tells me that Bright SDK is “not officially supported by LG, and their operation on the webOS platform is not guaranteed.” Samsung did not respond to multiple requests for comment. There are arguably many legitimate use cases for web crawling. “Our network serves exclusively legitimate purposes, supporting journalists, non-profits, academic researchers, cybersecurity companies, and other leading businesses worldwide,” says Burns. The problem is that consumers have no idea whether that legitimate purpose is something that aligns with their own personal values. Case in point: Bright Data does support a number of nonprofits, including some that use its proxy network to track hate speech on social media. However, the company also works with AMCHA Initiative. The group maintains an “anti-zionist faculty barometer” and includes student and faculty statements against Israel’s war in Gaza, as well as calls for schools to divest from the country, in its antisemitic incident tracker. With AI companies facing scrutiny over their environmental impact, treatment of intellectual property, and potential to replace human labor, some consumers may also feel uneasy about their TVs gathering data to train AI models. Now, some consumers may decide that such concerns are overblown, and willingly opt in to Bright’s network if it means that they get to watch fewer ads or pay less for their streaming services. I, for one, would rather watch an extra ad break or two. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Janko Roettgers Column Gadgets Lowpass Streaming Tech TVs",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/268376_Your_smart_TV_may_be_crawling_the_web_for_AI_CVirginia.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Cisco says hackers have been exploiting a critical bug to break into big customer networks since 2023",
      "url": "https://techcrunch.com/2026/02/26/cisco-says-hackers-have-been-exploiting-a-critical-bug-to-break-into-big-customer-networks-since-2023/",
      "published": "2026-02-26T16:03:36+00:00",
      "summary": "The U.S. government and its allies said hackers have been exploiting the newly identified bug in Cisco networking gear around the world for years, and urged organizations to patch.",
      "content_text": "Cisco says hackers have been exploiting a bug in one of its popular networking products used by large enterprises for at least three years, prompting the U.S. government and its allies to urge organizations to take action. The bug, which has a maximum-rated vulnerability severity score of 10.0 , allows hackers to remotely break into networks running its Catalyst SD-WAN products, which allow large companies and government agencies with multiple offices to connect their private networks over long distances. By exploiting this bug over the internet, hackers can gain the highest level of permissions to these devices and maintain persistent hidden access inside a victim’s network, allowing them to spy or steal data over a long period of time. Cisco said after discovering the bug, its researchers traced evidence of exploitation as far back as 2023. Some of the affected organizations are said to be critical infrastructure. The company did not provide specifics, but “critical infrastructure” can refer to everything from power grids and water supply to the transportation sector. Several governments, including Australia, Canada, New Zealand, the United Kingdom, and the United States, warned in an alert that threat actors are targeting organizations “globally.” U.S. cybersecurity agency CISA ordered all civilian federal agencies to patch their systems by end-of-day Friday, citing an imminent threat and unacceptable risk to the federal government. The federal cybersecurity agency, which is currently running at reduced capacity due to a partial government shutdown, said it was aware of ongoing exploitation. Neither Cisco nor the governments attributed the attacks to a specific threat group or nation state, if known, but tracked one cluster of activity as UAT-8616. In December, Cisco warned of a similarly rated 10.0 vulnerability in the Async software that runs most of its products, which was being actively used to hack into its customer networks.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2016/08/cisco.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Google’s latest AI image generation model",
      "url": "https://blog.google/innovation-and-ai/technology/ai/nano-banana-2/",
      "published": "2026-02-26T16:02:37+00:00",
      "summary": "<p>Article URL: <a href=\"https://blog.google/innovation-and-ai/technology/ai/nano-banana-2/\">https://blog.google/innovation-and-ai/technology/ai/nano-banana-2/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47167858\">https://news.ycombinator.com/item?id=47167858</a></p> <p>Points: 22</p> <p># Comments: 8</p>",
      "content_text": "In August of last year, our Gemini Image model, Nano Banana , became a viral sensation , redefining image generation and editing. Then in November, we released Nano Banana Pro , offering users advanced intelligence and studio-quality creative control. Today, we’re bringing the best of both worlds to users across Google. Introducing Nano Banana 2 (Gemini 3.1 Flash Image), our latest state-of-the-art image model. Now you can get the advanced world knowledge, quality and reasoning you love in Nano Banana Pro, at lightning-fast speed.",
      "cover_image_url": "https://storage.googleapis.com/gweb-uniblog-publish-prod/images/NB2_SS.width-1300.png"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "8BitDo’s customizable Pro 3 controller is $30 off for the first time",
      "url": "https://www.theverge.com/gadgets/885192/8bitdo-pro-3-controller-switch-2-pc-galaxy-buds-4-pro-deal-sale",
      "published": "2026-02-26T16:00:28+00:00",
      "summary": "Woot is offering steep discounts on many video games and accessories, some of which are fairly recent releases. No matter what you choose from its sale catalog, you can get up to $30 off your order with the code LEVEL20 used at checkout through the end of the day on February 27th (the sale lasts [&#8230;]",
      "content_text": "Woot is offering steep discounts on many video games and accessories, some of which are fairly recent releases. No matter what you choose from its sale catalog , you can get up to $30 off your order with the code LEVEL20 used at checkout through the end of the day on February 27th (the sale lasts through March 5th, but the coupon ends beforehand). 8BitDo’s highly customizable Pro 3 controller for Switch 2, PC and mobile devices is getting its biggest discount at Woot , selling for $39.99 (originally $69.99) with the code applied, or $49.99 without the code. The Pro 3 is a great, comfortable controller, and its swappable, magnetic face buttons are one of its top features. You can adjust the button layout from Switch to Xbox, or swap them for them for unlabeled button faces that are included with each controller. In terms of hardware features, the Pro 3 is similar to the Ultimate 2, packing TMR joysticks, triggers with adjustable stops, and extra macro buttons. One of the key differences, however, is that it has a PlayStation-style stick layout. It can wake the Switch 2, but its rumble performance is behind some of our favorite Switch 2 controllers. Read our review. Other Verge-approved deals",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/8bitdopro3dealroundup.png?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "HBO Max’s password-sharing crackdown is going global",
      "url": "https://www.theverge.com/streaming/885303/hbo-max-password-sharing-global-expansion-q4-2025",
      "published": "2026-02-26T16:00:09+00:00",
      "summary": "HBO Max's password-sharing crackdown is going to get a lot bigger. During an earnings call on Thursday, Warner Bros. Discovery streaming head JB Perrette said a global expansion \"will start in 2026,\" as reported earlier by The Wrap. Warner Bros. Discovery has ramped up its paid sharing initiative in the US over the past year, [&#8230;]",
      "content_text": "HBO Max’s password-sharing crackdown is going to get a lot bigger. During an earnings call on Thursday , Warner Bros. Discovery streaming head JB Perrette said a global expansion “will start in 2026,” as reported earlier by The Wrap . Warner Bros. Discovery has ramped up its paid sharing initiative in the US over the past year, introducing “more aggressive” prompts in August that push people toward paying an extra $7.99 per month to add another user to their account. Now that HBO Max has launched in several European countries and Latin America , with rollouts planned in the UK, Ireland , and the Asia-Pacific, the streamer likely sees more opportunities to squeeze international subscribers sharing their memberships. “We are in the second inning of our password sharing enforcement,” Perrette said during the call. “It is just beginning to get scale.” HBO Max added 3.5 million subscribers across the globe during the last quarter of 2025, bringing its total to 131.6 million. Warner Bros. Discovery says it expects to reach 150 million subscribers by the end of this year. In December, Warner Bros. Discovery agreed to a $83 billion deal to sell its studio and streaming service to Netflix, though it has since reopened negotiations with Paramount, which doesn’t seem to be taking “no” for an answer .",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/05/STK055_HBOMAX_2_A.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "A VC and some big-name programmers are trying to solve open source's funding problem, permanently",
      "url": "https://techcrunch.com/2026/02/26/a-vc-and-some-big-name-programmers-are-trying-to-solve-open-sources-funding-problem-permanently/",
      "published": "2026-02-26T16:00:00+00:00",
      "summary": "A group of well-known open source programmers and a VC have launched the Open Source Endowment. They hope this new method will provide funding for good.",
      "content_text": "A group of notable open-source programmers are joining with a VC investor to launch a nonprofit called the Open Source Endowment in hopes of permanently solving the perennial issue with developing open-source software: funding. Backers of the Open Source Endowment include Thomas Dohmke (the former GitHub CEO who raised a record $60 million for his dev tool startup Entire ); Mitchell Hashimoto (founder of HashiCorp, which sold to IBM for $6.4 billion last year ); Supabase founder and CEO Paul Copplestone ; an NGINX co-founder; the creators of Vue.js and cURL; plus execs from Elastic, Spotify, and others. All told, the project has over 50 donors so far. The nonprofit, which just achieved formal 501(c)(3) status, has currently raised more than $750,000 in commitments. But if things go according to the plan of its founder, Konstantin Vinogradov , it will have $100 million in assets within seven years. Vinogradov is a venture investor specializing in open-source, AI and infrastructure software, and was previously a general partner at Runa Capital. As such, he has “some experience with university endowments,” which are some of the largest investors in venture capital funds, he told TechCrunch. Vinogradov says as he scoured the world for open-source projects, one complaint kept popping up: “There is no source of sustainable funding for open-source maintainers. And that’s a really big problem.” (“Maintainer” refers to the developers who work on open-source projects, such as debugging, choosing and verifying features submitted by the community, or programming new features themselves.) The endowment will support projects based on criteria such as its number of users, or how many other projects rely on that specific software to operate. It will also choose projects that are not already well-supported by grants, donations or umbrella organizations such as Linux’s Alpha-Omega. Vinogradov has already assembled a board for the nonprofit. Cash strapped, burned out The lack of money in open source is hardly new. Open-source software is typically given away, and since the community often contributes time and efforts freely, up to 86% of open-source developers are not paid for their work. Techcrunch event Boston, MA | June 9, 2026 This isn’t much of a problem for hobbyists or for professional developers paid by their companies to maintain projects, but such a system stands on shaky ground. Open-source software is the bedrock upon which the internet stands, and virtually every large company uses open-source tools in some way. In fact, open-source software accounts for up to 55% of the tech stack in organizations , and is present in everything from databases to operating systems. While it is certainly possible for open-source developers to commercialize their free projects to gain wealth beyond their wildest dreams , the odds, to misquote the Hunger Games, are not in their favor. There is, and has been for decades, a core of developers who volunteer their time and efforts for free to manage popular, important and critical projects. And many of them are burned out. This issue came into the public’s consciousness briefly in 2014, with the OpenSSL Heartbleed disaster, where a bug was found in an open-source security project, used by most of the internet, that was maintained by a single developer. There have been many attempts to fix the funding situation over the years. Some projects take donations from corporate sponsors. For instance, The Linux Foundation, which brought in about $300 million last year largely from corporate sponsors, doles out grants to select projects through its Alpha-Omega Project. In 2025, Alpha-Omega issued $5.8 million to 14 projects, it said. Some projects take donations directly from corporate donors. In January, for instance, Anthropic donated $1.5 million to the Python Software Foundation . While the Foundation said it was thrilled to have that cash, Anthropic itself raised $30 billion this month . Such a donation is couch-change to the AI lab. Still, not every developer wants to take corporate donations, as there are worries of granting too much influence to donor companies. For instance, there was a big hubbub last year in the Ruby community surrounding some long-time maintainers leaving and its big sponsor Spotify, The Register reported. The Open Source Endowment hopes to support projects while displacing such risks. “The only way to support open source sustainably is private funds,” says Vinogradov. Why hasn’t an endowment been tried before? Endowments require patience, Vinogradov says. They invest many of their assets, spending only a fraction of their income in any given year, and require years or even decades to grow to a meaningful size. But if done right, that patience will result in an independent fund that could support critical open-source projects forever.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2023/08/GettyImages-1487613502.jpg?resize=1200,675"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Google launches Nano Banana 2 model with faster image generation",
      "url": "https://techcrunch.com/2026/02/26/google-launches-nano-banana-2-model-with-faster-image-generation/",
      "published": "2026-02-26T16:00:00+00:00",
      "summary": "Google is making Nano Banana 2 a default model in Gemini app and in AI mode",
      "content_text": "Google today announced the latest version of its popular image generation model , Nano Banana 2. The new model, which is technically Gemini 3.1 Flash Image, can create more realistic images than its predecessor. The model will also now become the default in the Gemini app for its Fast, Thinking, and Pro modes. The company first released Nano Banana in August 2025 , prompting people to generate millions of images in the Gemini app, especially in countries like India . In November, the company released Nano Banana Pro , which allows users to create more detailed and high-quality images. The new Nano Banana 2 retains some of the high-fidelity characteristics of the Pro model but produces images faster. The company says you can create images with a resolution ranging from 512px to 4K, in different aspect ratios. Image Credits: Google Nano Banana 2 can maintain character consistency for up to five characters and fidelity of up to 14 objects in one workflow for better storytelling. Users can also issue complex requests with detailed nuances for image generation, Google says. In addition, users can create media with more vibrant lighting, richer textures, and sharper detail. Image Credits: Google With the launch, Nano Banana 2 will become the default model for image generation across all apps in the Gemini app. The company is also making it the default model for image generation in its video editing tool, Flow . In Search, Nano Banana 2 will become the default for Google Search results via Google Lens and in AI Mode across 141 countries on the Google app and on the web across desktop and mobile. On Google’s higher-end plans , Google AI Pro and Ultra, subscribers can continue use Nano Banana Pro for specialized tasks by regenerating images via the three-dot menu. Techcrunch event Boston, MA | June 9, 2026 Image Credits: Google For developers, Nano Banana 2 will be available in preview through the Gemini API, Gemini CLI, and the Vertex API. It will also be available through AI Studio and the company’s development tool Antigravity , which was released last November. The company said that all images created through the new model will have a SynthID watermark, which is Google’s mark to denote AI-generated images. The images are also interoperable with C2PA Content Credentials , created by an industry body consisting of companies like Adobe, Microsoft, Google, OpenAI, and Meta. Google said that since launching the synthID verification in the Gemini app in November , people have used it over 20 million times.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/Landscape.jpeg?resize=1200,670"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Democrats to introduce bill aimed at resurrecting IRS Direct File",
      "url": "https://www.theverge.com/policy/885225/democrats-irs-direct-file-act-taxes",
      "published": "2026-02-26T16:00:00+00:00",
      "summary": "160 Democratic lawmakers from across the country are backing a soon-to-be-introduced bill that would reverse the Trump administration's decision to eliminate IRS Direct File. The Direct File Act, led by Sen. Elizabeth Warren (D-MA) and Rep. Brad Sherman (D-CA), would bring back the option to file taxes directly with the government for free. The Biden [&#8230;]",
      "content_text": "160 Democratic lawmakers from across the country are backing a soon-to-be-introduced bill that would reverse the Trump administration’s decision to eliminate IRS Direct File. The Direct File Act, led by Sen. Elizabeth Warren (D-MA) and Rep. Brad Sherman (D-CA), would bring back the option to file taxes directly with the government for free. The Biden administration first started testing the IRS Direct File system in select states during the 2024 tax season, and it even expanded the system to 25 states in 2025 . But uncertainty surrounding IRS Direct File swirled after President Donald Trump came into office, until IRS head Billy Long confirmed that it’s “gone” last August. The IRS later notified states that Direct File is no longer available. According to Sen. Warren, TurboTax parent company Intuit donated more than $1 million to Trump’s inauguration and has lobbied heavily against the program . (Companies like TurboTax offer similar tax filing services, but for a fee.) Under the Direct File Act, taxpayers would not only have the option to file their taxes directly to the IRS, but it would also ensure that the IRS doesn’t enter into agreements that “restrict its ability to provide free online tax preparation or filing services.” The IRS would have to enable “seamless integration” between state tax filing systems and Direct File, as well as publish annual reports on Direct File usage. Additionally, the bill would push the IRS to make Direct File available to at least 50 percent of taxpayers in participating states by the 2028 tax season. IRS Direct File isn’t to be confused with the agency’s Free File service, which allows taxpayers to file their taxes using one of its partners, such as TaxSlayer and FreeTaxUSA. TurboTax and H&R Block left the Free File Alliance after the IRS began prohibiting services from hiding free filing options. “Donald Trump canceled Direct File after giant tax prep companies spent millions lobbying to protect their profits,” Sen. Warren says in the press release. “We’re fighting to lower costs for families by bringing Direct File back and making it the law of the land.”",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/11/STK417_banking_money_2.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Google’s Nano Banana 2 brings advanced AI image tools to free users",
      "url": "https://www.theverge.com/tech/885275/google-nano-banana-2-ai-image-model-gemini-launch",
      "published": "2026-02-26T16:00:00+00:00",
      "summary": "Google is bringing a more powerful version of its Nano Banana AI image model to free users. Nano Banana 2 (also known as Gemini 3.1 Flash Image) is rolling out today across the Gemini app and other Google AI platforms, making knowledge and rendering features that were previously exclusive to Nano Banana Pro available for [&#8230;]",
      "content_text": "Google is bringing a more powerful version of its Nano Banana AI image model to free users. Nano Banana 2 (also known as Gemini 3.1 Flash Image) is rolling out today across the Gemini app and other Google AI platforms, making knowledge and rendering features that were previously exclusive to Nano Banana Pro available for everyone. Google says the update aims to bring “high-speed intelligence of Gemini Flash to visual generation,” making complex images faster, cheaper, and easier to generate. Like Nano Banana Pro , the Nano Banana 2 model utilizes real-time information, web search images, and Gemini’s real-world knowledge base. Google DeepMind product manager Naina Raisinghani says that this provides more relevant data for creating infographics or diagrams, and allows Nano Banana 2 to render “specific subjects” more accurately, though examples of such subjects were not provided. Other features inherited from Nano Banana Pro include the ability to generate images with accurate, legible text, and localized translation. These capabilities previously required a paid subscription to Google AI Plus, Pro, or Ultra to access in Gemini, but now they’ll be expanded to free Gemini users and AI Mode in Google Search. Nano Banana 2 also provides more creative control over generated images compared to the original Nano Banana model . Google says that visual improvements include more vibrant lighting, richer textures, and sharper details, alongside the ability to adhere to complex image requests more strictly. The appearance of up to five characters and 14 objects can also be maintained more consistently in a single workflow, and users get “full control” over aspect ratios and image resolution, ranging from 512px up to 4K. The new Nano Banana 2 model will replace the option for Nano Banana Pro across the Gemini app’s Fast, Thinking, and Pro generation modes. Google says AI Pro and Ultra subscribers will still be able to access Nano Banana Pro “for specialized tasks” by selecting the three-dot menu on images to regenerate them. The new model is also rolling out to AI Mode in Search, Google Lens, the Google app, and browsers for mobile and desktop, alongside being the new default image generation model in Google’s AI video tool, Flow .",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/Google-nano-banana-2-image-comparison.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "OpenAI Announces Major Expansion of London Office",
      "url": "https://www.wired.com/story/openai-expands-london-office-major-research-hub/",
      "published": "2026-02-26T15:56:01+00:00",
      "summary": "The San Francisco-based AI lab is growing its research team in London. The move puts it in direct competition with Google DeepMind for top research talent in the UK.",
      "content_text": "OpenAI has announced plans to turn its London office into its largest research hub outside of the United States. The companyâ€”which established a UK office in 2023â€”says it will expand its London-based research team, scooping up talent emerging from leading British universities. It has not indicated how many researchers it will hire. â€œThe UK brings together world class talent and leading scientific institutions and universities, making it an ideal place to deliver the important research which will ensure our AI is safe, useful and benefits everyone,â€� said Mark Chen, chief research officer at OpenAI, in a statement. The plans bring OpenAI into direct competition for top research talent with Google DeepMind, the AI lab run by British researcher Demis Hassabis , which is headquartered in London. DeepMind has long-running partnerships with Oxford University and the University of Cambridge, where it sponsors professorships , funds research , and works alongside researchers . At the latest careers fair at Oxford University, the floor was packed with undergraduates looking for technical roles and recruiters hiring for AI-related positions.â€œThe demand and supply is increasing on both sides, even within a year,â€� says Jonathan Black, director of the careers service at Oxford University. â€œTo have something like this turn up is a really positive sign.â€� OpenAIâ€™s team in London will continue to contribute to products like Codex and GPT-5.2, the company says, but will now â€œownâ€� certain aspects of model development relating to safety, reliability, and performance evaluation. In a statement, the UKâ€™s science and technology secretary, Liz Kendall, described the announcement as â€œa huge vote of confidence in the UKâ€™s world-leading position at the cutting edge of AI research.â€� The announcement coincides with a push in the UK to scale the nationâ€™s data center and power infrastructure to meet the voracious demand for compute among AI companies, including OpenAI.",
      "cover_image_url": "https://media.wired.com/photos/69a057d7b6ac674187e8a148/191:100/w_1280,c_limit/GettyImages-2153471578.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "New AirSnitch attack breaks Wi-Fi encryption in homes, offices, and enterprises",
      "url": "https://arstechnica.com/security/2026/02/new-airsnitch-attack-breaks-wi-fi-encryption-in-homes-offices-and-enterprises/",
      "published": "2026-02-26T15:55:48+00:00",
      "summary": "<p>Article URL: <a href=\"https://arstechnica.com/security/2026/02/new-airsnitch-attack-breaks-wi-fi-encryption-in-homes-offices-and-enterprises/\">https://arstechnica.com/security/2026/02/new-airsnitch-attack-breaks-wi-fi-encryption-in-homes-offices-and-enterprises/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47167763\">https://news.ycombinator.com/item?id=47167763</a></p> <p>Points: 37</p> <p># Comments: 16</p>",
      "content_text": "AirSnitch “breaks worldwide Wi-Fi encryption, and it might have the potential to enable advanced cyberattacks,” Xin’an Zhou, the lead author of the research paper, said in an interview. “Advanced attacks can build on our primitives to [perform] cookie stealing, DNS and cache poisoning. Our research physically wiretaps the wire altogether so these sophisticated attacks will work. It’s really a threat to worldwide network security.” Zhou presented his research on Wednesday at the 2026 Network and Distributed System Security Symposium . Previous Wi-Fi attacks that overnight broke existing protections such as WEP and WPA worked by exploiting vulnerabilities in the underlying encryption they used. AirSnitch, by contrast, targets a previously overlooked attack surface—the lowest levels of the networking stack, a hierarchy of architecture and protocols based on their functions and behaviors. The lowest level, Layer-1, encompasses physical devices such as cabling, connected nodes, and all the things that allow them to communicate. The highest level, Layer-7, is where applications such as browsers, email clients, and other Internet software run. Levels 2 through 6 are known as the Data, Link, Network, Transport, Session, and Presentation layers, respectively. Identity crisis Unlike previous Wi-Fi attacks, AirSnitch exploits core features in Layers 1 and 2 and the failure to bind and synchronize a client across these and higher layers, other nodes, and other network names such as SSIDs (Service Set Identifiers). This cross-layer identity desynchronization is the key driver of AirSnitch attacks. The most powerful such attack is a full, bidirectional machine-in-the-middle (MitM) attack , meaning the attacker can view and modify data before it makes its way to the intended recipient. The attacker can be on the same SSID, a separate one, or even a separate network segment tied to the same AP. It works against small Wi-Fi networks in both homes and offices and large networks in enterprises.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/06/wi-fi-1152x648-1751309982.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Why Developers Keep Choosing Claude Over Every Other AI",
      "url": "https://www.bhusalmanish.com.np/blog/posts/why-claude-wins-coding.html",
      "published": "2026-02-26T15:53:30+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.bhusalmanish.com.np/blog/posts/why-claude-wins-coding.html\">https://www.bhusalmanish.com.np/blog/posts/why-claude-wins-coding.html</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47167733\">https://news.ycombinator.com/item?id=47167733</a></p> <p>Points: 3</p> <p># Comments: 1</p>",
      "content_text": "I use AI coding tools every day. Claude Code for most of my actual work. I've tried the alternatives - Gemini, Codex, open-source models. I keep coming back. Not because of loyalty. Not because of marketing. Because the alternatives keep failing me in the same specific way. A new model drops. It tops the benchmarks. Developers try it. Developers complain. They go back to Claude. This has happened three or four times now, and the pattern is consistent enough that it deserves an explanation. Benchmarks Are Not Lying. But They're Not Telling You What You Think. When a new AI model tops the coding benchmarks, the benchmarks are usually accurate. The model genuinely produces better code on isolated problems. Higher accuracy on HumanEval . Cleaner solutions on LeetCode-style tasks. The numbers are real. Older benchmarks like HumanEval work exactly like that - you get an isolated function to write, and you're graded on whether it passes unit tests. Newer benchmarks like SWE-bench are more realistic. They give the model real GitHub issues from real repos and ask it to generate patches. That's closer to actual development. But even SWE-bench is still a controlled environment. Real coding work has more going on. You're managing a conversation with the user. You're deciding which files to read and which to skip. You're making targeted edits without breaking surrounding code. You're hitting unexpected errors and deciding whether to ask for help or try a different approach. You're staying on task across 20+ steps without drifting. That kind of sustained, interactive workflow is hard to capture in any benchmark. The Process vs. Raw Intelligence Gap The most useful frame I've found for understanding this: Anthropic appears to have trained Claude heavily on the process of coding, not just the output. The workflow. The sequence of decisions a competent developer actually makes when given a task in a real codebase. To be clear - every major coding agent can read files, edit code, and run terminal commands. Codex , Antigravity , Gemini CLI - they all have these capabilities. The difference is in how consistently the model behind them executes the workflow. Reading the right files before making changes. Making targeted edits instead of rewriting entire files unnecessarily. Knowing when to act and when to stop and ask. Staying on the original task instead of getting distracted. All these tools can do it. Claude does it more reliably. Other models produce excellent code - sometimes arguably better than Claude's on a per-snippet basis. The gap isn't in any individual output. It's in the consistency across a full task. They loop more often. They lose track of what they were doing mid-sequence. They make edits that break surrounding context. They need more steering to stay on track. Not always - but often enough that it changes how much you can trust the tool to work unsupervised. The difference isn't raw intelligence. It's process discipline. And that's harder to train for than most people realize. What \"Good at Coding\" Actually Requires Generating correct code is maybe 40% of what an AI coding assistant needs to do well. The other 60% is everything around the code: Editing files without corrupting surrounding code Reading the right files before making changes Completing a multi-step task without losing the thread halfway through Communicating clearly about what it's doing and what it found Knowing when to ask instead of assuming Staying on task instead of making unrequested changes to unrelated files Every major coding agent attempts all of these. The question is how often they succeed at each one across a full task. In my experience using Claude Code daily - building API endpoints, debugging production issues, refactoring components - it hits these consistently. Not perfectly, but consistently enough that I don't feel like I need to watch every step. With other tools, I find myself intervening more. The code they generate is often just as good. But somewhere in the middle of a multi-file task, something slips - a file gets partially overwritten, or the model goes off and starts \"improving\" something I didn't ask about. That's the gap. It's not about capability. It's about how often the tool stays on track without you having to course-correct. Why Google Has a Structural Problem Here I want to be fair. Gemini writes excellent code. The underlying model is clearly very capable. Give it a well-contained problem with a clear spec and it'll produce a good solution. Sometimes a great one. The problem seems structural. Google is fundamentally a search and general-use company. Their models are optimized across a massive range of tasks - translation, summarization, multimodal understanding, general conversation. Agentic software development is a narrow, specific workflow that requires its own focused training. Training for agentic workflows means the model needs to complete long sequences of tool calls successfully. Recover gracefully from errors mid-sequence. Maintain context across many steps without drifting. This takes focused reinforcement learning on exactly that scenario, not just scaling up the base model. Anthropic published research on agent autonomy showing that software engineering accounts for nearly 50% of all agentic activity on their API. Half their agentic usage is coding. When that's your reality, you train for it. You optimize the tool use, the file editing, the multi-step workflows - because that's what your paying users are actually doing. Google doesn't have that same pressure. Their model serves search, translation, multimodal tasks, general chat. Coding is one use case among dozens. Anthropic's model lives or dies by how well it codes. Where Things Actually Stand My honest assessment, as someone who uses these tools for real work every day: Claude is my primary tool. Claude Code handles everything from scaffolding new features to debugging tricky production issues. The workflow is reliable enough that I can trust it on tasks I don't want to babysit. Codex has gotten meaningfully better at agentic tasks. The gap has closed more than I expected over the past few months. It's not as reliable as Claude yet, but it's worth keeping an eye on. Gemini is capable on isolated tasks. I've had it produce genuinely impressive code for well-specified problems. As an agentic system that operates independently on multi-step tasks, it still struggles. The loops, the getting stuck, the needing constant redirection - those are real, consistent failure modes that I hit regularly. I've seen people try the \"plan in one model, execute in another\" approach. Use Gemini for architectural thinking, then switch to Claude for the actual work. In practice it adds friction without adding value. You might as well just stay in Claude for the whole thing. What This Means for the Next Few Months The benchmark leaders will keep changing. A new model will top the leaderboard. Developers will try it. Some will switch. Most will drift back. The gap will narrow. Google has the resources to fix the process discipline problem if they decide it's the priority. OpenAI is clearly taking agentic workflows seriously with Codex. The advantage Claude has today isn't permanent. But what Anthropic figured out - training for the workflow, not just the output - is a meaningful insight. Other labs will have to explicitly replicate that focus to close the gap. Bigger models alone won't do it. You can have the smartest model in the world, and it won't matter if it can't edit a file without breaking the one next to it. The benchmarks will tell you one thing. The developers who use these tools every day will tell you another. Usually, you should listen to the developers. Get the next one. New posts on building, breaking, and shipping products. Straight to your inbox. Manish Bhusal Software Developer from Nepal. 4x Hackathon Winner. Building digital products and learning in public.",
      "cover_image_url": "https://cdn.bhusalmanish.com.np/Featured%20Image/Why%20Claude%20Wins.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Spyware maker sentenced to prison in Greece for wiretapping politicians and journalists",
      "url": "https://techcrunch.com/2026/02/26/spyware-maker-sentenced-to-prison-in-greece-for-wiretapping-politicians-and-journalists/",
      "published": "2026-02-26T15:45:15+00:00",
      "summary": "A Greek court on Thursday sentenced the founder of Intellexa, a collective of spyware makers, to eight years in prison for illegal wiretapping and privacy violations, according to several reports.&#160; Tal Dilian and three other Intellexa executives were tried for their role in a scandal dubbed &#8220;Greek Watergate,&#8221; which dates back to 2022. The Greek [&#8230;]",
      "content_text": "A Greek court on Thursday sentenced the founder of Intellexa, a collective of spyware makers, to eight years in prison for illegal wiretapping and privacy violations, according to several reports . Tal Dilian and three other Intellexa executives were tried for their role in a scandal dubbed “Greek Watergate,” which dates back to 2022. The Greek government was accused of wiretapping the phones of politicians, journalists, businesspeople, and military officials with spyware developed by Intellexa. The other people sentenced today include Dilian’s business partner Sara Aleksandra Fayssal Hamou; his former deputy administrator and shareholder of Intellexa, Felix Bitzios; and Yiannis Lavranos, who owned a company linked to Intellexa. Dilian did not respond to TechCrunch’s request for comment. This is the first known time a spyware maker has been sentenced to jail following the misuse of their technology. In 2024, the U.S. government sanctioned Intellexa and several of its linked companies, Dilian, and Hamou, for their role in developing its spyware, known as Predator, used in the targeting of Americans, including government officials and journalists. The court ordered authorities to further investigate, and stayed the sentence pending appeal. Techcrunch event Boston, MA | June 9, 2026",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2023/06/stalkerware-spyware-lms-non-vignette.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "X tries wooing advertisers by letting them reuse creatives made for other platforms",
      "url": "https://techcrunch.com/2026/02/26/x-tries-wooing-advertisers-by-letting-them-reuse-creative-assets-from-other-platforms/",
      "published": "2026-02-26T15:41:55+00:00",
      "summary": "X has launched an expanded set of aspect ratio support for both image and video ads, so advertisers can now reuse assets they've created for other platforms.",
      "content_text": "Elon Musk’s X is making it easier for advertisers to bring their creative campaigns from other social sites to its platform. On Thursday, the company launched an expanded set of aspect ratio support for both image and video ads, which means advertisers can now reuse the material they’ve created for other platforms without having to reformat, crop, or rebuild their assets. While AI has been helping advertisers automate the process of resizing creative assets for different platforms, it’s easier if advertisers don’t have to take that extra step at all. So X is now allowing advertisers to upload the same assets they’re using elsewhere on social media to its own X Ads Manager via Media Studio or its Campaign Form. The change signals the continued importance of X’s ad business, which suffered declines after the company, then known as Twitter, was acquired by Musk. While ad sales improved under former CEO Linda Yaccarino, its 2025 revenues were still lower than they were prior to Musk’s acquisition. According to eMarketer’s forecast last May, X’s ad business was expected to start revitalizing sometime last year, which Bloomberg confirmed, but would remain half the size it was before the sale. X says the new aspect ratios now being supported include 4:5 (1440 x 1800 pixels) and 2:3 (1080 × 1620 pixels). The company already supports other formats, including 1:1 (1080 × 1080 pixels), 16:9 (1920 × 1080 pixels), 9:16 (1080 × 1920 pixels), and 1.91:1 (2064 × 1080 pixels). Techcrunch event Boston, MA | June 9, 2026 “We’re committed to empowering advertisers to hit their performance goals with greater ease and impact,” said Monique Pintarelli, head of global advertising at xAI, in a statement. (xAI acquired X last year.) “With full aspect ratio support, brands can now repurpose creatives directly on X—eliminating reformatting, duplication, or compromise—while unlocking faster testing, brand consistency, and incremental reach among our highly engaged, real-time audience for superior results,” she added.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2023/08/twitter-x-logo-musk-1.jpg?resize=1200,675"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Google might reshuffle search results to try to dodge fines in the EU",
      "url": "https://www.theverge.com/tech/885270/google-eu-dma-search-results-changes",
      "published": "2026-02-26T15:18:12+00:00",
      "summary": "Google is planning to test changes to how it displays search results for certain topics, nearly a year after it was charged with violating antitrust rules in the European Union, Reuters reports. The shift will show top-ranked rival services for hotels, flights, restaurants, and transportation higher up in results, rather than prioritizing Google's own services [&#8230;]",
      "content_text": "Google is planning to test changes to how it displays search results for certain topics, nearly a year after it was charged with violating antitrust rules in the European Union, Reuters reports. The shift will show top-ranked rival services for hotels, flights, restaurants, and transportation higher up in results, rather than prioritizing Google’s own services like Google Flights. It will be rolling out soon “across Europe,” starting with results for lodgings, with “flights and other services” following later. This update could address one of the core issues the European Commission highlighted when it ruled last year that Google was in violation of the Digital Markets Act , which aims to rein in anticompetitive practices by leading tech companies like Google, Apple, and Microsoft. Companies that fail to comply with DMA regulations can face fines of up to 10 percent of their annual revenue. Google initially pushed back against demands for it to rearrange search results, with Google’s head of competition, Oliver Bethell, claiming in a post on LinkedIn last year that early changes to search results forced European users to search longer and pay higher prices. However, Google could potentially face billions of dollars in fines if it doesn’t make adjustments to comply with the DMA.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/01/STK093_GOOGLE_B.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "@rbreich.bsky.social on Bluesky",
      "url": "https://bsky.app/profile/rbreich.bsky.social/post/3mfptlfeucn2i",
      "published": "2026-02-26T15:14:20+00:00",
      "summary": "<p>Article URL: <a href=\"https://bsky.app/profile/rbreich.bsky.social/post/3mfptlfeucn2i\">https://bsky.app/profile/rbreich.bsky.social/post/3mfptlfeucn2i</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47167171\">https://news.ycombinator.com/item?id=47167171</a></p> <p>Points: 112</p> <p># Comments: 67</p>",
      "content_text": "This is a heavily interactive web application, and JavaScript is required. Simple HTML interfaces are possible, but that is not what this is. Post Robert Reich rbreich.bsky.social did:plc:4u3hwe3p7oy3hoy3amlw7rp2 In 2025, Meta paid an effective federal tax rate of 3.5% — its lowest on record. Meanwhile, Meta is pumping $65 million into elections this year to boost AI friendly candidates. Trickle-down economics isn't just a hoax, it's corrosive to democracy. Big Money is the root of our dysfunction. 2026-02-25T23:30:12.954Z",
      "cover_image_url": "https://cdn.bsky.app/img/avatar/plain/did:plc:4u3hwe3p7oy3hoy3amlw7rp2/bafkreihnchke5wec4i5y4i7kzngmr2sghedr74ubq2ca7fwcqjl7mrw5hq@jpeg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "eBay to lay off 800 staff",
      "url": "https://techcrunch.com/2026/02/26/ebay-to-lay-off-800-staff/",
      "published": "2026-02-26T15:10:45+00:00",
      "summary": "The latest round of layoffs marks eBay’s third workforce reduction in the past three years.",
      "content_text": "eBay is cutting around 800 jobs, or 6% of its full-time employees. “We are taking steps to reinvest across our business and align our structure with our strategic priorities, which will affect certain roles across our workforce,” the company said in a statement. “We are grateful for the contributions of the employees impacted and are committed to supporting them with care and respect.” Bloomberg first reported the news. The move comes a week after eBay said it would acquire Depop , a second-hand clothing app popular with Gen Z and millennials, from Etsy for $1.2 billion in cash. eBay last week reported fourth-quarter results, with revenue rising 15% to $3 billion, exceeding analysts’ expectations. This round of layoffs marks the third time eBay has cut jobs in the past three years. In early 2024, it cut 1,000 jobs, or about 9% of its workforce. In early 2023, it laid off about 500 employees, or about 4% of its headcount.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2019/09/GettyImages-632621434.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "MIT Technology Review",
      "title": "Finding value with AI and Industry 5.0 transformation",
      "url": "https://www.technologyreview.com/2026/02/26/1133707/finding-value-with-ai-and-industry-5-0-transformation/",
      "published": "2026-02-26T15:00:59+00:00",
      "summary": "For years, Industry 4.0 transformation has centered on the convergence of intelligent technologies like AI, cloud, the internet of things, robotics, and digital twins. Industry 5.0 marks a pivotal shift from integrating emerging technologies to orchestrating them at scale. With Industry 5.0, the purpose of this interconnected web of technologies is more nuanced: to augment&#8230;",
      "content_text": "â€œTo realize the promise of Industry 5.0, companies must move beyond cost and efficiency to focus on growth, resilience, and human-centric outcomes,â€� says Sachin Lulla, EY Americas industrials and energy transformation leader. â€œThis requires not just new technologies, but new ways of workingâ€”where people and machines collaborate, and where value is measured not just in dollars saved, but in new opportunities created.â€� An MIT Technology Review Insights survey of 250 industry leaders from around the world reveals most industrial investments still target efficiency. And while the data shows human-centric and sustainable use cases deliver higher value, they are underfunded. The research shows most organizations are not realizing the full value potential of Industry 5.0 due to a combination of: â€¢ Culture, skills, and collaboration barriers. â€¢ Tactical and misaligned technology investments. â€¢ Use-case prioritization focused on efficiency over growth, sustainability, and well-being. The barrier to achieving Industry 5.0 transformation is not only about fixing the technology, according to research from EY and SaÃ¯d Business School at the University of Oxford, it is also about bolstering human-centric elements like strategy, culture, and leadership. Companies are investing heavily in digital transformation, but not always in ways that unlock the full human potential of Industry 5.0. â€œWeâ€™re not just doing digital work for workâ€™s sake, what I call â€˜chasing the digital fairies,â€™â€� says Chris Ware, general manager, iron ore digital, Rio Tinto. â€œWe have to be very clear on what pieces of work we go after and why. Every domain has a unique roadmap about how to deliver the best value.â€� Download the full report. This content was produced by Insights, the custom content arm of MIT Technology Review. It was not written by MIT Technology Reviewâ€™s editorial staff. It was researched, designed, and written by human writers, editors, analysts, and illustrators. This includes the writing of surveys and collection of data for surveys. AI tools that may have been used were limited to secondary production processes that passed thorough human review.",
      "cover_image_url": "https://wp.technologyreview.com/wp-content/uploads/2026/02/MITTR_V1_EY32026Cover1200Socials.png?resize=1200,600"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "2 days left: Lock in the best discounts for Disrupt 2026",
      "url": "https://techcrunch.com/2026/02/26/2-days-left-lock-in-the-best-discounts-for-techcrunch-disrupt-2026/",
      "published": "2026-02-26T15:00:00+00:00",
      "summary": "Register now to secure discounts of up to $680 on your TechCrunch Disrupt 2026 pass. Offer ends tomorrow, February 27, at 11:59 p.m. PT.",
      "content_text": "Super Early Bird pricing ends tomorrow, February 27, at 11:59 p.m. PT . After that, prices for TechCrunch Disrupt 2026 go up. Miss this, and you’ll be paying more for the same access to one of the most anticipated tech events of the year. Register now to secure discounts of up to $680 on your pass, or up to 30% on group passes . Disrupt: Your launchpad in the tech ecosystem If you want to raise capital, hire top talent, launch your startup, or discover your next portfolio company, don’t miss Disrupt , taking place October 13–15 at San Francisco’s Moscone West. Here’s what you’ll gain by attending: Actionable insights from builders, operators, and VCs actively shaping today’s market Direct access to the right investors for your next round, or founders aligned with your portfolio Early visibility into breakthrough innovations before they hit the broader market Connections that drive real impact, from partnerships to funding to career opportunities Image Credits: TechCrunch How Disrupt delivers value Access to 10,000+ founders, operators, and VCs with targeted programming Tactical, real-world onstage discussions with 250+ of today’s market leaders spanning multiple industry stages, roundtables, and breakout sessions 20,000+ curated 1:1 or small-group networking designed for real, actionable results 80+ Side Events across the Bay Area for networking, workshops, and social connections Image Credits: Eric Slomonson, The Photo Group Exclusive programming for founders and investors Founder Pass : Accelerate growth with the right insights, tools, and connections. Meet investors aligned with your startup. Investor Pass : Discover standout startups and expand your portfolio with curated access. Use matchmaking tools to make every conversation count. Don’t miss Disrupt at the biggest discounts This window to the lowest ticket rates of the year is closing after tomorrow ends. Register now to secure your ticket with up to a $680 discount. Or save up to 30% with community passes of 4+. Image Credits: Kimberly White / Getty Images",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/TCD26_2Days-16X9-dark.png?resize=1200,675"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Do we need AI-optimized resumes?",
      "url": "https://www.theverge.com/featured-video/884368/we-asked-experts-how-to-build-a-resume-for-the-ai-hiring-era",
      "published": "2026-02-26T15:00:00+00:00",
      "summary": "With AI-backed hiring on the rise, tips for \"hacking\" your resume are all over social media. As job search companies increasingly rely on artificial intelligence to sort through applications, job seekers wonder how to best position themselves with those filters in mind. We decided to speak directly with job search leaders about how a resume [&#8230;]",
      "content_text": "With AI-backed hiring on the rise, tips for “hacking” your resume are all over social media. As job search companies increasingly rely on artificial intelligence to sort through applications, job seekers wonder how to best position themselves with those filters in mind. We decided to speak directly with job search leaders about how a resume should look when you’re thinking about AI optimization, and what works in a job applicant’s favor. The Verge senior AI reporter Hayden Field spoke to representatives from Indeed, Glassdoor, LinkedIn, and Greenhouse, as well as Hilke Schellmann, author of The Algorithm . Their answers had a clear theme: Resume hacks won’t get you far with these AI systems. For instance, a common technique is to take keywords from job postings and include them throughout the resume, also known as “keyword stuffing.” Often, the words may even be hidden in white font. Glassdoor’s chief economist, Daniel Zhao, says this might get you past an initial screen, but once it reaches a human review it may not get far. “I’ve actually seen myself as a hiring manager, an application came in from a candidate who had put a bunch of text in all white at the bottom of the resume, but the system actually highlighted it. And so it was very clear that this was not actually relevant to their skills or experience. I would say that if you’re using that to put information that is not actually applicable to your skills and experience, that’s gonna be really hard to explain to an employer.” Virtually everyone we spoke to echoed a similar sentiment: that adding a human touch to your job application is now more important than ever. “ Think about the fact that you are creating your resume for two different audiences, right? You’re creating it for an algorithm and you’re also creating it for a human,” says Priya Rathod, workplace trends editor at Indeed. Watch our video to learn more about how the current hiring landscape looks in the age of AI and what else the experts say about standing out.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/AI_Resume_Site_Art.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Xbox is in danger. Will Microsoft fix it or kill it?",
      "url": "https://www.theverge.com/podcast/884693/xbox-phil-spencer-microsoft-gaming-future-cloud-game-pass",
      "published": "2026-02-26T15:00:00+00:00",
      "summary": "Today, we’re talking about the future of Xbox. Phil Spencer, a two&#8211;time Decoder guest who’s led Xbox for more than a decade, retired last week. But in a shocking twist, his deputy and long-assumed successor, Sarah Bond, is also out too, and the Xbox division is now in the hands of Asha Sharma, one of [&#8230;]",
      "content_text": "Today, we’re talking about the future of Xbox. Phil Spencer, a two - time Decoder guest who’s led Xbox for more than a decade, retired last week . But in a shocking twist, his deputy and long-assumed successor, Sarah Bond, is also out too, and the Xbox division is now in the hands of Asha Sharma, one of Microsoft’s AI executives with no prior game industry experience. It’s a major leadership transition that suggests Microsoft wants to make serious changes to its gaming division, which owns franchises like Halo , Call of Duty , and Minecraft . There is no better person to talk to about all of this than Tom Warren, a senior editor here at The Verge and author of the excellent Notepad newsletter. Tom is actually on parental leave right now, but Microsoft has a longstanding habit of disrupting his well-earned time off with major news. So, Tom was gracious enough to come on the show after he published a major scoop about what exactly went down at Xbox this past week. There is a lot to say about Xbox: The story of the console and Microsoft Gaming is a complicated one, with a lot of twists and turns since it made its big splash in the video game industry 25 years ago. Yet for a majority of that time, it’s been stuck in third place, behind Nintendo and PlayStation. That’s a surprising thing to say for a division of a company worth trillions of dollars that also owns some of the most celebrated gaming properties in all of entertainment. Verge subscribers, don’t forget you get exclusive access to ad-free Decoder wherever you get your podcasts. Head here . Not a subscriber? You can sign up here . So Phil Spencer, who started at Microsoft in the late 1980s and took charge of Xbox in 2014, was given the job of trying to turn the division around. Since then, Spencer has tried numerous moves: the Netflix-style Game Pass subscription service; a major push into cloud gaming; buying Activision Blizzard King , the maker of Warcraft and Candy Crush ; and many, many different iterations of Xbox hardware. As of last year, there are even plans to bring Halo to PlayStation — something game industry insiders thought was basically impossible just five years ago. But as you’ll hear Tom explain, the game industry has been changing faster than Xbox has been able to transform itself, and almost none of Spencer’s strategies have really clicked. Xbox is still far behind Nintendo and PlayStation, and on PC, it still stands in the shadow of Valve, which runs the dominant Steam store and now makes the Steam Deck handheld. Microsoft has spent tens of billions of dollars trying to acquire its way to a stronger position against the rise of Fortnite and Roblox , mobile giants like Tencent, and a zero-sum war for attention dominated by apps like YouTube, Instagram, and TikTok. And yet the company has very little to show for all of that. Today, Spencer’s grand vision of 100 million Game Pass subscribers streaming Xbox games to whatever screen they want using the cloud still feels out of reach. But, as Tom says, it’s not lost forever — Xbox is far from dead, and there is still hope yet that new leadership can take some big swings and make something happen again. Okay: Verge senior reporter Tom Warren on the future of Xbox. Here we go. This interview has been lightly edited for length and clarity. Tom Warren, you’re a senior reporter at The Verge . You’re currently out on paternity leave, but Microsoft just brought you back. Yep. This happens every time I take a vacation or leave. Microsoft decides, “We’re going to do something massive and ruin Tom’s life.” Just punishment for all of the scoops you’ve dropped on this company over the years. So this week, as you were playing with your beautiful new baby, Microsoft initiated a major shakeup at Xbox, something we’ve seen coming for a little bit, but maybe not on this scale or this magnitude. Describe what happened at Xbox this week. Phil Spencer, the longtime CEO of Microsoft Gaming, technically, but Xbox chief is what he’s known as, is retiring, so he is leaving Microsoft. Sarah Bond, the Xbox president, is also leaving Microsoft, and then they’re actually promoting Asha Sharma, from the CoreAI side of Microsoft, to the CEO of Microsoft Gaming. So she’s replacing Phil Spencer, essentially. So it’s big news, a big shakeup, should we say, of Xbox. I think with Phil Spencer, it’s been a long time coming, right? I think Xbox fans have expected that retirement, but perhaps not so much Sarah Bond’s leaving. And this is, I think, the shakeup, right? We knew Phil was going to retire. He’d been messaging that for some time. He’s been there for a long time. He’s a Microsoft lifer, really. Phil’s been on this show before, and we’re going to run some clips from his past interviews on Decoder , because I want to get your take on what happened between those interviews and now. At a very high level, we knew Phil was going. Is it that everyone expected Sarah to be his successor, and that didn’t happen, and that’s the surprise here? I think there are two surprises, right? One is obviously that Sarah wasn’t named Xbox chief and that Asha is the successor, because that was a quiet surprise and a surprise higher, really. But yeah, Sarah has always been the number two. She’s always traveled with Phil and always been the face of Xbox over the past couple of years as Phil has... I’d say he’s stepped back a little bit publicly since the Activision Blizzard acquisition. So Sarah’s become the face of Xbox during that time, and she took over the platform work, the hardware work. So whenever there was any mention of the next-gen Xbox, it was Sarah who would come out and talk about it and not Phil. So that’s a change in itself, right, because it’s usually Phil. So I think everyone just thought, “Okay, well she’s being prepped to be Phil’s replacement eventually, whether it be a couple of years, five years, whatever,” and it didn’t happen. Behind the scenes, I know that Xbox fans had heard, and expected, that this was going to happen, that Sarah Bond would be the heir apparent. But for a good year or so, I’ve been hearing different things about Sarah Bond, different from what perhaps the public perception is of her. So to me, it wasn’t a surprise. I was not surprised to see her not named, but I think it was more of a surprise to see Asha named. That was a surprise to me. I know Asha a little bit. I’ve spoken to her a few times, but she’s like a non-gamer. She’s very straight about that and honest about it, but not that that really matters, I don’t think, to be a CEO, really, to be honest. But to Xbox fans and that gaming segment, if they see a non-gamer, it’s like... Particularly with Xbox, I think, because Phil has instilled that over the years, so they’ve come to that expectation. So that was the surprise of it, but I don’t think Sarah Bond was a surprise to me. I want to come to Asha, the new leadership, and particularly the Microsoft AI of it all, because that seems like an important piece of the puzzle. I just want to stick with Phil and Sarah for one more second. There’s the reporting you have done about Sarah personally, and her skills as manager and potentially CEO, and then there’s Phil and the strategy he pursued for Xbox and Microsoft Gaming. A huge part of that strategy is making Microsoft Gaming as big as it is, bigger than Xbox, acquiring Activision Blizzard King, and doing all the other acquisitions of the studios they’ve done. I look at this, and I say, “Well, it doesn’t matter if Sarah was the best manager or the worst manager. The strategy that she was a part of failed.” I see this, and I say, “Okay, if I’m Satya Nadella,” or more importantly, “Amy Hood, the CFO of Microsoft, and we’ve done some of the biggest acquisitions in history, and certainly the biggest acquisitions in Microsoft history. None of this came to anything. We gotta reboot this whole thing.” Does that feel as important inside Microsoft as maybe Sarah wasn’t the right person? It’s a couple of things. Obviously, Microsoft Gaming has ballooned now, right, because it’s got Bethesda, and Activision Blizzard has made it bigger than ever before. And then you’ve got this tension of Microsoft: the corporate Microsoft of Satya Nadella and Amy Hood, putting the pressure on that new division to return the money that they’ve invested into this project, essentially, through profit margins. So they’ve cranked that pressure up over the past couple of years, and it forced Phil, Sarah, and everyone under them to then respond. They’ve done these studio closures, they’ve done cuts, they’ve done price increases. They’ve tried to accelerate getting more people using export services, essentially. That became the strategy, like, “Okay, we need to get to TVs, we need to get to mobile,” and all this stuff. And there was a lot of, I guess, trying to rush that, it felt like, and forgetting that the console was their base of building up Game Pass and their base of taking those people and perhaps moving them elsewhere, and user acquisition, growth. And it just feels like they tried to rush that, and they did the “This is an Xbox” campaign , which was just super strange. It was trying to say that the phone was an Xbox, and it was borne out of the idea that they needed to speed up profitability. They needed to get more revenue, get more growth, and improve those margins, essentially. So when you’re trying to pin blame on whoever it is, it comes from the top. Satya and Amy are pushing these margins, and I think they’re slightly unrealistic in the context of gaming. They’re not the margins that Sony has, for example. They’ve put the pressure on. Phil, I think, has stepped away a little bit over the last couple of years, so not so laser-focused on Xbox, and then that’s allowed Sarah to have a lot of power over Xbox and accumulate marketing power and do the “This is an Xbox” campaign, in her own org. It just hasn’t gone well. It hasn’t gone well for consoles, even if you argue that Microsoft perhaps doesn’t care about selling consoles, which maybe they don’t. I think they probably thought that they could replace them with cloud and mobile a little bit quicker. Well, so actually this is my big question. And this is, again, the reporting you have about Sarah as a manager and a leader, but then well, it’s Microsoft. All Satya and Amy care about is mobile and cloud. That’s not even the AI part of it. This is a business that runs huge cloud services in Azure and needs a new foothold in mobile. And they basically bought Candy Crush to get a bunch of mobile revenue, and of course, that’s what they wanted to do. It feels like the decision is not so much about Phil Spencer and Sarah Bond. It’s “this whole strategy failed, and now we’re going to try a new one,” and I’m just curious if you have insight into the balance. How much is it “The strategy failed, we just need a new regime,” versus, “We need a new strategy, and Sarah specifically cannot execute a new strategy”? I don’t think they’re going to change the strategy all that much, because the strategy makes sense in a way. You want to get to mobile, you want to get to cloud, and that’s how you’re going to get more users ultimately into your system without selling enough consoles, essentially. So I don’t think the strategy is terrible, but I think the execution has been. Over the past couple of years, I think that’s been the problem predominantly, which is the execution of the strategy. The messaging publicly has been pretty bad. I think it’s more of a regime change that’s needed to bring some element of people who understand user acquisition. And I think that’s where Asha is coming in. Let’s talk about Xbox strategy as a whole, because if you’re saying it’s not changing, it’s worth taking a beat to just understand what the goal has been. And I would say that since 2017, Phil Spencer has been very clear that where he wants to get to is everyone is subscribed to Game Pass, you can play Game Pass games anywhere because they’re streaming from the cloud, and we’re going to get out of this race of console generations and exclusives. Because they essentially lost to Sony, permanently lost to Sony. There was no coming back with a new generation. Did that work? I mean, I think we know now there’s executive turnover; it didn’t work. But did it ever work? Was there ever a glimmer of it working? So, going back to where it all started, this mess with Xbox essentially is the Xbox One, when they failed that sort of era. And what happened at that time is the PlayStation- This is 2013; this is over a decade ago. This is 2013, yeah. And that led up to kind of 2017 and the launch of xCloud and all that sort of stuff. But going back to that sort of era, they lost that generation, and it was a huge cost to them, because that was the generation that people started their digital libraries that weren’t on a PC. People on PlayStation have built up those libraries. They’re not willing to move away from those libraries now. They knew they’d lost that real key generation. So the response was, “Let’s do Game Pass because that will allow people to bring their games to different devices, this whole cloud vision, mobile, et cetera.” I think that was the only kind of response they could give, and it was designed to be consumer-friendly, right? You got day one games that they published immediately, so they took a bit of a risk. It was quite a bold move, really, to do that. And still, Sony doesn’t do day one games, for example. So they took a risk. The problem with Game Pass is that they’ve had to fuel it with content, right? They’ve done all these acquisitions, Bethesda, Activision, and there are nameless others as well. But the problem then with Game Pass is that you’re giving your games away with a subscription, but you need to scale that up, right? It needs to hit a certain number of million people that you’ve got that concurrent revenue every quarter, and you can rely on where it isn’t cannibalizing or eating into the traditional sales of those games that fuel the costs for developing those games. And frankly, it’s just getting more complicated to develop games these days, and a lot more expensive. So they’ve had those issues with Game Pass, and ultimately, I think the strategy was to respond to try and get that growth, to try and scale up this idea of Xbox on all devices. And the way they put it was “3 billion gamers,” right? That was the launch of xCloud. And remember, xCloud, now it’s called Xbox Cloud Gaming, was originally a mobile play. So it was literally to try and get people into the idea of playing via streaming on mobile with these attachments to your phone essentially. It’s worth noting that they ran into Apple’s App Store rules . They were not able to do this in a way that actually worked. Exactly. So they hit a bunch of regulatory hurdles. They had to launch it as a xbox.com/play in your browser, so you couldn’t get an app or anything like that. That completely knocked them back, right? Even when they were trying to playtest it, Apple was on the test flight, saying, “No, you have to change this.” They were very restricted in what they could do. So that kind of put their strategy back. Now, who do you blame for that? [Laughs] I think you can blame Apple in a very significant way. There are pretty major antitrust ramifications of that that Apple’s still feeling. Right. And then fast-forward from that point, from launching xCloud and having all those issues, to a couple of years ago, and they’re still trying to get all of that resolved, right? They still want this cloud gaming app. But they’re also now trying to get a store in there, essentially, is the idea. They’re going to have an Xbox mobile store. So we’ve moved on from having an Xbox Cloud Gaming app to something more ambitious now: “We want to do a store, we want to sell content in there directly to people.” And there was the promise that the app is going to arrive from both Phil and",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/DCD_0226.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "New York sues Valve for enabling \"illegal gambling\" with loot boxes",
      "url": "https://arstechnica.com/gaming/2026/02/new-york-sues-valve-for-enabling-illegal-gambling-with-loot-boxes/",
      "published": "2026-02-26T14:57:36+00:00",
      "summary": "The ability to resell Steam items for real value is key to the state's case.",
      "content_text": "Opening a valuable skin like this in a loot box is akin to winning a lottery, New York alleges in a new lawsuit. Opening a valuable skin like this in a loot box is akin to winning a lottery, New York alleges in a new lawsuit. Credit: Twitter / Luksusbums The lawsuit also takes Valve to task for allowing third-party sites that facilitate the resale of in-game skins for cash. While the suit notes that Valve has “sporadically enforced” rules against so-called skin gambling sites —which use Steam inventories as virtual chips for gambling games—it alleges that Valve “has not acted against sites that permit the sale of Valve’s virtual items.” The suit cites “internal communications” from numerous Valve employees suggesting that the company was OK with such “cash-out services” for Steam items as long as off-platform gambling wasn’t explicitly involved. We’ll see you in court In a press release announcing the suit , state Attorney General Letitia James said the gambling Valve’s system enables can “lead to serious addiction problems, especially for our young people. … These features are addictive, harmful, and illegal, and my office is suing to stop Valve’s illegal conduct and protect New Yorkers.” Back in 2016, Valve faced a pair of civil lawsuits from parents concerned about Valve’s connection to skin gambling sites—those suits were eventually dismissed . Around the same time, Valve received a letter from Washington state threatening “civil or criminal action” if Valve didn’t crack down on skin gambling, but the state stopped short of filing a lawsuit in that matter. In addition to asking Valve to modify or eliminate its loot box system, the New York suit asks for Valve to make “full restitution to consumers” for the disgorgement of “all monies” received from its gambling system, and for fines of “three times the amount of its gain.” Ars Technica has reached out to Valve for comment.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/cslootboxes.jpg"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "A non-public document reveals that science may not be prioritized on next Mars mission",
      "url": "https://arstechnica.com/space/2026/02/a-non-public-document-reveals-that-science-may-not-be-prioritized-on-next-mars-mission/",
      "published": "2026-02-26T14:44:25+00:00",
      "summary": "For some reason, NASA chose not to publicly release its Mars orbiter objectives.",
      "content_text": "The way this document is written suggests that when NASA scores bidders for the Mars Telecommunications Network, the addition of a camera or other scientific payloads won’t be a net positive. However, if they pose an overall risk to the mission, they would be a net negative. New award to Rocket Lab may complicate things One of the other intriguing parts of this mission is that it sets up a battle royale of sorts for some of NASA’s most prominent contractors. Rocket Lab and Blue Origin have both waged very public campaigns that tout their solutions to NASA’s needs. SpaceX is also interested in winning a Mars mission for its Starship launch system. Then there are traditional contractors, such as Lockheed Martin, which have a long and storied history of building robust (if costly) Mars missions. If NASA is going to launch the Mars Telecommunications Network by late 2028 to make the next “window” to the red planet, it must move quickly with this solicitation. In particular, industry protests after a decision is made could hold up the project for months and would almost certainly doom NASA’s hopes of making the 2028 launch opportunity. On Monday the space agency awarded a $390,936 contract to Rocket Lab to study “Mars End-to-End Communication Service Architectures.” The award is not significant monetarily, but it does indicate that NASA is interested in Rocket Lab’s ideas for improving communications between Earth and Mars, and potentially a Mars Sample Return mission down the road. However, one source suggested to Ars that the award is a potential conflict of interest. The contracting office for the Rocket Lab award is Goddard Space Flight Center, which is also responsible for managing the Mars Telecommunications Network. That Rocket Lab, alone, received an award like this from the NASA center that will also decide on the orbiting spacecraft—coterminous when such a decision will be made—is surely to be the basis of one or more protests should Rocket Lab win the Mars Telecommunications Network contract, the source told Ars.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/mars-telecom-1152x648.jpg"
    }
  ]
}