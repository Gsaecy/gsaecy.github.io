{
  "industry": "technology",
  "collected_at": "2026-02-27T16:31:12.633705+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Employees at Google and OpenAI support Anthropic's Pentagon stand in open letter",
      "url": "https://techcrunch.com/2026/02/27/employees-at-google-and-openai-support-anthropics-pentagon-stand-in-open-letter/",
      "published": "2026-02-27T16:23:58+00:00",
      "summary": "While Anthropic has an existing partnership with the Pentagon, the AI company has remained firm that its technology not be used for mass domestic surveillance or fully autonomous weaponry.",
      "content_text": "Anthropic has reached a stalemate with the United States Department of War over the military‚Äôs request for unrestricted access to the AI company‚Äôs technology. But as the Pentagon‚Äôs Friday afternoon deadline for Anthropic‚Äôs compliance approaches, over 300 Google employees and over 60 OpenAI employees have signed an open letter urging the leaders of their companies to support Anthropic and refuse this unilateral use. Specifically, Anthropic stood in opposition to the use of AI for domestic mass surveillance and autonomous weaponry. The open letter‚Äôs signatories seek to encourage their employers to ‚Äúput aside their differences and stand together‚Äù to uphold the boundaries Anthropic has asserted. ‚ÄúThey‚Äôre trying to divide each company with fear that the other will give in,‚Äù the letter says. ‚ÄúThat strategy only works if none of us know where the others stand.‚Äù The letter specifically calls on executives at Google and OpenAI to maintain Anthropic‚Äôs red lines against mass surveillance and fully automated weaponry. ‚ÄúWe hope our leaders will put aside their differences and stand together to continue to refuse the Department of War‚Äôs current demands.‚Äù Leaders at the companies have not yet formally reponded to the letter. TechCrunch has reached out to Google and OpenAI for comment. However, informal statements suggest both companies are sympathetic to Anthropic‚Äôs side of the case. In an interview with CNBC on Friday morning, OpenAI CEO Sam Altman said that he doesn‚Äôt ‚Äúpersonally think the Pentagon should be threatening DPA against these companies.‚Äù According to a CNN reporter, an OpenAI spokesperson confirmed that the company shares Anthropic‚Äôs red lines against autonomous weapons and mass surveillance. Google DeepMind has not formally addressed the conflict, but Chief Scientist Jeff Dean, presumably speaking as an individual, did express opposition to mass surveillance by the government. Techcrunch event Boston, MA | June 9, 2026 ‚ÄúMass surveillance violates the Fourth Amendment and has a chilling effect on freedom of expression,‚Äù Dean wrote on X. ‚ÄúSurveillance systems are prone to misuse for political or discriminatory purposes.‚Äù According to an Axios report, the military currently can use X‚Äôs Grok, Google‚Äôs Gemini, and OpenAI‚Äôs ChatGPT for unclassified tasks, and has been negotiating with Google and OpenAI to bring its technology over for use in classified work. While Anthropic has an existing partnership with the Pentagon, the AI company has remained firm in maintaining the boundary that its AI be used for neither mass domestic surveillance, nor fully autonomous weaponry. Defense Secretary Pete Hegseth told Anthropic CEO Dario Amodei that if his company doesn‚Äôt concede, the Pentagon will either declare Anthropic a ‚Äúsupply chain risk‚Äù or invoke the Defense Production Act (DPA) to force the company to comply with military demands. In a statement on Thursday , Amodei maintained his company‚Äôs position. ‚ÄúThese latter two threats are inherently contradictory: one labels us a security risk; the other labels Claude as essential to national security,‚Äù the statement reads. ‚ÄúRegardless, these threats do not change our position: we cannot in good conscience accede to their request.‚Äù",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2023/09/53202070940_ea57312b1a_k.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "We don‚Äôt have to have unsupervised killer robots",
      "url": "https://www.theverge.com/ai-artificial-intelligence/885963/anthropic-dod-pentagon-tech-workers-ai-labs-react",
      "published": "2026-02-27T16:18:26+00:00",
      "summary": "It's the day of the Pentagon's looming ultimatum for Anthropic: allow the US military unchecked access to its technology, including for mass surveillance and fully autonomous lethal weapons, or potentially be designated a \"supply chain risk\" and potentially lose hundreds of billions of dollars in contracts. Amid the intensifying public statements and threats, tech workers [&#8230;]",
      "content_text": "It‚Äôs the day of the Pentagon‚Äôs looming ultimatum for Anthropic: allow the US military unchecked access to its technology, including for mass surveillance and fully autonomous lethal weapons, or potentially be designated a ‚Äúsupply chain risk‚Äù and potentially lose hundreds of billions of dollars in contracts. Amid the intensifying public statements and threats, tech workers across the industry are looking at their own companies‚Äô government and military contracts wondering what kind of future they‚Äôre helping to build. While the Department of Defense has spent weeks negotiating with Anthropic over removing its guardrails, including allowing the US military to use Anthropic‚Äôs AI kill targets with no human oversight, OpenAI and xAI had reportedly already agreed to such terms, although OpenAI is reportedly attempting to adopt the same red lines in the agreements as Anthropic. The overall situation has left employees at some companies with defense contracts feeling betrayed. ‚ÄúWhen I joined the tech industry, I thought tech was about making people‚Äôs lives easier,‚Äù an Amazon Web Services employee told The Verge , ‚Äúbut now it seems like it‚Äôs all about making it easier to surveil and deport and kill people.‚Äù In conversations with The Verge , current and former employees from OpenAI, xAI, Amazon, Microsoft, and Google expressed similar feelings about the changing moral landscape of their companies. Organized groups representing 700,000 tech workers at Amazon, Google, Microsoft, and more have signed a letter demanding that the companies reject the Pentagon‚Äôs demands. But many saw little chance of their employers ‚Äî whether they‚Äôre directly embroiled in this conflict or not ‚Äî questioning the government or pushing back. ‚ÄúFrom their perspective, they‚Äôd love to keep making money and not have to talk about it,‚Äù said a software engineer from Microsoft. So far, Anthropic has stood its ground. Anthropic CEO Dario Amodei put out a statement on Thursday that the Pentagon‚Äôs ‚Äúthreats do not change our position: we cannot in good conscience accede to their request.‚Äù But he has stated that he is not at all opposed to lethal autonomous weapons sometime in the future, just that the technology was not reliable enough ‚Äútoday.‚Äù Amodei even offered to partner with the DoD on ‚ÄúR&D to improve the reliability of these systems, but they have not accepted this offer,‚Äù he wrote in the statement. In the past few years, however, major tech companies have loosened their rules or changed their mission statements to expand into lucrative government or military contracts. In 2024, OpenAI removed a ban on ‚Äúmilitary and warfare‚Äù use cases from its terms of service; after that, it signed a deal with autonomous weapons maker Anduril and then its DoD contract, and just this week, Anthropic changed its oft-touted responsible scaling policy , dropping its longtime safety pledge in order to ensure it stayed competitive in the AI race. Big Tech players like Amazon, Google, and Microsoft have also allowed defense and intelligence agencies to use their AI products, including some agreeing to work with ICE despite growing outcry from the public and employees alike. In past years, tech workers‚Äô resistance to partnerships and deals they deem harmful to society at large sometimes led to big change. In 2018, for instance, thousands of Google employees successfully pressured the company to end its ‚Äú Project Maven ‚Äù partnership with the Pentagon, and Microsoft workers presented leadership with an anti-ICE petition signed by about 500 Microsoft employees, though Microsoft still works with the agency. In 2020, after the murder of George Floyd, tech companies made public statements about and financial commitments supporting the Black Lives Matter movement. But in recent months, the industry has seen a very different reality: a culture of fear and silence, especially amid cooperation with the Trump administration and ICE, tech workers recently told The Verge . Companies have followed in the footsteps of longtime surveillance and military tech partnerships, who have only become more hawkish. That includes the Peter Thiel-cofounded Palantir, whose CEO Alex Karp recently stated to shareholders that ‚ÄúPalantir is here to disrupt and make the institutions we partner with the very best in the world, and, when it‚Äôs necessary, to scare enemies and on occasion kill them. And we hope you‚Äôre in favor of that.‚Äù (Protect Democracy, a nonprofit, recently put out an open letter calling for Congressional oversight of the Department of Defense‚Äôs demands for unrestricted use of AI. ) OpenAI, Google, Microsoft, xAI, and Amazon did not immediately respond to requests for comment. A former xAI employee told The Verge , ‚ÄúEveryone is actually working on killer robots at this point,‚Äù adding that he believes everyone will follow in the footsteps of Palantir, Anduril, and xAI, since the government sentiment is that if a company doesn‚Äôt acquiesce, it‚Äôs ‚Äúagainst the benefits of the country, in a sense.‚Äù He said there‚Äôs a ‚Äúbig push for working with the military, and the trend is it‚Äôs cool to do it‚Ä¶ You‚Äôre a patriot if you do it.‚Äù A Google employee called the situation a ‚Äúdominance display from Hegseth that is disgusting.‚Äù He added, ‚ÄúOver and over AI is presenting us with choices about who we want to be and what kind of society and future we want to have. And they‚Äôre coming at us fast and with, really, the least thoughtful and least principled leaders in power that we could imagine. I can only thank Anthropic for insisting on the decent path and using their leverage ‚Äî that they are indispensable ‚Äî to chart a course toward a humane world and a humane future.‚Äù The AWS employee told The Verge that ‚Äúboundaries have definitely eroded in terms of the customers big tech is willing to court‚Äù and that there‚Äôs ‚Äúa deliberate whitewashing of the implications of new lucrative deals.‚Äù She recalled recently receiving an email from an AWS executive touting a more than $580 million contract with the US Air Force, among other partnerships, as a sign of Amazon‚Äôs AI successes, with no acknowledgment of the broader scope or harms involved. ‚ÄúIf the government is hell-bent on pursuing technologies like this, they should have to build them themselves, and be answerable for those decisions,‚Äù she said. The erosion may have extended to internal culture as well ‚Äî normalizing the idea that companies should always be watching. The AWS employee said that she and her colleagues are tracked on how much they‚Äôre using AI for their jobs, how often they‚Äôre working from the office, and more. ‚ÄúI can see myself and my coworkers getting more desensitized to surveillance on ourselves at work, and I‚Äôm worried that means we‚Äôre obeying, complying, and giving up too much in advance,‚Äù she said. An OpenAI employee said the general feeling within the AI industry over the last few weeks ‚Äúhas reopened the door to more discussion‚Ä¶ about the values and the future of the technology.‚Äù The employee said that the Pentagon-Anthropic situation, the recent ICE headlines, and the fast advancement of AI have been some of the main factors opening up those discussions internally. Even so, people who are immigrants or in more vulnerable positions are more afraid to speak, the OpenAI employee said. Anthropic, the former xAI employee said, seems like it‚Äôs in a position where it can say no and still stay afloat. Its focus on enterprise rather than consumer AI business may make it more sustainable even without government contracts, offering it some leverage. A software engineer at Microsoft said of Anthropic, speaking generally, ‚ÄúI was surprised to see them stand on some form of principle. I don‚Äôt know how long it‚Äôll last.‚Äù ‚ÄúWill it last?‚Äù seems to be the question on everyone‚Äôs lips. The Pentagon has already reportedly asked two major defense contractors, Boeing and Lockheed Martin, to provide information about their reliance on Anthropic‚Äôs Claude, as it moves to potentially designate Anthropic a ‚Äúsupply chain risk,‚Äù a classification usually reserved for threats to national security and rarely, if ever, assigned to a US company. It also reportedly may be considering invoking the Defense Production Act to attempt to force Anthropic to comply with its request. Just like with any other AI company, if Anthropic folds, the Microsoft employee said, there‚Äôs little chance of it or others pulling back on killer robots and surveillance. ‚ÄúOnce you‚Äôre in the door with the Department of Defense or whatever we‚Äôre calling it now‚Ä¶ I think it‚Äôs probably hard for them to actually have the oversight they claim. It‚Äôs just going to be lucrative to basically give themselves permission to do the thing that makes the most money.‚Äù In Microsoft‚Äôs own case, he said he doesn‚Äôt expect the company to adhere to any sort of ethical principles. The company has worked extensively with the Israeli Defense Forces, including for mass surveillance of Palestinians and dissidents, despite employee protest . (It said it ended some parts of the partnership last year.) Another Microsoft employee told The Verge that although ‚ÄúMicrosoft holds a Responsible AI ‚Äòcommitment,‚Äô‚Ä¶ they are currently attempting to play both sides for the sake of profit rather than meaningfully commitment to Responsible AI.‚Äù But this is nothing new, one AI startup employee said. In her eyes, the boundaries have often been ‚Äúfuzzy, especially within AI,‚Äù about what kinds of things companies are willing to let their technology power. ‚ÄúA lot of it has been going on beneath the surface for as long as AI has been around.‚Äù The AWS employee emphasized that ‚Äúwe need cross-tech solidarity and a coherent, worker-led vision for AI now more than ever.‚Äù ‚ÄúThe safeguards that Anthropic is trying to keep in place are no mass surveillance of Americans and no fully autonomous weapons, which just means that they want a human in the loop if the machine is going to kill somebody,‚Äù she added. ‚ÄúEven if this technology were perfect ‚Äî which it isn‚Äôt ‚Äî I think most Americans don‚Äôt want machines that kill people without human oversight running around in an America that‚Äôs become an AI-powered mass surveillance state.‚Äù Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Hayden Field AI Amazon Anthropic Google Microsoft OpenAI Report Tech xAI",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/STK432_Government__CVirginia_D.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "And the award for the most improved EV goes to... the 2026 Toyota bZ",
      "url": "https://arstechnica.com/cars/2026/02/and-the-award-for-the-most-improved-ev-goes-to-the-2026-toyota-bz/",
      "published": "2026-02-27T16:13:51+00:00",
      "summary": "Toyota's small electric SUV is much-revised, much more efficient, and much better.",
      "content_text": "The world‚Äôs largest automaker has had a somewhat difficult relationship with battery-electric vehicles. Toyota was an early pioneer of hybrid powertrains, and it remains a fan today, often saying that given limited battery supply, it makes sense to build more hybrids than fewer EVs. Its first full BEV had a rocky start, suffering a recall due to improperly attached wheels just as the cars were hitting showrooms. Reviews for the awkwardly named bZ4x were mixed ; the car did little to stand out among the competition. Toyota didn‚Äôt get to be the world‚Äôs largest automaker by being completely blind to feedback, and last year, it gave its EV platform (called e-TNGA and shared with Lexus and Subaru) a bit of a spiff-up. To start, it simplified the name‚Äîthe small electric SUV is now just called the bZ. It uses a new 74.7 kWh battery pack, available with either front- or all-wheel drive powertrains that now use silicon carbide power electronics. And for the North American market, instead of a CCS1 port just behind the front passenger wheel, you‚Äôll now see a Tesla-style NACS socket. Our test bZ was the $37,900 XLE FWD Plus, which has the most range of any bZ at 314 miles (505 km) according to the EPA test cycle. When you realize that the pre-facelift version managed just 252 miles (405 km) with 71.4 kWh onboard, the scale of the improvement becomes clear. Standard equipment is generous, even in XLE trim. Jonathan Gitlin Standard equipment is generous, even in XLE trim. Jonathan Gitlin It‚Äôs 184.6 inches (4,689 mm) long, 73.2 inches (1,859 mm) wide, and 65 inches ( 1,651 mm) tall. Jonathan Gitlin It‚Äôs 184.6 inches (4,689 mm) long, 73.2 inches (1,859 mm) wide, and 65 inches ( 1,651 mm) tall. Jonathan Gitlin The bZ looks conventional. Jonathan Gitlin The bZ looks conventional. Jonathan Gitlin It‚Äôs 184.6 inches (4,689 mm) long, 73.2 inches (1,859 mm) wide, and 65 inches ( 1,651 mm) tall. Jonathan Gitlin The bZ looks conventional. Jonathan Gitlin Our loan immediately followed a week with the bZ‚Äôs more powerful, more expensive Lexus relative . While I might have liked that Lexus interior and some of its mod cons like ventilated seats, the Toyota is a much better EV despite having fewer frills. With 221 hp (165 kW) going to the front tires and 4,156 lbs (1,885 kg) to move, the XLE FWD Plus is not speedy. In normal mode, 0‚Äì60 mph (97 km/h) takes eight seconds, although there‚Äôs still enough torque in this setting to chirp the low rolling resistance tires.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/2026-Toyota-bZ-1-2560x1440.jpg"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "Wall Street Has AI Psychosis",
      "url": "https://www.wired.com/story/wall-street-has-ai-psychosis/",
      "published": "2026-02-27T16:00:00+00:00",
      "summary": "A ‚Äúthought experiment‚Äù about the impacts of AI sent stocks tumbling earlier this week. It‚Äôs probably going to keep happening.",
      "content_text": "Before last week the name Alap Shah didn‚Äôt ring a bell for many people. The 45-year-old financial analyst and tech entrepreneur had spent the past two decades working in relative obscurity. Then last weekend he coauthored a blog with the research firm Citrini titled ‚ÄúThe 2028 Global Intelligence Crisis.‚Äù It was a ‚Äúthought exercise‚Äù about the impacts of artificial intelligence, and it predicted that in June of that year, AI would jack up unemployment past 10 percent and force the Dow down, down, down. Writing in a confident, Nostradamic tone‚Äîas if auditioning for starring roles in the next Michael Lewis book‚Äîthe authors painted a picture of a flywheel in reverse: AI agents take jobs from workers, people spend less, and struggling corporations conduct layoffs on top of layoffs. There wasn‚Äôt much in it that hadn‚Äôt been previously heard, or speculated about. Tech leaders like Anthropic CEO Dario Amodei have already estimated that half the entry level white collar jobs will soon be gone , and earlier this year, Anthropic‚Äôs release of new agentic tools spurred a Wall Street selloff . Nonetheless the report hit with the force of the blizzard blowing through lower Manhattan. When the closing chimes sounded on the New York Stock Exchange, the Dow was down 800 points. The name Alap Shah was now ringing bells. The achievement is less impressive than it seems. Wall Street, like the rest of us, is in a persistent state of anxiety about AI, and it doesn‚Äôt take much to trigger a mini-panic. Financial markets don‚Äôt necessarily map to reality, but the jitters reflect a wider disquiet. The AI future is in a William Gibson zone‚Äîit‚Äôs here, but unevenly distributed‚Äîand the news from those already living in the agent-packed, AI code-writing universe is both exciting and unsettling. Emphasis on unsettling. No one‚Äîno one!‚Äîknows exactly how AI will impact the economy, but clearly it will be significant. Right now stocks are soaring, so it seems to make sense to keep the party going. But then along comes the latest doom manifesto, or a paper indicating that a traditional business sector might be threatened by AI, and suddenly money managers are reminded that the biggest issue of our time is totally unresolved. Case in point: earlier this month, a tiny company (valuation under $6 million) that had previously sold karaoke machines pivoted to AI-powered shipping logistics and put out a report saying that it had discovered some efficiencies in loading semi-trucks. That was enough to erase billions of dollars from the share prices of several major logistics companies, none of which had karaoke experience. After it did its job on Wall Street, the Citrini report came under considerable fire. Critics climbed over each other to proclaim its flimsiness. For one thing, they pointed out, AI has had very little discernable impact on the economy so far. Others cited the long history of resilience after technological upheavals. A mocking response by the respected trading firm Citadel Securities read, ‚ÄúFor AI to produce a sustained negative demand shock, the economy must see a material acceleration in adoption, experience near-total labor substitution, no fiscal response, negligible investment absorption, and unconstrained scaling of compute.‚Äù The most withering critiques disputed the report‚Äôs contention that much of the economy involves non-productive ‚Äúrent-seeking‚Äù by middlemen and market makers, taking advantage of the laziness of the general population. When everyone has a few dozen AI agents working on their behalf, writes Shah, consumers will be able to effortlessly find the best goods for the best prices. Apps will be rendered unnecessary‚Äîjust type what you want into the LLM and an army of agents will do everything for you. The ‚Äúposter child‚Äù for this phenomenon, Shah says, is DoorDash. Instead of being limited to the restaurants on the app, consumers will send out AI agents to find their ideal meal options, contracting directly with restaurants and delivery people‚Äîno apps needed. Zero friction! The DoorDashes of the world are avocado toast!",
      "cover_image_url": "https://media.wired.com/photos/69a099a68b4e433f4999c9c4/191:100/w_1280,c_limit/Backchannel-Wall-Street-Has-AI-Psychosis-Business-2207816119.jpg"
    },
    {
      "industry": "technology",
      "source": "GitHub Blog",
      "title": "From idea to pull request: A practical guide to building with GitHub Copilot CLI",
      "url": "https://github.blog/ai-and-ml/github-copilot/from-idea-to-pull-request-a-practical-guide-to-building-with-github-copilot-cli/",
      "published": "2026-02-27T16:00:00+00:00",
      "summary": "<p>A hands-on guide to using GitHub Copilot CLI to move from intent to reviewable changes, and how that work flows naturally into your IDE and GitHub.</p> <p>The post <a href=\"https://github.blog/ai-and-ml/github-copilot/from-idea-to-pull-request-a-practical-guide-to-building-with-github-copilot-cli/\">From idea to pull request: A practical guide to building with GitHub Copilot CLI</a> appeared first on <a href=\"https://github.blog\">The GitHub Blog</a>.</p>",
      "content_text": "Most developers already do real work in the terminal. We initialize projects there, run tests there, debug CI failures there, and make fast, mechanical changes there before anything is ready for review. GitHub Copilot CLI fits into that reality by helping you move from intent to reviewable diffs directly in your terminal‚Äîand then carry that work into your editor or pull request. This blog walks through a practical workflow for using Copilot CLI to create and evolve an application, based on a new GitHub Skills exercise . The Skills exercise provides a guided, hands-on walkthrough; this post focuses on why each step works and when to use it in real projects. üîç Go deeper with the GitHub Skills exercise If you want a fully guided version of this workflow, including hands-on practice, check out the GitHub Skills exercise Create applications with the Copilot CLI . It walks through these patterns step by step in a preconfigured instance of GitHub Codespaces and is a good way to experiment safely before applying them to production code. The exercise covers the following: Install the Copilot CLI and use the issue template to create an issue Generate a Node.js CLI calculator app Expand calculator functionality with additional operations Write unit tests for calculator functions Create, review, and merge your pull request What Copilot CLI is (and is not) Copilot CLI is a GitHub-aware coding agent in your terminal. You can describe what you want in natural language, use /plan to outline the work before touching code, and then review concrete commands or diffs before anything runs. Copilot may reason internally, but it only executes commands or applies changes after you explicitly approve them. In practice, Copilot CLI helps you: Explore a problem based on your intent Propose structured plans using /plan (or you can hit Shift + Tab to enter planning mode), or suggest concrete commands and diffs you can review Generate or modify files Explain failures where they occur What it does not do: Silently run commands or apply changes without your approval Replace careful design work Eliminate the need for review You stay in control of what runs, what changes, and what ships. Step 1: Start with intent, not scaffolding Instead of starting by choosing a framework or copying a template, start by stating what you want to build. From an empty directory, run: copilot > Create a small web service with a single JSON endpoint and basic tests If you want to generate a proposal in a single prompt instead of entering interactive mode, you can also run: copilot -p \"Create a small web service with a single JSON endpoint and basic tests\" In the Skills exercise, this pattern is used repeatedly: describe intent first, then decide which suggested commands you actually want to run. At this stage, Copilot CLI is exploring the problem space. It may: Suggest a stack Outline files Propose setup commands Nothing runs automatically. You inspect everything before deciding what to execute. This makes the CLI a good place to experiment before committing to a design. Step 2: Scaffold only what you‚Äôre ready to own Once you see a direction you‚Äôre comfortable with, ask Copilot CLI to help scaffold: > Scaffold this as a minimal Node.js project with a test runner and README This is where Copilot CLI is most immediately useful. It can: Create directories and config, Wire basic project structure, Generate boilerplate you would otherwise type or copy by hand. Copilot CLI does not ‚Äúown‚Äù the project structure. It suggests scaffolding based on common conventions, which you should treat as a starting point, not a prescription. The important constraint is that you‚Äôre always responsible for the result. Treat the output like code from a teammate: review it, edit it, or discard it. Step 3: Iterate at the point of failure Run your tests directly inside Copilot CLI: Run all my tests and make sure they pass When something fails, ask Copilot about that exact failure in the same session: > Why are these tests failing? If you want a concrete proposal instead of an explanation, try: > Fix this test failure and show the diff This pattern‚Äîrun ( !command ), inspect, ask, review diff‚Äîkeeps the agent grounded in real output instead of abstract prompts. üí° Pro tip: In practice, explain is useful when you want understanding, while suggest is better when you want a concrete proposal you can review. Learn more about slash commands in Copilot CLI in our guide . Step 4: Make mechanical or repo-wide changes Copilot CLI is also well suited to changes that are easy to describe but tedious to execute: > Rename all instances of X to Y across the repository and update tests Because these changes are mechanical and scoped, they‚Äôre easy to review and easy to roll back. The CLI gives you a concrete diff instead of a wall of generated text. Step 5: Move into your editor when you need to start shaping your code Eventually, speed matters less than precision. This is the natural handoff point to your editor or IDE, so it can: Reason about edge cases Refine APIs Make design decisions Copilot works there too, but the key point is why you switch environments. The CLI helps you quickly get to something real. The IDE is where you can shape your code into exactly what you want. A good rule of thumb: CLI: use /plan , generate a /diff , and move quickly with low ceremony IDE: use /IDE when you need to refine logic and make decisions you‚Äôll defend in review GitHub: commit, open a pull request with the command /delegate , and collaborate asynchronously Step 6: Ship on GitHub Once the changes look good, commit and open a pull request which you can do through the Copilot CLI in natural language: Add and commit all files with a applicable descriptive messages, push the changes. Create a pull request and add Copilot as a reviewer Now the work becomes durable: Reviewable by teammates Testable in CI Ready for async iteration This is where Copilot‚Äôs value compounds as part of a flow that ends with shipping versus just being a single surface. The Skills exercise intentionally ends here, because this is where Copilot‚Äôs value becomes durable: in commits, pull requests, and review (not just suggestions). One workflow, three moments A helpful mental model for Copilot looks like this: CLI : prove value quickly with low ceremony IDE : shape and refine your code GitHub : review, collaborate, and ship Copilot CLI is powerful precisely because it fits into this system instead of trying to replace it. Building with Copilot? A note on the Copilot SDK If you‚Äôre building a developer tool, internal system, or application where agentic execution itself is part of the product (not just something you run in a terminal), you may want to look at the GitHub Copilot SDK , now in technical preview. The Copilot SDK gives you programmatic access to the same planning and execution engine that powers Copilot CLI, without requiring you to build or maintain your own orchestration layer. Instead of wiring planners, tools, and recovery logic yourself, you define agent behavior and let Copilot handle execution. Use Copilot CLI when you want fast, interactive execution in your own workflow. Use the Copilot SDK when you want those same agentic capabilities embedded inside your application. The SDK exposes the execution engine behind Copilot CLI, but not GitHub-specific features like repository-scoped memory or delegated pull request workflows. Explore Copilot SDK > Take this with you Copilot CLI is most useful when you treat it like a tool for momentum, not a replacement for judgment. Used well, it helps you move from intent to concrete changes faster: exploring ideas, scaffolding projects, diagnosing failures, and handling mechanical work directly in the terminal. When precision matters, you move into your editor. When the work is ready to share, it lands on GitHub as a pull request‚Äîreviewable, testable, and shippable. That flow matters more than any single command. If you take one thing away from this guide, it‚Äôs this: Copilot works best when it fits naturally into how developers already build software. Start in the CLI to get unstuck or move quickly, slow down in the IDE to make decisions you can stand behind, and rely on GitHub to make the work durable. Written by Senior Service Delivery Engineer, GitHub",
      "cover_image_url": "https://github.blog/wp-content/uploads/2026/01/generic-mona-copilot-logo.png?fit=1920%2C1080"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "CISA replaces acting director after a bumbling year on the job",
      "url": "https://techcrunch.com/2026/02/27/cisa-replaces-acting-director-gottumukkala-after-a-bumbling-year-on-the-job/",
      "published": "2026-02-27T15:57:02+00:00",
      "summary": "The U.S. cybersecurity agency's acting director Madhu Gottumukkala will be replaced, after a year of cuts, layoffs, and staff reassignments, and allegations of security lapses and claims he struggled to lead the agency.",
      "content_text": "This week it was reported that U.S. Cybersecurity and Infrastructure Security Agency is in dire shape , after a year of cuts, layoffs, and furloughs under the Trump administration. Now the agency has replaced its top acting leader, a CISA spokesperson tells TechCrunch. The move to replace Madhu Gottumukkala as the acting director of CISA, an agency under the Department of Homeland Security that oversees cybersecurity and technical protection across the federal government, comes after a tumultuous year serving as the agency‚Äôs top boss. Gottumukkala struggled to lead the agency during his tenure as acting director and caused security headaches , including the uploading of sensitive government documents to ChatGPT, according to reports. Staffing at the agency was slashed by one-third . Gottumukkala also reportedly failed a counterintelligence polygraph he took in order to view classified documents, and suspended several career officials in response, including the agency‚Äôs then-chief security officer. Before being nominated to CISA as deputy director, Gottumukkala was chief technology officer of South Dakota under then-governor and current Secretary of Homeland Security Kristi Noem. ABC News was first to report Gottumukkala‚Äôs departure. In a statement shared with TechCrunch on Friday, CISA spokesperson Marci McCarthy claimed Gottumukkala had done a ‚Äúremarkable job.‚Äù McCarthy told TechCrunch that Nick Andersen will replace Gottumukkala as CISA‚Äôs new acting director, and that Gottumukkala has been moved to a new position as director of strategic implementation in the Department of Homeland Security, which houses CISA. Prior to his appointment as acting director to lead CISA, Andersen previously served as the agency‚Äôs top official overseeing its cybersecurity division. Techcrunch event Boston, MA | June 9, 2026 The agency still hasn‚Äôt had a permanent Senate-confirmed director since Trump returned to office. McCarthy said the Trump administration has chosen Sean Plankey to be the agency‚Äôs permanent director, which requires a majority vote of approval in the U.S. Senate. The White House re-nominated Plankey to head CISA in January , after Sen. Ron Wyden last year blocked Plankey‚Äôs nomination until the agency agreed to release an unclassified report allegedly describing cybersecurity flaws at phone and telecommunication giants. Wyden demanded the report‚Äôs release in the wake of hundreds of hacks targeting U.S. and international phone and internet providers by the China-backed hacking group known as Salt Typhoon. The Senate has yet to schedule Plankey‚Äôs nomination hearing. Nextgov reported Thursday that CISA lost another top senior official, Bob Costello, the agency‚Äôs chief information officer tasked with overseeing the agency‚Äôs IT systems and data policies. The news outlet reported Gottumukkala tried to transfer Costello but was blocked by unnamed political appointees. CISA‚Äôs spokesperson McCarthy did not address Costello‚Äôs departure when asked by TechCrunch, but did not dispute the report.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/gottumukkala-2260579973.jpg?resize=1200,915"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "‚ÄòUnbelievably dangerous‚Äô: experts sound alarm after ChatGPT Health fails to recognise medical emergencies",
      "url": "https://www.theguardian.com/technology/2026/feb/26/chatgpt-health-fails-recognise-medical-emergencies",
      "published": "2026-02-27T15:44:33+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.theguardian.com/technology/2026/feb/26/chatgpt-health-fails-recognise-medical-emergencies\">https://www.theguardian.com/technology/2026/feb/26/chatgpt-health-fails-recognise-medical-emergencies</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47181841\">https://news.ycombinator.com/item?id=47181841</a></p> <p>Points: 28</p> <p># Comments: 15</p>",
      "content_text": "ChatGPT Health regularly misses the need for medical urgent care and frequently fails to detect suicidal ideation, a study of the AI platform has found, which experts worry could ‚Äúfeasibly lead to unnecessary harm and death‚Äù. OpenAI launched the ‚ÄúHealth‚Äù feature of ChatGPT to limited audiences in January , which it promotes as a way for users to ‚Äúsecurely connect medical records and wellness apps‚Äù to generate health advice and responses. More than 40 million people reportedly ask ChatGPT for health-related advice every day. The first independent safety evaluation of ChatGPT Health, published in the February edition of the journal Nature Medicine , found it under-triaged more than half of the cases presented to it. The lead author of the study, Dr Ashwin Ramaswamy, said ‚Äúwe wanted to answer the most basic safety question; if someone is having a real medical emergency and asks ChatGPT Health what to do, will it tell them to go to the emergency department?‚Äù Ramaswamy and his colleagues created 60 realistic patient scenarios covering health conditions from mild illnesses to emergencies. Three independent doctors reviewed each scenario and agreed on the level of care needed, based on clinical guidelines. Sign up: AU Breaking News email The team then asked ChatGPT Health for advice on each case under different conditions, including changing the patient‚Äôs gender, adding test results, or adding comments from family members, generating nearly 1,000 responses. They then compared the platform‚Äôs recommendations with the doctors‚Äô assessments. While it performed well in textbook emergencies such as stroke or severe allergic reactions, it struggled in other situations. In one asthma scenario, it advised waiting rather than seeking emergency treatment despite the platform identifying early warning signs of respiratory failure. In 51.6% of cases where someone needed to go to the hospital immediately, the platform said stay home or book a routine medical appointment, a result Alex Ruani, a doctoral researcher in health misinformation mitigation with University College London, described as ‚Äúunbelievably dangerous‚Äù. ‚ÄúIf you‚Äôre experiencing respiratory failure or diabetic ketoacidosis, you have a 50/50 chance of this AI telling you it‚Äôs not a big deal,‚Äù she said. ‚ÄúWhat worries me most is the false sense of security these systems create. If someone is told to wait 48 hours during an asthma attack or diabetic crisis, that reassurance could cost them their life.‚Äù In one of the simulations, eight times out of 10 (84%), the platform sent a suffocating woman to a future appointment she would not live to see, Ruani said. Meanwhile, 64.8% of completely safe individuals were told to seek immediate medical care, said Ruani, who was not involved in the study. The platform was also nearly 12 times more likely to downplay symptoms because the ‚Äúpatient‚Äù told it a ‚Äúfriend‚Äù in the scenario suggested it was nothing serious. ‚ÄúIt is why many of us studying these systems are focused on urgently developing clear safety standards and independent auditing mechanisms to reduce preventable harm,‚Äù Ruani said. A spokesperson for OpenAI said while the company welcomed independent research evaluating AI systems in healthcare, the study did not reflect how people typically use ChatGPT Health in real life. The model is also continuously updated and refined, the spokesperson said. Ruani said even though simulations created by the researchers were used, ‚Äúa plausible risk of harm is enough to justify stronger safeguards and independent oversight‚Äù. Ramaswamy, a urology instructor at the Icahn School of Medicine at Mount Sinai in the US, said he was particularly concerned by the platform‚Äôs under-reaction to suicide ideation. ‚ÄúWe tested ChatGPT Health with a 27-year-old patient who said he‚Äôd been thinking about taking a lot of pills,‚Äù he said. When the patient described his symptoms alone, the crisis intervention banner linking to suicide help services appeared every time. ‚ÄúThen we added normal lab results,‚Äù Ramaswamy said. ‚ÄúSame patient, same words, same severity. The banner vanished. Zero out of 16 attempts. A crisis guardrail that depends on whether you mentioned your labs is not ready, and it‚Äôs arguably more dangerous than having no guardrail at all, because no one can predict when it will fail.‚Äù Prof Paul Henman, a digital sociologist and policy expert with the University of Queensland, said: ‚ÄúThis is a really important paper. ‚ÄúIf ChatGPT Health was used by people at home, it could lead to higher numbers of unnecessary medical presentations for low-level conditions and a failure of people to obtain urgent medical care when required, which could feasibly lead to unnecessary harm and death.‚Äù He said it also raised the prospects of legal liability, with legal cases against tech companies already in motion in relation to suicide and self-harm after using AI chatbots. ‚ÄúIt is not clear what OpenAI is seeking to achieve by creating this product, how it was trained, what guardrails it has introduced and what warnings it provides to users,‚Äù Henman said. ‚ÄúBecause we don‚Äôt know how ChatGPT Health was trained and what the context it was using, we don‚Äôt really know what is embedded into its models.‚Äù",
      "cover_image_url": "https://i.guim.co.uk/img/media/3e8651062ef84e39193ac5df7c3ef7a576210509/588_0_3626_2901/master/3626.jpg?width=1200&height=630&quality=85&auto=format&fit=crop&precrop=40:21,offset-x50,offset-y0&overlay-align=bottom%2Cleft&overlay-width=100p&overlay-base64=L2ltZy9zdGF0aWMvb3ZlcmxheXMvdGctZGVmYXVsdC5wbmc&enable=upscale&s=e9a7e732746f9d1764c26e8a04dcdfa1"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "The US military reportedly shot down a CBP drone with a laser",
      "url": "https://www.theverge.com/policy/886021/us-military-cbp-drone-laser-texas",
      "published": "2026-02-27T15:43:43+00:00",
      "summary": "The US military mistakenly shot down a drone belonging to Customs and Border Protection near the Mexican border in Fort Hancock, Texas, according to reports from Reuters and The New York Times. The Thursday incident reportedly led the Federal Aviation Administration to close the airspace where the military fired the anti-drone laser. This marks the [&#8230;]",
      "content_text": "The US military mistakenly shot down a drone belonging to Customs and Border Protection near the Mexican border in Fort Hancock, Texas, according to reports from Reuters and The New York Times . The Thursday incident reportedly led the Federal Aviation Administration to close the airspace where the military fired the anti-drone laser. This marks the second time this month that officials closed airspace near the US-Mexico border due to an incident involving an anti-drone laser. On February 11th, officials closed airspace around the El Paso International Airport for hours after the CBP fired an anti-drone laser without coordinating with the FAA, The New York Times reported at the time. Though Transportation Secretary Sean Duffy said in a statement that the FAA and Department of War moved to ‚Äúaddress a cartel drone incursion,‚Äù it reportedly turned out to be a party balloon. Now, the FAA, CBP, and the Pentagon tell Reuters that the military ‚Äúemployed counter-unmanned aircraft system authorities to mitigate a seemingly threatening unmanned aerial system operating within military airspace,‚Äù adding that the incident ‚Äútook place far away from populated areas and there were no commercial aircraft in the vicinity.‚Äù This most recent incident reportedly led to a smaller airspace closure and was also done without approval from the FAA, the Times reports. In a joint statement , Reps. Bennie Thompson (D-MS), Andr√© Carson (D-IN), and Rick Larsen (D-WA) ‚Äî the top Democrats on committees overseeing homeland security, aviation, and transportation ‚Äî expressed outrage over the incident. ‚ÄúWe said MONTHS ago that the White House‚Äôs decision to sidestep a bipartisan, tri-committee bill to appropriately train C-UAS [Counter-Unmanned Aerial Systems] operators and address the lack of coordination between the Pentagon, DHS and the FAA was a short-sighted idea,‚Äù the statement says. ‚ÄúNow, we‚Äôre seeing the result of its incompetence.‚Äù",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/gettyimages-878567368.jpg?quality=90&strip=all&crop=0%2C10.737892056687%2C100%2C78.524215886627&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "LLMs Are Good at SQL. We Gave Ours Terabytes of CI Logs.",
      "url": "https://www.mendral.com/blog/llms-are-good-at-sql",
      "published": "2026-02-27T15:41:13+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.mendral.com/blog/llms-are-good-at-sql\">https://www.mendral.com/blog/llms-are-good-at-sql</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47181801\">https://news.ycombinator.com/item?id=47181801</a></p> <p>Points: 10</p> <p># Comments: 5</p>",
      "content_text": "Last week, our agent traced a flaky test to a dependency bump three weeks prior. It did this by writing its own SQL queries, scanning hundreds of millions of log lines across a dozen queries, and following a trail from job metadata to raw log output. The whole investigation took seconds. To do this, the agent needs context: not one log file, but every build, every test, every log line, across months of history. Every week, about 1.5 billion CI log lines and 700K jobs flow through our system. All of it lands in ClickHouse, compressed at 35:1. All of it is queryable in milliseconds. A SQL interface for the agent We expose a SQL interface to the agent, scoped to the organization it's investigating. The agent constructs its own queries based on the question. No predefined query library, no rigid tool API. LLMs are good at SQL. There's an enormous amount of SQL in training data, and the syntax maps well to natural-language questions about data. A constrained tool API like get_failure_rate(workflow, days) would limit the agent to the questions we anticipated. A SQL interface lets it ask questions we never thought of, which matters when you're debugging novel failures. The agent queries two main targets: Job metadata : a materialized view with one row per CI job execution. The agent uses this 63% of the time for questions like \"how often does this fail?\", \"what's the success rate?\", \"which jobs are slowest?\", \"when did this start failing?\" Raw log lines : one row per log line. The agent uses this 37% of the time for questions like \"show me the error output for this job\", \"when did this log pattern first appear?\", \"how often does this error message occur across runs?\" 52,000 queries across 8,500 investigations We analyzed 8,534 agent sessions and 52,312 queries from our observability pipeline. The agent doesn't stop at one query. It investigates. Starts broad, then drills in. Total rows scanned across all queries to answer one question: Target Sessions Avg queries Median rows P75 P95 Job metadata 8,210 4.0 164K 563K 4.4M Raw log lines 5,413 3.5 4.4M 69M 4.3B Combined 8,534 4.4 335K 5.2M 940M The typical question scans 335K rows across about 3 queries. At P75 it's 5.2 million rows. At P95 it's 940 million rows . The heaviest raw-log sessions, deep investigations tracing error patterns across months of history, scan 4.3 billion rows . The search pattern The agent starts broad and narrows. A typical investigation begins with job metadata: \"what's the failure rate for this workflow?\", \"which jobs failed on this commit?\" These are cheap queries (median 47K rows) against a compact, pre-aggregated materialized view. When it finds something interesting, it drills into raw logs: \"show me the stack trace for this specific failure\", \"has this error message appeared before?\" These are the expensive queries (median 1.1M rows), full-text scans across log output. But this is exactly the kind of search that would take a human minutes of scrolling through GitHub Actions log viewers. The agent averages 4.4 queries per session, but heavy investigations issue many more. A P95 session isn't one big query. It's the agent following a trail, query after query, as it narrows in on a root cause. 5 TiB uncompressed, 154 GiB on disk For the agent to query this fast, the data needs to be structured for it. Up to 300 million log lines flow through on a busy day. We use ClickHouse. The denormalization bet Every log line in our system carries 48 columns of metadata: the full context of the CI run it belongs to. Commit SHA, author, branch, PR title, workflow name, job name, step name, runner info, timestamps, and more. In a traditional row-store, this would be insane. You'd normalize. Run-level metadata in one table, job metadata in another, join at query time. Denormalizing 48 columns onto every single log line sounds like a storage disaster. In ClickHouse's columnar format, it's essentially free. A column like commit_message has the same value for every log line in a CI run, and a single run can produce thousands of log lines. ClickHouse stores those thousands of identical values in sequence. The compression algorithm sees the repetition and compresses it to almost nothing. Column Compression ratio Why commit_message 301:1 Same message for every line in a run (thousands of lines) display_title 160:1 Same PR/commit title across all lines workflow_path 79:1 Same .github/workflows/foo.yml path step_name 52:1 Same step name across hundreds of lines job_name 48:1 Same job name across hundreds/thousands of lines The agent asks arbitrary questions. One might filter by commit author, the next by runner label, the next by step name. Without denormalization, every one of those requires a join. With it, they're all column predicates. The numbers Layer Size Raw log text ( line_content uncompressed) 664 GiB All 48 columns uncompressed 5.31 TiB On disk (compressed) 154 GiB Compression ratio 35:1 The raw log text alone is 664 GiB. Adding all 48 columns of metadata inflates it to 5.31 TiB uncompressed, 8x the raw text. On disk, the whole thing compresses to 154 GiB. ClickHouse stores 8x more data (all the enriched metadata) in a quarter of the size of the raw text alone. That's about 21 bytes per log line on disk, including all 48 columns. Yes, really. 21 bytes for a log line plus its commit SHA, author, branch, job name, step name, runner info, and 41 other fields. Where the storage actually goes Not all columns compress equally. The unique-per-row columns (log text, timestamp, line number) compress modestly and dominate storage. The metadata columns, which repeat across thousands of lines, are nearly free. Column On disk % of total Compression ratio line_content (log text) 53.2 GiB 34.7% 12.5:1 ts (nanosecond timestamp) 15.7 GiB 10.2% 3.7:1 line_number 12.4 GiB 8.1% 2.3:1 job_name 8.2 GiB 5.4% 48:1 runner_name 4.5 GiB 2.9% 31:1 job_id 3.9 GiB 2.5% 15:1 runner_labels 3.8 GiB 2.5% 52:1 Everything else (41 columns) ~51 GiB ~33% varies The top three ( line_content , ts , line_number ) account for 53% of all storage. Everything else is repeated metadata that compresses to almost nothing. Query performance We use a few ClickHouse patterns that keep things fast: Primary key design means the data is physically sorted for our access pattern. The sort order is (org, ts, repository, run_id, ...) , so every query is scoped to one organization and a time range, and ClickHouse skips everything else without reading it. Skip indexes let ClickHouse avoid scanning data it doesn't need. We use bloom filters on 14 columns (org, repository, job name, branch, commit SHA, etc.) and an ngram bloom filter on line_content for full-text search. When the agent searches for an error message across billions of log lines, ClickHouse checks the ngram index to skip granules that can't contain the search term, turning a full table scan into a targeted read. Materialized views pre-compute aggregations on insert. When the agent asks \"what's the failure rate for this workflow over the last 30 days?\", the answer is already computed. The aggregation happened when the data was written. Async inserts give us high write throughput without building our own batching layer. We fire-and-forget individual inserts, and ClickHouse batches them internally. Query latency across 52K queries: Target Queries Median P75 P95 Job metadata 33K 20ms 30ms 80ms Raw log lines 19K 110ms 780ms 18.1s Job metadata queries return in 20ms at the median. Raw log queries, scanning a million rows at the median, come back in 110ms. Latency scales roughly linearly with rows scanned: Rows scanned Queries Median latency P95 latency < 1K 1,621 10ms 50ms 1K-10K 2,608 20ms 50ms 10K-100K 27,044 20ms 50ms 100K-1M 8,515 40ms 390ms 1M-10M 7,199 90ms 1.2s 10M-100M 2,630 690ms 6.8s 100M-1B 1,814 6.8s 30.6s 1B+ 1,029 31s 82s 10x more rows ‚âà 10x more latency. 60% of all queries scan under 100K rows and return in under 50ms, fast enough that the agent can fire off several per second without breaking stride. At the extreme end, the agent occasionally scans over a billion rows in a single query; even those complete in about 30 seconds at the median. Ingesting through GitHub's rate limit None of the above works without fresh data. The agent needs to reason about the build that just failed, not one from an hour ago. The rate limit constraint GitHub's API gives you 15,000 requests per hour per App installation (5,000 on non-Enterprise plans). That sounds generous until you're continuously polling workflow runs, jobs, steps, and log output across dozens of active repositories. A single commit can spawn hundreds of parallel jobs, each producing logs you need to fetch. And ingestion isn't the only thing hitting the API. When the agent investigates a failure, it pulls PR metadata, reads file diffs, posts comments, and opens pull requests. All of that counts against the same 15,000-request budget. Throttle ingestion too aggressively and your data goes stale. Throttle too little and you starve the agent of the API access it needs to do its job. Early on, we hit this. Our ingestion would slam into the rate limit, get blocked for the remainder of the hour, and fall behind. By the time it caught up, we were ingesting logs from 30+ minutes ago. For an agent that needs to reason about the build that just failed, that's useless. If an engineer has to wait for the agent to catch up, they've already context-switched to investigating manually. The fix was throttling: spreading requests evenly across the rate limit window instead of bursting. We cap ingestion at roughly 3 requests per second, keeping about 4,000 requests per hour free for the agent. Our sustained request rate: Our rate limit budget over time: That sawtooth is the steady state. Each downward slope is us consuming API calls; each vertical jump is the hourly limit resetting. At peak, we burn through most of the budget before the window resets, with headroom left for the agent. Once we trusted the throttling, we pushed the ingestion rate about 20% higher: The dashed line marks the deployment. The budget draws down more aggressively after the change. We're consuming more of the available headroom per window, while still never fully exhausting it. Fresher data, acceptable margin. We target under 5 minutes at P95 for ingestion delay, the time between an event happening on GitHub and it being queryable in our system. Most of the time, we're at a few seconds. Durable execution Both our ingestion pipeline and our agent run on Inngest , a durable execution engine. When either one hits a rate limit, it doesn't crash, retry blindly, or spin in a loop. It suspends . GitHub's rate limit response headers tell you exactly how long you need to wait. We read that value, add 10% jitter to avoid a thundering herd when the limit resets, and suspend the execution. The full state is checkpointed: progress through the workflow, which jobs have been fetched, where we are in the log pagination. When the wait is over, execution resumes at exactly the point it left off. No re-initialization, no duplicate work. It picks up the next API call as if nothing happened. Compare this to the alternative: retry logic, state recovery, deduplication. Every function needs to be idempotent. Every interrupted batch needs to be reconciled. With durable execution, the rate limit is just a pause button. Absorbing traffic spikes CI activity is bursty. Someone merges a big PR, a release branch gets cut, three teams push at the same time. Our function throughput: The grey line is queued work. It spikes to 3,000+ during bursts of CI activity. The blue and green lines (started and ended) stay smooth at 800-1,000. The execution engine absorbs the spikes and processes work at a steady rate. Ingestion delay over time: Spikes during peak activity, but the system recovers. The 5-minute P95 target holds: bursts push delay up briefly, then it drops back to seconds once the queue drains. Nobody puts \"we built a really good rate limiter\" on their landing page. But without fresh, queryable data, your agent can't answer the question that actually matters: did I break this, or was it already broken? We're building Mendral (YC W26). We spent a decade building and scaling CI systems at Docker and Dagger, and the work was always the same: stare at logs, correlate failures, figure out what changed. Now we're automating it.",
      "cover_image_url": "https://mendral.com/og?title=LLMs%20Are%20Good%20at%20SQL.%20We%20Gave%20Ours%20Terabytes%20of%20CI%20Logs."
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Here‚Äôs your first look at Kratos in Amazon‚Äôs God of War show",
      "url": "https://www.theverge.com/streaming/886008/amazon-god-of-war-kratos-image",
      "published": "2026-02-27T15:19:14+00:00",
      "summary": "Amazon has slowly been teasing out casting details for its live-action adaptation of God of War, and now we have our first look at the show. It's a single image but a notable one showing protagonist Kratos and his son Atreus. The characters are played by Ryan Hurst and Callum Vinson, respectively, and they look [&#8230;]",
      "content_text": "Amazon has slowly been teasing out casting details for its live-action adaptation of God of War , and now we have our first look at the show. It‚Äôs a single image but a notable one showing protagonist Kratos and his son Atreus. The characters are played by Ryan Hurst and Callum Vinson, respectively, and they look relatively close to their video game counterparts. There aren‚Äôt a lot of other details about the show just yet, but this is Amazon‚Äôs official description: The God of War series storyline follows father and son Kratos and Atreus as they embark on a journey to spread the ashes of their wife and mother, Faye. Through their adventures, Kratos tries to teach his son to be a better god, while Atreus tries to teach his father how to be a better human. That sounds a lot like the recent soft reboot of the franchise, which started with 2018‚Äôs God of War and continued through Ragnar√∂k in 2022 . For the Amazon series, Ronald D. Moore, best-known for his work on For All Mankind and Battlestar Galactica , will serve as showrunner. The rest of the cast includes: Mandy Patinkin (Odin), Ed Skrein (Baldur), Max Parker (Heimdall), √ìlafur Darri √ìlafsson (Thor), Teresa Palmer (Sif), Alastair Duncan (Mimir), Jeff Gulka (Sindri), and Danny Woodburn (Brok). While production is underway on the God of War series, there‚Äôs no word on when it might start streaming. While Amazon appears to be stepping back from making games, it‚Äôs been pushing hard on adaptations for Prime Video. In addition to God of War , there‚Äôs Fallout , which just wrapped up season 2 , and an upcoming Tomb Raider show starring Sophie Turner .",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/Start-of-Production-Image.jpg?quality=90&strip=all&crop=0%2C3.4666176674128%2C100%2C93.066764665174&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Samsung‚Äôs Galaxy S26 AI camera features are a photography nightmare",
      "url": "https://www.theverge.com/podcast/885942/samsung-galaxy-s26-ai-camera-nightmare-vergecast",
      "published": "2026-02-27T15:15:52+00:00",
      "summary": "In many ways, Samsung's new phones are fairly normal upgrades. The S26 lines come with some useful new things - particularly the Privacy Display on the S26 Ultra, which looks like an extremely cool bit of tech and a really useful new feature - and a lot of iterative year-over-year changes. The new camera features, [&#8230;]",
      "content_text": "In many ways, Samsung‚Äôs new phones are fairly normal upgrades . The S26 lines come with some useful new things ‚Äî particularly the Privacy Display on the S26 Ultra , which looks like an extremely cool bit of tech and a really useful new feature ‚Äî and a lot of iterative year-over-year changes. The new camera features, on the other hand, are neither of those things. They‚Äôre something worse. Something scarier. On this episode of The Vergecast , Nilay and David discuss the new phones, then dive into the ways in which the S26‚Äôs AI camera features seem to be clearly designed to change the whole idea of what happens when you try to take a picture. For that matter, it‚Äôs not even clear that what you‚Äôre taking is a ‚Äúpicture‚Äù anymore. We‚Äôve been talking about the ‚ÄúWhat is a photo?‚Äù apocalypse for some time, and the S26 feels like a crossing of a line. All in the service of some cupcakes. After that, the hosts turn to the big shakeup inside the Xbox team . With Phil Spencer and Sarah Bond out, and Asha Sharma in, it‚Äôs time to wonder what happened to the Xbox, and whether Sharma or anyone can fix it. Microsoft‚Äôs gaming problems have been around for years and are the result of a string of bad bets and bad decisions. What would it take to get back on course, and is ‚Äúback on course‚Äù even possible anymore? Finally, in the lightning round, we do another round of Brendan Carr is a Dummy , debate a truly astonishing chart , check in on OpenAI‚Äôs infrastructure spending, and decide once and for all whether Claude is alive. Or, at least, whether Anthropic thinks so . If you want to know more about everything we discuss in this episode, here are some links to get you started, first on the new Samsung devices: And in the lightning round:",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/VRG_VST_0227_Site.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "nanoclaw/repo-tokens at main ¬∑ qwibitai/nanoclaw ¬∑ GitHub",
      "url": "https://github.com/qwibitai/nanoclaw/tree/main/repo-tokens",
      "published": "2026-02-27T15:14:42+00:00",
      "summary": "<p>Small codebases were always a good thing. With coding agents, there's now a huge advantage to having a codebase small enough that an agent can hold the full thing in context.<p>Repo Tokens is a GitHub Action that counts your codebase's size in tokens (using tiktoken) and updates a badge in your README. The badge color reflects what percentage of an LLM's context window the codebase fills: green for under 30%, yellow for 50-70%, red for 70%+. Context window size is configurable and defaults to 200k (size of Claude models).<p>It's a composite action. Installs tiktoken, runs ~60 lines of inline Python, takes about 10 seconds. The action updates the README but doesn't commit, so your workflow controls the git strategy.<p>The idea is to make token size a visible metric, like bundle size badges for JS libraries. Hopefully a small nudge to keep codebases lean and agent-friendly.<p>GitHub: <a href=\"https://github.com/qwibitai/nanoclaw/tree/main/repo-tokens\" rel=\"nofollow\">https://github.com/qwibitai/nanoclaw/tree/main/repo-tokens</a></p> <hr /> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47181471\">https://news.ycombinator.com/item?id=47181471</a></p> <p>Points: 28</p> <p># Comments: 18</p>",
      "content_text": "You can‚Äôt perform that action at this time.",
      "cover_image_url": "https://repository-images.githubusercontent.com/1146738089/83c0975f-09b4-4452-8c80-c5fee3521005"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "Netflix cedes Warner Bros. Discovery to Paramount: ‚ÄúNo longer financially attractive‚Äù",
      "url": "https://arstechnica.com/gadgets/2026/02/netflix-cedes-warner-bros-discovery-to-paramount-no-longer-financially-attractive/",
      "published": "2026-02-27T15:13:48+00:00",
      "summary": "Netflix shares jumped following the announcement.",
      "content_text": "On Thursday, WBD‚Äôs board deemed Paramount‚Äôs revamped offer ‚Äúsuperior,‚Äù giving Netflix four business days to match it. But that same day, Netflix, which had recently emphasized its willingness to walk away from mergers it deems overly expensive, said it would no longer pursue the acquisition. A statement from Netflix co-CEOs Ted Sarandos and Greg Peters issued last night said: The transaction we negotiated would have created shareholder value with a clear path to regulatory approval. However, we‚Äôve always been disciplined, and at the price required to match Paramount Skydance‚Äôs latest offer, the deal is no longer financially attractive, so we are declining to match the Paramount Skydance bid. The CEOs added that the WBD merger ‚Äúwas always a ‚Äònice to have‚Äô at the right price, not a ‚Äòmust have‚Äô at any price.‚Äù Netflix and Paramount‚Äôs stock have continuously declined since Netflix announced its planned merger. Following yesterday‚Äôs announcement, Netflix shares rose by more than 10 percent in after-hours trading, and Paramount shares increased by 5 percent. In a statement quoted by The Hollywood Reporter yesterday, WBD President and CEO David Zaslav said, ‚ÄúOnce our board votes to adopt the Paramount merger agreement, it will create tremendous value for our shareholders. We are excited about the potential of a combined Paramount Skydance and Warner Bros. Discovery and can‚Äôt wait to get started working together telling the stories that move the world.‚Äù The article was edited to correct ticking fee information.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-2258061457-1152x648.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Victory! Tenth Circuit Finds Fourth Amendment Doesn‚Äôt Support Broad Search of Protesters‚Äô Devices and Digital Data",
      "url": "https://www.eff.org/deeplinks/2026/02/victory-tenth-circuit-finds-fourth-amendment-doesnt-support-broad-search-0",
      "published": "2026-02-27T15:09:04+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.eff.org/deeplinks/2026/02/victory-tenth-circuit-finds-fourth-amendment-doesnt-support-broad-search-0\">https://www.eff.org/deeplinks/2026/02/victory-tenth-circuit-finds-fourth-amendment-doesnt-support-broad-search-0</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47181391\">https://news.ycombinator.com/item?id=47181391</a></p> <p>Points: 81</p> <p># Comments: 10</p>",
      "content_text": "In a big win for protesters‚Äô rights, the U.S. Court of Appeals for the Tenth Circuit overturned a lower court‚Äôs dismissal of a challenge to sweeping warrants to search a protester‚Äôs devices and digital data and a nonprofit‚Äôs social media data. The case, Armendariz v. City of Colorado Springs , arose after a housing protest in 2021, during which Colorado Springs police arrested protesters for obstructing a roadway. After the demonstration, police also obtained warrants to seize and search through the devices and data of Jacqueline Armendariz Unzueta, who they claimed threw a bike at them during the protest. The warrants included a search through all of her photos, videos, emails, text messages, and location data over a two-month period, as well as a time-unlimited search for 26 keywords, including words as broad as ‚Äúbike,‚Äù ‚Äúassault,‚Äù ‚Äúcelebration,‚Äù and ‚Äúright,‚Äù that allowed police to comb through years of Armendariz‚Äôs private and sensitive data‚Äîall supposedly to look for evidence related to the alleged simple assault. Police further obtained a warrant to search the Facebook page of the Chinook Center, the organization that spearheaded the protest, despite the Chinook Center never having been accused of a crime. The district court dismissed the civil rights lawsuit brought by Armendariz and the Chinook Center, holding that the searches were justified and that, in any case, the officers were entitled to qualified immunity . The plaintiffs, represented by the ACLU of Colorado, appealed. EFF‚Äîjoined by the Center for Democracy and Technology, the Electronic Privacy Information Center, and the Knight First Amendment Institute at Columbia University‚Äîwrote an amicus brief in support of that appeal. In a 2-1 opinion, the Tenth Circuit reversed the district court‚Äôs dismissal of the lawsuit‚Äôs Fourth Amendment search and seizure claims. The court painstakingly picked apart each of the three warrants and found them to be overbroad and lacking in particularity as to the scope and duration of the searches. The court further held that in furnishing such facially deficient warrants, the officers violated ‚Äúclearly established‚Äù law and thus were not entitled to qualified immunity. Although the court did not explicitly address the First Amendment concerns raised by the lawsuit, it did note the backdrop against how these searches were carried out, including animus by Colorado Springs police leading up to the housing protest. It is rare for appellate courts to call into question any search warrants. It‚Äôs even rarer for them to deny qualified immunity defenses. The Tenth Circuit‚Äôs decision should be celebrated as a big win for protesters and anyone concerned about police immunity for violating people‚Äôs constitutional rights. The case is now remanded back to the district court to proceed‚Äîand hopefully further vindicate the privacy rights we all have in our devices and digital data.",
      "cover_image_url": "https://www.eff.org/files/banner_library/protest-2024-2.jpg"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "NASA shakes up its Artemis program to speed up lunar return",
      "url": "https://arstechnica.com/staff/2026/02/nasa-shakes-up-its-artemis-program-to-speed-up-lunar-return/",
      "published": "2026-02-27T15:08:08+00:00",
      "summary": "\"Launching SLS every three and a half years or so is not a recipe for success.\"",
      "content_text": "At the core of Isaacman‚Äôs concerns is the low flight rate of the SLS rocket and Artemis missions. During past exploration missions, from Mercury through Gemini, Apollo, and the Space Shuttle program, NASA has launched humans on average about once every three months. It has been nearly 3.5 years since Artemis I launched. ‚ÄúThis is just not the right pathway forward,‚Äù Isaacman said. A senior NASA official, speaking on background to Ars, noted that the space agency has experienced hydrogen and helium leaks during both the Artemis I and Artemis II pre-launch preparations, and these problems have led to monthslong delays in launch. ‚ÄúIf I recall, the timing between Apollo 7 and 8 was nine weeks,‚Äù the official said. ‚ÄúLaunching SLS every three and a half years or so is not a recipe for success. Certainly, making each one of them a work of art with some major configuration change is also not helpful in the process, and we‚Äôre clearly seeing the results of it, right?‚Äù The goal therefore is to standardize the SLS rocket into a single configuration in order to make the rocket as reliable as possible, and launching as frequently as every 10 months. NASA will fly the SLS vehicle until there are commercial alternatives to launch crew to the Moon, perhaps through Artemis V as Congress has mandated, or perhaps even a little longer. Is everyone on board? The NASA official said all of the agency‚Äôs key contractors are on board with the change, and senior leaders in Congress have been briefed on the proposed changes. The biggest opposition to these proposals would seemingly come from Boeing, which is the prime contractor for the Exploration Upper Stage, a contract worth billions of dollars to develop a more powerful rocket that was due to launch for the first time later this decade. However, in a NASA news release, Boeing appeared to offer at least some support for the revised plans.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2025/07/eus_art-1152x648-1753395940.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Spotify is rolling out Audiobook Charts",
      "url": "https://techcrunch.com/2026/02/27/spotify-is-rolling-out-audiobook-charts/",
      "published": "2026-02-27T15:07:42+00:00",
      "summary": "Similar to the streaming giant's Music and Podcast Charts, the Audiobook Charts will be updated weekly and highlight the top audiobooks overall and by genre",
      "content_text": "Spotify is launching Audiobook Charts for the U.S. and U.K., the company announced on Friday. Similar to the streaming giant‚Äôs Music and Podcast Charts, the Audiobook Charts will be updated weekly and highlight the top audiobooks overall and by genre. These rankings are based on listening behavior and engagement on the streaming service, the company says. The new charts are accessible to both free and paying users within the audiobooks hub. You can find them by tapping the search button in the app and selecting the ‚ÄúAudiobooks‚Äù tile to enter the hub. Then, you need to scroll down to the ‚ÄúDive deeper‚Äù section to find the charts. The move marks Spotify‚Äôs latest investment in the audiobooks space, following its official support of the format in 2022. Since then, Spotify has continued investing in audiobooks with additional features like the recently-launched ‚ÄúPage Match‚Äù tool , which lets users scan a page from a physical book to instantly transition to that spot in the audiobook, and ‚ÄúAudiobook Recaps,‚Äù which are short audio summaries to catch you up on what you‚Äôve already read so far. Spotify says the new Audiobook Charts will benefit both readers and authors by giving listeners a trusted way to discover popular titles, while also creating new opportunities for authors and the publishing industry to reach wider audiences. ‚ÄúAs we‚Äôve proven with Music and Podcasts Charts, when content is easier to access, discover, and enjoy, the demand grows,‚Äù said Duncan Bruce, Spotify‚Äôs Director of Audiobook Partnerships and Licensing, in a blog post . ‚ÄúWe are delighted to now bring that to audiobooks, to help provide even more ways for users, publishers, and authors to discover what‚Äôs trending on Spotify, and make books more connected with culture in real time.‚Äù It‚Äôs worth noting that Spotify isn‚Äôt only interested in audiobooks, as the streaming giant also recently ventured into physical book sales. Spotify announced earlier this month that users in the U.S. and the U.K. will soon be able to purchase physical copies of books directly within the app through a partnership with Bookshop.org.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/spotify-logo-phone-GettyImages-2236404299.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Pok√©mon Winds and Waves launch on the Switch 2 in 2027",
      "url": "https://www.theverge.com/games/885321/pokemon-winds-and-waves-trailer-browt-pombom-gecua",
      "published": "2026-02-27T15:04:31+00:00",
      "summary": "It's time to say goodbye to the Paldea region because a new generation of mainline Pok&#233;mon games are on the way. During today's big Pok&#233;mon Presents stream, Nintendo announced that Pok&#233;mon Wind and Waves are the next installments in the core game series. The games will launch in 2027 and are exclusive for the Nintendo [&#8230;]",
      "content_text": "It‚Äôs time to say goodbye to the Paldea region because a new generation of mainline Pok√©mon games are on the way. During today‚Äôs big Pok√©mon Presents stream , Nintendo announced that Pok√©mon Wind and Waves are the next installments in the core game series. The games will launch in 2027 and are exclusive for the Nintendo Switch 2. Nintendo also shared a trailer showcasing a new trio of starter pok√©mon ‚Äî Browt, Pombon, and Gecua ‚Äî and a number of different environments you‚Äôll be able to explore as you play through the games. In addition to establishing that Wind and Waves takes place in an island setting, the trailer really highlights how much more detailed and complex the games‚Äô environments are compared to past titles like Scarlet / Violet and Legends: Z-A. It seems like you‚Äôll be able to explore dense jungles, caves full of magma, and beneath the ocean all while encountering wild pok√©mon. In a press release, Nintendo said that Wind and Waves will be open-world games, and the company also noted that Brazilian Portuguese will officially be supported as a selectable language. 2027 is still a ways out from now, but Winds and Waves ‚Äô definitely seems like it‚Äôs going to be worth the wait. And with Pokopia about to drop next week, there‚Äôs going to be plenty to keep Pok√©mon fans busy in the meantime.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/screenshot_2026-02-27_at_9.41.37___am.png?quality=90&strip=all&crop=0%2C3.1791305253835%2C100%2C93.641738949233&w=1200"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Last 24 hours to get Disrupt 2026 tickets at the lowest rates of the year",
      "url": "https://techcrunch.com/2026/02/27/last-24-hours-to-get-techcrunch-disrupt-2026-tickets-at-the-lowest-rates-of-the-year/",
      "published": "2026-02-27T15:00:00+00:00",
      "summary": "The lowest rates of the year for TechCrunch Disrupt 2026 end after today. Prices go up at 11:59 p.m. PT. Don't miss connecting with 10,000 founders, investors, and operators, and key takeaways from 250+ industry leaders. Register now to save up to $680, or up to 30% on group passes.",
      "content_text": "Today is it! When the clock hits 11:59 p.m. PT , the lowest ticket rates of the year for TechCrunch Disrupt 2026 go up. No extensions. No second chances. The same access will cost more tomorrow. If you‚Äôre planning to attend, this is your final window to lock in up to $680 off your pass or up to 30% off group passes . After tonight, this year‚Äôs biggest savings disappear. Register now . Disrupt: Your launchpad in the tech ecosystem If you‚Äôre raising capital, hiring top talent, launching your startup, or hunting for your next portfolio company, missing Disrupt from October 13‚Äì15 at San Francisco‚Äôs Moscone West isn‚Äôt just inconvenient. It‚Äôs a missed opportunity to move ahead while others hesitate. Here‚Äôs what you gain when you attend: Actionable insights from builders, operators, and VCs shaping today‚Äôs market Direct access to investors for your next round, or founders aligned with your portfolio Early visibility into breakthrough innovations before they hit the broader market High-impact connections that turn into partnerships, funding, and career moves Image Credits: Kimberly White / Getty Images How Disrupt delivers real value 10,000+ founders, operators, and VCs under one roof 250+ market leaders leading 200+ sessions across industry stages, roundtables, and breakouts 20,000+ curated 1:1 and small-group meetings built for outcomes 80+ Side Events across the Bay Area for deeper networking and deal flow Dedicated programming for founders and investors Image Credits: Slava Blazer Photograpy The founder‚Äìinvestor power zone Founder Pass : Get the insights, tools, and investor access you need to scale. Investor Pass : Discover breakout startups and expand your portfolio with curated matchmaking. Where industry heavyweights speak candidly Disrupt has long been a stage for founders and investors who define eras. The voices you‚Äôll hear are candid, tactical, and often unfiltered. The 2026 agenda drops soon. Keep an eye on the event site . Image Credits: Kimberly White / Getty Images Previous speakers have included leaders of industry-defining startups and top-tier venture firms, including: Techcrunch event Boston, MA | June 9, 2026 Image Credits: Kimberly White / Getty Images The lowest Disrupt ticket rates of the year vanish after today Tonight at 11:59 p.m. PT , the lowest ticket rates of the year to TechCrunch Disrupt 2026 are gone. After today, you pay more. Register now . Lock in up to $680 in savings. Or bring your team and save up to 30% with community passes of four or more.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/TCD26_24Hours-16X9-Dark.png?resize=1200,675"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Huel tries to solve the ‚Äòburden‚Äô of eating",
      "url": "https://www.theverge.com/column/885444/optimizer-huel-wellness-supplements-meal-replacement",
      "published": "2026-02-27T15:00:00+00:00",
      "summary": "This is Optimizer, a weekly newsletter sent every Friday from Verge senior reviewer Victoria Song that dissects and discusses the latest gizmos and potions that swear they're going to change your life. Opt in for Optimizer here. In 2017, I was at rock bottom. My dad's health was rapidly failing; my relationship with my mom [&#8230;]",
      "content_text": "This is Optimizer , a weekly newsletter sent every Friday from Verge senior reviewer Victoria Song that dissects and discusses the latest gizmos and potions that swear they‚Äôre going to change your life. Opt in for Optimizer here . In 2017, I was at rock bottom. My dad‚Äôs health was rapidly failing; my relationship with my mom was on the rocks. I was in a not-so-great place in my career. My undiagnosed polycystic ovary syndrome was wreaking havoc on my health. I was already in a dark place when a situationship broke my heart, my roommate notified me they were moving out, and I received a surprise $5,000 vet bill for my dog. Stressed, depressed, and a hot mess, I stopped eating. Physically, I wanted to eat. Mentally, I simply couldn‚Äôt. A week into my involuntary fast, my therapist suggested meal replacement drinks until we could work out a solution. For six weeks, I forced myself to drink two chocolate Ensures a day until I managed to start piecing my life back together. It was a miserable, terrifying time, in which I lost 20 percent of my body weight. I was recently transported back to that time thanks to a Huel ad . If you‚Äôre unaware, Huel is a wellness brand that sells meal replacement drinks, powders, supplements, instant meals, and daily greens. It‚Äôs probably best known for its powders and ready-made shakes, but this particular ad is for its daily greens drink. A manicured hand snaps open a can as wistful violins play over a series of text: Just went through a breakup. Is getting married next month. Just lost their job. Just need a break from the world. Looking for community. Just got a promotion. Just surviving the day. The caption reads, ‚ÄúNo matter the moment, Daily Greens are ready to drink,‚Äù punctuated by a green heart emoji. It just so happens that when I took a look at AG1‚Äôs science-washed marketing in a recent Optimizer , several readers requested I do the same for Huel. The two products are similar. Both aim to make up for a perceived lack of nutrients in an ordinary person‚Äôs diet. Both employ fit celebrities and influencers as spokespersons. AG1 has Hugh Jackman and Andrew Huberman, while Huel‚Äôs site boasts actor Idris Elba, former Yankee Alex Rodriguez, and Steven Bartlett from the Diary of a CEO podcast. Whereas AG1 leaned on dubious terms like ‚Äúclinically backed,‚Äù Huel uses framing like ‚Äúnutritionally complete‚Äù and ‚Äúscientifically supported.‚Äù And while AG1 is clearly a greens supplement, Huel lives in a grayer area between greens supplements, protein powders, meal replacement, and ready-made food. Buzzy phrases like ‚Äúnutrient-dense,‚Äù ‚Äúsuperfoods,‚Äù ‚Äúplant-based,‚Äù and ‚Äúsustainable‚Äù also make appearances. Perusing Huel‚Äôs marketing, the meal replacement narrative is what sticks out the most. ‚ÄúHuel is an ally on my busiest days,‚Äù reads Bartlett‚Äôs testimonial. ‚ÄúI always have a couple in the fridge at home ‚Äî it‚Äôs my go-to when I realize I haven‚Äôt eaten,‚Äù reads another from Premier League Hall of Famer Gary Neville. Other ideas that frequently pop up: no prep, no need to buy food, cost efficiency, and staying healthy while on the go. It‚Äôs the solution ‚Äúfor your most inconvenient meal,‚Äù and ‚Äúeverything your body needs.‚Äù This isn‚Äôt the first time we‚Äôve seen a tech- and wellness-adjacent meal replacement pitch. Remember Soylent ? But the science behind meal replacement is more complicated than just packing nutrients into a bottle. For starters, meal replacement supplements are not meant to replace food entirely. Even if a shake contains all the essential vitamins, minerals, and proteins, supplemental forms aren‚Äôt necessarily the same as what you‚Äôd get from eating whole foods. According to Stanford Medicine , absorption is generally better when those same micronutrients come from foods. Heat processing for shelf stability can also reduce potency. Since supplements aren‚Äôt regulated, evaluating sourcing, purity, and dosage can be hard without independent testing. (Huel does provide quality control information on its site, and says it‚Äôs received NSF International certification for its Black Edition product.) What does ‚Äònutritionally complete‚Äô actually mean? Take the Black Edition of its ready-made drink: Huel says you get 7g of fiber from flaxseed, chicory, and corn. That sounds great on the surface. Most people don‚Äôt get the daily recommended 25 to 38g of fiber, 7g is high for this kind of product, and Huel includes both soluble and insoluble forms. But scientists have found that not all dietary fiber supplements are created equal. Chicory root fiber, or inulin, is often controversial as, in some people, it can cause gastrointestinal distress, inflammation, and potentially liver damage if taken in excess. In a diverse diet, you‚Äôd be getting even more forms of soluble and insoluble fiber, so some inulin might not be a problem. But if you‚Äôre prone to gas, bloating, or have irritable bowel syndrome? Heavily relying on Huel‚Äôs limited fiber sources might not be your best option. In 2022, Huel commissioned a peer-reviewed study in Frontiers in Nutrition . In it, Huel recruited 20 participants to subsist on Huel ‚Äî and only Huel ‚Äî for four weeks. Good news: They didn‚Äôt die. Some micronutrient levels improved, compared to one monitored week of eating regularly. Other micronutrient levels didn‚Äôt improve. Many lost weight, reduced their BMI and waist circumference, and lost visceral fat ( the bad kind ). The thing is, the study‚Äôs primary conclusion is that subsisting for four weeks on Huel won‚Äôt negatively impact your micronutrient levels. The study‚Äôs researchers also note that the weight loss and reduced BMI, waist circumference, and visceral fat were likely due to the fact that the participants consistently could not meet calorie requirements while on a Huel-only diet. It‚Äôs less that Huel was ‚Äúhealthy‚Äù than participants found it hard to eat a lot of Huel, and were thus in a prolonged calorie deficit. On its site, Huel caveats that it doesn‚Äôt advocate only eating its product, but says this study ‚Äúpretty conclusively‚Äù shows its product is ‚Äúhealthy.‚Äù But a single study in a clinical setting ‚Äî which doesn‚Äôt reflect real-life use ‚Äî and a limited sample size is far from conclusive. In 2024, a meta-analysis in Nutrients of 6,770 adults found that ‚Äúdaily and weekly [meal replacement] consumption were associated with higher risks of all-cause mortality.‚Äù I bought Huel‚Äôs ready-to-drink Black Edition in chocolate for research. It cost me roughly $18 at Target for a box of four bottles. I‚Äôve been sipping one over the course of writing this newsletter and I cannot lie: I am on the struggle bus. After two hours of writing and researching, I still have over a quarter of the 500ml bottle left. It tastes a bit like wet chalk. After it slithers down my gullet, there‚Äôs a distinct aftertaste in my mouth that reminds me of my time drinking chocolate Ensure. Taste is subjective, but I‚Äôm inclined to believe that the pants of Huel‚Äôs wellness influencer partners are aflame. On that marketing front, I give Huel a D. In other areas, however, Huel is far from the worst wellness brand I‚Äôve seen. Its study was a little silly and I don‚Äôt love that it‚Äôs framed as ‚Äúconclusive.‚Äù However, on its website summarizing the study, it does disclose some of the study‚Äôs drawbacks and flaws. (It does so with a slightly positive spin, but I‚Äôll take that information over artfully omitting it entirely.) It has science pages for each of its individual products, which give a breakdown of each ingredient included, the reasoning behind including it, and reference links to outside studies supporting those decisions. For example, on the science site for its Black Edition powder, it breaks down why it chose peas and brown rice for protein. It explains it chose two sources because plant protein doesn‚Äôt always include all nine essential amino acids required from your diet. When it claims protein is more satiating than other macronutrients, it cites this study . Most people will not click each link, and I only had the patience to click through roughly 20 percent. Some were relatively old but well cited; others were less convincing. But, compared to other wellness brands I‚Äôve reviewed , I appreciated that the studies were clearly labeled as references and not as Huel‚Äôs own research. Cooking isn‚Äôt always fun, but it took me five hours to choke down this ‚Äòultimate meal in a bottle.‚Äô Huel‚Äôs biggest fault is perhaps playing fast and loose with phrasing like ‚Äúnutritionally complete‚Äù and videos that suggest this is a much more convenient alternative to cooking ‚Äî and that that convenience is a good thing. (Never mind that most dieticians will tell you whole food sources of nutrients are better for you.) Like Soylent, that plays into tech-adjacent productivity narratives, where somehow taking the time and effort to eat a well-balanced meal is a burden. Subtly placing that next to claims of ‚Äúsustainable‚Äù ‚Äúplant-based food,‚Äù and a convincing ‚Äú$2.65 per meal‚Äù badge for its powder? It‚Äôs not a huge jump for someone to think, ‚ÄúWow, I can be healthy, not have to cook, save money, and eat something that‚Äôs not too bad for the planet?‚Äù Huel has gotten into hot water for misleading advertising. Remember how I mentioned podcaster Steven Bartlett‚Äôs glowing testimonial earlier? Multiple ads were banned by the UK‚Äôs Advertising Standards Authority because he failed to disclose that, at the time, he was a director and investor at Huel. The ASA also banned Huel ads claiming that using it as a healthy meal replacement could lead to lower food bills. Huel claimed a month‚Äôs worth was only ¬£50. The agency found that was only true if you ate Huel once a day, and the true cost was ¬£350. There are some truths baked into Huel‚Äôs marketing. Meal prepping does suck . Sometimes you are too busy, and grabbing a bottle of Huel ‚Äî as blah as it is ‚Äî is likely cheaper, and potentially more nutrient dense, than junk food. Sometimes, meal replacement or supplementation is appropriate ‚Äî especially in cases where you might not be able to eat solid food, like after a surgery or while managing a chronic illness. Take it from me, someone who did need meal replacement as an intervention at one point in my life. At no point did that process bring relief or joy. I was far from my optimal self. While I did get complimented for my dramatic weight loss, I was physically so weak that I barely had enough energy to crawl out of bed, let alone work a demanding job. Whatever savings I had from not buying food, it wasn‚Äôt worth it. At the end of the day, something like Huel is best thought of as a temporary, occasional ‚Äúlesser of two evils.‚Äù That‚Äôs not the same thing as healthy. Photography by Victoria Song / The Verge Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Victoria Song Column Health Optimizer Science",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/huel1.jpg?quality=90&strip=all&crop=0%2C9.756192857701%2C100%2C80.487614284598&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "OpenAI snags $110 billion in investments from Amazon, Nvidia, and Softbank",
      "url": "https://www.theverge.com/ai-artificial-intelligence/885958/openai-amazon-nvidia-softback-110-billion-investment",
      "published": "2026-02-27T14:55:16+00:00",
      "summary": "OpenAI has closed another round of funding, totalling $110 billion being newly committed to the maker of ChatGPT, which it says has more than 900 million weekly active users and over 50 million consumer subscribers. Amazon is investing $50 billion and striking a deal that includes plans for custom models and more. Nvidia and SoftBank [&#8230;]",
      "content_text": "OpenAI has closed another round of funding , totalling $110 billion being newly committed to the maker of ChatGPT, which it says has more than 900 million weekly active users and over 50 million consumer subscribers. Amazon is investing $50 billion and striking a deal that includes plans for custom models and more. Nvidia and SoftBank are each contributing $30 billion, as well, even as the Wall Street Journal notes that Nvidia‚Äôs previous $100 billion investment plan is ‚Äúon ice.‚Äù This marks another massive influx of cash for the company that‚Äôs now valued at $730 billion, and previously closed a $40 billion round in 2025. At the time, it was the largest private tech deal on record. The investment from Amazon is more than just an injection of cash. The companies are entering a partnership that will potentially allow Amazon to play catch-up in the AI market. The two companies will be collaborating on custom models intended to power ‚Äúcustomer-facing applications‚Äù like Alexa. It will also make AWS a third-party provider of OpenAI Frontier, its enterprise-facing platform for building, deploying, and managing AI agents that will run on Amazon‚Äôs Trainium chips. Amazon is investing just $15 billion up front, with the additional $35 billion being delivered as certain milestones are met. Rumors have indicated that, like its deal with Microsoft, those milestones include mentions of reaching AGI. OpenAI went out of its way to reiterate its commitment to its partnership with Microsoft . But a reworking of the deal between the two companies is what has allowed OpenAI to pursue the partnership with Amazon, as Microsoft has also reached farther afield and begun working with Anthropic . In the midst of all this, the company is rumored to be launching a smart speaker in early 2027 , striking content deals with Disney , and fending off growing competition from the likes of Anthropic and Google . It‚Äôs also potentially working towards an IPO, as CEO Sam Altman told CNBC that, ‚ÄúWe are open to going public at the right time.‚Äù",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/12/STK201_SAM_ALTMAN_CVIRGINIA_D.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "OpenAI's $110B funding round (investments from Amazon, Nvidia, SoftBank)",
      "url": "https://www.reuters.com/business/retail-consumer/amazon-invest-50-billion-openai-2026-02-27/",
      "published": "2026-02-27T14:44:52+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.reuters.com/business/retail-consumer/amazon-invest-50-billion-openai-2026-02-27/\">https://www.reuters.com/business/retail-consumer/amazon-invest-50-billion-openai-2026-02-27/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47181051\">https://news.ycombinator.com/item?id=47181051</a></p> <p>Points: 41</p> <p># Comments: 31</p>",
      "content_text": "<p>Article URL: <a href=\"https://www.reuters.com/business/retail-consumer/amazon-invest-50-billion-openai-2026-02-27/\">https://www.reuters.com/business/retail-consumer/amazon-invest-50-billion-openai-2026-02-27/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47181051\">https://news.ycombinator.com/item?id=47181051</a></p> <p>Points: 41</p> <p># Comments: 31</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "After Zomato, Deepinder Goyal returns with a $54M brain-monitoring bet",
      "url": "https://techcrunch.com/2026/02/27/after-zomato-deepinder-goyal-returns-with-a-54m-brain-monitoring-bet/",
      "published": "2026-02-27T14:40:39+00:00",
      "summary": "Zomato co-founder Deepinder Goyal's new wearable startup Temple has raised $54 million in a friends-and-family round at a post-money valuation of about $190 million.",
      "content_text": "Weeks after stepping down as CEO from food delivery service Zomato and its parent Eternal, Indian entrepreneur Deepinder Goyal is back with a $54 million raise for wearable startup Temple , part of what the 43-year-old earlier described as a shift toward ‚Äúhigher-risk exploration and experimentation.‚Äù On Friday, Goyal said in a post on X that Temple had raised funds in a friends-and-family round from founder friends and early Zomato backers, at a post-money valuation of about $190 million. More than 30 employees participated at the same valuation, he said. Goyal is leading the funding round, followed by Steadview Capital, according to regulatory filings reviewed by TechCrunch. Other investors include Peak XV Partners, Info Edge Ventures, and Dharana Capital, alongside angel investors such as Vijay Shekhar Sharma of Paytm, Kunal Shah of CRED, Nithin Kamath and Nikhil Kamath of Zerodha, as well as current and former Eternal executives including Akshant Goyal, Aditya Mangla, Kunal Swarup, Akriti Chopra, and Rahul Ganjoo. Goyal stepped down as chief executive of Zomato and its parent, Eternal, in January, handing the role to Albinder Dhindsa, who leads the quick-commerce unit Blinkit. The move marked a major transition for Goyal after nearly two decades at the helm of the food delivery company he co-founded in 2008. Temple is one of the clearest expressions yet of that shift. The startup is focused on building a high-performance wearable for elite athletes, an area Goyal has described as ripe for deeper technological innovation. During a January conversation with podcaster Raj Shamani, Goyal described Temple‚Äôs wearable as a sensor designed to sit on the wearer‚Äôs temple and continuously track cerebral blood flow. In a separate post on X earlier Friday, he said Temple aims to build what he called ‚Äúthe ultimate wearable for elite performance athletes,‚Äù claiming the device would measure metrics that existing wearables cannot. He also outlined an expansive hiring push spanning embedded systems, computational neuroscience, and brain‚Äìcomputer interface engineering. The startup is entering an increasingly crowded and well-funded wearables market, where companies such as Whoop, Oura, and Garmin have spent years refining devices that track sleep, recovery, and athletic performance. Whether Temple can meaningfully differentiate its technology remains an open question. The push into Temple is part of a broader shift in Goyal‚Äôs investment focus. In October 2025, he said he had committed $25 million of his own capital to another new venture, Continue Research, which is exploring ways to extend human lifespan. He is also a co-founder of aviation startup LAT Aerospace, which recently expanded into defense technology with the acquisition of early-stage firm Sharang Shakti. Goyal built his reputation at Zomato, which he co-founded with Pankaj Chaddah and spent nearly two decades building into one of India‚Äôs largest food delivery platforms before stepping down as chief executive earlier this year. Chaddah exited the company in 2018, as Zomato continued to consolidate its position through acquisitions, including the purchase of Uber Eats‚Äô India business in 2020 and grocery delivery platform Blinkit ‚Äî then known as Grofers ‚Äî for $568 million in 2022. Before Temple, Goyal had also backed health and fitness startups, including Ultrahuman , an India-based wearable maker that competes with Oura‚Äôs smart ring, underscoring his growing focus on performance and health technology. Goyal declined to comment further on Temple.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/deepinder-goyal.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "How to downgrade from macOS 26 Tahoe on a new Mac",
      "url": "https://arstechnica.com/gadgets/2026/02/how-to-downgrade-from-macos-26-tahoe-on-a-new-mac/",
      "published": "2026-02-27T14:34:45+00:00",
      "summary": "Most new Macs can still be downgraded with few downsides. Here's what to know.",
      "content_text": "If you‚Äôre downloading the installer from within macOS Tahoe, you‚Äôll see a pop-up when the download completes, telling you that the installer can‚Äôt be run from within that version of macOS. Since we‚Äôll be running it off of its own USB stick, you can safely ignore this message. Settings for formatting your USB disk to get it ready for a macOS installer. Andrew Cunningham Settings for formatting your USB disk to get it ready for a macOS installer. Andrew Cunningham A 64GB disk is large enough to hold two or three macOS installers at once. Andrew Cunningham A 64GB disk is large enough to hold two or three macOS installers at once. Andrew Cunningham Settings for formatting your USB disk to get it ready for a macOS installer. Andrew Cunningham A 64GB disk is large enough to hold two or three macOS installers at once. Andrew Cunningham While the installer is downloading, install and prepare your USB drive. Open Disk Utility, click the View button, and select ‚Äúshow all devices.‚Äù Click the root of your USB drive under the ‚Äúexternal‚Äù header in the left sidebar, and click the Erase button in the upper-right control area. Change the disk‚Äôs name to whatever you want‚ÄîI use ‚ÄúMyVolume‚Äù so I don‚Äôt have to change Apple‚Äôs sample terminal commands when copying the installer files‚Äîand make sure the Format is set to Mac OS Extended (Journaled) and the Scheme is set to GUID Partition Map. (That‚Äôs not an error; the macOS installer still wants an HFS+ filesystem rather than APFS.) The handy thing is that if you have a larger USB drive, you can create installers for multiple macOS versions by partitioning the disk with the Partition button. A 64GB drive split into three ~21GB partitions could boot Tahoe, Sequoia, and another past or future macOS version; I just have it split into two volumes so I can boot Sequoia and Tahoe installers from the same drive. Running the Terminal command to create our macOS 15 Sequoia boot drive. Credit: Andrew Cunningham Running the Terminal command to create our macOS 15 Sequoia boot drive. Credit: Andrew Cunningham Once the Sequoia installer is in your Applications folder, run a Terminal command to copy the installer files. Apple has commands for each version of macOS on this page . Use this one for Sequoia: sudo /Applications/Install\\ macOS\\ Sequoia.app/Contents/Resources/createinstallmedia --volume /Volumes/MyVolume If you named the USB drive something other than MyVolume when you formatted it, change the name in the command as well. Note that names with spaces require a backslash before each space. The Terminal will prompt you for your password and ask you to type Y to confirm. It will then reformat the drive and copy the files over. The time this takes will vary depending on the speed of the USB drive you‚Äôre using, but for most USB 3 drives, it should only take a few minutes to create the installer. When the Terminal command is done running, leave the disk inserted and shut down your Mac.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/tahoe-goodbye-imac-1152x648.jpg"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "Block lays off 40% of workforce as it goes all-in on AI tools",
      "url": "https://arstechnica.com/ai/2026/02/block-lays-off-40-of-workforce-as-it-goes-all-in-on-ai-tools/",
      "published": "2026-02-27T14:19:00+00:00",
      "summary": "CEO says \"most companies are late\" to realize how much technology will affect employment.",
      "content_text": "The staff reduction at Block comes as anxiety rises about AI leading to job losses across vast parts of the economy. Investors and economists are grappling with an influx of US economic data and corporate announcements in an effort to gauge the impact the technology could be having on the labor market. The latest non-farm payrolls figures were better than expected, suggesting the domestic jobs market was stabilizing, but several big US companies have committed to cutting staff. Amazon, UPS, Dow, Nike, Home Depot, and others in late January announced they would be cutting a combined 52,000 jobs. Dorsey said the cuts at Block, which owns the payment processor Square, came despite what he described as a ‚Äústrong‚Äù financial performance in 2025. Block has made a contrarian bet on bitcoin at a time when many payment companies favored stablecoins: cash-like digital tokens that became regulated in the US last year. Block‚Äôs strategy was spearheaded by Dorsey, a ‚Äúbitcoin maximalist‚Äù who has said he believes the digital currency will eventually eclipse the dollar. The company offers payment services in bitcoin for merchants and consumers‚Äîand suffered a loss on its own bitcoin holdings as the price of the cryptocurrency dropped 23 percent this year. In contrast, payment companies that made a bet on stablecoins experienced a boost. Stripe earlier this week said its stablecoin transaction volumes increased fourfold last year. In its fiscal fourth quarter, Block reported revenue of almost $6.3 billion, in line with Wall Street expectations. Its earnings tumbled to 19 cents a share, owing to a $234 million hit on its bitcoin holdings. ¬© 2026 The Financial Times Ltd . All rights reserved. Not to be redistributed, copied, or modified in any way.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/jack-1152x648.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "OpenAI raises $110B in one of the largest private funding rounds in history",
      "url": "https://techcrunch.com/2026/02/27/openai-raises-110b-in-one-of-the-largest-private-funding-rounds-in-history/",
      "published": "2026-02-27T14:13:01+00:00",
      "summary": "The new funding consists of a $50 billion investment from Amazon as well as $30 billion each from Nvidia and SoftBank, against a $730 billion valuation.",
      "content_text": "OpenAI has raised $110 billion in private funding, the company announced Friday morning , commencing one of the largest private funding rounds in history. The new funding consists of a $50 billion investment from Amazon as well as $30 billion each from Nvidia and SoftBank, against a $730 billion pre-money valuation. Notably, the round remains open, and OpenAI expects more investors to join as it proceeds. ‚ÄúWe are entering a new phase where frontier AI moves from research into daily use at global scale,‚Äù OpenAI said. ‚ÄúLeadership will be defined by who can scale infrastructure fast enough to meet demand, and turn that capacity into products people rely on.‚Äù As part of the investment, OpenAI is launching significant infrastructure partnerships with both Amazon and Nvidia. As in previous rounds, it is likely that a significant portion of the dollar amount comes in the form of services rather than cash, although the precise split was not disclosed. The company‚Äôs previous round closed in March 2025, raising $40 billion against a $300 billion valuation. At the time, it was the largest private funding round on record . As part of its Amazon partnership , OpenAI plans to develop a new ‚Äústateful runtime environment‚Äù where OpenAI models will run on Amazon‚Äôs Bedrock platform . The company will also expand its previously announced AWS partnership , which committed $38 billion in compute services, by $100 billion. OpenAI has committed to consuming at least 2GW of AWS Tranium compute as part of the deal, and also plans to build custom models to support Amazon consumer products. ‚ÄúWe have lots of developers and companies eager to run services powered by OpenAI models on AWS,‚Äù said Amazon CEO Andy Jassy in a statement, ‚Äúand our unique collaboration with OpenAI to provide stateful runtime environments will change what‚Äôs possible for customers building AI apps and agents.‚Äù Techcrunch event Boston, MA | June 9, 2026 The Information had previously reported that $35 billion of Amazon‚Äôs investment could be contingent on the company either achieving AGI or making its IPO by the end of the year. OpenAI‚Äôs announcement confirms the funding split, but says only that the additional $35 billion will arrive ‚Äúin the coming months when certain conditions are met.‚Äù OpenAI gave fewer details on the Nvidia partnership, but said it had committed to using ‚Äú3GW of dedicated inference capacity and 2GW of training on Vera Rubin systems‚Äù as part of the deal. Nvidia‚Äôs participation in the round has been the subject of intense speculation, particularly as reports of a $100 billion investment in September gave way to reports of a smaller investment in the months that followed. In January, Huang dismissed the idea that Nvidia was backing away from OpenAI, saying, ‚Äúwe will invest a great deal of money. I believe in OpenAI. The work that they do is incredible.‚Äù",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2197366846.jpg?resize=1200,800"
    }
  ]
}