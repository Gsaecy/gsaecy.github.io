{
  "industry": "technology",
  "collected_at": "2026-02-28T02:31:22.988198+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Defense secretary Pete Hegseth designates Anthropic a supply chain risk",
      "url": "https://www.theverge.com/policy/886632/pentagon-designates-anthropic-supply-chain-risk-ai-standoff",
      "published": "2026-02-28T02:19:16+00:00",
      "summary": "Nearly two hours after President Donald Trump announced on Truth Social that he was banning Anthropic products from the federal government, Secretary of Defense Pete Hegseth took it one step further and announced that he was now designating the AI company as a \"supply-chain risk,\" which Anthropic says it is willing to challenge in court. [&#8230;]",
      "content_text": "This week, Anthropic delivered a master class in arrogance and betrayal as well as a textbook case of how not to do business with the United States Government or the Pentagon. Our position has never wavered and will never waver: the Department of War must have full, unrestricted access to Anthropic’s models for every LAWFUL purpose in defense of the Republic. Instead, @AnthropicAI and its CEO @DarioAmodei, have chosen duplicity. Cloaked in the sanctimonious rhetoric of “effective altruism,” they have attempted to strong-arm the United States military into submission - a cowardly act of corporate virtue-signaling that places Silicon Valley ideology above American lives. The Terms of Service of Anthropic’s defective altruism will never outweigh the safety, the readiness, or the lives of American troops on the battlefield. Their true objective is unmistakable: to seize veto power over the operational decisions of the United States military. That is unacceptable. As President Trump stated on Truth Social, the Commander-in-Chief and the American people alone will determine the destiny of our armed forces, not unelected tech executives. Anthropic’s stance is fundamentally incompatible with American principles. Their relationship with the United States Armed Forces and the Federal Government has therefore been permanently altered. In conjunction with the President’s directive for the Federal Government to cease all use of Anthropic’s technology, I am directing the Department of War to designate Anthropic a Supply-Chain Risk to National Security. Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic. Anthropic will continue to provide the Department of War its services for a period of no more than six months to allow for a seamless transition to a better and more patriotic service. America’s warfighters will never be held hostage by the ideological whims of Big Tech. This decision is final.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/gettyimages-2253879905.jpg?quality=90&strip=all&crop=0%2C10.737015400442%2C100%2C78.525969199116&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Statement on the comments from Secretary of War Pete Hegseth",
      "url": "https://www.anthropic.com/news/statement-comments-secretary-war",
      "published": "2026-02-28T01:20:10+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.anthropic.com/news/statement-comments-secretary-war\">https://www.anthropic.com/news/statement-comments-secretary-war</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47188697\">https://news.ycombinator.com/item?id=47188697</a></p> <p>Points: 238</p> <p># Comments: 44</p>",
      "content_text": "Earlier today, Secretary of War Pete Hegseth shared on X that he is directing the Department of War to designate Anthropic a supply chain risk. This action follows months of negotiations that reached an impasse over two exceptions we requested to the lawful use of our AI model, Claude: the mass domestic surveillance of Americans and fully autonomous weapons. We have not yet received direct communication from the Department of War or the White House on the status of our negotiations. We have tried in good faith to reach an agreement with the Department of War, making clear that we support all lawful uses of AI for national security aside from the two narrow exceptions above. To the best of our knowledge, these exceptions have not affected a single government mission to date. We held to our exceptions for two reasons. First, we do not believe that today’s frontier AI models are reliable enough to be used in fully autonomous weapons. Allowing current models to be used in this way would endanger America’s warfighters and civilians. Second, we believe that mass domestic surveillance of Americans constitutes a violation of fundamental rights. Designating Anthropic as a supply chain risk would be an unprecedented action—one historically reserved for US adversaries, never before publicly applied to an American company. We are deeply saddened by these developments. As the first frontier AI company to deploy models in the US government’s classified networks, Anthropic has supported American warfighters since June 2024 and has every intention of continuing to do so. We believe this designation would both be legally unsound and set a dangerous precedent for any American company that negotiates with the government. No amount of intimidation or punishment from the Department of War will change our position on mass domestic surveillance or fully autonomous weapons. We will challenge any supply chain risk designation in court. What this means for our customers Secretary Hegseth has implied this designation would restrict anyone who does business with the military from doing business with Anthropic. The Secretary does not have the statutory authority to back up this statement. Legally, a supply chain risk designation under 10 USC 3252 can only extend to the use of Claude as part of Department of War contracts—it cannot affect how contractors use Claude to serve other customers. In practice, this means: If you are an individual customer or hold a commercial contract with Anthropic , your access to Claude—through our API, claude.ai, or any of our products—is completely unaffected. If you are a Department of War contractor , this designation—if formally adopted—would only affect your use of Claude on Department of War contract work. Your use for any other purpose is unaffected. Our sales and support teams are standing by to answer any questions you may have. We are deeply grateful to our users, and to the industry peers, policymakers, veterans, and members of the public who have voiced their support in recent days. Thank you. Above all else, our priorities are to protect our customers from any disruption caused by these extraordinary events and to work with the Department of War to ensure a smooth transition—for them, for our troops, and for American military operations.",
      "cover_image_url": "https://cdn.sanity.io/images/4zrzovbb/website/04e461ada1956ddd7390fe7053f8eb865a7ec26c-4800x2520.png"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "We Will Not Be Divided",
      "url": "https://notdivided.org",
      "published": "2026-02-28T00:54:53+00:00",
      "summary": "<p>Article URL: <a href=\"https://notdivided.org\">https://notdivided.org</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47188473\">https://news.ycombinator.com/item?id=47188473</a></p> <p>Points: 409</p> <p># Comments: 146</p>",
      "content_text": "Frequently Asked Questions Have you thought about broadening the requests to be more comprehensive? The goal of this letter is to find common ground. The signatories likely have a diverse set of views. The current situation with the DoW is so clear-cut that it can bring together a very broad coalition. Signing this letter doesn't mean you think it's the only thing that needs to be done, just that you agree with the bottom line. Who is behind this? This letter was organized by a few citizens who are concerned about the potential misuse of AI against Americans. We are not affiliated with any political party, advocacy group, or organization. We are not affiliated with any AI company and are not paid. Who can sign? Current and former employees of Google and OpenAI are invited to sign. We verify every signature to ensure authenticity. You may sign anonymously. How is my data handled? If you sign anonymously, your personal information (name, email) is automatically and permanently deleted from our database within 24 hours of verification. After deletion, only your anonymous public listing remains (e.g. \"Anonymous, verified current employee at [Company]\"). Only one organizer has access to review anonymous signatures during that 24-hour window. No one else can see your identity. If you sign publicly, we store your name and affiliation to display on the letter. Email addresses used for verification are never published or shared. What if I accidentally fill out the form twice? Don't worry. We de-duplicate non-anonymous signatures automatically, and anonymous signatures within 24 hours (before personal data is deleted). For anonymous signatories beyond 24 hours, we cannot verify there are no duplicates, though there is one human who manually reads all signatures and will try hard to notice and correct any abuse of the system. I signed anonymously but now want to put my name on it. How can I fix that? Sign again using the \"Alternative verification\" method. In the verification details, mention that you previously signed anonymously and would like to switch to a named signature. We'll update your entry and make sure you're not double-counted. How do you verify signatures? Every signature is verified before it appears on the letter. If you sign using the Google Form or email verification options, we confirm that you have access to a @google.com or @openai.com email address. If you use alternative verification, an organizer manually reviews your proof of employment. No signature is published without verification. Have there been any mistakes in signature verification for this letter? We are aware of two mistakes in our efforts to verify the signatures in the form so far. One person who was not an employee of OpenAI or Google found a bug in our verification system and signed falsely under the name \"You guys are letting China Win\". This was noticed and fixed in under 10 minutes, and the verification system was improved to prevent mistakes like this from happening again. We also had two people submit twice in a way that our automatic de-duplication didn't catch. We do periodic checks for this. Because of anonymity considerations, all signatures are manually reviewed by one fallible human. We do our best to make sure we catch and correct any mistakes, but we are not perfect and will probably make mistakes. We will log those mistakes here as we find them. What infrastructure does this site use and is it secure? This site is hosted on Fly.io , a US-based infrastructure provider. The database is SQLite, stored on an encrypted persistent volume. Verification emails are sent via Resend . Google Forms is used as one verification option because it allows email confirmation without sending anything to your inbox. The site itself is a simple open-source Flask application. No analytics or tracking scripts are used. DNS and SSL are managed through Cloudflare.",
      "cover_image_url": "https://notdivided.org/og-image.png"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "The Air Force's new ICBM is nearly ready to fly, but there’s nowhere to put it",
      "url": "https://arstechnica.com/space/2026/02/the-air-forces-new-icbm-is-nearly-ready-to-fly-but-theres-nowhere-to-put-them/",
      "published": "2026-02-28T00:32:24+00:00",
      "summary": "\"There were assumptions that were made in the strategy that obviously didn’t come to fruition.\"",
      "content_text": "“We’ve gotten all the capability that we can out of the Minuteman,” said Gen. Stephen “S.L.” Davis, commander of Air Force Global Strike Command. Potential enemy threats to the Minuteman ICBM have “evolved significantly” since its initial deployment in the Cold War, Davis said. The $141 billion figure is already out of date, as the Air Force announced last year that it would need to construct new silos for the Sentinel missile. The original plan was to adapt existing Minuteman III silos for the new weapons, but engineers determined that it would take too long and cost too much to modify the aging Minuteman facilities. Instead, the Air Force, in partnership with contractors and the US Army Corps of Engineers, will dig hundreds of new holes across Colorado, Montana, Nebraska, North Dakota, and Wyoming. The new silos will include 24 new forward launch centers, three centralized wing command centers, and more than 5,000 miles of fiber connections to wire it all together, military and industry officials said. Sentinel, which had its official start in 2016, will be the largest US government civil works project since the completion of the interstate highway system, and is the most complex acquisition program the Air Force has ever undertaken, wrote Sen. Roger Wicker (R-Mississippi) and Sen. Deb Fischer (R-Nebraska) in a 2024 op-ed published in the Wall Street Journal. Gen. Dale White, the Pentagon’s director of critical major weapons systems, said Wednesday the Defense Department plans to complete a “restructuring” of the Sentinel program by the end of the year. Only then will an updated budget be made public. The military stopped constructing new missile silos in the late 1960s and hasn’t developed a new ICBM since the 1980s. It shows.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/6404099-1152x648-1772236795.jpg"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "The best instant cameras for 2026",
      "url": "https://www.theverge.com/23133103/best-instant-cameras-fujifilm-polaroid-kodak",
      "published": "2026-02-28T00:32:11+00:00",
      "summary": "Even with the ability to take excellent photos with our phones and instantly share them across the world, there’s something magical about the old-school instant camera. With just a click of a button, you can capture a moment in a photo that you can see and touch almost immediately. Images captured by an instant camera [&#8230;]",
      "content_text": "Even with the ability to take excellent photos with our phones and instantly share them across the world, there’s something magical about the old-school instant camera. With just a click of a button, you can capture a moment in a photo that you can see and touch almost immediately. Images captured by an instant camera aren’t as pristine or perfect as those produced by modern digital cameras, but their soft images and imperfections are often a big part of the allure. Yet not all instant cameras are the same, and some of them are better suited for different needs and budgets. That’s why we tested some of the most popular instant cameras on the market from brands like Fujifilm, Polaroid, Leica, Canon, Kodak, and others. All the models featured in our instant camera buying guide are enjoyable to use, but each offers a distinct set of features at a different price point. As a result, some are more appropriate for a child or budding photographer, while others are more advanced and provide added creative control (for a price). When it comes down to it, though, we consider print quality, ease of use, and affordability to be the hallmarks of a quality shooter. That’s why we picked Fujifilm’s Instax Mini 12 as the best instant camera for most people, as it ticks all three boxes wonderfully. Best for social occasions If you’re looking for more creative control or features like filters, however, the Instax Mini Evo is our choice, one that offers great image quality and lets you choose which photos you’d like to print. Other instant cameras, like Kodak’s Mini Retro 3 , also offer a variety of advanced creative modes for those who desire more. Take a look at this list of our instant camera recommendations to find the best fit for you. The best instant camera for most people $86 The Good Produces relatively true-to-life photos Terrific ease of use Very affordable The Bad Instax film can get pricey Minimal creative control Flash can be overpowering Film type: Fujifilm Instax Mini film (sold separately) / Film size: 2 x 3-inches / Weight: 306 grams / Charging method: AA batteries / Companion app: None / Other features: Built-in selfie mirror, film counter If all you’re looking to do is just click a button and get a decent print for a reasonable price, we recommend Fujifilm’s Instax Mini 12. It’s a basic instant camera that’s similar to our former pick, the Instax Mini 11, but with some minor updates. It still takes less than five minutes to start shooting, but the setup process is easier since all you need to do is twist the lens to either “on” or “off.” Such ease of use, combined with the camera’s thinner build, makes it particularly well-suited for kids and those new to photography. For an instant camera, image quality is also better than most of the other cameras I tested, producing relatively true-to-life photos. Most struggle to capture low-light conditions well, and this one is no exception, but the built-in flash helps. Fujifilm claims the Mini 12 optimizes image quality in both bright and dark environments better than its predecessor, but I didn’t notice much of a difference. The flash — which you can’t disable — is also still overpowering in some instances, resulting in a few overexposed images. Photos actually seemed a little darker and less vivid than before, but selfies captured my features and skin tone more accurately, thanks in part to the small front-facing mirror. The updated lens design also lets you twist into Close-Up Mode to zoom slightly and activate the Parallax Correction features for a more aligned photo. It’s a fun, point-and-shoot-style feature, though aligning photos still takes some practice (as well as some composition guidance from the manual). For an instant camera, Fujifilm’s Instax Mini 12 produces vivid, relatively true-to-life photos. Image: Sheena Vasani / The Verge The Mini 12 also offers a number of other niceties. I appreciated the larger-than-average viewfinder and the small counter that shows your remaining shots, which is a useful tracking feature given that each print costs about $1. However, it doesn’t support Bluetooth or pair with a companion app that allows you to edit photos (only scan them), and it doesn’t feature filters, lens options, or portrait modes. But if you’re looking for a solid instant camera that caters to all ages and experience levels, you’ll likely be satisfied with the Instax Mini 12. The best premium instant camera $229 The Good Great use of dials and buttons Lots of printing flexibility Good battery life The Bad Internal storage is limited Micro USB port is annoying No viewfinder Film type: Fujifilm Instax Mini film (sold separately) / Film size: 2 x 3-inches / Weight: 285 grams / Charging method: USB-C (on newer models) / Companion app: Yes / Other features: LCD screen, smartphone printing One of Fujifilm’s Instax Mini Evo was a favorite of my former colleague Becca Farcase — and it’s mine as well. A hybrid camera that bears a resemblance to Fujifilm’s more expensive Fujifilm X100 line of cameras, it looks good and boasts vintage dials and buttons so stylish that they even caught the attention of passersby as I walked around Los Angeles taking photos. I tested the black camera, but Fujifilm also sells a handsome brown version, as well as a newer pink model. It’s easy to balk at its price tag, but this camera offers a level of flexibility that could save you money in the long run if you use it a lot. That’s because the Instax Mini Evo includes a full-color three-inch LCD screen that lets you preview and select which images you want to print, which can help you avoid wasting film on unwanted shots. The added flexibility gave me more room for creative experimentation, too, as I wasn’t worried about running out of film. I also loved using the Instax Mini Evo app to print photos from my smartphone. Plus, unlike the Instax Mini 12, the Evo now uses a USB-C port (though older black models still use the Micro USB port) for charging, so you don’t need to keep buying new batteries. Being able to adjust the brightness of the prints helped me capture night photos and a low-light immersive exhibit a little more clearly and realistically, which is a feature the Instax Mini 12 doesn’t offer. Image: Sheena Vasani / The Verge Unlike the Mini 12, the Evo comes with a few extra features that can help you capture better photos. For example, you can disable the flash, leverage the 3-inch LCD screen as a viewfinder, and adjust the brightness of a print — a helpful feature, given Evo doesn’t capture dark environments well. The camera’s dials also let you apply various lens options and effects, from retro filters to monochrome shades, and you can even take app-based remote shots, allowing for better seflies and more photographic control. The Evo isn’t perfect, though. The companion app isn’t as feature-rich as competing software, the menu system can be confusing to navigate, and the camera’s internal storage maxes out at 45 images. Still, these are relatively minor drawbacks for a stylish, portable camera that makes it easy to quickly capture and print quality shots. The best instant camera for social occasions $155 The Good Lets you print photos from your phone Entertaining companion app Comes with film The Bad So-so image quality Unable to store images Not as stylish as the Instax Mini Evo Film type: Kodak Instant Print 3 x 3-inch cartridge (included) / Film size: 3 x 3-inch square prints / Weight: 467 grams / Charging method: Micro USB / Companion app: Yes / Other features: LCD screen, smartphone printing Whereas the Instax Mini Evo’s companion app is more functional, Kodak’s hybrid Mini Shot 3 Retro is all about fun. The camera’s accompanying mobile app lets you apply frames, stickers, filters, and a wide range of customization options to photos, making it great for scrapbooking. There’s even a beauty feature in the app to conceal blemishes, as well as a set of Snapchat-like filters you can use to add, say, dog ears, making it a fun instant camera to use as a mini photo booth of sorts at parties. Like the Evo, the Shot 3 Retro features an LCD screen — albeit a much smaller one — that lets you decide whether to print a shot. It also supports Bluetooth, and you can use the Kodak Photo Printer app to upload photos to social media or print decent, relatively crisp images from your phone. Unlike the Evo, however, the Shot 3 Retro retails for around $170 and includes a pack of film. It also uses cheaper film; you can often pick up a 60-sheet cartridge for under $20 . The cheaper arguably encourages creative experimentation, even if the large 3 x 3-inch square prints feel lower in quality and more flimsy than those from both Fujifilm and Polaroid. Photos taken with the Kodak Mini Shot 3 aren’t particularly sharp and can have an excessive pink tint. Image: Sheena Vasani / The Verge However, there are notable drawbacks to the Shot 3 Retro. The resulting prints aren’t nearly as crisp or clear as those taken with a smartphone, for one, nor were they as clear or sharp as what you might get with the Evo or Mini 12 (some even have an excessive pink tint). The Shot 3 Retro doesn’t store images the way the Evo does, either, which means you can’t decide whether you’d like to print them later. It’s also noticeably heavier than the Evo and, frankly, nowhere near as stylish. Nonetheless, if you don’t mind compromising on photo quality and want a relatively affordable hybrid camera with fun app features, the Shot 3 Retro is a good choice. The best instant camera for retro fans $213 The Good Attractive, retro design Prints dreamy, vintage-style photos that are relatively sharp for a Polaroid photo Several creative modes USB-C The Bad Struggles in low light Film takes up to 15 minutes to develop Bulky and relatively heavy Film type: Polaroid i-Type Color Film (sold separately) / Film size: 4.2 x 3.5-inch prints / Weight: 648 grams / Charging method: USB-C / Companion app: Yes / Other features: Flip-up lid, scene analysis feature If you’re looking for an instant camera that offers the most old-fashioned, instant-film experience, the Polaroid Flip is the camera for you. It resembles vintage instant cameras like the Polaroid 600 more than any other camera on our list, thanks to its classic, retro-inspired design and flip-up lid. Its square I-Type film prints and iconic white frame give photos an authentically vintage look, while modern touches like Bluetooth, USB-C charging, and a beginner-friendly companion app add greater convenience and creative control. Compared to the third-gen Polaroid Now Plus , my former retro pick, the Flip delivers clearer shots with fewer wasted photos, making the extra $50 worthwhile given that eight I-Type sheets are a spendy $18.99 . The increased clarity can be attributed to several factors, including the Flip’s sonar autofocus and a four-lens hyperfocal system — which result in sharper, more focused images — along with its excellent flash. It’s the most powerful of any Polaroid camera, and while it can sometimes overexpose images, you can adjust exposure directly from the camera or app. The Scene Analysis feature also helps by warning if a shot is likely to be over- or underexposed, or if you’re too close to your subject. In my experience, the warnings didn’t always prevent overexposure, but they did leave me with shots that looked less blown than those from the Now Plus. A few outdoor examples I captured with the Polaroid Flip. Image: Sheena Vasani / The Verge All that being said, there are some notable drawbacks. The Flip is relatively heavy and awkwardly sized, so you can’t slip it into a purse or easily carry it around. Prints also take up to 15 minutes to develop — during which they must be shielded from light — which can be quite an inconvenience. Low-light performance remains a weak spot as well, and I struggled to capture indoor shots given the contrast and saturation are lower than with Instax film. Admittedly, this gave my pictures a more dreamy, vintage look that felt artistic, and you can use the Polaroid Lab to slightly adjust the saturation and exposure settings. Truth be told, you could argue that many of these shortcomings are typical of a retro Polaroid-inspired instant camera and, thus, part of the experience. If that’s what you’re looking for, the Flip is the perfect camera for you. The best instant camera for portability $80 The Good Tiny and lightweight Prints vintage-like photos just like the Polaroid Flip USB-C charging The Bad Struggles in low light Film takes up to 15 minutes to develop No Bluetooth support or companion app Film type: Polaroid i-Type Color Film (sold separately) / Film size: 2.6 x 2.1-inch prints / Weight: 239 grams / Charging method: USB-C / Companion app: No / Other features: Self-timer, selfie mirror, film counter Whereas the Flip is huge, the second-gen Polaroid Go is tiny. It weighs just over a pound and fits easily in the palm of my hand — which is saying a lot, given I’m petite and a little over five feet tall — making it the most portable instant camera on our list. If its images were more true to life and didn’t require you to sheild them from the light for about 15 minutes while developing, I’d call it the best instant camera for kids or travel. At $89.99, the latest Go is the most affordable Polaroid camera available, with film that costs just a little more than Fujifilm’s Instax Mini shots ( a 16-sheet pack runs $21.99 ). The new Go sports a few upgrades over the last-gen model, including USB-C support, and Polaroid claims the camera produces clearer stills than its predecessor. Photos are slightly brighter, though the original Go produced warmer images that felt more true to life. Still, the photos are charming in the way only a Polaroid photo can be. Contrast and color saturation levels are still low, but in a way that exudes the vintage, almost dreamy look of the photos taken with the Flip. The second-gen Polaroid Go produces charming photos but with a cooler tone. Photo by Sheena Vasani / The Verge Unlike the Flip, the Go lacks creative modes and more advanced features. Instead, it’s just a simple point-and-shoot camera, just like the Mini 12, which makes it a little easier to use. There’s no Bluetooth or companion app for added effects; however, the camera does include a self-timer and a larger selfie mirror. The smaller prints may disappoint those who prefer traditional Polaroid sizes, though, and its modern design lacks the retro charm of older models. But classic Polaroid cameras didn’t come with an app, either, and the Go’s simplicity makes it an a easy-to-use option that delivers a traditional instant film experience at less than half the price of the Flip. Other instant cameras to consider Fujifilm’s $116.99 Instax Mini 41 is the long-awaited follow-up to the Mini 40 . The updated model retains the retro design found on the prior model but introduces parallax correction, a feature borrowed from the Instax Mini 12 to help users avoid off-center shots when taking close-ups. It didn’t take long testing the Mini 41 for me to realize it’s simply the Mini 12 for adults. With its black-and-silver body and flatter, squarer edges, the Mini 41 looks sleeker and more stylish. The two cameras are nearly identical, aside from the design, with the same solid photo quality and feature set. Both battery-powered options turn on with a simple twist of the lens, and each comes equipped with a selfie mirror, a close-up mode, and a flash (which cannot be disabled). There are a few subtle upgrades to the Mini 41, however. A textured grip in the front makes it easier to hold, and its shape makes shooting in landscape mode more comfortable. But those are small differences, and at their core, the cameras offer the same experience. Since the Instax Mini 12 retails for less, I ultimately believe it’s the better value; however, if a fashionable, mature look appeals to you, the Mini 41 is a great alternative, especial",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/24859242/236751_Instant_Camera_Buying_Guide.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "18 Best Wireless Chargers, All Tested and Reviewed (2026)",
      "url": "https://www.wired.com/gallery/best-wireless-chargers/",
      "published": "2026-02-27T23:51:20+00:00",
      "summary": "Stop fumbling for cables in the dark. These WIRED-tested stands and pads will take the hassle out of refueling your phone, wireless earbuds, and watch.",
      "content_text": "Other Wireless Chargers We Tested There are a lot of wireless chargers. Here are a few more we like, but for one reason or another don't warrant a place above. Photograph: Simon Hill Krafted Couch Wireless Charger for $52 : I thought this wireless charger that’s designed to be draped over the arm of your couch was a great idea when I saw it, but the ridges failed to keep it in place on my velvety couch, so it kept slipping down the side. The silicone finish with the Krafted logo is also a bit ugly. It's just a silicone mat with a magnetic charger inside, though there is a fairly generous 6.6-foot (2-meter) cable, and it is Qi2 rated. If you’re always rooting around for a charger and one of the colors blends well with your furniture, it might be a good solution for you. Einova Eggtronic Charging Stone for $70 : Made with 100 percent solid marble or stone—you can choose from a variety. Every single pick in this guide looks very much like a wireless charger, but I've had visiting friends ask if this one is a drink coaster. (I'm still figuring out whether that's a good or bad thing.) It has zero LEDs, perfect for bedrooms; just try to hide the cable to truly make it blend into your home. We recommend putting a case on your phone when using it with this charger, as there's a risk of scuffing up the back with these harder surfaces. Baseus Nomos 5-in-1 Charging Station for $100 : If you liked the PicoGo W2 above but need more gadget-charging power, this 5-in-1 could be worth a look. It also has a tilting pad and retractable USB-C cable, but adds two more USB-C ports and one USB-A, along with a stats-filled display. It’s perfect for your desktop. I also tried and quite liked the Baseus Nomos 8-in-1 Magnetic Charging Station ($70) , which combines a similar folding Qi2 pad with three US AC outlets, three USB-C ports, and one USB-A. Rapport London Formula Wireless Charging Tray for $475 : Yes, this is an obscene price for a Qi wireless charger. You can probably make a version for a fraction of the cost. But Rapport's build quality is quite nice, with a lacquered grey box and a soft-touch fabric to keep your watches and phone scratch-free. It reliably recharged several Android phones without making them too warm, all while offering storage for a few watches. It's attractive, but you have to have cash to burn at this price. iOttie iOS Wireless Duo for $50 : This dual-charging system looks pretty—I like the fabric-wrapped stand—and you can charge another device on the rubberized charging pad next to it. The stand can be used in portrait or landscape, though in the latter orientation it'll block the pad. I use the pad to top up my wireless earbuds, but I wouldn't use this iOttie on a nightstand, because the LED on the front can be glaring. A cable and adapter are included, which makes it a good value. It can charge Pixel phones at up to 15 watts, iPhones at 7.5 watts, and other Android phones at 10 watts. Journey Alti Play Performance Desk Mat for $120 : This is a desk mat that doubles as a wireless charging pad. On the left side is a plasticky rectangle with a Qi2 magnetic puck for your smartphone. Above it is a little area to charge wireless earbuds (5 watts). Naturally, there's RGB all over, and there are two buttons you can press to cycle through patterns and colors. It's a smart-looking system, though the quality of the actual mat leaves a bit to be desired. I didn't have issues gliding my mouse on it, and it stays put thanks to the rubber underside, but I just didn't like the look and feel of the Lycra surface. Journey has some other versions of this mat that use different materials , so take a look if you like the overall aesthetic. Courant Catch:2 Essentials for $75 : Wireless chargers should look nice. You shouldn't settle for anything less! This Courant dual charger oozes luxury with its Belgian linen-wrapped surface (especially in the camel color). I've used it by my front door to recharge my partner's and my wireless earbuds for two years. The rubber feet prevent it from shifting around, but even if there are five coils in this pad, you should try to be precise when you put your device down to charge and make sure the LED lights up to double-check. It comes with a color-matching USB-C cable. Photograph: Simon Hill Zens Liberty Wireless Charger for $150 : I tested the Glass Edition of this wireless charging pad, and it looks stunning with the 16 overlapping copper coils on display (the standard version has a woolen fabric top). It can charge two devices simultaneously at up to 15 watts apiece, and there’s an optional Apple Watch add-on ($19) . As stylish as it is, the price is too high. Because you can see the coils, placement is never an issue, but it’s a bulky charger; the fan is audible at times, and while I had no problem charging my iPhone or AirPods, my Pixel 6 Pro got very warm on this pad. Xiaomi Mi 80-W Wireless Charging Stand for $50 : By far the fastest wireless charger we have tested, this stand is only worth considering for Xiaomi phones (it seems to charge most other phones at 10 watts or below). I tested with the Xiaomi 13 Ultra , which tops out at 50 watts (some Xiaomi models can go higher). The unusual sail shape combines a white triangular section with a clear acrylic base that has a subtle groove to hold your phone in place and a gap underneath for the exhaust grill from the noisy fan. The USB-C port and LED indicator are on the back. Power up with unlimited access to WIRED . Get best-in-class reporting and exclusive subscriber content that's too important to ignore. Subscribe Today .",
      "cover_image_url": "https://media.wired.com/photos/685f6984f3c91f1a1ba5e76a/191:100/w_1280,c_limit/The%20Best%20Wireless%20Chargers%20to%20Refuel%20Your%20Phone.png"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Qt45: A small polymerase ribozyme that can synthesize itself",
      "url": "https://www.science.org/doi/10.1126/science.adt2760",
      "published": "2026-02-27T23:42:14+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.science.org/doi/10.1126/science.adt2760\">https://www.science.org/doi/10.1126/science.adt2760</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47187649\">https://news.ycombinator.com/item?id=47187649</a></p> <p>Points: 42</p> <p># Comments: 6</p>",
      "content_text": "<p>Article URL: <a href=\"https://www.science.org/doi/10.1126/science.adt2760\">https://www.science.org/doi/10.1126/science.adt2760</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47187649\">https://news.ycombinator.com/item?id=47187649</a></p> <p>Points: 42</p> <p># Comments: 6</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "VentureBeat",
      "title": "Google's Opal just quietly showed enterprise teams the new blueprint for building AI agents",
      "url": "https://venturebeat.com/technology/googles-opal-just-quietly-showed-enterprise-teams-the-new-blueprint-for",
      "published": "2026-02-27T23:25:00+00:00",
      "summary": "<p>For the past year, the enterprise AI community has been locked in a debate about how much freedom to give AI agents. Too little, and you get expensive workflow automation that barely justifies the &quot;agent&quot; label. Too much, and you get the kind of data-wiping disasters that plagued early adopters of tools like OpenClaw. This week, Google Labs released an update to<a href=\"https://opal.google/\"> Opal</a>, its no-code visual agent builder, that quietly lands on an answer — and it carries lessons that every IT leader planning an agent strategy should study carefully.</p><p>The update introduces what Google calls an &quot;agent step&quot; that transforms Opal&#x27;s previously static, drag-and-drop workflows into dynamic, interactive experiences. Instead of manually specifying which model or tool to call and in what order, builders can now define a goal and let the agent determine the best path to reach it — selecting tools, triggering models like Gemini 3 Flash or Veo for video generation, and even initiating conversations with users when it needs more information.</p><div></div><p>It sounds like a modest product update. It is not. What Google has shipped is a working reference architecture for the three capabilities that will define enterprise agents in 2026:</p><ol><li><p>Adaptive routing</p></li><li><p>Persistent memory</p></li><li><p>Human-in-the-loop orchestration</p></li></ol><p>...and it&#x27;s all made possible by the rapidly improving reasoning abilities of frontier models like <a href=\"https://venturebeat.com/technology/google-launches-gemini-3-1-pro-retaking-ai-crown-with-2x-reasoning\">the Gemini 3 series</a>.</p><h2><b>The &#x27;off the rails&#x27; inflection point: Why better models change everything about agent design</b></h2><p>To understand why the Opal update matters, you need to understand a shift that has been building across the agent ecosystem for months.</p><p>The first wave of enterprise agent frameworks — tools like the early versions of CrewAI and the initial releases of LangGraph — were defined by a tension between autonomy and control. Early models simply were not reliable enough to be trusted with open-ended decision-making. The result was what practitioners began calling &quot;agents on rails&quot;: tightly constrained workflows where every decision point, every tool call, and every branching path had to be pre-defined by a human developer.</p><p>This approach worked, but it was limited. Building an agent on rails meant anticipating every possible state the system might encounter — a combinatorial nightmare for anything beyond simple, linear tasks. Worse, it meant that agents could not adapt to novel situations, the very capability that makes agentic AI valuable in the first place.</p><p>The Gemini 3 series, along with recent releases like Anthropic&#x27;s Claude Opus 4.6 and Sonnet 4.6, represents a threshold where models have become reliable enough at planning, reasoning, and self-correction that the rails can start coming off. Google&#x27;s own Opal update is an acknowledgment of this shift. The new agent step does not require builders to pre-define every path through a workflow. Instead, it trusts the underlying model to evaluate the user&#x27;s goal, assess available tools, and determine the optimal sequence of actions dynamically.</p><p>This is the same pattern that made Claude Code&#x27;s agentic workflows and tool calling viable: the models are good enough to decide the agent’s next step and often even to self-correct without a human manually re-prompting every error. The difference compared to Claude Code is that Google is now packaging this capability into a consumer-grade, no-code product — a strong signal that the underlying technology has matured past the experimental phase.</p><p>For enterprise teams, the implication is direct: if you are still designing agent architectures that require pre-defined paths for every contingency, you are likely over-engineering. The new generatio",
      "content_text": "<p>For the past year, the enterprise AI community has been locked in a debate about how much freedom to give AI agents. Too little, and you get expensive workflow automation that barely justifies the &quot;agent&quot; label. Too much, and you get the kind of data-wiping disasters that plagued early adopters of tools like OpenClaw. This week, Google Labs released an update to<a href=\"https://opal.google/\"> Opal</a>, its no-code visual agent builder, that quietly lands on an answer — and it carries lessons that every IT leader planning an agent strategy should study carefully.</p><p>The update introduces what Google calls an &quot;agent step&quot; that transforms Opal&#x27;s previously static, drag-and-drop workflows into dynamic, interactive experiences. Instead of manually specifying which model or tool to call and in what order, builders can now define a goal and let the agent determine the best path to reach it — selecting tools, triggering models like Gemini 3 Flash or Veo for video generation, and even initiating conversations with users when it needs more information.</p><div></div><p>It sounds like a modest product update. It is not. What Google has shipped is a working reference architecture for the three capabilities that will define enterprise agents in 2026:</p><ol><li><p>Adaptive routing</p></li><li><p>Persistent memory</p></li><li><p>Human-in-the-loop orchestration</p></li></ol><p>...and it&#x27;s all made possible by the rapidly improving reasoning abilities of frontier models like <a href=\"https://venturebeat.com/technology/google-launches-gemini-3-1-pro-retaking-ai-crown-with-2x-reasoning\">the Gemini 3 series</a>.</p><h2><b>The &#x27;off the rails&#x27; inflection point: Why better models change everything about agent design</b></h2><p>To understand why the Opal update matters, you need to understand a shift that has been building across the agent ecosystem for months.</p><p>The first wave of enterprise agent frameworks — tools like the early versions of CrewAI and the initial releases of LangGraph — were defined by a tension between autonomy and control. Early models simply were not reliable enough to be trusted with open-ended decision-making. The result was what practitioners began calling &quot;agents on rails&quot;: tightly constrained workflows where every decision point, every tool call, and every branching path had to be pre-defined by a human developer.</p><p>This approach worked, but it was limited. Building an agent on rails meant anticipating every possible state the system might encounter — a combinatorial nightmare for anything beyond simple, linear tasks. Worse, it meant that agents could not adapt to novel situations, the very capability that makes agentic AI valuable in the first place.</p><p>The Gemini 3 series, along with recent releases like Anthropic&#x27;s Claude Opus 4.6 and Sonnet 4.6, represents a threshold where models have become reliable enough at planning, reasoning, and self-correction that the rails can start coming off. Google&#x27;s own Opal update is an acknowledgment of this shift. The new agent step does not require builders to pre-define every path through a workflow. Instead, it trusts the underlying model to evaluate the user&#x27;s goal, assess available tools, and determine the optimal sequence of actions dynamically.</p><p>This is the same pattern that made Claude Code&#x27;s agentic workflows and tool calling viable: the models are good enough to decide the agent’s next step and often even to self-correct without a human manually re-prompting every error. The difference compared to Claude Code is that Google is now packaging this capability into a consumer-grade, no-code product — a strong signal that the underlying technology has matured past the experimental phase.</p><p>For enterprise teams, the implication is direct: if you are still designing agent architectures that require pre-defined paths for every contingency, you are likely over-engineering. The new generation of models supports a design pattern where you define goals and constraints, provide tools, and let the model handle routing — a shift from programming agents to managing them.</p><h2><b>Memory across sessions: The feature that separates demos from production agents</b></h2><p>The second major addition in the Opal update is persistent memory. Google now allows Opals to remember information across sessions — user preferences, prior interactions, accumulated context — making agents that improve with use rather than starting from zero each time.</p><p>Google has not disclosed the technical implementation behind Opal&#x27;s memory system. But the pattern itself is well-established in the agent-building community. Tools like OpenClaw handle memory primarily through markdown and JSON files, a simple approach that works well for single-user systems. Enterprise deployments face a harder problem: maintaining memory across multiple users, sessions, and security boundaries without leaking sensitive context between them.</p><p>This single-user versus multi-user memory divide is one of the most under-discussed challenges in enterprise agent deployment. A personal coding assistant that remembers your project structure is fundamentally different from a customer-facing agent that must maintain separate memory states for thousands of concurrent users while complying with data retention policies.</p><p>What the Opal update signals is that Google considers memory a core feature of agent architecture, not an optional add-on. For IT decision-makers evaluating agent platforms, this should inform procurement criteria. An agent framework without a clear memory strategy is a framework that will produce impressive demos but struggle in production, where the value of an agent compounds over repeated interactions with the same users and datasets.</p><h2><b>Human-in-the-loop is not a fallback — it is a design pattern</b></h2><p>The third pillar of the Opal update is what Google calls &quot;interactive chat&quot; — the ability for an agent to pause execution, ask the user a follow-up question, gather missing information, or present choices before proceeding. In agent architecture terminology, this is human-in-the-loop orchestration, and its inclusion in a consumer product is telling.</p><p>The most effective agents in production today are not fully autonomous. They are systems that know when they have reached the limits of their confidence and can gracefully hand control back to a human. This is the pattern that separates reliable enterprise agents from the kind of runaway autonomous systems that have generated cautionary tales across the industry.</p><p>In frameworks like LangGraph, human-in-the-loop has traditionally been implemented as an explicit node in the graph — a hard-coded checkpoint where execution pauses for human review. Opal&#x27;s approach is more fluid: the agent itself decides when it needs human input based on the quality and completeness of the information it has. This is a more natural interaction pattern and one that scales better, because it does not require the builder to predict in advance exactly where human intervention will be needed.</p><p>For enterprise architects, the lesson is that human-in-the-loop should not just be treated as a safety net bolted on after the agent is built. It should be a first-class capability of the agent framework itself — one that the model can invoke dynamically based on its own assessment of uncertainty.</p><h2><b>Dynamic routing: Letting the model decide the path</b></h2><p>The final significant feature is dynamic routing, where builders can define multiple paths through a workflow and let the agent select the appropriate one based on custom criteria. Google&#x27;s example is an executive briefing agent that takes different paths depending on whether the user is meeting with a new or existing client — searching the web for background information in one case, reviewing internal meeting notes in the other.</p><p>This is conceptually similar to the conditional branching that LangGraph and similar frameworks have supported for some time. But Opal&#x27;s implementation lowers the barrier dramatically by allowing builders to describe routing criteria in natural language rather than code. The model interprets the criteria and makes the routing decision, rather than requiring a developer to write explicit conditional logic.</p><p>The enterprise implication is significant. Dynamic routing powered by natural language criteria means that business analysts and domain experts — not just developers — can define complex agent behaviors. This shifts agent development from a purely engineering discipline to one where domain knowledge becomes the primary bottleneck, a change that could dramatically accelerate adoption across non-technical business units.</p><h2><b>What Google is really building: An agent intelligence layer</b></h2><p>Stepping back from individual features, the broader pattern in the Opal update is that Google is building an intelligence layer that sits between the user&#x27;s intent and the execution of complex, multi-step tasks. Building on lessons from an internal agent SDK called “<a href=\"https://github.com/breadboard-ai/breadboard\">Breadboard</a>”, the agent step is not just another node in a workflow — it is an<a href=\"https://blog.google/innovation-and-ai/models-and-research/google-labs/opal-agent/#:~:text=The%20agent%20step%20understands%20your,it%20needs%20to%20get%20there.&amp;text=Today%20we&#x27;re%20upgrading%20Opal,in%20the%20%22generate%22%20step\"> orchestration layer</a> that can recruit models, invoke tools, manage memory, route dynamically, and interact with humans, all driven by the ever improving reasoning capabilities of the underlying Gemini models.</p><p>This is the same architectural pattern emerging across the industry. Anthropic&#x27;s Claude Code, with its ability to autonomously manage coding tasks overnight, relies on similar principles: a capable model, access to tools, persistent context, and feedback loops that allow self-correction. <a href=\"https://venturebeat.com/technology/how-ralph-wiggum-went-from-the-simpsons-to-the-biggest-name-in-ai-right-now\">The Ralph Wiggum plugin</a> formalized the insight that models can be pressed through their own failures to arrive at correct solutions — a brute-force version of the self-correction that Opal now packages some of that into a polished consumer experience.</p><p>For enterprise teams, the takeaway is that agent architecture is converging on a common set of primitives: goal-directed planning, tool use, persistent memory, dynamic routing, and human-in-the-loop orchestration. The differentiator will not be which primitives you implement, but how well you integrate them — and how effectively you leverage the improving capabilities of frontier models to reduce the amount of manual configuration required.</p><h2><b>The practical playbook for enterprise agent builders</b></h2><p>Google shipping these capabilities in a free, consumer-facing product sends a clear message: the foundational patterns for building effective AI agents are no longer cutting-edge research. They are productized. Enterprise teams that have been waiting for the technology to mature now have a reference implementation they can study, test, and learn from — at zero cost.</p><p>The practical steps are straightforward. First, evaluate whether your current agent architectures are over-constrained. If every decision point requires hard-coded logic, you are likely not leveraging the planning capabilities of current frontier models. Second, prioritize memory as a core architectural component, not an afterthought. Third, design human-in-the-loop as a dynamic capability the agent can invoke, rather than a fixed checkpoint in a workflow. And fourth, explore natural language routing as a way to bring domain experts into the agent design process.</p><p>Opal itself probably won’t become the platform enterprises adopt. But the design patterns it embodies — adaptive, memory-rich, human-aware agents powered by frontier models — are the patterns that will define the next generation of enterprise AI. Google has shown its hand. The question for IT leaders is whether they are paying attention.</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "VentureBeat",
      "title": "OpenAI's big investment from AWS comes with something else: new 'stateful' architecture for enterprise agents",
      "url": "https://venturebeat.com/orchestration/openais-big-investment-from-aws-comes-with-something-else-new-stateful",
      "published": "2026-02-27T23:12:00+00:00",
      "summary": "<p>The landscape of enterprise artificial intelligence shifted fundamentally today as <a href=\"https://openai.com/index/scaling-ai-for-everyone/\">OpenAI announced $110 billion in new funding</a> from three of tech&#x27;s largest firms: $30 billion from SoftBank, $30 billion from Nvidia, and $50 billion from Amazon.</p><p>But while the former two players are providing money, OpenAI is going further with Amazon in a new direction, establishing an upcoming fully &quot;Stateful Runtime Environment&quot; on Amazon Web Services (AWS), <a href=\"https://aws.amazon.com/what-is-aws/\">the world&#x27;s most used cloud environment.</a></p><p>This signals OpenAI&#x27;s and Amazon&#x27;s vision of the next phase of the AI economy — moving from chatbots to autonomous &quot;AI coworkers&quot; known as agents — and that this evolution requires a different architectural foundation than the one that built GPT-4. </p><p>For enterprise decision-makers, this announcement isn’t just a headline about massive capital; it is a technical roadmap for where the next generation of agentic intelligence will live and breathe.</p><p>And especially for those enterprises currently using AWS, it&#x27;s great news, giving them more options with a new runtime environment from OpenAI coming soon (the companies have yet to announce a precise timeline for when it will arrive).</p><h2><b>The great divide between &#x27;stateless&#x27; and &#x27;stateful&#x27;</b></h2><p>At the heart of the new OpenAI-Amazon partnership is a technical distinction that will define developer workflows for the next decade: the difference between &quot;stateless&quot; and &quot;stateful&quot; environments.</p><p>To date, most developers have interacted with OpenAI through stateless APIs. In a stateless model, every request is an isolated event; the model has no &quot;memory&quot; of previous interactions unless the developer manually feeds the entire conversation history back into the prompt. OpenAI&#x27;s prior cloud partner and major investor, Microsoft Azure, remains the exclusive third-party cloud provider for these stateless APIs.</p><p>The newly announced Stateful Runtime Environment, by contrast, will be hosted on Amazon Bedrock — a paradigm shift. </p><p>This environment allows models to maintain persistent context, memory, and identity. Rather than a series of disconnected calls, the stateful environment enables &quot;AI coworkers&quot; to handle ongoing projects, remember prior work, and move seamlessly across different software tools and data sources. </p><p>As <a href=\"https://openai.com/index/introducing-the-stateful-runtime-environment-for-agents-in-amazon-bedrock/\">OpenAI notes on its website</a>: &quot;Now, instead of manually stitching together disconnected requests to make things work, your agents automatically execute complex steps with &#x27;working context&#x27; that carries forward memory/history, tool and workflow state, environment use, and identity/permission boundaries.&quot;</p><p>For builders of complex agents, this reduces the &quot;plumbing&quot; required to maintain context, as the infrastructure itself now handles the persistent state of the agent.</p><h2><b>OpenAI Frontier and the AWS Integration</b></h2><p>The vehicle for this stateful intelligence is OpenAI Frontier, an end-to-end platform designed to help enterprises build, deploy, and manage teams of AI agents, <a href=\"https://venturebeat.com/orchestration/openai-launches-centralized-agent-platform-as-enterprises-push-for-multi\">launched back in early February 2026</a>. </p><p>Frontier is positioned as a solution to the &quot;AI opportunity gap&quot;—the disconnect between model capabilities and the ability of a business to actually put them into production.</p><p>Key features of the Frontier platform include:</p><ul><li><p><b>Shared Business Context:</b> Connecting siloed data from CRMs, ticketing tools, and internal databases into a single semantic layer.</p></li><li><p><b>Agent Execution Environment: ",
      "content_text": "<p>The landscape of enterprise artificial intelligence shifted fundamentally today as <a href=\"https://openai.com/index/scaling-ai-for-everyone/\">OpenAI announced $110 billion in new funding</a> from three of tech&#x27;s largest firms: $30 billion from SoftBank, $30 billion from Nvidia, and $50 billion from Amazon.</p><p>But while the former two players are providing money, OpenAI is going further with Amazon in a new direction, establishing an upcoming fully &quot;Stateful Runtime Environment&quot; on Amazon Web Services (AWS), <a href=\"https://aws.amazon.com/what-is-aws/\">the world&#x27;s most used cloud environment.</a></p><p>This signals OpenAI&#x27;s and Amazon&#x27;s vision of the next phase of the AI economy — moving from chatbots to autonomous &quot;AI coworkers&quot; known as agents — and that this evolution requires a different architectural foundation than the one that built GPT-4. </p><p>For enterprise decision-makers, this announcement isn’t just a headline about massive capital; it is a technical roadmap for where the next generation of agentic intelligence will live and breathe.</p><p>And especially for those enterprises currently using AWS, it&#x27;s great news, giving them more options with a new runtime environment from OpenAI coming soon (the companies have yet to announce a precise timeline for when it will arrive).</p><h2><b>The great divide between &#x27;stateless&#x27; and &#x27;stateful&#x27;</b></h2><p>At the heart of the new OpenAI-Amazon partnership is a technical distinction that will define developer workflows for the next decade: the difference between &quot;stateless&quot; and &quot;stateful&quot; environments.</p><p>To date, most developers have interacted with OpenAI through stateless APIs. In a stateless model, every request is an isolated event; the model has no &quot;memory&quot; of previous interactions unless the developer manually feeds the entire conversation history back into the prompt. OpenAI&#x27;s prior cloud partner and major investor, Microsoft Azure, remains the exclusive third-party cloud provider for these stateless APIs.</p><p>The newly announced Stateful Runtime Environment, by contrast, will be hosted on Amazon Bedrock — a paradigm shift. </p><p>This environment allows models to maintain persistent context, memory, and identity. Rather than a series of disconnected calls, the stateful environment enables &quot;AI coworkers&quot; to handle ongoing projects, remember prior work, and move seamlessly across different software tools and data sources. </p><p>As <a href=\"https://openai.com/index/introducing-the-stateful-runtime-environment-for-agents-in-amazon-bedrock/\">OpenAI notes on its website</a>: &quot;Now, instead of manually stitching together disconnected requests to make things work, your agents automatically execute complex steps with &#x27;working context&#x27; that carries forward memory/history, tool and workflow state, environment use, and identity/permission boundaries.&quot;</p><p>For builders of complex agents, this reduces the &quot;plumbing&quot; required to maintain context, as the infrastructure itself now handles the persistent state of the agent.</p><h2><b>OpenAI Frontier and the AWS Integration</b></h2><p>The vehicle for this stateful intelligence is OpenAI Frontier, an end-to-end platform designed to help enterprises build, deploy, and manage teams of AI agents, <a href=\"https://venturebeat.com/orchestration/openai-launches-centralized-agent-platform-as-enterprises-push-for-multi\">launched back in early February 2026</a>. </p><p>Frontier is positioned as a solution to the &quot;AI opportunity gap&quot;—the disconnect between model capabilities and the ability of a business to actually put them into production.</p><p>Key features of the Frontier platform include:</p><ul><li><p><b>Shared Business Context:</b> Connecting siloed data from CRMs, ticketing tools, and internal databases into a single semantic layer.</p></li><li><p><b>Agent Execution Environment: </b>A dependable space where agents can run code, use computer tools, and solve real-world problems. </p></li><li><p><b>Built-in Governance:</b> Every AI agent has a unique identity with explicit permissions and boundaries, allowing for use in regulated environments.</p></li></ul><p>While the Frontier application itself will continue to be hosted on Microsoft Azure, AWS has been named the exclusive third-party cloud distribution provider for the platform. </p><p>This means that while the &quot;engine&quot; may sit on Azure, AWS customers will be able to access and manage these agentic workloads directly through Amazon Bedrock, integrated with AWS’s existing infrastructure services.</p><h2><b>OpenAI opens the door to enterprises: how to register your interest in its upcoming new Stateful Runtime Environment on AWS</b></h2><p>For now, <a href=\"https://openai.com/index/introducing-the-stateful-runtime-environment-for-agents-in-amazon-bedrock/\">OpenAI has launched a dedicated Enterprise Interest Portal on its website.</a> This serves as the primary intake point for organizations looking to move past isolated pilots and into production-grade agentic workflows.</p><p>The portal is a structured &quot;request for access&quot; form where decision-makers provide:</p><ul><li><p><b>Firmographic Data:</b> Basic details including company size (ranging from startups of 1–50 to large-scale enterprises with 20,000+ employees) and contact information.</p></li><li><p><b>Business Needs Assessment:</b> A dedicated field for leadership to outline specific business challenges and requirements for &quot;AI coworkers&quot;.</p></li></ul><p>By submitting this form, enterprises signal their readiness to work directly with OpenAI and AWS teams to implement solutions like multi-system customer support, sales operations, and finance audits that require high-reliability state management.</p><h2><b>Community and leadership reactions</b></h2><p>The scale of the announcement was mirrored in the public statements from the key players on social media.</p><p>Sam Altman, CEO of OpenAI, expressed excitement about the Amazon partnership, specifically highlighting the &quot;stateful runtime environment&quot; and the use of Amazon&#x27;s custom Trainium chips. </p><p>However, Altman was quick to clarify the boundaries of the deal: &quot;Our stateless API will remain exclusive to Azure, and we will build out much more capacity with them&quot;.</p><p>Amazon CEO Andy Jassy emphasized the demand from his own customer base, stating, &quot;We have lots of developers and companies eager to run services powered by OpenAI models on AWS&quot;. He noted that the collaboration would &quot;change what’s possible for customers building AI apps and agents&quot;.</p><p>Early adopters have already begun to weigh in on the utility of the Frontier approach. Joe Park, EVP at State Farm, noted that the platform is helping the company accelerate its AI capabilities to &quot;help millions plan ahead, protect what matters most, and recover faster&quot;.</p><h2><b>The enterprise decision: where to spend your dollars?</b></h2><p>For CTOs and enterprise decision-makers, the OpenAI-Amazon-Microsoft triangle creates a new set of strategic choices. The decision of where to allocate budget now depends heavily on the specific use case:</p><ol><li><p><b>For High-Volume, Standard Tasks:</b> If your organization relies on standard API calls for content generation, summarization, or simple chat, Microsoft Azure remains the primary destination. These &quot;stateless&quot; calls are exclusive to Azure, even if they originate from an Amazon-linked collaboration.</p></li><li><p><b>For Complex, Long-Running Agents:</b> If your goal is to build &quot;AI coworkers&quot; that require deep integration with AWS-hosted data and persistent memory across weeks of work, the AWS Stateful Runtime Environment is the clear choice.</p></li><li><p><b>For Custom Infrastructure: </b>OpenAI has committed to consuming 2 gigawatts of AWS Trainium capacity to power Frontier and other advanced workloads. This suggests that enterprises looking for the most cost-efficient way to run OpenAI models at massive scale may find an advantage in the AWS-Trainium ecosystem.</p></li></ol><h2><b>Licensing, revenue and the Microsoft &#x27;safety net&#x27;</b></h2><p>Despite the massive infusion of Amazon capital, the legal and financial ties between Microsoft and OpenAI remain remarkably rigid. A <a href=\"https://openai.com/index/continuing-microsoft-partnership/\">joint statement released by both companies</a> clarified that their &quot;commercial and revenue share relationship remains unchanged&quot;.</p><p>Crucially, Microsoft continues to maintain its &quot;exclusive license and access to intellectual property across OpenAI models and products&quot;. Furthermore, Microsoft will receive a share of the revenue generated by the OpenAI-Amazon partnership. </p><p>This ensures that while OpenAI is diversifying its infrastructure, Microsoft remains the ultimate beneficiary of OpenAI’s commercial success, regardless of which cloud the compute actually runs on.</p><p>The definition of Artificial General Intelligence (AGI) also remains a protected term in the Microsoft agreement. The contractual processes for determining when AGI has been reached—and the subsequent impact on commercial licensing—have not been altered by the Amazon deal.</p><p>Ultimately, OpenAI is positioning itself as more than a model or tool provider; it is an infrastructure player attempting to straddle the two largest clouds on Earth. </p><p>For the user, this means more choice and more specialized environments. For the enterprise, it means that the era of &quot;one-size-fits-all&quot; AI procurement is over. </p><p>The choice between Azure and AWS for OpenAI services is now a technical decision about the nature of the work itself: whether your AI needs to simply &quot;think&quot; (stateless) or to &quot;remember and act&quot; (stateful).</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "NASA is pushing back its plans for a Moon landing",
      "url": "https://www.theverge.com/science/886656/nasa-artemis-moon-landing-delayed-2028",
      "published": "2026-02-27T23:11:40+00:00",
      "summary": "NASA announced at a press conference on Friday that it's delaying its plans for a Moon landing until Artemis IV in 2028. The Artemis III mission, scheduled for 2027, was originally going to attempt to land on the Moon but will now be a test flight instead. NASA also says it's \"increasing its cadence of [&#8230;]",
      "content_text": "NASA announced at a press conference on Friday that it’s delaying its plans for a Moon landing until Artemis IV in 2028. The Artemis III mission, scheduled for 2027, was originally going to attempt to land on the Moon but will now be a test flight instead. NASA also says it’s “increasing its cadence of missions,” including adding a second test flight in 2027 and aiming for “at least one surface landing every year thereafter,” including the Artemis IV landing. The overhaul to the Artemis launch schedule follows a report from NASA’s Aerospace Safety Advisory Panel (ASAP) earlier this month that highlighted serious safety risks with NASA’s previous plans for future launches. ASAP was particularly concerned about Artemis III, which its report said included too many “cumulative technical, operational, and schedule risks associated with multiple first-of-a-kind objectives planned for a single mission.” The Artemis II mission, scheduled for this year, has faced a string of issues during testing over recent weeks, delaying its launch until no earlier than April. Artemis II is intended to orbit the Moon — if it’s successful, it will be the first time humans visit lunar orbit since Apollo 17 in 1972.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/chorus/uploads/chorus_asset/file/23965100/1242549824.jpg?quality=90&strip=all&crop=0%2C10.729279508242%2C100%2C78.541440983517&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "wkoszek/emuko: Fast RISC-V emulator written in Rust. Boots Linux.",
      "url": "https://github.com/wkoszek/emuko",
      "published": "2026-02-27T23:01:49+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.com/wkoszek/emuko\">https://github.com/wkoszek/emuko</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47187121\">https://news.ycombinator.com/item?id=47187121</a></p> <p>Points: 42</p> <p># Comments: 4</p>",
      "content_text": "You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/965c86b64670b10f9664a9a6d3724de97583075415327626b03e29e902c9bdcd/wkoszek/emuko"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "OpenAI fires employee for using confidential info on prediction markets",
      "url": "https://techcrunch.com/2026/02/27/openai-fires-employee-for-using-confidential-info-on-prediction-markets/",
      "published": "2026-02-27T23:00:54+00:00",
      "summary": "The company said such trades violates its internal company policies about using confidential information for personal gain.",
      "content_text": "OpenAI has fired an employee over the employee’s activity on prediction markets, including Polymarket, the company confirmed to Wired. The employee used confidential OpenAI information in connection with the trades made, the company alleges. OpenAI didn’t release the name of the employee. However, a spokesperson said that such actions violated a company policy that bans workers from using inside information for personal gain, including on prediction markets. Prediction markets like Polymarket and Kalshi allow people to make wagers on the outcomes of real-world events. For instance, on Polymarket, there are wagers being made around the kind of products OpenAI will announce in 2026 and when the company will go public. They can cover any event, and some eye-popping money can be made. As we recently reported, an accountant won a $470,300 jackpot on Kalshi by betting against DOGE believers. Prediction markets insist they are not gambling sites, preferring to label themselves as financial platforms. Kalshi is a regulated exchange and, in fact, it fined and banned a MrBeast editor for similar alleged insider trading earlier this week. OpenAI did not immediately respond to a request for additional comment.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2023/06/OpenAI-logo-symmetry.jpg?resize=1200,675"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "Under a Paramount-WBD merger, two struggling media giants would unite",
      "url": "https://arstechnica.com/gadgets/2026/02/under-a-paramount-wbd-merger-two-struggling-media-giants-would-unite/",
      "published": "2026-02-27T22:39:00+00:00",
      "summary": "Can two declining companies form a profitable one?",
      "content_text": "A successful Paramount-WBD merger would be the largest streaming merger ever and would lead to further consolidation in the industry . “What started as a fragmented but flexible streaming ecosystem is increasingly trending toward rebundling—fewer, larger super-platforms offering broader catalogues at higher price points,” Mathur said. Paramount holds on to cable Paramount’s WBD bid is unique in its aggressive push for cable channels, which are struggling with viewership and advertising revenue. Under a WBD merger, Paramount would add networks like HGTV, Cartoon Network, TLC, and CNN to its linear TV lineup, which currently includes Comedy Central, Nickelodeon, and CBS. Although Paramount and WBD’s cable businesses are both in decline, they are both profitable. Paramount’s TV/media business, which includes its cable channels and production studios, reported $1.1 billion in adjusted OIBDA in Q4 2025. WBD’s cable business posted adjusted EBITDA of $1.41 billion that quarter. Ultimately, a Paramount-WBD merger would put diversity of viewpoints at risk. Under Ellison’s ownership, CBS News has adjusted its approach with new editor-in-chief Bari Weiss. There have also been concerns about censoring CBS under Ellison’s Paramount , including from Stephen Colbert , who said this month that CBS forbade him from interviewing Texas Democratic Senate candidate James Talarico; CBS denied Colbert’s claim. Further, Paramount could have a lasting impact on CNN , including costs, layoffs, and coverage. More to come Regulatory scrutiny will be at the center of Paramount and WBD’s merger over the upcoming months. Federal approval is likely, but the merger also faces European regulation and potential state lawsuits . The theater industry is also lobbying against Paramount’s WBD merger. Should a Paramount-WBD merger ultimately be greenlit, two declining businesses will be challenged to form a profitable one. Even with regulatory approval, Paramount-Skydance-Warner-Bros.-Discovery faces an uphill climb. Although the bidding war may be settled, the fight for WBD is only beginning.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/GettyImages-79075226-1152x648.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Scientific gaps, field-based insights, and a framework for future research",
      "url": "https://emt.pensoft.net/article/185117/",
      "published": "2026-02-27T22:13:54+00:00",
      "summary": "<p>Article URL: <a href=\"https://emt.pensoft.net/article/185117/\">https://emt.pensoft.net/article/185117/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47186444\">https://news.ycombinator.com/item?id=47186444</a></p> <p>Points: 19</p> <p># Comments: 2</p>",
      "content_text": "Subscribe to email alerts for current Article's categories",
      "cover_image_url": "https://emt.pensoft.net/showimg/d200x_1525594.jpg"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "These Deals Can Have You Zipping Around on a New E-Scooter This Spring",
      "url": "https://www.wired.com/story/electric-scooters-spring-deals-2026/",
      "published": "2026-02-27T21:55:44+00:00",
      "summary": "With spring just around the corner, now's the smart time to snag an electric scooter.",
      "content_text": "The snow is melting, the days are getting longer, and I can almost smell the springtime ahead. Soon, we'll be cruising around town on ebikes and electric scooters instead of burning fossil fuels. For now, the weather hasn't quite caught up, which is great for markdowns. Many of the best electric scooters are still seeing significant discounts. If you've been thinking about buying one, now's the best time: prices are low, and sunny commuting days are just ahead. Gear editor Julian Chokkattu has spent five years testing more than 45 electric scooters . These are his top picks that are also on sale right now. Apollo Go for $849 ($450 Off) Photograph: Julian Chokkattu This is Gear editor Julian Chokkattu's favorite scooter. The riding experience is powerful and smooth, thanks to its dual 350-watt motors and solid front and rear suspensions. The speed maxes out at 28 miles per hour (mph), which doesn't make it the fastest scooter on the market, but it has a good range. (Chokkattu is a very tall man and was able to travel 15 miles on a single charge at 15 mph.) Other Apollo features he appreciates: turn signals, a dot display, a bell, along with a headlight and an LED strip for extra visibility. Apollo Phantom 2.0 for $2099 ($900 Off) Photograph: Julian Chokkattu Photograph: Julian Chokkattu Photograph: Julian Chokkattu The Apollo Phantom 2.0 maxes out at 44 mph, with plenty of power from its dual 1,750-watt motors. It's a gorgeous scooter, designed with 11-inch self-healing tubeless tires and a dual-spring suspension system for a smooth riding experience. But with great power comes great weight. At 102 pounds, the Phantom 2.0 is the heaviest electric scooter Chokkattu has tested, so I would only recommend this purchase if you don't live in a walkup and/or have a garage. More Discounted Electric Scooters Segway Max G3 This is the best commuter scooter, with more power and range than the Apollo Go and a fast 3.5-hour recharge time. Segway Ninebot F3 Electric Scooter The Segway F3 is designed with turn signals, a bell, a bright display, and a feature-rich app experience. Niu KQi 300X This is the best all-terrain scooter, with reliable suspension, dual disc brakes, and thick 10.5-inch tubeless tires. Segway E2 Pro This is the best budget scooter, designed with a decent 350-watt motor, a max speed of 15 mph, a front drum brake, and a rear electronic brake.",
      "cover_image_url": "https://media.wired.com/photos/69a20ae5eb0d16f48f12ac6f/191:100/w_1280,c_limit/Our%20Favorite%20Electric%20Scooters%20Just%20Dropped%20in%20Price.png"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Pentagon moves to designate Anthropic as a supply-chain risk",
      "url": "https://techcrunch.com/2026/02/27/pentagon-moves-to-designate-anthropic-as-a-supply-chain-risk/",
      "published": "2026-02-27T21:53:14+00:00",
      "summary": "\"We don't need it, we don't want it, and will not do business with them again,\" the president wrote in the post.",
      "content_text": "In a post on Truth Social, President Trump directed federal agencies to cease use of all Anthropic products after the company’s public dispute with the Department of Defense . The president allowed for a six-month phase-out period for departments using the products, but emphasized that Anthropic was no longer welcome as a federal contractor. “We don’t need it, we don’t want it, and will not do business with them again,” the president wrote in the post. Notably, the president’s post did not mention any plans to designate Anthropic as a supply chain risk, as had been previously mentioned as a consequence. However, a subsequent tweet from Secretary of Defense Pete Hegseth made good on the threat. “In conjunction with the President’s directive for the Federal Government to cease all use of Anthropic’s technology, I am directing the Department of War to designate Anthropic a Supply-Chain Risk to National Security,” Secretary Hegseth wrote. “Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic.” The Pentagon dispute centered on Anthropic’s refusal to allow its AI models to be used to power either mass domestic surveillance or fully autonomous weapons, which Secretary Hegseth found unduly restrictive. CEO Dario Amodei reiterated his stance in a public post on Thursday , refusing to compromise on the two points. “Our strong preference is to continue to serve the Department and our warfighters — with our two requested safeguards in place,” Amodei wrote at the time. “Should the Department choose to offboard Anthropic, we will work to enable a smooth transition to another provider, avoiding any disruption to ongoing military planning, operations, or other critical missions.” Techcrunch event Boston, MA | June 9, 2026 OpenAI has come out in support of Anthropic’s decision. Per the BBC , CEO Sam Altman sent a memo to staff on Thursday saying he shared the same “red lines” and that any OpenAI-related defense contracts would also reject uses that were “unlawful or unsuited to cloud deployments, such as domestic surveillance and autonomous offensive weapons.” OpenAI co-founder Ilya Sutskever, who very publicly fell out with Altman in November 2023 and has since co-founded his own AI company, also waded into the conversation on Friday, writing on X : “It’s extremely good that Anthropic has not backed down, and it’s significant that OpenAI has taken a similar stance. In the future, there will be much more challenging situations of this nature, and it will be critical for the relevant leaders to rise up to the occasion, for fierce competitors to put their differences aside. Good to see that happen today.” Anthropic, OpenAI and Google each received contract awards from the U.S. Defense Department last July. While some Google employees have come out in support of Anthropic, Google and its parent company have yet to comment.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/07/GettyImages-2225249178.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Warner Bros. Discovery agrees to $110 billion Paramount merger",
      "url": "https://www.theverge.com/entertainment/886478/warner-bros-discovery-paramount-merger-agreement",
      "published": "2026-02-27T21:43:37+00:00",
      "summary": "Warner Bros. Discovery and Paramount Skydance's merger agreement is now official. On Friday, the two companies announced plans to merge into a massive media company that will fold WBD's studio, linear channels, streaming service, and gaming segment into Paramount. Though WBD initially signed onto an $83 billion agreement to merge part of Warner Bros. with [&#8230;]",
      "content_text": "Warner Bros. Discovery and Paramount Skydance’s merger agreement is now official. On Friday, the two companies announced plans to merge into a massive media company that will fold WBD’s studio, linear channels, streaming service, and gaming segment into Paramount. Though WBD initially signed onto an $83 billion agreement to merge part of Warner Bros. with Netflix, Paramount persisted with a hostile takeover bid , followed by a series of offers. That persistence paid off, as WBD determined that Paramount’s “best and final” offer is “superior” to Netflix’s deal. On Thursday, Netflix declined to match Paramount’s bid , calling it “no longer financially attractive.” Paramount and WBD say the board of directors of both companies has signed off on the deal. The companies expect it to close in the third quarter of 2026, subject to regulatory and shareholder approval. Under the agreement, Paramount will acquire WBD in a deal valued at $110 billion. Paramount has also agreed to cover the $7 billion regulatory termination fee and the $2.8 billion breakup fee owed to Netflix, which it has already paid, according to Bloomberg . “Together, Paramount and WBD will deliver greater choice for consumers through its leading streaming platforms with an exceptional intellectual property portfolio that has produced popular franchises such as Game of Thrones, Mission Impossible, Harry Potter, Top Gun, the DC Universe and SpongeBob SquarePants ,” the companies say in the press release. If approved, the deal would transform Paramount into an entertainment behemoth. Skydance only just completed its acquisition of Paramount last August , putting David Ellison, the son of Oracle co-founder and President Donald Trump ally Larry Ellison, into the CEO role. Ellison has made a number of changes at the Paramount-owned CBS News, including installing The Free Press founder Bari Weiss as editor-in-chief . These changes have raised concerns among staff members at CNN, according to Variety . Lawmakers and regulators are skeptical about the Paramount-WBD merger. “A handful of Trump-aligned billionaires are trying to seize control of what you watch and charge you whatever price they want,” Sen. Elizabeth Warren (D-MA) said in a statement. California Attorney General Rob Bonta also warned that the agreement isn’t a “done deal,” and that the state’s Department of Justice will be “vigorous” in its review of the merger.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/10/STKB374_WARNER_BROS_B.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "MIT Technology Review",
      "title": "MIT Technology Review is a 2026 ASME finalist in reporting",
      "url": "https://www.technologyreview.com/2026/02/27/1133769/asme-finalist-reporting/",
      "published": "2026-02-27T21:41:31+00:00",
      "summary": "The American Society of Magazine Editors has named MIT Technology Review as a finalist for a 2026 National Magazine Award in the reporting category. The shortlisted story—“We did the math on AI’s energy footprint. Here’s the story you haven’t heard”—is part of the publication&#8217;s Power Hungry package on AI’s energy burden. AI is often described&#8230;",
      "content_text": "AI is often described as a black box, but it’s not just its inner workings that are mysterious. Leading AI companies have kept figures on energy use closely guarded, making it hard to determine its climate impact. In a rigorous investigation, senior AI reporter James O’Donnell and senior climate reporter Casey Crownhart spent six months digging through hundreds of pages of reports, interviewing experts, and crunching the numbers. The team drilled down into the energy cost of a single prompt, and then zoomed out to build a broader picture illustrating the potential impacts of AI’s current and future energy demand. Their work revealed just how big AI’s energy footprint is, where that energy comes from, and who will pay for it. In the months following the project’s publication, major AI companies including Open AI, Mistral, and Google published details about their models’ energy and water usage. The 2026 awards will be presented in New York City on May 19.",
      "cover_image_url": "https://wp.technologyreview.com/wp-content/uploads/2026/02/monster-thumb.jpg?resize=1200,600"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "Trump Moves to Ban Anthropic From the US Government",
      "url": "https://www.wired.com/story/trump-moves-to-ban-anthropic-from-the-us-government/",
      "published": "2026-02-27T21:36:31+00:00",
      "summary": "President Donald Trump’s sudden order comes after the Defense Department pressured Anthropic to drop restrictions on how its AI can be used by the military.",
      "content_text": "US President Donald Trump announced Friday that he was instructing every federal agency to “immediately cease” use of Anthropic’s AI tools. The move comes after Anthropic and top officials clashed for weeks over military applications of artificial intelligence. \"The Leftwing nut jobs at Anthropic have made a DISASTROUS MISTAKE trying to STRONG-ARM the Department of War,” Trump said in a post on Truth Social . Trump said that there would be a “six month phase out period” for agencies using Anthropic, which could allow time for further negotiations between the government and the AI startup. The Pentagon and Anthropic did not immediately respond to requests for comment. Shortly after the President’s announcement, defense secretary Pete Hegseth said that Anthropic would also be designated a “supply chain risk,” a move normally reserved for foreign businesses considered a danger to American national security. The designation will bar the US military and its contractors and suppliers from working with the AI company. Hegseth also lashed out at Anthropic and its CEO, Dario Amodei, over the company's refusal to agree to its demands. “Cloaked in the sanctimonious rhetoric of ‘effective altruism,' they have attempted to strong-arm the United States military into submission—a cowardly act of corporate virtue-signaling that places Silicon Valley ideology above American lives,” Hegseth wrote on X. The Department of Defense has sought to change the terms of a deal struck with Anthropic and other companies last July to eliminate restrictions on how AI can be deployed and instead permit “all lawful use” of the technology. Anthropic objected to the change, claiming that it could allow AI to be used to fully control lethal autonomous weapons or to conduct mass surveillance on US citizens. The Pentagon does not currently use AI in these ways, and has said it has no plans to do so. However, top Trump administration officials have voiced opposition to the idea of a civilian tech company dictating military use of such an important technology. Anthropic was the first major AI lab to work with the US military, through a $200 million deal signed with the Pentagon last year. It created several custom models known as Claude Gov that have fewer restrictions than its regular ones. Google, OpenAI, and xAI signed similar deals around the same time, but Anthropic is the only AI company currently working with classified systems. Anthropic’s model is available through platforms provided by Palantir and Amazon’s cloud platform for classified military work. Claude Gov is currently largely used for run-of-the-mill tasks, like writing reports and summarizing documents, but it is also used for intelligence analysis and military planning, according to one source familiar with the situation who spoke to WIRED on condition of anonymity because they are not authorized to discuss the matter publicly. In recent years, Silicon Valley has gone from largely avoiding defense work to increasingly embracing it and eventually becoming full-blown military contractors. The fight between Anthropic and the Pentagon is now testing the limits of that shift. This week, several hundred workers from OpenAI and Google signed an open letter supporting Anthropic and criticizing their own companies’ decisions to remove restrictions on military use of AI. In a memo sent to OpenAI staff today, CEO Sam Altman said that the company agreed with Anthropic and also viewed mass surveillance and fully autonomous weapons as a “red line.” Altman added that the company would try to agree to a deal with the Pentagon that would let it continue working with the military, The Wall Street Journal reported .",
      "cover_image_url": "https://media.wired.com/photos/69a0a09c6c9d7076f06f28c6/191:100/w_1280,c_limit/Pentagon-Goes-Nuclear-on-Anthropic-Business-2261852583.jpg"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Trump orders federal agencies to drop Anthropic’s AI",
      "url": "https://www.theverge.com/policy/886489/pentagon-anthropic-trump-dod",
      "published": "2026-02-27T21:30:47+00:00",
      "summary": "On Friday afternoon, Donald Trump posted on Truth Social, accusing Anthropic, the AI company behind Claude, of attempting to \"STRONG-ARM\" the Pentagon and directing federal agencies to \"IMMEDIATELY CEASE\" use of its products. At issue is Anthropic CEO Dario Amodei's refusal of an updated agreement with the US military agreeing to \"any lawful use\" of [&#8230;]",
      "content_text": "THE UNITED STATES OF AMERICA WILL NEVER ALLOW A RADICAL LEFT, WOKE COMPANY TO DICTATE HOW OUR GREAT MILITARY FIGHTS AND WINS WARS! That decision belongs to YOUR COMMANDER-IN-CHIEF, and the tremendous leaders I appoint to run our Military. The Leftwing nut jobs at Anthropic have made a DISASTROUS MISTAKE trying to STRONG-ARM the Department of War, and force them to obey their Terms of Service instead of our Constitution. Their selfishness is putting AMERICAN LIVES at risk, our Troops in danger, and our National Security in JEOPARDY. Therefore, I am directing EVERY Federal Agency in the United States Government to IMMEDIATELY CEASE all use of Anthropic’s technology. We don’t need it, we don’t want it, and will not do business with them again! There will be a Six Month phase out period for Agencies like the Department of War who are using Anthropic’s products, at various levels. Anthropic better get their act together, and be helpful during this phase out period, or I will use the Full Power of the Presidency to make them comply, with major civil and criminal consequences to follow. WE will decide the fate of our Country — NOT some out-of-control, Radical Left AI company run by people who have no idea what the real World is all about. Thank you for your attention to this matter. MAKE AMERICA GREAT AGAIN!",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2025/02/STK466_ELECTION_2024_CVirginia_E.jpg?quality=90&strip=all&crop=0%2C9.9676601489831%2C100%2C80.064679702034&w=1200"
    },
    {
      "industry": "technology",
      "source": "Ars Technica",
      "title": "Photons that aren't actually there influence superconductivity",
      "url": "https://arstechnica.com/science/2026/02/photons-that-arent-actually-there-influence-superconductivity/",
      "published": "2026-02-27T21:27:33+00:00",
      "summary": "Interactions between neighboring materials is mediated by virtual photons.",
      "content_text": "Despite the headline, this isn’t really a story about superconductivity—at least not the superconductivity that people care about, the stuff that doesn’t require exotic refrigeration to work. Instead, it’s a story about how superconductivity can be used as a test of some of the weirder consequences of quantum mechanics, one that involves non-existent particles of light that still act as if they exist. Researchers have found a way to get these virtual photons to influence the behavior of a superconductor, ultimately making it worse. That may, in the end, tell us something useful about superconductivity, but it’ll probably take a little while. Virtual reality The story starts with quantum field theory, which is incredibly complex, but the simplified version is that even empty space is filled with fields that could govern the interactions of any quantum objects in or near that space. You can think of different particles as energetic excitements of these fields—so a photon is simply an energetic state of the quantum field. Some of these particles have real existences we can track, like a photon emitted by a laser and absorbed by a detector some distance away. But the quantum field also allows for virtual photons , which simply act to transmit the electromagnetic force between particles. We can’t really directly detect these, but we can definitely track their effects. One of the stranger consequences of this is that locations that have a strong electromagnetic field can be filled with virtual photons even when no real ones are present. Which brings us to one of the materials central to the new work: boron nitride. Like the more famous graphene, boron nitride forms a series of interlinked hexagonal rings, extending out into macroscopic sheets. The bulk material is made of sheets layered onto sheets layered onto yet more sheets. This has an effect on light transiting through the material. In one direction, the light will simply slam into the material, getting absorbed or scattered. But if it’s oriented along the plane of the sheets, it’s possible for the light to travel in the space between the boron and nitrogen atoms.",
      "cover_image_url": "https://cdn.arstechnica.net/wp-content/uploads/2026/02/niac_2011_thibeault-1041x648.jpg"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "The Best Roku Is $20 Off",
      "url": "https://www.wired.com/story/roku-ultra-deal-226/",
      "published": "2026-02-27T20:38:58+00:00",
      "summary": "The Roku Ultra isn’t just speedier, it also offers some advanced features that some viewers will find really handy.",
      "content_text": "Looking for an upgraded Roku that's a great match for your new 4K TV? Right now, both Amazon and Best Buy have the 2024 Roku Ultra discounted to $80, a $20 break from the usual price. It sports dual-band Wi-Fi and Ethernet for a more consistent connection, support for Dolby Vision and HDR10+, and the remote has a headphone port. While there are a ton of great Roku streaming devices to choose from, the Ultra stands out for a few reasons. Streaming in 4K requires a huge amount of bandwidth, and some wireless networks just aren't up to the task, particularly if your TV isn't near your router. A true dual-band Wi-Fi setup in the Roku Ultra helps ensure a stutter-free experience on all of your favorite streaming services. If you really hate buffering and dropped connections, there's an Ethernet port around back for a wired hookup, something most other streaming devices can't claim. Another nice upgrade you get with your Roku Ultra kit is the remote, which includes a built-in 3.5-mm headphone jack. That's perfect if you like to sneak in a few episodes of your favorite show after everyone's gone to bed, or want to catch a movie without waking a sleeping baby. The Roku Ultra even includes a pair of earbuds you can use right out of the box, which are surprisingly good for what they are, and they include extra ear tips for getting the fit right. Like some of the other premium Roku streaming devices, the hands-free voice controls make it super easy to find what you're looking for. Rather than dig through all of your apps and services looking for a movie, you can just say the title into the remote and let Roku go and find it for you. If you're ready to take your 4K streaming to the next level, both Best Buy and Amazon have the Roku Ultra marked down to $80. We also have a great guide that breaks down the differences between all of the available Roku streamers , and a roundup of our favorite media streamers , in case you're wondering what the Roku alternatives look like.",
      "cover_image_url": "https://media.wired.com/photos/69a1fdf1067f37c7d49f5276/191:100/w_1280,c_limit/Our%20Favorite%20Upgraded%20Roku%20Is%20$20%20Off.png"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Musk bashes OpenAI in deposition, saying 'nobody committed suicide because of Grok'",
      "url": "https://techcrunch.com/2026/02/27/musk-bashes-openai-in-deposition-saying-nobody-committed-suicide-because-of-grok/",
      "published": "2026-02-27T19:42:00+00:00",
      "summary": "In his lawsuit against OpenAI, Musk touted xAI safety compared with ChatGPT. A few months later, xAI's Grok flooded X with nonconsensual nude images.",
      "content_text": "In a newly released deposition filed in Elon Musk’s case against OpenAI, the tech executive attacked OpenAI’s safety record, claiming that his company, xAI, better prioritizes safety. He went so far as to say that “Nobody has committed suicide because of Grok, but apparently they have because of ChatGPT.” The comment came up in a line of questioning about a public letter Musk signed in March 2023. In it, he called on AI labs to pause development of AI systems more powerful than GPT-4, OpenAI’s flagship model at the time, for at least six months. The letter, which was signed by over 1,100 people, including many AI experts, stated there was not enough planning and management taking place at AI labs, as they were locked in an “out-of-control race to develop and deploy ever more powerful digital minds that no one — not even their creators — can understand, predict, or reliably control.” Those fears have since gained credibility. OpenAI now faces a series of lawsuits alleging that ChatGPT’s manipulative conversation tactics have led several people to experience negative mental health effects, with some dying by suicide. Musk’s comment suggests that these incidents could be used as fodder in his case against OpenAI. The transcript of Musk’s video testimony, which took place back in September, was filed publicly this week, ahead of the expected jury trial next month. The lawsuit against OpenAI centers on the company’s shift from a nonprofit AI research lab to a for-profit company, which Musk claims violated its founding agreements. As part of his arguments, Musk claims that AI safety could be compromised by OpenAI’s commercial relationships, as such relationships would place speed, scale, and revenue above safety concerns. However, since that recording, xAI has faced safety concerns of its own. Last month, Musk’s social network X was flooded with nonconsensual nude images generated by xAI’s Grok, some of which were said to be of minors . This led the California Attorney General’s office to open an investigation into the matter. The EU is also running its own investigation , and other governments have taken action, too, with some imposing blocks and bans. In the newly filed deposition, Musk claimed he had signed the AI safety letter because “it seemed like a good idea,” not because he had just incorporated an AI company looking to compete with OpenAI. “I signed it, as many people did, to urge caution with AI development,” Musk said. “I just wanted … AI safety to be prioritized.” Image Credits: imgflip Musk also responded to other questions in the deposition, including those about artificial general intelligence, or AGI — the concept of AI that can match or surpass human reasoning across a broad range of tasks — saying “it has a risk.” He also confirmed that he “was mistaken” about his supposed $100 million donation to OpenAI; the second amended complaint in the case puts the actual figure closer to $44.8 million. He also recalled why OpenAI was founded, which, from his perspective, was because he was “increasingly concerned about the danger of Google being a monopoly in AI,” adding that his conversations with Google co-founder Larry Page were “alarming, in that he did not seem to be taking AI safety seriously.” OpenAI was formed as a counterweight to that threat, Musk claimed.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2024/11/GettyImages-2183887189.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "What's an E-Bike? California Wants You to Know",
      "url": "https://www.wired.com/story/what-is-an-e-bike-california-might-find-out/",
      "published": "2026-02-27T19:39:15+00:00",
      "summary": "Cities want to stop kids from getting hurt. A lawmaker thinks warning them away from legal gray-area “e-motos” could help.",
      "content_text": "A few months ago, a family came into Pasadena Cyclery in Pasadena, California, for a repair on what they thought was their teenager’s ebike. “I can’t fix that here,’ Daniel Purnell, a store manager and technician, remembers telling them. “That’s a motorcycle.” The mother got upset. She didn’t realize that what she thought was an ebike could go much faster, perhaps up to 55 miles per hour. “There’s definitely an education problem,” Purnell says. In California, bike advocates are pushing a new bill designed to clear up that confusion around what counts as an electric bicycle —and what doesn’t. It’s a tricky balance. On one hand, backers want to allow riders access to new, faster, and more affordable non-car transportation options, ones that don’t require licenses and are emission-free. On the other hand, people, and especially kids, seem to be getting hurt. Ebike-related injuries jumped more than 1,020 percent nationwide between 2020 and 2024, according to hospital data , though it’s not clear if the stats-keepers can routinely distinguish between ebikes and their faster, “e-moto” cousins. (Moped and powered-assisted cycle injuries jumped 67 percent in that same period.) “We’re overdue to have better ebike regulation,” says California state senator Catherine Blakespear, a Democrat who sponsored the bill and represents parts of North County in San Diego. “This has been an ongoing and growing issue for years.” Senate Bill 1167 would make it illegal for retailers to label higher-powered, electric-powered vehicles as ebikes. It would clarify that ebikes have fully operative pedals and electric motors that don’t exceed 750 watts, enough to hit top speeds between 20 and 28 mph. “We’re not against these devices,” says Kendra Ramsey, the executive director of the California Bicycle Coalition, which represents riders and is promoting the legislation. “People think they’re ebikes and they're not really ebikes.” Bill backers say they hope the fix, if it passes, makes a difference, especially for teenagers, who love the freedom that electric motors give them but can get into trouble if something goes wrong at higher speeds. Kids 17 and younger accounted for 20 percent of US ebike injuries from 2020 to 2024, about in line with the share of the total population. But headlines—and the laws that follow them—have focused on teen injuries and even deaths . There are no national laws governing ebike riding. But bike backers spent years moving between states to pass laws that put ebikes into three classes : Class 1, which have pedal-assist that only works when they’re actually pedaled, and goes up to 20 mph; Class 2, which have throttles that work without pedaling but still only reach 20 mph; and Class 3, which use pedal-assist to move up to 28 mph. Plenty of states and cities restrict the most powerful Class 3 bikes to people older than 16. (In a complicated twist, some ebikes have different “modes,” allowing riders to toggle between Class 2 and Class 3.) Last year, researchers visited 19 San Francisco Bay Area middle and high schools and found that 88 percent of the electric two-wheeled devices parked there were so high-powered and high-speed that they didn’t comply with the three-class system at all. Ebikes have clearly struck a chord with state policymakers: at least 10 bills introduced this year deal with ebikes, according to Ramsey. Some bike advocates believe injuries have less to do with ebikes than “e-motos,” a category that’s less likely to appear in retail stores or the sort of social media ads attracting teens to the tech. These have more powerful motors and can travel in excess of 30 mph. Vehicles, like the Surron Ultra Bee , which can hit top speeds of 55 mph, or Tuttio ICT , which can hit 50, are often marketed by retailers as \"electric bikes.” Because so many sales happen online, it can be hard for people, and especially parents, to know what they’re getting into.",
      "cover_image_url": "https://media.wired.com/photos/69a15254557a18dd5b8f3939/191:100/w_1280,c_limit/What-Is-An-Ebike-Gear-2242247597.jpg"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "The Trump phone sure looks a lot like this HTC handset",
      "url": "https://www.theverge.com/tech/886135/trump-mobile-t1-phone-htc-u24-pro",
      "published": "2026-02-27T19:27:12+00:00",
      "summary": "Where's the Trump phone? We're going to keep talking about it every week. We've reached out, as usual, to ask about the Trump phone's whereabouts, and have stopped getting a response. This week, thanks to a reader tip, we think we've found the original phone the T1 is based on. A long time ago, back [&#8230;]",
      "content_text": "Where’s the Trump phone? We’re going to keep talking about it every week . We’ve reached out, as usual, to ask about the Trump phone’s whereabouts, and have stopped getting a response. This week, thanks to a reader tip, we think we’ve found the original phone the T1 is based on. A long time ago, back when the Trump phone was but a single, inaccurate render and a contradictory spec sheet, we tried to figure out what other phone it might be based on . Now, eight months, two spec overhauls, and one redesign later, I have a good guess: the HTC U24 Pro. I didn’t spot this by myself. A reader first tipped me off to the similarities between the U24 Pro and the Trump phone I revealed a few weeks ago , which are numerous: a similar angled body and curved display, a unique front sensor array, and broadly similar specs, including oddities like a headphone jack and microSD card support. Let’s get one thing out the way at the top: I’m pretty sure HTC isn’t secretly building the Trump phone. Sohaib Ahmed, the company’s global director of PR, told me as much: “HTC does not design or manufacture phones for third parties.” But that doesn’t rule out another company playing a part in designing or building both phones, and given just how similar they look, I suspect that’s exactly what happened. It’s a little hard to make out in this screenshot, but the Trump phone shares the sharply angled edges of the HTC U24 Pro. Screenshot: The Verge and Screenshot: JerryRigEverything The U24 Pro is an odd phone in its own right. It launched in 2024 for €549 (around $600 at the time), and was heralded in some corners as a return from the dead for HTC, despite the fact that it followed the U23 Pro a year earlier, and a string of smaller releases that targeted the Asian market. HTC, once one of the major players in the Android phone industry, had been greatly diminished ever since selling a large part of its smartphone business to Google for $1.1 billion in 2017. Both the T1 Phone and the U24 Pro share a slightly asymmetric angular frame, jutting out into a point along every edge, with a heavily curved screen on the front. I cannot think of, nor find, another phone that is quite the same shape — even small details like the positions of the antenna lines around the power and volume buttons line up. Even more telling is the set of sensors along each phone’s top. The U24 Pro splits up its speaker grill, notification LED, and proximity sensor into three, resulting in an unusual design with a long bar, a small dot for the LED, and then a second shorter bar, at the point where the display meets the phone’s top. What looks like the same sensor design can be clearly seen on the Trump phone I was shown, though I can’t confirm that the sensors themselves are the same, or that the T1 Phone will also have a notification LED. Both phones have near-identical sets of speakers and sensors about the front selfie camera, with headphone jack and microphone visible behind them on the top edges. Screenshot: The Verge and Screenshot: JerryRigEverything Other details are subtler. It’s hard to tell exactly from the glimpses I got of the Trump phone, but along the top frame it certainly looks to have both a headphone jack and a microphone in the exact same positions as on the HTC device. Even having a headphone jack in the first place is evidence of the phones’ connection, given how rare the feature is in modern devices. The same can be said for the fact that both phones include a microSD card slot, sharing support for up to 1TB cards on top of a base 512GB of storage. While the rear cameras look completely different, which seems to scupper my theory, look again: The U24 Pro’s cameras are split into a pair close together, with a third lens lower down. The new Trump phone sets all its cameras in one mount, but they’re unevenly spaced, with a larger gap between the second and third lenses. These cameras may look totally different on the surface, but I suspect that underneath you’ll find they’re similar. And what we know of the specs matches too: Trump Mobile told me that its phone will have 50-megapixel sensors for both the main and selfie cameras, and my glimpse of its camera UI showed an ultrawide and a 2x zoom option — all of which you’ll find on the U24 Pro. The two phones’ cameras look different at first, but the unusual lens placement might just line up. Screenshot: Dominic Preston / The Verge and Image: HTC Assuming that the two phones are essentially the same, does the U24 Pro tell us any more about what to expect from the T1? It’s powered by Qualcomm’s Snapdragon 7 Gen 3, matching what I’d been told about a Snapdragon 7-series chip in the Trump phone. The U24 Pro has a 6.8-inch OLED display, 60W wired charging and even wireless charging support, and an IP67 rating for dust and water protection. There’s reason to be cautious reading too much into the spec sheet, though: The U24 Pro released with a 4,600mAh battery, smaller than the 5,000mAh capacity I’ve been told will be in the Trump phone. If that spec differs, then other elements of the internals could well too — the bigger battery in particular might replace the wireless charging coils of the HTC phone. The U24 Pro launched to middling reviews, which may not inspire much confidence in Trump Mobile’s offering. Tech Advisor gave the phone two and a half stars out of five, calling it “hard to recommend over rivals,” while Notebookcheck declared it “modern and yet out of date.” Still, it fared surprisingly well in a JerryRigEverything teardown and durability test. He noticed, however, that this didn’t appear to be the HTC of old, lacking the sapphire crystal HTC previously used on its displays and optical image stabilization on the front camera it once pioneered. The U24 Pro and other HTC phones released in the last few years share little consistent design language, and ship with near-stock Android software. Speculation has been rife that HTC isn’t in fact manufacturing the phones internally, but had commissioned an ODM — original design manufacturer — to produce the hardware. ODMs design and manufacture phones for other companies, usually to a set of specifications provided by the consumer-facing brands, and often retain ownership of the designs, allowing them to reuse and repurpose them for other clients. I asked HTC for clarification, but the company wouldn’t confirm whether the U24 Pro was made in-house or contracted out. It’s certainly possible that Trump Mobile, or its manufacturing partner, is simply ripping off the design of a little-known HTC device. But I think the most likely answer here is a more mundane one: HTC probably worked with some unnamed ODM to design and manufacture the U24 Pro, and Trump Mobile just happened to work with the same company. That manufacturer may have either dug out its old designs for HTC when developing the T1 Phone, or perhaps gave new life to old, unused components from HTC’s production run. Without knowing the hypothetical ODM involved, it’s hard to say for sure. Trump Mobile has previously confirmed that it’s working with a partner or partners to manufacture its phones outside the US, before their “final assembly” in Miami, but executive Don Hendrickson wouldn’t tell me the name of its manufacturer or where it’s based. I reached out to the company again for comment on this story, and received no reply. So no, I don’t think that HTC made the Trump phone. But it does look likely that it is based, more or less, on one of that company’s phones. It remains to be seen how the T1 Phone will differ in its details, but the fact that its origins seem so closely tied to an unpopular midranger from two years ago doesn’t exactly inspire confidence in the T1 Phone’s flagship credentials. Got inside information on Trump Mobile or the Trump phone? Reach out securely from a personal device to tips@theverge.com , or see our How to Tip Us page. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Dominic Preston Gadgets HTC Mobile Phones Policy Politics Report Tech",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/htc-u24-pro.avif?quality=90&strip=all&crop=0.3054298642534%2C0%2C99.389140271493%2C100&w=1200"
    }
  ]
}