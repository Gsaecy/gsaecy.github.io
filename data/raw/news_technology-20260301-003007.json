{
  "industry": "technology",
  "collected_at": "2026-02-28T16:31:12.077864+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "OpenAI’s Sam Altman announces Pentagon deal with ‘technical safeguards’",
      "url": "https://techcrunch.com/2026/02/28/openais-sam-altman-announces-pentagon-deal-with-technical-safeguards/",
      "published": "2026-02-28T16:17:36+00:00",
      "summary": "OpenAI's CEO claims its new defense contract includes protections addressing the same issues that became a flashpoint for Anthropic.",
      "content_text": "OpenAI CEO Sam Altman announced late on Friday that his company has reached an agreement allowing the Department of Defense to use its AI models in the department’s classified network. This follows a high-profile standoff between the department — also known under the Trump administration as the Department of War — and OpenAI’s rival Anthropic. The Pentagon pushed AI companies, including Anthropic, to allow their models be used “all lawful purposes,” while Anthropic sought to draw a red line around mass domestic surveillance and fully autonomous weapons. In a lengthy statement released Thursday , Anthropic CEO Dario Amodei said the company “never raised objections to particular military operations nor attempted to limit use of our technology in an ad hoc manner,” but he argued that “in a narrow set of cases, we believe AI can undermine, rather than defend, democratic values.” More than 60 OpenAI employees and 300 Google employees signed an open letter this week asking their employers to support Anthropic’s position. After Anthropic and the Pentagon failed to reach an agreement, President Donald Trump criticized the “Leftwing nut jobs at Anthropic” in a social media post that also directed federal agencies to stop using the company’s products after a six-month phase out period. In a separate post , Secretary of Defense Pete Hegseth claimed Anthropic was trying to “seize veto power over the operational decisions of the United States military.” Hegseth also said he is designating Anthropic as a supply-chain risk: “Effective immediately, no contractor, supplier, or partner that does business with the United States military may conduct any commercial activity with Anthropic.” On Friday, Anthropic said it had “not yet received direct communication from the Department of War or the White House on the status of our negotiations,” but insisted it would “challenge any supply chain risk designation in court.” Techcrunch event Boston, MA | June 9, 2026 Surprisingly, Altman claimed in a post on X that OpenAI’s new defense contract includes protections addressing the same issues that became a flashpoint for Anthropic. “Two of our most important safety principles are prohibitions on domestic mass surveillance and human responsibility for the use of force, including for autonomous weapon systems,” Altman said. “The DoW agrees with these principles, reflects them in law and policy, and we put them into our agreement.” Altman said OpenAI “will build technical safeguards to ensure our models behave as they should, which the DoW also wanted,” and it will deploy engineers with the Pentagon “to help with our models and to ensure their safety.” “We are asking the DoW to offer these same terms to all AI companies, which in our opinion we think everyone should be willing to accept,” Altman added. “We have expressed our strong desire to see things de-escalate away from legal and governmental actions and towards reasonable agreements.” Fortune’s Sharon Goldman reports that Altman told OpenAI employees at an all-hands meeting that the government will allow the company to build its own “safety stack” to prevent misuse, and that “if the model refuses to do a task, then the government would not force OpenAI to make it do that task.” Altman’s post came shortly before news broke that the U.S. and Israeli governments have begun bombing Iran , with Trump calling for the overthrow of the Iranian government.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2236544077.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "You can still grab great deals on Bose headphones and Astro Bot this weekend",
      "url": "https://www.theverge.com/gadgets/886520/bose-quietcomfort-headphones-samsung-galaxy-s26-ultra-deal-sale",
      "published": "2026-02-28T16:07:14+00:00",
      "summary": "Welcome to the weekend, friends! While the rest of our team was checking out Samsung’s forthcoming Galaxy S26 lineup and prepping for Apple’s “special experience” next week, we’ve been sifting through Woot’s “Video Games for All” sale and a truly weird slate of deals that, frankly, don’t have a throughline. (Some of us have also [&#8230;]",
      "content_text": "Welcome to the weekend, friends! While the rest of our team was checking out Samsung’s forthcoming Galaxy S26 lineup and prepping for Apple’s “special experience” next week, we’ve been sifting through Woot’s “Video Games for All” sale and a truly weird slate of deals that, frankly, don’t have a throughline. (Some of us have also spent the last week unpacking what Huel is , but that’s neither here nor there.) Here’s what we can tell you. If you’re thinking of picking up the Galaxy S26 Ultra at launch, putting in your preorder now isn’t a bad idea. It’s also a great time to pick up the midrange QuietComfort Headphones and what many of us at The Verge consider to be the game of 2024: Astro Bot . And who doesn’t want to save on a slick handheld vac ? If you’re craving a little peace and quiet, Bose’s QuietComfort Headphones are currently on sale at Amazon in multiple colors for $199 ($150 off), which is the best price we’ve seen this year. The standard QC Headphones are essentially a refresh of the last-gen QC45s with some new software tricks, including the ability to adjust noise cancellation levels and set custom listening modes. That being the case, you still get up to 24 hours of battery life, excellent comfort, and multipoint support, making it easy to switch between Bluetooth devices on the fly. They lack Bose’s immersive audio mode and the higher-quality Bluetooth found in the newer QC Ultras , though, as well as support for lossless audio over USB-C. Then again, that probably shouldn’t come as a surprise given they’re retailing for $250 less. As we alluded to earlier, Samsung announced its Galaxy S26 lineup this week. There are already plenty of preorder deals to consider, but one of the best comes courtesy of Amazon , which is throwing in a $200 gift card alongside a free storage upgrade when you preorder the 512GB Galaxy S26 Ultra starting at $1,299.99. Other retailers are also running promos ahead of the phone’s March 11th release date, mind you, though they’re not as impressive; Best Buy is only providing a free storage upgrade, while Samsung is offering a mere $150 in credit. While the Galaxy S26 and S26 Plus both feel like underwhelming, iterative updates, the 6.9-inch Galaxy S26 Ultra actually impressed our resident phone reviewer , Allison Johnson. That’s largely because of the new Privacy Display, which can help shield your screen from people sitting near you (if desired), and a more powerful camera array that should improve low-light performance. Plus, like the rest of the S26 lineup, the Ultra is powered by Qualcomm’s Snapdragon 8 Elite Gen 5, which supports more advanced generative AI tools and a souped-up version of Gemini that can carry out certain tasks in third-party apps on your behalf. No one likes calling an Uber themselves, anyway. You can still grab a physical copy of Astro Bot at Walmart for $32.99 ($27 off), an all-time low. The fantastic PlayStation 5 exclusive — which won Game of the Year at the 2024 Game Awards — has players take on the role of Astro, a lovable robot who sets off on a space adventure after his crew is lost in a sudden attack. Despite the prior game being a pack-in title for the PS5, Team Asobi’s full-sized sequel brims with inventive platforming, whimsical power-ups, and a kind of lighthearted fun that recalls the best of Crash Bandicoot and Spyro the Dragon . Thankfully, it never feels outdated, even if ‘90s vibes are totally there. If you’re looking for a relatively compact handheld vacuum that can reach into car crevices and suck up crumbs on your desk, Fanttik’s foldable Fold V10 Apex is still on sale at Amazon for $85.49 (about $65 off), matching its best price to date. Fanttik’s 17,000Pa vac features an extendable nozzle that pivots up to 210 degrees, along with a built-in LED light to help illuminate the dark corners of your vehicle. An onboard display, meanwhile, indicates the remaining battery life and suction mode, as well as the status of the washable filter. It also comes with a range of useful add-ons, including an upholstery tool, two brush heads, and an extendable hose with a crevice tool for hard-to-reach areas. It even charges via USB-C, making it easy to juice after the battery runs out in about 30 minutes or so. More ways to save this weekend",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/Bose-QuietComfort-Headphones-Deal-Image.png?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "NASA Is Making Big Changes to Speed Up the Artemis Program",
      "url": "https://www.wired.com/story/nasa-is-making-big-changes-to-speed-up-the-artemis-program/",
      "published": "2026-02-28T16:00:00+00:00",
      "summary": "America’s journey back to the moon has run into a few missteps. NASA administrator Jared Isaacman is banking on a new approach.",
      "content_text": "“This is just not the right pathway forward,” Isaacman said. A senior NASA official, speaking on background to Ars, noted that the space agency has experienced hydrogen and helium leaks during both the Artemis I and Artemis II prelaunch preparations, and these problems have led to monthslong delays in launch. “If I recall, the timing between Apollo 7 and 8 was nine weeks,” the official said. “Launching SLS every three and a half years or so is not a recipe for success. Certainly, making each one of them a work of art with some major configuration change is also not helpful in the process, and we’re clearly seeing the results of it, right?” The goal therefore is to standardize the SLS rocket into a single configuration in order to make the rocket as reliable as possible, and launching as frequently as every 10 months. NASA will fly the SLS vehicle until there are commercial alternatives to launch crews to the moon, perhaps through Artemis V as Congress has mandated, or perhaps even a little longer. Is Everyone on Board? The NASA official said all of the agency’s key contractors are on board with the change, and senior leaders in Congress have been briefed on the proposed changes. The biggest opposition to these proposals would seemingly come from Boeing, which is the prime contractor for the Exploration Upper Stage, a contract worth billions of dollars to develop a more powerful rocket that was due to launch for the first time later this decade. However, in a NASA news release, Boeing appeared to offer at least some support for the revised plans. “Boeing is a proud partner to the Artemis mission and our team is honored to contribute to NASA’s vision for American space leadership,” said Steve Parker, Boeing Defense, Space & Security president and CEO, in the news release. “The SLS core stage remains the world’s most powerful rocket stage, and the only one that can carry American astronauts directly to the moon and beyond in a single launch. As NASA lays out an accelerated launch schedule, our workforce and supply chain are prepared to meet the increased production needs.” Solid Reasons for Changing Artemis III NASA’s new approach to Artemis reflects a return to the philosophy of the Apollo program. During the late 1960s, the space agency flew a series of preparatory crewed missions before the Apollo 11 lunar landing. These included Apollo 7 (a low-Earth-orbit test of the Apollo spacecraft), Apollo 8 (a lunar orbiting mission), Apollo 9 (a low-Earth-orbit rendezvous with the lunar lander), and Apollo 10 (a test of the lunar lander descending to the moon, without touching down). With its previous Artemis template, NASA skipped the steps taken by Apollo 7, 9, and 10. In the view of many industry officials, this leap from Artemis II—a crewed lunar flyby of the moon testing only the SLS rocket and Orion spacecraft—to Artemis III and a full-on lunar landing was enormous and risky. The Artemis II crew rehearse a walkout from the Neil A. Armstrong Operations and Checkout Building at NASA’s Kennedy Space Center. Photograph: Joe Raedle/Getty Images",
      "cover_image_url": "https://media.wired.com/photos/69a1fc5ccd255f245e966b8e/191:100/w_1280,c_limit/sci-artemis2-2256758081.jpg"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "Hacked Prayer App Sends ‘Surrender’ Messages to Iranians Amid Israeli and US Strikes",
      "url": "https://www.wired.com/story/hacked-prayer-app-sends-surrender-messages-to-iranians-amid-israeli-strikes/",
      "published": "2026-02-28T15:58:09+00:00",
      "summary": "As Israeli airstrikes hit Tehran this morning, Iranians received mysterious push notifications saying that “help is on the way,” promising amnesty if they surrender.",
      "content_text": "Residents across Tehran and other Iranian cities were jolted awake by sounds of loud explosions in the early hours of Saturday morning, as Israel and the US launched joint attacks on Iran . The attacks, which the US and Israel are calling “preemptive strikes,” come after a period of failed negotiations between the countries, and on the heels of mass protests in Iran earlier this year that saw the death of at least 3,117 civilians, according to government statistics. Shortly after the first set of explosions, Iranians received bursts of notifications on their phones. They came not from the government advising caution, but from an apparently hacked prayer-timing app called ‘BadeSaba Calendar’ that has been downloaded more than 5 million times from the Google Play Store. The messages arrived in quick succession over a period of 30 minutes, starting with the phrase ‘Help Has Arrived’ at 9:52 am Tehran time, shortly after the first set of explosions. No party has claimed responsibility for the hacks. Screenshots shared with WIRED Middle East show messages urging Iranian military personnel to surrender their weapons with the promise of amnesty. They also urged army personnel to join “the forces of liberation” and to “defend your brothers.” The push notifications are all titled “Help is on the way”, and call on Iranian military members to surrender. Screenshot: WIRED Middle East “The time for revenge has come,” one notification received at 10:02 am read (translated from Farsi). “The regime's repressive forces will pay for their cruel and merciless actions against the innocent people of Iran. Anyone who joins in defending and protecting the Iranian nation will be granted amnesty and forgiveness.” “For the freedom of our Iranian brothers and sisters, this is a call to all oppressive forces—lay down your weapons or join the forces of liberation. Only in this way can you save your lives. For a free Iran,” another message sent at 10:14 am read. Cybersecurity analysts confirmed that BadeSabah users had received notifications around the time of the strikes, but have not been able to identify the source of the hack. “At this point, we genuinely do not know who is behind them, whether it was Israel or other anti-government Iranian groups,” says Narges Keshavarznia, digital rights researcher at the Miaan Group, adding that no hacker group has claimed credit. “Attribution in cases like this is always complex, and it’s still too early to draw conclusions.” ​​Morey Haber, the chief security advisor at BeyondTrust, however, pointed out that a cyber operation of this nature would almost certainly have been planned in advance. “The compromise of assets [likely] happened some time ago, and these messages of ‘help’ were timed” strategically, he claims. “This is not a smash-and-grab style of attack. It is nation-state versus nation-state and is being executed with intent and precision.” Iran on Saturday launched retaliatory kinetic attacks targeting key military bases across the Middle East. Explosions were reported in Bahrain, Kuwait, the UAE, and Qatar on Saturday, including multiple missiles that were intercepted . Digital Blackout, Cyber Warfare As the war unfolds, the Iranian public has already faced internet blackouts and weeks of severely reduced connectivity. “The country has been experiencing a widespread internet disruption, and access to the internet has significantly decreased in several parts of the country, including Tehran,” Keshavarznia says. According to internet monitoring tool NetBlocks, overall network traffic has dropped to 4 percent . Data from ArvanCloud’s Radar monitoring system, an Iranian-operated cloud service, indicates that many of the country’s main data centers and domestic PoP sites have either lost connectivity to the international internet or are experiencing severe disruption, Keshavarznia pointed out. Communication networks are also down with outages in phone lines and SMS services, and severe degradation of both mobile data and fixed broadband connections. “Incoming international calls to Iran are also reportedly affected. Even using VPNs has become extremely difficult,” she says.",
      "cover_image_url": "https://media.wired.com/photos/69a2fc44d16e57b38c5e2d95/191:100/w_1280,c_limit/MobileHackLead.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Cognitive Debt: When Velocity Exceeds Comprehension",
      "url": "https://www.rockoder.com/beyondthecode/cognitive-debt-when-velocity-exceeds-comprehension/",
      "published": "2026-02-28T15:39:10+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.rockoder.com/beyondthecode/cognitive-debt-when-velocity-exceeds-comprehension/\">https://www.rockoder.com/beyondthecode/cognitive-debt-when-velocity-exceeds-comprehension/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47196582\">https://news.ycombinator.com/item?id=47196582</a></p> <p>Points: 16</p> <p># Comments: 1</p>",
      "content_text": "The engineer shipped seven features in a single sprint. DORA metrics looked immaculate. The promotion packet practically wrote itself. Six months later, an architectural change required modifying those features. No one on the team could explain why certain components existed or how they interacted. The engineer who built them stared at her own code like a stranger’s. Code has become cheaper to produce than to perceive. The Comprehension Lag When an engineer writes code manually, two parallel processes occur. The first is production: characters appear in files, tests get written, systems change. The second is absorption: mental models form, edge cases become intuitive, architectural relationships solidify into understanding. These processes are coupled. The act of typing forces engagement. The friction of implementation creates space for reasoning. AI-assisted development decouples these processes. A prompt generates hundreds of lines in seconds. The engineer reviews, adjusts, iterates. Output accelerates. But absorption cannot accelerate proportionally. The cognitive work of truly understanding what was built, why it was built that way, and how it relates to everything else remains bounded by human processing speed. This gap between output velocity and comprehension velocity is cognitive debt. Unlike technical debt, which surfaces through system failures or maintenance costs, cognitive debt remains invisible to velocity metrics . The code works. The tests pass. The features ship. The deficit exists only in the minds of the engineers who built the system, manifesting as uncertainty about their own work. The debt is not truly invisible. It eventually appears in reliability metrics: Mean Time to Recovery stretches longer, Change Failure Rate creeps upward. But these are lagging indicators, separated by months from the velocity metrics that drive quarterly decisions. By the time MTTR signals a problem, the comprehension deficit has already compounded. What Organizations Actually Measure Engineering performance systems evolved to measure observable outputs. Story points completed. Features shipped. Commits merged. Review turnaround time. These metrics emerged from an era when output and comprehension were tightly coupled, when shipping something implied understanding something. The metrics never measured comprehension directly because comprehension was assumed. An engineer who shipped a feature was presumed to understand that feature. The presumption held because the production process itself forced understanding. That presumption no longer holds. An engineer can now ship features while maintaining only surface familiarity with their implementation. The features work. The metrics register success. The organizational knowledge that would traditionally accumulate alongside those features simply does not form at the same rate. Performance calibration committees see velocity improvements. They do not see comprehension deficits. They cannot, because no artifact of the organizational measurement system captures that dimension. The Reviewer’s Dilemma The discussion of cognitive debt typically focuses on the engineer who generates code. The more acute problem sits with the engineer who reviews it. Code review evolved as a quality gate. A senior engineer examines a junior engineer’s work, catching errors, suggesting improvements, transferring knowledge. The rate-limiting factor was always the junior engineer’s output speed. Senior engineers could review faster than juniors could produce. AI-assisted development inverts this relationship. A junior engineer can now generate code faster than a senior engineer can critically audit it. The volume of generated code exceeds the bandwidth available for deep review. Something has to give, and typically it is review depth. The reviewer faces an impossible choice. Maintain previous review standards and become a bottleneck that negates the velocity gains AI provides. Or approve code at the rate it arrives and hope the tests catch what the review missed. Most choose the latter, often unconsciously, because organizational pressure favors throughput. This is where cognitive debt compounds fastest. The author’s comprehension deficit might be recoverable through later engagement with the code. The reviewer’s comprehension deficit propagates: they approved code they do not fully understand, which now carries implicit endorsement. The organizational assumption that reviewed code is understood code no longer holds. The Burnout Pattern Engineers working extensively with AI tools report a specific form of exhaustion that differs from traditional burnout. Traditional burnout emerges from sustained cognitive load, from having too much to hold in mind while solving complex problems. The new pattern emerges from something closer to cognitive disconnection. The work happens quickly. Progress is visible. But the engineer experiences a persistent sense of not quite grasping their own output. They can execute, but explanation requires reconstruction. They can modify, but prediction becomes unreliable. The system they built feels slightly foreign even as it functions correctly. This creates a distinctive psychological state: high output combined with low confidence . Engineers produce more while feeling less certain about what they have produced. In organizations that stack-rank based on visible output, this creates pressure to continue generating despite the growing uncertainty. The engineer who pauses to deeply understand what they built falls behind in velocity metrics. The engineer who prioritizes throughput over comprehension meets their quarterly objectives. The incentive structure selects for the behavior that accelerates cognitive debt accumulation. When Organizational Memory Fails Knowledge in engineering organizations exists in two forms. The first is explicit: documentation, design documents, recorded decisions. The second is tacit: understanding held in the minds of people who built and maintained systems over time. Tacit knowledge cannot be fully externalized because much of it exists as intuition, pattern recognition, and contextual judgment that formed through direct engagement with the work. When the people who built a system leave or rotate to new projects, tacit knowledge walks out with them. Organizations traditionally replenished this knowledge through the normal process of engineering work. New engineers building on existing systems developed their own tacit understanding through the friction of implementation. AI-assisted development potentially short-circuits this replenishment mechanism. If new engineers can generate working modifications without developing deep comprehension, they never form the tacit knowledge that would traditionally accumulate. The organization loses knowledge not just through attrition but through insufficient formation. This creates a delayed failure mode. The system continues to function. New features continue to ship. But the reservoir of people who truly understand the system gradually depletes. When circumstances eventually require that understanding, when something breaks in an unexpected way or requirements change in a way that demands architectural reasoning, the organization discovers the deficit. How the Debt Compounds Three failure modes emerge as cognitive debt accumulates. The first involves the reversal of a normally reliable heuristic. Engineers typically trust code that has been in production for years. If it survived that long, it probably works. The longer code exists without causing problems, the more confidence it earns. AI-generated code inverts this pattern. The longer it remains untouched, the more dangerous it becomes , because the context window of the humans around it has closed completely. Code that was barely understood when written becomes entirely opaque after the people who wrote it have moved on. They are debugging a black box written by a black box. The second failure mode surfaces during incidents. An alert fires at 3:00 AM. The on-call engineer opens a system they did not build, generated by tools they did not supervise, documented in ways that assume familiarity they do not possess. They are debugging a black box written by a black box. What would have been a ten-minute fix when someone understood the system becomes a four-hour forensic investigation when no one does. Multiply this across enough incidents and the aggregate cost exceeds whatever velocity gains the AI-assisted development provided. The organization is effectively trading its pipeline of future Staff Engineers for this quarter's feature delivery. The third failure mode operates on a longer timescale. Junior engineers who rely primarily on AI-assisted development never develop the intuition that comes from manual implementation. They ship features without forming the scar tissue that informs architectural judgment. The organization is effectively trading its pipeline of future Staff Engineers for this quarter’s feature delivery. The cost does not appear in current headcount models because the people who would have become senior architects five years from now are not yet absent. They simply never form. The Director’s View From the perspective of engineering leadership, AI-assisted development presents as productivity gain. Teams ship faster. Roadmaps compress. Headcount discussions become more favorable. These are the observable signals that propagate upward through organizational reporting structures. The cognitive debt accumulating in those teams does not present as a signal. There is no metric for “engineers who can explain their own code without re-reading it.” There is no dashboard for “organizational comprehension depth.” The concept does not fit into quarterly business review formats or headcount justification narratives. Directors make decisions based on observable signals. When those signals uniformly indicate success, the decision to double down on the approach that produced those signals is rational within the information environment available to leadership. The decision is not wrong given the data. The data is incomplete. Where This Model Breaks The cognitive debt framing does not apply uniformly across all engineering work. Some tasks genuinely are mechanical. Some codebases genuinely benefit from rapid iteration without deep architectural understanding. Some features genuinely do not require the level of comprehension that would traditionally form through manual implementation. The model also assumes that comprehension was previously forming at adequate rates. This assumption may be generous. Engineers have always varied in how deeply they understood their own work. The distribution may simply be shifting rather than a new phenomenon emerging. Additionally, tooling and documentation practices may evolve to partially close the comprehension gap. If organizations develop methods for capturing and transmitting the understanding that AI-assisted development fails to form organically, the debt may prove manageable rather than accumulative. The Measurement Problem The system is optimizing correctly for what it measures. What it measures no longer captures what matters. The fundamental challenge is that organizations cannot optimize for what they cannot measure . Velocity is measurable. Comprehension is not, or at least not through any mechanism that currently feeds into performance evaluation, promotion decisions, or headcount planning. Until comprehension becomes legible to organizational decision-making systems, the incentive structure will continue to favor velocity. Engineers who prioritize understanding over output will appear less productive than peers who prioritize output over understanding. Performance calibration will reward the behavior that accumulates debt faster. This is not a failure of individual managers or engineers. It is a measurement system designed for an era when production and comprehension were coupled, operating in an era when that coupling no longer holds. The system is optimizing correctly for what it measures. What it measures no longer captures what matters. The gap will eventually manifest. Whether through maintenance costs that exceed projections, through incidents that require understanding no one possesses, or through new requirements that expose the brittleness of systems built without deep comprehension. The timing and form of manifestation remain uncertain. The underlying dynamic does not.",
      "cover_image_url": "https://www.rockoder.com/images/id/id.png"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "This Is the System That Intercepted Iran's Missiles Over the UAE",
      "url": "https://www.wired.com/story/uae-missile-intercept-system-iran/",
      "published": "2026-02-28T15:12:51+00:00",
      "summary": "As Iranian missiles targeted US-linked sites across the Gulf, the UAE’s missile shield was activated in real-time.",
      "content_text": "After Israel and the US launched joint attacks on Iran on Saturday, Tehran responded with missile attacks across the Gulf, targeting US military bases in those countries. Within hours, the UAE Ministry of Defense confirmed that its air defense systems had successfully intercepted several incoming ballistic missiles. According to the ministry, the missiles were destroyed before impact. However, debris from one interception fell in Abu Dhabi, killing one civilian. Abu Dhabi sits near several strategic military installations, including Al Dhafra Air Base, which hosts Emirati and US forces. For many residents, the event unfolded as a series of distant flashes and muffled explosions in the sky. Behind those brief moments, however, is a complex network of radars, interceptors and command systems designed to detect, track and destroy ballistic missiles traveling at hypersonic speeds. Understanding what happened in those seconds means understanding how the UAE’s layered missile defense network works. The System Designed to Stop Ballistic Missiles The UAE’s missile shield includes multiple layers of defense, such as the high-altitude Terminal High Altitude Area Defense (THAAD) and the lower-altitude MIM-104 Patriot. A Terminal High Altitude Area Defense (THAAD) missile, a PAC-3 air-defense missile and a PrSM precision strike missile at the Lockheed Martin Corp. Photograph: Jose Sarmento Matos/Getty Images Developed by Lockheed Martin, THAAD is designed to intercept ballistic missiles during the final phase of their flight, when they descend towards their target. Unlike traditional air defense missiles that explode near a threat, THAAD interceptors destroy incoming missiles through direct kinetic impact, basically colliding with them at extremely high speeds in what is known as “hit-to-kill” interception. The UAE became the first country outside the US to deploy THAAD in January 2022, having received the system in 2015 as part of a multibillion-dollar defense agreement. A Layered Defense Network THAAD is only one component of the UAE’s broader air- and missile-defense architecture. The country also operates the MIM-104 Patriot system, which is designed to intercept aircraft and ballistic missiles at lower altitudes. Together, these systems form what defense planners describe as a layered missile-defense architecture, giving operators more than one opportunity to intercept an incoming threat before it reaches the ground. In a typical interception sequence, several steps happen within seconds: Detection: Early-warning sensors and radar systems detect a missile launch and begin tracking its speed and projected flight path. Tracking and command: That data is relayed to command-and-control networks, which analyze whether the missile threatens populated areas or critical infrastructure and determine where an interception should occur. Interception: High-altitude interceptors such as THAAD attempt to destroy the missile in the upper atmosphere. If necessary, lower-altitude systems like Patriot provide another interception opportunity.",
      "cover_image_url": "https://media.wired.com/photos/69a2ffd3d16e57b38c5e2d9a/191:100/w_1280,c_limit/2263468713"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Xiaomi launches 17 Ultra smartphone, an AirTag clone, and an ultra slim powerbank",
      "url": "https://techcrunch.com/2026/02/28/xiaomi-launches-17-ultra-smartphone-an-airtag-clone-and-an-ultra-slim-powerbank/",
      "published": "2026-02-28T15:09:03+00:00",
      "summary": "We round up everything Xiaomi announced at its Mobile World Congress event.",
      "content_text": "Xiaomi today launched a slew of gadgets ahead of the Mobile World Congress (MWC) in Barcelona including a camera-focused flagship smartphone, an AirTag clone, Xiaomi Watch 5 smartwatch, and an ultra slim power bank. The China-based company has partnered with camera maker Leica to co-brand its Xiaomi 17 Ultra smartphone. As part of the partnership, it is using Leica lenses and creating filters in the style of the German camera company. The phone has a 50-megapixel main sensor with an F/1.67 aperture and a 1-inch sensor. But the main attraction is the 200-megapixel telephoto camera that has a variable focal length of 75mm-100mm equivalent. That means you can zoom optically between 3.2x and 4.3x. The phone also has a 50 MP ultrawide camera with an f/2.2 aperture. Image Credits: Xiaomi Image Credits: Xiaomi Also notable: The phone packs a 6,000 mAh battery (the Chinese version comes with a bigger 6,800mAh battery). The phone could be charged using a 90W USB PD-PPS, and it supports Xiaomi’s Hypercharge wireless tech at 50W. The device has a 6.9-inch Xiaomi HyperRGB OLED display protected by Xiaomi’s own Shield Glass 3.0. The company has picked Qualcomm’s latest Snapdragon 8 Elite Gen 5 processor, which was also used in the recently launched Galaxy S26 series. The company is also releasing a special Leica edition phone to celebrate 100 years of the camera company. The device has a durable aluminum-alloy body with a nickel-anodized finish. Xiaomi has also added a Leica theme on the software side. Image Credits Xiaomi The device has a rotating ring that mimics zoom on a physical camera. The special edition also has a “Leica Essential mode,” which has filters that recreate photos in the style of Leica M9 and Leica M3. Techcrunch event Boston, MA | June 9, 2026 Xiaomi launched the Xiaomi 17 with a larger 6,330 mAh battery, which can be charged at 100W using the company’s HyperCharge tech. The company is also launching two photography add-ons for the Xiaomi 17 Ultra. The 17 Ultra Photography Kit is a Bluetooth-connected snap-on that has a two-stage shutter button and a video recording button.The Xiaomi 17 Ultra Photography Kit Pro aims to mimic a physical camera with a leather finish, a video recording button, a detachable shutter button, and zoom control. This kit snaps on using a USB-C connection and also has a 2,000 mAh battery for its operation. Using this add-on, users can also use a new fastshot mode on the phone. Image Credits: Xiaomi Through this launch, the company is making these devices available in the EU and the UK. The Xiaomi 17 starts at €999, and the Xiaomi 17 Ultra starts at €1,499. The Leica edition comes with 16GB RAM and 1TB storage, and is priced at €1,999. The Xiaomi 17 Ultra Photography Kit is priced at €99.99, and the Xiaomi 17 Ultra Photography Kit Pro is priced at €199.99. Apart from phones, the company also launched a bunch of other devices, including a scooter. Xiaomi said that its Electric Scooter 6 Ultra has 1200W peak power and 75km of range. The scooter has 12-inch all-terrain tires with front and rear disc brakes. It has a three-inch TFT display to measure things like speed and range. The scooter starts at €329.99 with five different versions, with the top version priced at €799.99. Image Credits: Xiaomi The company also launched a new Xiaomi tag, an AirTag-like device, which works with both Apple Find My and Google Android Find Hub. The tag weighs just 10 grams and has a button cell battery that lasts over a year. You can also play a sound remotely to find the tag or the time at which the tag is attached. The company is pricing this tag at €14.9 for one and €49.99 for a pack of four. Image Credits: Xiaomi What’s more, the company released a slim power bank with just 6mm of thickness. The powerbank weighs 98 grams and has a 5,000 mAh battery capacity. It can charge devices at 22.5W through a wired connection and at 15W through a wireless connection. The powerbank is magnetic, so it can stick to supporting phones like iPhones, and charge them wirelessly. The powerbank is priced at €59.99 for black and silver colorways. It also has an orange colorway priced at €64.99. Image Credits: Xiaomi Xiaomi launched its new smartphone, Xiaomi Watch 5, with a 930mAh battery that could last up to six days. The smartwatch has a round 1.54-inch AMOLED display and supports gestures to dismiss calls or alarms. The watch can also prepare a health report in 60 seconds by using metrics like heart rate, blood oxygen, stress levels, sleep duration, sleep heart rate, and sleep SpO₂. The watch is priced at €299.99. Image Credits: Xiaomi The company also launched a €69.9 Redmi Buds 8 Pro earbuds with active noise cancellation and up to 33 hours of battery life.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/xiaomi.jpg?resize=1200,600"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Why China’s humanoid robot industry is winning the early market",
      "url": "https://techcrunch.com/2026/02/28/why-chinas-humanoid-robot-industry-is-winning-the-early-market/",
      "published": "2026-02-28T15:00:00+00:00",
      "summary": "China’s push into humanoid robots is accelerating, with domestic firms shipping more units and iterating faster than U.S. competitors in a still-nascent market.",
      "content_text": "China’s humanoid robots grabbed global attention with kung fu flips at the nation’s televised Spring Festival Gala, while Chinese phone maker Honor is set to unveil its first humanoid robot at MWC in Spain. Robotics was flagged as a priority under the country’s “Made in China 2025” plan , albeit originally focused on factory automation, rather than humanoids. Now, rapid advances in multimodal AI are accelerating so-called embodied AI — autonomous machines operating in the real world — a push officials say could help offset labor shortages and drive productivity gains. At this early stage of humanoid robot development, Chinese companies are outpacing their U.S. rivals in both speed and volume, Selina Xu, a China and AI policy lead at the office of Eric Schmidt said. “China has a more robust hardware supply chain — much of it built up through the EV sector, from sensors to batteries — and the world’s strongest manufacturing base, allowing companies to iterate far faster than Western competitors,” Xu told TechCrunch. As a result, not only are Chinese robots cheaper but companies can also release new models more quickly, Xu noted, adding that leading Chinese player Unitree shipped roughly 36 times more units last year than U.S. rivals Figure and Tesla. Global humanoid robot shipments totaled just 13,317 units last year, according to a Forbes report released last month. That is a tiny base for an industry expected to nearly double annually and reach 2.6 million units by 2035. (Still, the figures should be viewed with caution. The report notes it remains unclear how many units represent commercial sales versus demo models or pilot deployments, underscoring the early-stage nature of the industry.) The top humanoid robot makers by 2025 shipments were led by China’s Agibot and Unitree, followed by UBTech, Leju Robotics, Engine AI, and Fourier Intelligence, underscoring Beijing’s early dominance in the sector. Techcrunch event Boston, MA | June 9, 2026 The biggest shift recently has been from “demo-driven excitement” to “operations-driven adoption,” Yuli Zhao, chief strategy officer at Galbot, told TechCrunch. Galbot’s humanoid robot, the G1, appeared at this year’s Spring Festival Gala, China’s annual, state-run lunar New Year’s Eve television show, alongside robots from Unitree Robotics, Noetix, and MagicLab. “More customers are asking: Can the robot run stably in real environments and actually take work off people’s plates? That practical pull is strengthened in China because policy and industrial strategy encourage automation upgrades, and the manufacturing ecosystem makes iteration extremely fast,” Zhao said. While increased funding toward humanoid startups “has definitely accelerated” the pace of progress, “the most durable adoption comes when you can show reliable and repeatable value in production or service operations, not just a one-off showcase,” Zhao added. Still, investing helps and Chinese robotics makers are securing it. Last year Unitree was valued at around $3 billion after closing its Series C, with ambitions to reach as much as $7 billion in a future IPO . Meanwhile, Galbot has raised more than $300 million in fresh funding, reportedly pushing its valuation to $3 billion, one of the largest financings in China’s humanoid robotics sector to date. U.S. companies are moving beyond flashy demos as well to focus on real-world deployments. Plus, they are pursuing their own aggressive goals. U.S. startup Foundation , for instance, plans to build 50,000 humanoid robots by the end of 2027. But China is already targeting a mix of affordable mass-market models and high-end applications, rapidly expanding humanoids across industrial, consumer, and rehabilitation sectors, according to a December TrendForce report . Bottlenecks to China’s dominance When it comes to AI systems and integrated software, it’s still unclear where Chinese humanoid firms truly stand. The industry is largely betting on vision-language-action models and “world models,” but both technologies remain in early stages. Nvidia currently leads the space with its end-to-end humanoid software stack, according to Xu, so naturally most humanoid startups in China are powered by Nvidia’s Orin chips. However, domestic chipmakers are developing homegrown alternatives, she said. Yet humanoid robotics makers are still working on fundamental problems. The challenge is enabling robot foundation models to predict the “next physical state” the robot will face in unpredictable environments, like how large language models predict the next word. But unlike LLMs, humanoid robotics companies can’t simply scrape the internet for training data, Xu said. So most are relying on simulation environments, which generates synthetic data, though real-world data collection remains essential. “Because of the data scarcity problem, humanoids are still far away from autonomy. The hardware is currently ahead of the software — the robot body can handle a lot more dexterity today than years ago (though it has reliability issues, as we saw with the robots that broke down at humanoid marathons), but the brain is still nascent,” the analyst said. Safety is a major hurdle for humanoid robots, too. One high-profile accident could trigger public backlash, and China is likely weighing how to roll out the technology quickly without moving too fast. As the industry matures, more regulations are expected. Given the lack of data, Zhao believes that demand for humanoids will grow first in fairly contained workplaces. “Early momentum is likely to be in industrial manufacturing, warehouse logistics, and retail, where tasks are repetitive, hours are long, and processes are clear — creating real demand and ideal conditions for humanoid robots to deliver value at scale,” he said. Other APAC players Humanoid robot development is not a two-country race. Japan’s robotics ecosystem — from startups to semiconductor heavyweights — is targeting humanoid mass production by 2027 . Long a pioneer through projects like Honda’s Asimo, Murata Manufacturing’s Murata Boy, and SoftBank Robotics’ Pepper, Japan leans on precision and advanced control. One area unique to this nation: Humanoid robots are increasingly used in eldercare. Coral Capital CEO James Riney, who invests in tech companies in Japan, believes Tokyo will continue to thrive in the humanoid robotics industry. “There are three factors likely to drive the adoption of robotics in Japan. One is the labor shortage and the desire to depend less on mass immigration. The second is the widespread cultural view of robots as our friends — more Doraemon vs. Terminator. The third is that Japan is already dominant in many parts of the robotics supply chain.” Hyundai Motor’s Boston Dynamics unit introduced a new Atlas humanoid for factory use by 2028 , with plans to produce up to 30,000 units annually in the U.S. as part of its AI-driven robotics push. Still, for China, government policy, industrial strategy, labor shortages, and private capital are all converging to turbocharge the country’s humanoid robotics push. “China’s leadership is best understood as a speed-to-scale advantage,” Zhao said. “The ecosystem here compresses the entire cycle — R&D, supply chain, manufacturing, integration, and customer deployment — into a very tight loop. That means humanoid companies can move from prototype to real-world deployment faster, learn from real operations, and iterate at a pace that’s difficult to match elsewhere.”",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-1287582736.jpg?resize=1200,657"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "GitHub - Krira-Labs/krira-chunker: ⚡ Production-grade RAG chunking engine powered by Rust. Process GBs of CSV, PDF, JSON, JSONL, DOCX, XLSX, URLs, ETC., in seconds with O(1) memory. 40x faster than LangChain.",
      "url": "https://github.com/Krira-Labs/krira-chunker",
      "published": "2026-02-28T14:58:02+00:00",
      "summary": "<p>I built a document chunking library for RAG pipelines with a Rust core and Python bindings.<p>The problem: LangChain's chunker is pure Python and becomes a bottleneck at scale — slow and memory-hungry on large document sets.<p>What Krira Chunker does differently: - Rust-native processing — 40x faster than LangChain's implementation - O(1) space complexity — memory stays flat regardless of document size - Drop-in Python API — works with any existing RAG pipeline - Production-ready — 17 versions shipped, 315+ installs<p>pip install krira-augment<p>Would love brutal feedback from anyone building RAG systems — what chunking problems are you running into that this doesn't solve yet?</p> <hr /> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47196069\">https://news.ycombinator.com/item?id=47196069</a></p> <p>Points: 14</p> <p># Comments: 3</p>",
      "content_text": "You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/4268476d5eb247815a6dabaa8b3906fa9b0b5bd5651ab9fb2e20ce96734450e2/Krira-Labs/krira-chunker"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "Review: Xiaomi 17 Ultra and Leitzphone Pack Leica Magic Into a Flagship Phone",
      "url": "https://www.wired.com/review/xiaomi-17-ultra-leitzphone/",
      "published": "2026-02-28T14:32:00+00:00",
      "summary": "The latest Xiaomi flagship is a beast and comes in a specially co-designed Leica edition that’s picture-perfect.",
      "content_text": "A big screen, powerful camera system, and top-notch performance can eat right into your battery life, but Xiaomi has managed to pack a 6,000-mAh battery into the 17 Ultra (up from 5,410 mAh last year). The jump gives it serious stamina, and this phone can go a couple of days between charges. I wish Xiaomi had found a way to include Qi2, as magnetic wireless charging is the one thing I missed in switching from the Pixel 10 Pro XL (though you can sort of add it with the photography kit case). The 17 Ultra does support wireless charging at an impressively fast 50-watt rate, but the camera module makes it awkward to use with some wireless chargers . Wired charging goes up to 90 watts with the right adapter (not included). Software used to be the big caveat, but I didn’t find much to complain about with the 17 Ultra. Xiaomi’s HyperOS apes iOS in places, and I still don’t like the unlabeled quick-settings icons, but it’s mostly perfectly fine. The Leica interface, with minimalist app icons and photography widgets, is much nicer than the slightly cartoonish HyperOS, but it’s very easy to customize. I don’t think bloatware has any place on a flagship phone, so I’m always annoyed to see apps like Facebook and TikTok preinstalled. There’s plenty of AI onboard, if you care, and you can use Google’s Gemini or Xiaomi’s HyperAI for all sorts of photo and video editing, transcription, translation, summarization, and more. It’s not quite as slick and elegant as Google’s Pixel, but you can broadly achieve all the same results. The Xiaomi 17 Ultra is not officially available in the US, but you can pick it up for £1,299 in the UK (1,499 euros in Europe). The Leitzphone costs £1,799 (1,999 euros). For folks who can get their hands on the global model more easily, it’s a near-flawless flagship contender that will satisfy anyone craving a big, powerful, photography-first phone.",
      "cover_image_url": "https://media.wired.com/photos/69a25bc28fe42fcd6044ab2f/191:100/w_1280,c_limit/Xiaomi%20Leitzphone%20with%20Photography%20Kit%202%20%20SOURCE%20Simon%20Hill.jpg"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Xiaomi’s tracker doesn’t need a case to clip to your keys",
      "url": "https://www.theverge.com/tech/884567/xiaomi-tag-tracker-apple-find-my-google-hub-bluetooth",
      "published": "2026-02-28T14:30:00+00:00",
      "summary": "Xiaomi has announced its first Bluetooth tracker, and while the Xiaomi Tag has a more elongated design than the Apple AirTag, that lets you use it in more places right out of the box. On one end of the tracker you'll find an integrated metal loop that can be attached to a keyring or clipped [&#8230;]",
      "content_text": "Xiaomi has announced its first Bluetooth tracker, and while the Xiaomi Tag has a more elongated design than the Apple AirTag , that lets you use it in more places right out of the box. On one end of the tracker you’ll find an integrated metal loop that can be attached to a keyring or clipped to a carabiner without the need for an extra case. The Xiaomi Tag is compatible with both Apple’s Find My and Google’s Find Hub tracking networks and mobile apps, but not at the same time. You’ll need to choose one or the other during setup. Like Apple’s AirTag, the Xiaomi Tag is powered by a replaceable CR2032 coin cell battery good for up to a year of use, and boasts an IP67 dust and water resistance rating, so it can survive a short dunking. There are also NFC capabilities that others can use to load your contact details should they find a lost device with the tag attached. One big differentiator is that unlike Apple’s AirTags, the Xiaomi Tag lacks ultra wideband (UWB) functionality for pinpointing its exact location. You’ll instead have to rely on audible alerts to locate it once you’re nearby. If that’s not a deal-breaker, the Xiaomi Tag will be a cheaper alternative to Apple’s AirTags, selling for £12.99 (around $18) each, or £44.99 (around $61) for a four-pack. A single second-gen AirTag is $29 , or $99 for four .",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/xiaomi_tag2.jpg?quality=90&strip=all&crop=0%2C10.723437243423%2C100%2C78.553125513154&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Xiaomi’s Leica Leitzphone mostly earns the name",
      "url": "https://www.theverge.com/gadgets/886131/xiaomi-leica-leitzphone-17-ultra-review",
      "published": "2026-02-28T14:30:00+00:00",
      "summary": "Xiaomi and Leica's long-running phone partnership just got a little closer. Alongside the new international release of its 17 Ultra flagship, Xiaomi has been entrusted with manufacturing a separate version that is the first Leica Leitzphone to release outside of Japan, following three Sharp-made models exclusive to the country. In truth, the Leitzphone is a [&#8230;]",
      "content_text": "Xiaomi and Leica’s long-running phone partnership just got a little closer. Alongside the new international release of its 17 Ultra flagship, Xiaomi has been entrusted with manufacturing a separate version that is the first Leica Leitzphone to release outside of Japan, following three Sharp-made models exclusive to the country . In truth, the Leitzphone is a 17 Ultra with Leica branding and a rotatable camera ring, and apart from a few design tweaks, it’s mostly the same as the Leica Edition of that phone already available in China. But the branding is a big deal: Leica hasn’t let Xiaomi use its red dot logo on hardware until now, even though the companies have partnered on Xiaomi’s flagship cameras since 2022. The jump to a fully Leica-branded phone is a vote of confidence from the camera company. After two weeks using the Leitzphone version of the 17 Ultra, it’s clear that confidence was well placed. This is my favorite phone of 2026 so far, Leica logo or not, though most buyers would be better off saving money with the standard 17 Ultra. $2300 The Good One of the best cameras in any phone Two-day battery life (just) All the flagship features The Bad Big, bulky, and heavy Expensive The rotating camera ring feels like a gimmick The 17 Ultra and its original Leica Edition launched in China on December 25th, 2025. The international version and the Leitzphone were launched at Xiaomi’s pre- MWC press conference in Barcelona on February 28th, alongside the regular Xiaomi 17 . The 17 Ultra starts from £1,299 / €1,499 (about $1,750) with 512GB storage, rising by £400 / €700 for the Leica version. That’s a hefty premium, but there are a few differences from the regular 17 Ultra. Let’s start with the Leica of it all. It’s obvious first and foremost in the design: an ever-so-slightly glossy black finish on the back, an industrial touch in the knurled aluminum-alloy edges, and Leica’s red dot logo in one corner. It’s a slightly different design to the 17 Ultra Leica Edition that released in China at the end of December , which has a two-tone finish and orients the Leica logo the other way. It also ships with branded accessories, including a faux leather case with a Leica lens cap, a microfiber cleaning cloth, and a bright red wrist strap. The Leica logo isn’t just printed on; that lettering is raised metal. The textured edges make the phone more grippy, even without a case. My favorite accessory by far is this case, which preserves the red dot logo and adds a lens cap. Other changes run through the software. While both versions of the 17 Ultra run Xiaomi’s HyperOS 3, based on Android 16, the Leitzphone’s interface has been customized. There are dedicated Leica widgets, including photo galleries and a golden-hour timer, and custom monochrome app icons for the most popular apps from Xiaomi and third parties — which look great when you first turn the phone on, but less so once they’re mixed in with all the non-monochromatic apps you’ll inevitably download from elsewhere. Leica and Xiaomi’s design languages coexist in the camera app. Most of the customization is in the camera. There’s an expanded array of Leica filters, and the interface uses Leica fonts and red as its accent color, instead of Xiaomi’s usual yellow. A new Leica Essential shooting mode lets you pick between two camera simulations: a color re-creation of the M9 and a monochromatic take on the M3. The Leitzphone also adds the option to enable C2PA content credentials on every shot you take. None of this is as novel as the Leitzphone’s unique hardware feature: a rotatable camera ring. The edge of the camera island can be twisted round, with a satisfying haptic buzz to emulate the feel of gears clicking. It makes for an excellent fidget spinner, though its real purpose is to control zoom in the camera app, or cycle through exposure settings or filters if you prefer. The metal rim of the camera island is the part that twists round. This sounds like a great idea, and it’s something I’ve wanted to see on more phones since spotting it on Nubia’s Focus 2 Ultra . In practice, it’s not that useful. The camera island may be enormous by phone standards, but it would be small on a real camera, and it’s too flush against the body to hold comfortably. I’ve had to force myself to use the camera ring to zoom, finding the onscreen controls quicker and more natural every time. Perhaps with persistence I could drill it in my muscle memory; for now, I mostly rotate it by accident and get annoyed when I do. The addition of the zoom ring makes sense given the 17 Ultra’s headline photography feature: a telephoto with continuous optical zoom. While Xiaomi’s 15 Ultra featured two telephoto cameras, the 17 Ultra combines them into one. (The company skipped 16 to catch up with Apple .) A single 1/1.4-inch type 200-megapixel sensor is paired with a Leica APO zoom lens that covers 3.2-4.3x magnification — the equivalent of 75-100mm — adjusting the aperture from f/2.39-2.96 as it goes. The obvious criticism is the same we levied at Sony’s Xperia 1 IV , which boasted continuous 3.5-5.2x zoom: This is too short a spread to make much difference. It’s rare that the framing of a photo changes drastically as you move through the range, and outside those limits you’re back to the same digital zoom and sensor cropping that every other phone offers. 1/20 I took all of these photos using the 17 Ultra’s telephoto camera. Photos are excellent. The large sensor delivers natural bokeh, along with macro support at a minimum distance of 30cm. It can handle challenging lighting conditions, with good results in dim light — though it did once struggle with the inverse, blowing out highlights on an especially bright day. Mostly I’ve shot exclusively on the Leica Authentic mode — the other option being Leica Vibrant — which I like for its filmic qualities, preserving more of the highlights and shadows than most phones and avoiding the flattened sheen of excessive HDR. The other lenses are just as impressive, though I do find myself defaulting to the telephoto. The main camera has a large 1-inch-type sensor, and the same 50-megapixel resolution as the ultrawide and selfie camera. It’s one of the first phones to include a LOFIC (lateral overflow integration capacitor) sensor , which expands the dynamic range for highlights, helping me take some of the most dramatic skyline shots I’ve managed on a phone, and contributing to excellent performance in nighttime shots with bright lights. 1/14 These are a mix of photos from the other lenses. Despite the Leica logo, this isn’t just a camera. The Leitzphone has all of the flagship specs you’d expect: Qualcomm’s Snapdragon 8 Elite Gen 5 chipset, 16GB of RAM ( in this economy?! ) and 1TB of storage (with an option for 512GB on the regular 17 Ultra), a 6.9-inch 1-120Hz LTPO OLED display, and IP68 protection. The battery is another standout feature. The 6,000mAh silicon-carbon cell isn’t the biggest around, and is smaller than the phone’s Chinese edition, but it’s still impressive. Even powering a demanding phone with a big display, I’ve usually been able to just about get two days of use from it between charges, though with very little left in the tank afterwards. 90W PPS wired charging and 50W wireless top it back up fast, though you’ll be limited to slow Qi speeds over third-party wireless chargers, and there’s no support for the magnetic Qi2 standard. This is my favorite phone of the year so far. The biggest problem the Leitzphone has is that it’s mostly a more expensive version of the 17 Ultra, which shares most of its best features. I prefer the look of the Leitzphone, and like a few of the Leica-specific shooting styles and the included case. But those aren’t worth £200, and the rotatable camera ring isn’t either. Unless that little red dot is very dear to your heart, there’s not quite enough reason to shell out extra for it — but mostly because the 17 Ultra is such a good phone in its own right. Photography by Dominic Preston / The Verge Agree to Continue: Xiaomi 17 Ultra Every smart device now requires you to agree to a series of terms and conditions before you can use it — contracts that no one actually reads. It’s impossible for us to read and analyze every single one of these agreements. But we started counting exactly how many times you have to hit “agree” to use devices when we review them since these are agreements most people don’t read and definitely can’t negotiate. To use the 17 Ultra, you must agree to: Google Terms of Service Google Play Terms of Service Google Privacy Policy (included in ToS ) Install apps and updates: “You agree this device may also automatically download and install updates and apps from Google, your carrier, and your device’s manufacturer, possibly using cellular data.” Xiaomi Agreement Xiaomi Privacy Policy There’s also a variety of optional agreements, including: Provide anonymous location data for Google’s services “Allow apps and services to scan for Wi-Fi networks and nearby devices at any time, even when Wi-Fi or Bluetooth is off.” Send usage and diagnostic data to Google Google Gemini Apps Privacy Notice if you opt in to using Gemini Assistant Send usage and diagnostic data to Xiaomi Xiaomi personalized ads Other features, like Google Wallet, may require additional agreements. Final tally: six mandatory agreements and at least six optional agreements. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Dominic Preston Gadgets Mobile MWC 2026 Phone Reviews Phones Reviews Tech Xiaomi",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/leica-leitzphone-xiaomi-17-ultra-06.jpg?quality=90&strip=all&crop=0%2C10.741906587151%2C100%2C78.516186825698&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Xiaomi 17 is a small(ish) phone with a big(ish) battery",
      "url": "https://www.theverge.com/gadgets/886322/xiaomi-17-release-specs-price-mwc-ultra-leica",
      "published": "2026-02-28T14:30:00+00:00",
      "summary": "Xiaomi has just given a global launch to two of its latest flagship phones, the Xiaomi 17 and 17 Ultra, along with a Leica-branded Leitzphone edition of the Ultra. There's no sign, however, of the 17 Pro, which launched in China with an additional display mounted next to the rear cameras. The 17 and 17 [&#8230;]",
      "content_text": "Xiaomi has just given a global launch to two of its latest flagship phones, the Xiaomi 17 and 17 Ultra, along with a Leica-branded Leitzphone edition of the Ultra . There’s no sign, however, of the 17 Pro, which launched in China with an additional display mounted next to the rear cameras. The 17 and 17 Ultra will apparently be available soon in the UK, Europe, and select other markets. The 17 — pitched as a rival to the likes of the iPhone 17 and Samsung Galaxy S26 — will cost £899 / €999 (about $1,200), while the larger and more capable Ultra starts from £1,299 / €1,499 ($1,750). The limited-edition Leitzphone will be substantially more expensive at £1,699 / €1,999 ($2,300), though it includes 16GB of RAM and 1TB of storage, along with a few extra accessories. I like the simple, sleek aesthetic of the phone. The 6.3-inch display isn’t tiny, but it does make the phone small by modern standards. All three of the phone’s rear cameras are 50-megapixel. The 17 is an extremely capable small-ish flagship, with a 6.3-inch OLED display, Qualcomm Snapdragon 8 Elite Gen 5, and large 6,330mAh silicon-carbon battery (though sadly smaller than the 7,000mAh version launched in China ). I won’t be writing a full review of the 17, but did spend a week using it as my main phone, and found that the battery cruised past the full-day mark, though wasn’t quite enough for two full days of my typical usage. That’s far better battery life than you’d find in similarly sized phones from Apple, Samsung, or Google. The cameras impress too, with 50-megapixel sensors behind each of the four lenses, selfie included. Pound for pound, you won’t find many better camera systems in any phone this size. 1/10 I’ve been largely impressed by the Xiaomi 17’s cameras. The Ultra, unsurprisingly, takes things to another level. It’s much larger, with a 6.9-inch display, and weighs a hefty 218g. Despite that, the 6,000mAh is actually smaller, though I found it delivered pretty similar longevity. The 17 Ultra is larger in just about every respect, but strangely has a smaller battery. The enormous camera is, as ever for Xiaomi’s Ultra phones, the highlight. There are 50-megapixel sensors for each of the main, ultrawide, and selfie cameras, with a large 1-inch-type sensor behind the primary lens. The periscope telephoto is even more impressive: 200-megapixel resolution, a large 1/1.4-inch sensor, and continuous optical zoom from 3.2x to 4.3x, the equivalent of 75-100mm. Xiaomi isn’t the first to pull off a true zoom phone — Sony’s Xperia 1 IV got there first in 2022 — but the telephoto camera here is far more capable than that phone’s, with natural bokeh and impressive performance even in low light. This is the Leica-branded Leitzphone version of the 17 Ultra. The camera capabilities are supported by Xiaomi’s ongoing photography partner Leica, but it’s the pair’s Leitzphone that really emphasizes that. Slightly redesigned from the 17 Ultra Leica Edition that was released in China last December , this includes Leica branding across the hardware and software, a range of Leica filters and shooting styles, and a rotatable rear camera ring that can be used to control the zoom. It’s the first Leica Leitzphone produced by Xiaomi — after a trio of Japan-only Sharp models — and comes with additional branded accessories, including a case with a lens cap and a microfiber cleaning cloth. Xiaomi has plenty of other announcements alongside the 17 series phones at MWC this year, including a super-slim magnetic power bank , the Pad 8 and Pad 8 Pro tablets , and a smart tag that supports both Google and Apple’s tech-tracking networks. Photography by Dominic Preston / The Verge Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Dominic Preston Gadgets Mobile MWC 2026 News Phones Tech Xiaomi",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/xiaomi-17-ultra-2.jpg?quality=90&strip=all&crop=0%2C10.741906587151%2C100%2C78.516186825698&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "nocodemf/werld: agentic life simulation from inception",
      "url": "https://github.com/nocodemf/werld",
      "published": "2026-02-28T14:05:27+00:00",
      "summary": "<p>at a pub in london, 2 weeks ago - I asked myself, if you spawned agents into a world with blank neural networks and zero knowledge of human existence — no language, no economy, no social templates — what would they evolve on their own?<p>would they develop language? would they reproduce? would they evolve as energy dependent systems? what would they even talk about?<p>so i decided to make myself a god, and built WERLD - an open-ended artificial life sim, where the agent's evolve their own neural architecture.<p>Werld drops 30 agents onto a graph with NEAT neural networks that evolve their own topology, 64 sensory channels, continuous motor effectors, and 29 heritable genome traits. communication bandwidth, memory decay, aggression vs cooperation — all evolvable. No hardcoded behaviours, no reward functions. - they could evolve in any direction.<p>Pure Python, stdlib only — brains evolve through survival and reproduction, not backprop. There's a Next.js dashboard (\"Werld Observatory\") that gives you a live-view: population dynamics, brain complexity, species trajectories, a narrative story generator, live world map.<p>thought this would be more fun as an open-source project!<p>can't wait to see where this could evolve - i'll be in the comments and on the repo.<p><a href=\"https://github.com/nocodemf/werld\" rel=\"nofollow\">https://github.com/nocodemf/werld</a></p> <hr /> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47195530\">https://news.ycombinator.com/item?id=47195530</a></p> <p>Points: 31</p> <p># Comments: 24</p>",
      "content_text": "You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/9341cc60e4fdc9a12c2cef94b975e6e222f76be19037c113ce334761c11311f3/nocodemf/werld"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "The Witcher is a perfect fit for Reigns’ Tinder-like roleplaying",
      "url": "https://www.theverge.com/entertainment/885432/reigns-the-witcher-interview-steam-iphone-android",
      "published": "2026-02-28T14:00:00+00:00",
      "summary": "I never knew how easy it was to die in an orgy. But that's just one of the many threats facing Geralt of Rivia in his latest adventure. The studio behind the Reigns series of Tinder-like choose-your-own-adventure games has now adapted The Witcher, following a handful of original titles and a take on Game of [&#8230;]",
      "content_text": "I never knew how easy it was to die in an orgy. But that’s just one of the many threats facing Geralt of Rivia in his latest adventure. The studio behind the Reigns series of Tinder-like choose-your-own-adventure games has now adapted The Witcher , following a handful of original titles and a take on Game of Thrones . And for Francois Alliot, creative director at Reigns studio Nerial, the series’ structure actually makes it an ideal way to ease players into sprawling fantasies like this. “There’s something about the way you can bring really complex universes, lore, and storylines to simple actions,” he says. “It can work in a lot of contexts.” What makes Reigns so approachable is the way it distills every action into a binary choice. As you play, you’re presented with cards, and you progress by either swiping right or left. In the case of The Witcher , for instance, an elf might ask Geralt for protection, and your options are simply to say either yes or no and then deal with the consequences. Each run through the game involves making a number of these decisions to progress a storyline until, well, you die. The idea was for Reigns: The Witcher to work on two levels. For existing fans, it’s a fun way to play around and experiment in the world. “It’s not a new Witcher ,” Alliot notes. “It’s a meta game around this universe, a bit like a fanfiction simulator.” But for those who might be intimidated by the franchise, which spans multiple books, games, and TV shows, it’s also a good place to start. “It works nicely as an entry point because you can really get a feel for the tone and rules, or lack of rules, of the world,” says narrative designer Oscar Harrington-Shaw. “But you’re not having to commit to a complex RPG.” There are several aspects of the Reigns formula that had to be tweaked to work with The Witcher . One of the key conceits in the games is that you can die; in the original Reigns you played as a king, and when that was over you picked up as their successor. But that doesn’t really work when you’re playing a character like Geralt who can’t die. So you aren’t actually playing as Geralt; instead, you’re his bard pal Dandelion, singing tales of Geralt’s exploits that may or may not be true. This allowed the team at Nerial to “free ourselves from the lore,” as Alliot describes it, and have fun with things. This is especially apparent in the deaths, which come in the form of the aforementioned orgies or even from Geralt drinking himself to an early grave. “It really helped in two ways,” Harrington-Shaw says of coming up with the Dandelion idea, which came about from discussions with Witcher studio CD Projekt Red. “One is that it helps explain the loop; it gives a really neat end point. And we can have loads of fun deaths because it’s just a satisfying ending to a song. But we think it adds a really fun tension because you are playing as Geralt and you’re trying to survive, but you’re also trying to write good content.” As I played, this setup made me much more open to experimenting. Instead of trying to roleplay as Geralt, I would often make odd choices just to see what happened. This, in turn, helps open up new storylines, giving some payoff for making the seemingly wrong decision. Even an early death can lead somewhere interesting in future runs. The other notable addition in Reigns: The Witcher is a combat system. It wouldn’t be The Witcher if Geralt wasn’t slaying some monsters, but the idea of battles also had the potential to complicate the streamlined Reigns structure. The team settled on a sort of rhythm game, where you’re moving Geralt side to side on a board to attack or avoid monsters. What makes this system work within the confines of Reigns is that you’re still using the same commands; whether you’re making a pivotal decision or staring down a striga, everything comes down to swiping either right or left. Despite those changes, Harrington-Shaw says that The Witcher universe is an almost ideal fit for Reigns thanks to its dark sense of humor and frequently bleak world full of opposing factions. More important, though, is the main witcher himself. “Geralt is always facing these tricky binary choices,” he says. “The world of The Witcher is full of murky, gray morality, and that seemed perfect to translate.” Reigns: The Witcher is out now on PC and mobile. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. Andrew Webster Entertainment Gaming Interview Report",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/ss_24697beeceaf90658f9429787136b4c36148d529.1920x1080.jpg?quality=90&strip=all&crop=0%2C3.4613147178592%2C100%2C93.077370564282&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Addressing Antigravity Bans & Reinstating Access · google-gemini gemini-cli · Discussion #20632 · GitHub",
      "url": "https://github.com/google-gemini/gemini-cli/discussions/20632",
      "published": "2026-02-28T13:50:13+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.com/google-gemini/gemini-cli/discussions/20632\">https://github.com/google-gemini/gemini-cli/discussions/20632</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47195371\">https://news.ycombinator.com/item?id=47195371</a></p> <p>Points: 69</p> <p># Comments: 50</p>",
      "content_text": "You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/fc2981ff76e80f18510f4d1db2dc34f6e1357f167f3806027bd67d3ee5c12c5c/google-gemini/gemini-cli/discussions/20632"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "OpenAI Fires an Employee for Prediction Market Insider Trading",
      "url": "https://www.wired.com/story/openai-fires-employee-insider-trading-polymarket-kalshi/",
      "published": "2026-02-28T13:46:20+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.wired.com/story/openai-fires-employee-insider-trading-polymarket-kalshi/\">https://www.wired.com/story/openai-fires-employee-insider-trading-polymarket-kalshi/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47195317\">https://news.ycombinator.com/item?id=47195317</a></p> <p>Points: 82</p> <p># Comments: 41</p>",
      "content_text": "OpenAI has fired an employee following an investigation into their activity on prediction market platforms including Polymarket, WIRED has learned. OpenAI CEO of Applications, Fidji Simo , disclosed the termination in an internal message to employees earlier this year. The employee, she said, â€œused confidential OpenAI information in connection with external prediction markets (e.g. Polymarket).â€� â€œOur policies prohibit employees from using confidential OpenAI information for personal gain, including in prediction markets,â€� says spokesperson Kayla Wood. OpenAI has not revealed the name of the employee or the specifics of their trades. Evidence suggests that this was not an isolated event. Polymarket runs on the Polygon blockchain network, so its trading ledger is pseudonymous but traceable. According to an analysis by the financial data platform Unusual Whales, there have been clusters of activities, which the service flagged as suspicious, around OpenAI-themed events since March 2023. Unusual Whales flagged 77 positions in 60 wallet addresses as suspected insider trades, looking at the age of the account, trading history, and significance of investment, among other factors. Suspicious trades hinged on the release dates of products like Sora , GPT-5 , and the ChatGPT Browser, as well as CEO Sam Altmanâ€™s employment status. In November 2023, two days after Altman was dramatically ousted from the company, a new wallet placed a significant bet that he would return, netting over $16,000 in profits. The account never placed another bet. The behavior fits into patterns typical of insider trades. â€œThe tell is the clustering. In the 40 hours before OpenAI launched its browser, 13 brand-new wallets with zero trading history appeared on the site for the first time to collectively bet $309,486 on the right outcome,â€� says Unusual Whales CEO Matt Saincome. â€œWhen you see that many fresh wallets making the same bet at the same time, it raises a real question about whether the secret is getting out.â€� Prediction markets have exploded in popularity in recent years. These platforms allow customers to buy â€œevent contractsâ€� on the outcomes of future events ranging from the winner of the Super Bowl to the daily price of Bitcoin to whether the United States will go to war with Iran. There are a wide array of markets tied to events in the technology sector; you can trade on what Nvidiaâ€™s quarterly earnings will be, or when Tesla will launch a new car, or which AI companies will IPO in 2026. As the platforms have grown, so have concerns that they allow traders to profit from insider knowledge. â€œThis prediction market world makes the Wild West look tame in comparison,â€� says Jeff Edelstein, a senior analyst at the betting news site InGame. â€œIf there's a market that exists where the answer is known, somebody's going to trade on it.â€� Earlier this week, Kalshi announced that it had reported several suspicious insider trading cases to the Commodity Futures Trading Commission, the government agency overseeing these markets. In one instance, an employee of the popular YouTuber Mr. Beast was suspended for two years and fined $20,000 for making trades related to the streamerâ€™s activities; in another, the far-right political candidate Kyle Langford was banned from the platform for making a trade on his own campaign. The company also announced a number of initiatives to prevent insider trading and market manipulation. While Kalshi has heavily promoted its crackdown on insider trading, Polymarket has stayed silent on the matter. The company did not return requests for comments. In the past, major trades on technology-themed markets have sparked speculation that there are Big Tech employees profiting by using their insider knowledge to gain an edge. One notorious example is the so-called â€œGoogle whale,â€� a pseudonymous account on Polymarket that made over $1 million trading on Google-related events, including a market on who the most-searched person of the year would be in 2025. (It was the singer D4vd, who is best known for his connection to an ongoing murder investigation after a young fanâ€™s remains were found in a vehicle registered to him.)",
      "cover_image_url": "https://media.wired.com/photos/69a0b01c157af8f83feddf9b/191:100/w_1280,c_limit/OpenAI-Employee-Fired-Insider-Trading-Business-2210029299.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Everything changes, and nothing changes",
      "url": "https://btao.org/posts/2026-02-28-everything-changes-nothing-changes/",
      "published": "2026-02-28T13:35:54+00:00",
      "summary": "<p>Article URL: <a href=\"https://btao.org/posts/2026-02-28-everything-changes-nothing-changes/\">https://btao.org/posts/2026-02-28-everything-changes-nothing-changes/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47195210\">https://news.ycombinator.com/item?id=47195210</a></p> <p>Points: 11</p> <p># Comments: 7</p>",
      "content_text": "It’s a strange time to be a software engineer. We’re speedrunning a technical revolution that transforms our industry from one of craftsmanship to mass production and cheap code . This is painful to those who, like me, identified with the art and elegance of programming, and now have to reckon with the fact that we’re no longer artists but just people who type for money . I’m sympathetic to those who initially rejected the usefulness of LLMs, citing hallucinations and so on, but at some point over the last year it became absurd to hold on to this claim. Today it seems like willful ignorance to reject a future where AI writes 90-100% of the code . Indeed, at the leading AI labs, some engineers no longer write any code themselves . Startups and eventually enterprises are following suit. If your daily routine as a SWE doesn’t already look vastly different than it did in 2022, it soon will. Yet in spite of these rapid changes, I’ve found some relief in the fact that many of the fundamentals are staying the same, at least for now. Software engineering has always really been about outcomes, not code . This is why strong engineers spend much of their time thinking about productivity and team coordination. We’re fortunate, because the principles and tools that make a team operate fast also tend to make coding agents work better: small, stacked diffs? Works great for human understanding and also for swarms of agents making concurrent changes. Continuous deployment, automated testing, and easy rollbacks? Already a good idea, and even better when you’re shipping more code than ever before. What makes a good software engineer? I think a lot of it comes down to taste and intuition (often built up through years of experience). This will remain true, though this intuition increasingly operates at the level of architecture rather than individual lines of code. Junior engineers now have to start developing this architectural taste immediately out of the gate, largely sidestepping the need for code-taste. Frontier models are writing ever-cleaner code, especially when paired with a good AGENTS.md to guide them. But they continue to fall short when it comes to understanding and really engaging with the constraints (both social and technical) that define much of our jobs. I’ve been telling myself that this is enough; that my identity as a builder can remain intact. In the short-to-medium term (<5 years), I’m pretty confident that these principles will hold true. Beyond that, I’m less sure. LLMs can, in theory, automate anything that can be expressed symbolically, and I think that engineering principles, and even taste, can be. Adam Leventhal and Simon Willison coined the term Deep Blue for the pervasive feeling of dread that many software engineers are sitting with these days. I have days where I feel this deeply. But on other days, when I really lean into this new way of building, it’s hard not to get caught up in the sheer joy of the insanely fast feedback loop and the feeling of expansiveness you get when you’re orchestrating concurrent agents all building towards something new at once. Not everyone will enjoy this kind of work, and many engineers (especially earlier in their careers) won’t have the experience and professional networks that can cushion the tumult. We’re all living through the creative destruction . There’s real excitement, but also grief — and it can be painful to hold both at once.",
      "cover_image_url": "/_astro/textilemill.rVG4l-uz_Z1OhaEq.webp"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "The Life Cycle of Money",
      "url": "https://doap.metal.bohyen.space/blog/post/complete-life-cycle-of-money/",
      "published": "2026-02-28T13:32:28+00:00",
      "summary": "<p>Article URL: <a href=\"https://doap.metal.bohyen.space/blog/post/complete-life-cycle-of-money/\">https://doap.metal.bohyen.space/blog/post/complete-life-cycle-of-money/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47195157\">https://news.ycombinator.com/item?id=47195157</a></p> <p>Points: 22</p> <p># Comments: 2</p>",
      "content_text": "The Life Cycle of Money | Understanding how deficits inject deposits, trade creates dollar outflows, and reserves recycle back into government debt February 2026 36 min read <h1 data-number=\"1\" id=\"ontology-of-money\"><span class=\"header-section-number\">1</span> Ontology of Money</h1> <h2 data-number=\"1.1\" id=\"objective\"><span class=\"header-section-number\">1.1</span> Objective</h2> <p>Define what money is before explaining how it is created.</p> <h2 data-number=\"1.2\" id=\"what-is-money\"><span class=\"header-section-number\">1.2</span> What Is Money?</h2> <p>Money is fundamentally a claim on the state or a financial intermediary. It is not a thing. It is a relationship recorded on a balance sheet. In modern economies, money exists in three forms:</p> <ol type=\"1\"> <li><p><strong>Base Money (Monetary Base)</strong>: Central bank liabilities. These consist of physical currency in circulation and reserve balances held by banks at the central bank. Base money is the liability of the central bank.</p></li> <li><p><strong>Broad Money (M2, M3)</strong>: Includes base money plus deposits held at commercial banks. These bank deposits are liabilities of the commercial bank, not the central bank.</p></li> <li><p><strong>Credit Money</strong>: Claims on the future output or assets of a private entity (e.g., a corporate bond or a personal IOU).</p></li> </ol> <h2 data-number=\"1.3\" id=\"distinguishing-money-from-credit-debt-and-capital\"><span class=\"header-section-number\">1.3</span> Distinguishing Money from Credit, Debt, and Capital</h2> <p><strong>Money</strong> is a universal medium of exchange and store of value, accepted throughout an economy without question.</p> <p><strong>Credit</strong> is a conditional claim on future payment. When a bank extends a loan, it creates credit (not yet money). That credit becomes money only when it is accepted as payment by third parties and deposits are created in the borrower’s account.</p> <p><strong>Debt</strong> is the obligation to repay. Every monetary unit has a corresponding debt claim somewhere in the system. When the central bank creates reserves, it is simultaneously creating a liability (the reserve balance is a debt owed by the central bank to the bank holding it).</p> <p><strong>Capital</strong> is equity ownership or productive assets. A business owner’s equity is capital, not money. Capital and money are fundamentally different categories.</p> <h2 data-number=\"1.4\" id=\"the-balance-sheet-nature-of-money\"><span class=\"header-section-number\">1.4</span> The Balance Sheet Nature of Money</h2> <p>Money is a liability on one side of a balance sheet and an asset on the other. For example:</p> <ul> <li><strong>Federal Reserve perspective</strong>: Reserve balances are a liability of the Fed; the Treasury securities it holds are an asset.</li> <li><strong>Commercial bank perspective</strong>: Depositors’ accounts are liabilities; loans and securities are assets.</li> <li><strong>Private household perspective</strong>: A bank deposit is an asset (a claim on the bank); a mortgage is a liability.</li> </ul> <h2 data-number=\"1.5\" id=\"commodity-representative-and-fiat-money\"><span class=\"header-section-number\">1.5</span> Commodity, Representative, and Fiat Money</h2> <p><strong>Commodity money</strong> (gold, silver) has intrinsic value independent of its use as money. Historical example: gold coins.</p> <p><strong>Representative money</strong> is a claim on a commodity held in reserve. Historical example: gold-backed currency where you could exchange paper dollars for gold at a fixed rate.</p> <p><strong>Fiat money</strong> is money by legal declaration (fiat). It has no commodity backing and derives its value from:</p> <ul> <li>State acceptance for tax payment</li> <li>Network effects (widespread acceptance)</li> <li>Legal enforceability of contracts denominated in that currency</li> </ul> <p>All modern currencies are fiat currencies. Their stability depends on institutional credibility and the depth of markets denominated in that currency, not physical backing.</p> <h2 data-number=\"1.6\" id=\"why-this-matters\"><span class=\"header-section-number\">1.6</span> Why This Matters</h2> <p>Understanding that money is a legal and institutional creation (not a commodity) is essential to understanding the lifecycle that follows. Money is created by law and destroyed by accounting entries. The quantity of money is not exogenous (fixed by mining or government decree); it is endogenous to the credit cycle, shaped by the decisions of millions of borrowers and lenders.</p> <hr /> <h1 data-number=\"2\" id=\"legal-authority-and-sovereign-issuance\"><span class=\"header-section-number\">2</span> Legal Authority and Sovereign Issuance</h1> <h2 data-number=\"2.1\" id=\"objective-1\"><span class=\"header-section-number\">2.1</span> Objective</h2> <p>Explain how modern states acquire the authority to issue currency.</p> <h2 data-number=\"2.2\" id=\"the-legal-framework\"><span class=\"header-section-number\">2.2</span> The Legal Framework</h2> <p>In the United States, the authority to issue currency is distributed across two institutions:</p> <ol type=\"1\"> <li><strong>The Federal Reserve</strong> issues the monetary base (currency and reserves) under the authority granted by the Federal Reserve Act of 1913 and subsequent legislation.</li> <li><strong>The U.S. Treasury</strong> issues debt securities and directs fiscal spending. The Treasury also mints coins (a negligible share of the money supply).</li> </ol> <p>This division reflects a historical compromise: fiscal authority (spending) rests with elected officials in Congress, while monetary authority (interest rates and reserve creation) rests with an independent central bank.</p> <h2 data-number=\"2.3\" id=\"the-treasury-general-account-tga\"><span class=\"header-section-number\">2.3</span> The Treasury General Account (TGA)</h2> <p>The Treasury General Account is the operating account of the U.S. government. It holds all tax receipts and serves as the source from which government checks are drawn. The TGA is not a demand deposit account at a commercial bank; it is a reserve account at the Federal Reserve itself.</p> <p>When the Treasury spends:</p> <ol type=\"1\"> <li>A check is drawn on the TGA</li> <li>The Federal Reserve debits the TGA and credits the reserve account of the bank receiving the check</li> <li>That bank credits the account of the government contractor or employee</li> <li>Net reserves in the system increase</li> </ol> <h2 data-number=\"2.4\" id=\"debt-issuance-and-spending\"><span class=\"header-section-number\">2.4</span> Debt Issuance and Spending</h2> <p>Contrary to popular belief, governments do not <q>print money</q> to spend. Instead:</p> <ol type=\"1\"> <li><strong>Congress appropriates spending</strong> and the Treasury issues debt (Treasury securities: bills, notes, bonds)</li> <li><strong>Primary dealers and the public purchase these securities</strong>, paying with bank deposits (which are claims on the Federal Reserve’s reserves)</li> <li><strong>The proceeds are deposited in the Treasury General Account</strong></li> <li><strong>The Treasury spends</strong> by instructing its bank (the Fed) to transfer reserves to the accounts of recipients</li> <li><strong>The public receives deposits</strong>, not currency (except for a tiny fraction that withdraw cash)</li> </ol> <p>The Treasury does not <q>borrow from the Fed.</q> Instead, it issues debt to the public and primary dealers. The Federal Reserve is a separate legal entity. However, when the Fed conducts quantitative easing, it purchases Treasury securities from the market, which indirectly finances government spending by absorbing debt that would otherwise require higher interest rates.</p> <h2 data-number=\"2.5\" id=\"fiscal-and-monetary-authority\"><span class=\"header-section-number\">2.5</span> Fiscal and Monetary Authority</h2> <p><strong>Fiscal authority</strong> determines the size and composition of government spending and taxation. This rests with Congress and the Executive Branch.</p> <p><strong>Monetary authority</strong> determines the quantity of reserves in the system and the level of short-term interest rates. This rests with the Federal Reserve.</p> <p>These are institutionally separate for good reason: elected officials are accountable to voters; central bankers are accountable to technical objectives (price stability and full employment in the U.S. mandate) and insulated from political pressure to inflate.</p> <hr /> <h1 data-number=\"3\" id=\"creation-of-base-money\"><span class=\"header-section-number\">3</span> Creation of Base Money</h1> <h2 data-number=\"3.1\" id=\"objective-2\"><span class=\"header-section-number\">3.1</span> Objective</h2> <p>Explain how central bank liabilities enter the system.</p> <h2 data-number=\"3.2\" id=\"what-are-reserves\"><span class=\"header-section-number\">3.2</span> What Are Reserves?</h2> <p>Reserves are liabilities of the central bank held by commercial banks. They are electronic entries in the Federal Reserve’s books. When you see $3 trillion in <q>reserves</q> reported by the Fed, this refers to the deposits that banks hold in accounts at the Federal Reserve. This is exactly analogous to how you hold a deposit at your commercial bank.</p> <p>Reserves are not:</p> <ul> <li>Physical cash in a vault (though the Fed holds physical currency too)</li> <li>Something that <q>backs</q> the money supply</li> <li>Constrained by some fixed quantity</li> </ul> <h2 data-number=\"3.3\" id=\"how-the-central-bank-creates-reserves\"><span class=\"header-section-number\">3.3</span> How the Central Bank Creates Reserves</h2> <p>The Federal Reserve creates reserves by purchasing assets, typically Treasury securities. This is called an <strong>open market operation (OMO)</strong>. Here is the balance sheet entry:</p> <p><strong>Federal Reserve Balance Sheet:</strong></p> <table> <thead> <tr class=\"header\"> <th>Assets</th> <th>Liabilities</th> </tr> </thead> <tbody> <tr class=\"odd\"> <td>Treasury Securities: +$1 billion</td> <td>Reserve Balances: +$1 billion</td> </tr> </tbody> </table> <p>When the Fed purchases a Treasury security from a primary dealer:</p> <ol type=\"1\"> <li>The dealer exchanges the security for a credit to its reserve account at the Fed</li> <li>The Fed’s assets increase (it now owns the security)</li> <li>The Fed’s liabilities increase (reserves owed to the dealer’s bank)</li> <li><strong>Net new reserves have been created</strong></li> </ol> <p>The dealer can now use those reserves to conduct other business, or the underlying bank can lend those reserves to other banks. Reserves circulate through the banking system. At no point does a <q>constraint</q> prevent reserve creation. The Fed simply credits accounts.</p> <h2 data-number=\"3.4\" id=\"physical-currency-vs.-reserves\"><span class=\"header-section-number\">3.4</span> Physical Currency vs. Reserves</h2> <p>When we discuss <q>the money supply,</q> we are mostly discussing reserves and deposits, not physical currency. Physical currency represents only about 1-2% of the U.S. money supply. When you withdraw $100 from an ATM:</p> <ol type=\"1\"> <li>Your bank debits your deposit account</li> <li>Your bank debits its reserve account at the Fed</li> <li>Physical currency (already printed by the Bureau of Engraving and Printing) is delivered to you</li> </ol> <p>The act of currency printing does not create new money; it simply converts existing electronic reserves into physical form. The money supply does not change.</p> <h2 data-number=\"3.5\" id=\"interest-on-reserves-ior\"><span class=\"header-section-number\">3.5</span> Interest on Reserves (IOR)</h2> <p>The Federal Reserve pays interest on reserve balances held by banks. This is a powerful tool:</p> <ul> <li><strong>High IOR rate</strong>: Banks earn more by holding reserves, so they lend less to businesses and consumers. This tightens monetary conditions.</li> <li><strong>Low or zero IOR rate</strong>: Banks earn nothing by holding reserves, so they seek returns by lending. This loosens monetary conditions.</li> </ul> <p>IOR is a fiscal payment made by the Fed to banks. When reserves are abundant and IOR is high, the Fed transfers significant income to the banking sector. This has macroeconomic consequences.</p> <h2 data-number=\"3.6\" id=\"quantitative-easing-qe-vs.-normal-open-market-operations\"><span class=\"header-section-number\">3.6</span> Quantitative Easing (QE) vs. Normal Open Market Operations</h2> <p><strong>Normal OMOs</strong> adjust reserves to maintain a target interest rate. The Fed buys and sells securities in small quantities daily, maintaining the federal funds rate at its target level. This is routine.</p> <p><strong>Quantitative Easing</strong> is the large-scale, sustained purchase of longer-term securities (Treasury notes and bonds, mortgage-backed securities) during periods when the policy rate is already at zero. QE serves multiple objectives:</p> <ol type=\"1\"> <li><strong>Inject reserves</strong> into the system during crises</li> <li><strong>Drive down longer-term interest rates</strong> by purchasing large quantities of long-duration securities</li> <li><strong>Signal commitment</strong> to low rates and support for asset prices</li> <li><strong>Increase the monetary base</strong> in the hope of spurring credit growth</li> </ol> <p>During the 2008 financial crisis, the Fed expanded its balance sheet from ~$900 billion to over $2 trillion through QE. In 2020, during the COVID-19 crisis, it expanded by over $3 trillion in weeks.</p> <h2 data-number=\"3.7\" id=\"the-balance-sheet-mechanics-of-crisis-purchases\"><span class=\"header-section-number\">3.7</span> The Balance Sheet Mechanics of Crisis Purchases</h2> <p>When the Fed conducts emergency OMOs during a crisis:</p> <p><strong>Fed Balance Sheet Before:</strong></p> <table> <thead> <tr class=\"header\"> <th>Assets</th> <th>Liabilities</th> </tr> </thead> <tbody> <tr class=\"odd\"> <td>Securities: $2.0 trillion</td> <td>Reserves: $1.5 trillion</td> </tr> <tr class=\"even\"> <td></td> <td>Currency: $0.5 trillion</td> </tr> </tbody> </table> <p><strong>Fed Balance Sheet After ($1 Trillion QE):</strong></p> <table> <thead> <tr class=\"header\"> <th>Assets</th> <th>Liabilities</th> </tr> </thead> <tbody> <tr class=\"odd\"> <td>Securities: $3.0 trillion</td> <td>Reserves: $2.5 trillion</td> </tr> <tr class=\"even\"> <td></td> <td>Currency: $0.5 trillion</td> </tr> </tbody> </table> <p>The Fed’s balance sheet expands. It has more assets and more liabilities. This is not <q>printing money</q> in the colloquial sense; it is creating electronic reserve accounts that banks can use for lending or other purposes.</p> <h2 data-number=\"3.8\" id=\"boundaries\"><span class=\"header-section-number\">3.8</span> Boundaries</h2> <p>This section remains at the central bank layer. Commercial bank lending, which multiplies money further, is discussed in Section IV.</p> <hr /> <h1 data-number=\"4\" id=\"commercial-bank-credit-creation\"><span class=\"header-section-number\">4</span> Commercial Bank Credit Creation</h1> <h2 data-number=\"4.1\" id=\"objective-3\"><span class=\"header-section-number\">4.1</span> Objective</h2> <p>Explain how broad money is created through lending.</p> <h2 data-number=\"4.2\" id=\"loans-create-deposits\"><span class=\"header-section-number\">4.2</span> Loans Create Deposits</h2> <p>The most important accounting principle in modern money creation is this: <strong>loans create deposits</strong>. When a commercial bank approves a loan, it simultaneously creates a new deposit in the borrower’s account.</p> <h2 data-number=\"4.3\" id=\"double-entry-accounting-for-loan-origination\"><span class=\"header-section-number\">4.3</span> Double Entry Accounting for Loan Origination</h2> <p>Suppose a borrower walks into a bank and is approved for a $100,000 mortgage. Here is what happens on the bank’s balance sheet:</p> <p><strong>Commercial Bank Balance Sheet:</strong></p> <table> <thead> <tr class=\"header\"> <th>Assets</th> <th>Liabilities</th> </tr> </thead>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Now I Get It!",
      "url": "https://nowigetit.us",
      "published": "2026-02-28T13:29:36+00:00",
      "summary": "<p>Understanding scientific articles can be tough, even in your own field. Trying to comprehend articles from others? Good luck.<p>Enter, Now I Get It!<p>I made this app for curious people. Simply upload an article and after a few minutes you'll have an interactive web page showcasing the highlights. Generated pages are stored in the cloud and can be viewed from a gallery.<p>Now I Get It! uses the best LLMs out there, which means the app will improve as AI improves.<p>Free for now - it's capped at 20 articles per day so I don't burn cash.<p>A few things I (and maybe you will) find interesting:<p>* This is a pure convenience app. I could just as well use a saved prompt in Claude, but sometimes it's nice to have a niche-focused app. It's just cognitively easier, IMO.<p>* The app was built for myself and colleagues in various scientific fields. It can take an hour or more to read a detailed paper so this is like an on-ramp.<p>* The app is a place for me to experiment with using LLMs to translate scientific articles into software. The space is pregnant with possibilities.<p>* Everything in the app is the result of agentic engineering, e.g. plans, specs, tasks, execution loops. I swear by Beads (<a href=\"https://github.com/steveyegge/beads\" rel=\"nofollow\">https://github.com/steveyegge/beads</a>) by Yegge and also make heavy use of Beads Viewer (<a href=\"https://news.ycombinator.com/item?id=46314423\">https://news.ycombinator.com/item?id=46314423</a>) and Destructive Command Guard (<a href=\"https://news.ycombinator.com/item?id=46835674\">https://news.ycombinator.com/item?id=46835674</a>) by Jeffrey Emanuel.<p>* I'm an AWS fan and have been impressed by Opus' ability to write good CFN. It still needs a bunch of guidance around distributed architecture but way better than last year.</p> <hr /> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47195123\">https://news.ycombinator.com/item?id=47195123</a></p> <p>Points: 42</p> <p># Comments: 27</p>",
      "content_text": "Drop your PDF here, or click to browse Works best with files under 10 MB",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Customer Update on Simplenote",
      "url": "https://forums.simplenote.com/forums/topic/customer-update-on-simplenote/?view=all",
      "published": "2026-02-28T13:26:51+00:00",
      "summary": "<p>Article URL: <a href=\"https://forums.simplenote.com/forums/topic/customer-update-on-simplenote/?view=all\">https://forums.simplenote.com/forums/topic/customer-update-on-simplenote/?view=all</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47195093\">https://news.ycombinator.com/item?id=47195093</a></p> <p>Points: 29</p> <p># Comments: 22</p>",
      "content_text": "Support Get Help with Simplenote on our public forum. Customer Update on Simplenote We appreciate your continued use of Simplenote and the support of our community over the years. Simplenote is no longer in active development, and while the app remains available, only its basic functionality is being maintained at this time. No new features or enhancements are planned. The topic ‘Customer Update on Simplenote’ is closed to new replies.",
      "cover_image_url": "https://forums.simplenote.com/wp-content/uploads/2023/03/cropped-cropped-icon_512x512.png?w=200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Virtual-Protest-Protocol/README.md at main · voice-of-japan/Virtual-Protest-Protocol · GitHub",
      "url": "https://github.com/voice-of-japan/Virtual-Protest-Protocol/blob/main/README.md",
      "published": "2026-02-28T13:17:53+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.com/voice-of-japan/Virtual-Protest-Protocol/blob/main/README.md\">https://github.com/voice-of-japan/Virtual-Protest-Protocol/blob/main/README.md</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47194994\">https://news.ycombinator.com/item?id=47194994</a></p> <p>Points: 6</p> <p># Comments: 1</p>",
      "content_text": "You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/efad5fd765f1386527bf6c8df93a517007cd319b20f16f026083a21705918864/voice-of-japan/Virtual-Protest-Protocol"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "What AI coding costs you",
      "url": "https://tomwojcik.com/posts/2026-02-15/finding-the-right-amount-of-ai/",
      "published": "2026-02-28T13:05:03+00:00",
      "summary": "<p>Article URL: <a href=\"https://tomwojcik.com/posts/2026-02-15/finding-the-right-amount-of-ai/\">https://tomwojcik.com/posts/2026-02-15/finding-the-right-amount-of-ai/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47194847\">https://news.ycombinator.com/item?id=47194847</a></p> <p>Points: 107</p> <p># Comments: 84</p>",
      "content_text": "Every developer I know uses AI for coding now. The productivity gains are real, but there are costs that don’t show up on any dashboard. Imagine a spectrum. On the far left are humans typing on the keyboard, seeing the code in the IDE. On the far right: AGI. It implements everything on its own. Cheaply, flawlessly, better than any human, and no human overseer is required. Somewhere between those two extremes there’s you, using AI, today. That threshold moves to the right every week as models improve, tools mature, and workflows get refined. Recently I stumbled upon this awesome daxfohl comment on HN : Which is higher risk, using AI too much, or using AI too little? and it made me think about LLMs for coding differently, especially after reading what other devs share on AI adoption in different workplaces. You can be wrong in both directions, but is the desired amount of AI usage at work changing as the models improve? How We Got Here Not long ago the first AI coding tools like Cursor (2023) or Copilot (2022) emerged. They were able to quickly index the codebase using RAG, so they had the local context. They had all the knowledge of the models powering them, so they had an external knowledge of the Internet as well. Googling and browsing StackOverflow wasn’t needed anymore. Cursor gave the users a custom IDE with built in AI powered autocomplete and other baked-in AI tools, like chat, to make the experience coherent. Then came the agent promise. MCPs, autonomous workflows, articles about agents running overnight started to pop up left and right. It was a different use of AI than Cursor. It was no longer an AI-assisted human coding, but a human-assisted AI coding. Many devs tried it and got burned. Agents made tons of small mistakes. The AI-first process required a complete paradigm shift in how devs think about coding, in order to achieve great results. Also, agents often got stuck in loops, hallucinate dependencies, and produced code that looks almost right but isn’t. You needed to learn about a completely new tech, fueled by FOMO. And this new shiny tool never got it 100% right on the first try. Software used to be deterministic. You controlled it with if/else branches, explicit state machines, clear logic. The new reality is controlling the development process with prompts, system instructions, and CLAUDE.md files, and hope the model produces the output you expect. Then Opus 4.5 came out. The workflows everyone were talking about just worked, out of the box (not always, obviously, but more often). Engineers transitioned to Forward Deployed Engineers , becoming responsible for many other things than coding. Sometimes not even coding by hand at all. Recently Spotify’s co-CEO Gustav Söderström said An engineer at Spotify on their morning commute from Slack on their cell phone can tell Claude to fix a bug or add a new feature to the iOS app. And once Claude finishes that work, the engineer then gets a new version of the app, pushed to them on Slack on their phone, so that he can then merge it to production, all before they even arrive at the office.” I hope they at least review the code before merging. The next stage is an (almost) full automation. That’s what many execs want and try to achieve. It’s a capitalistic wet dream, a worker that never sleeps, never gets tired, always wants to work, is infinitely productive. But Geoffrey Hinton predicted in 2016 that deep learning would outperform radiologists at image analysis within five years. Anthropic’s CEO predicted AI would write 90% of code within three to six months of March 2025. None of this happened as predicted. The trajectory is real, but the timeline keeps slipping. Your Brain on AI In 2012, neuroscientist Manfred Spitzer published Digital Dementia , arguing that when we outsource mental tasks to digital devices, the brain pathways responsible for those tasks atrophy. Use it or lose it. Not all of this is proven scientifically, but neuroplasticity research shows the brain strengthens pathways that get used and weakens ones that don’t. The core principle of the book is that the cognitive skills that you stop practicing will decline. Margaret-Anne Storey, a software engineering researcher, recently gave this a more precise name: cognitive debt . Technical debt lives in the code. Cognitive debt lives in developers’ heads. It’s the accumulated loss of understanding that happens when you build fast without comprehending what you built. She grounds it in Peter Naur’s 1985 theory that a program is a theory existing in developers’ minds, capturing what it does, how intentions map to implementation, and how it can evolve. When that theory fragments, the system becomes a black box. Apply this directly to fully agentic coding. If you stop writing code and only review AI output, your ability to reason about code atrophies. Slowly, invisibly, but inevitably. You can’t deeply review what you can no longer deeply understand. This isn’t just theory. A 2026 randomized study by Shen and Tamkin tested this directly: 52 professional developers learning a new async library were split into AI-assisted and unassisted groups. The AI group scored 17% lower on conceptual understanding, debugging, and code reading. The largest gap was in debugging, the exact skill you need to catch what AI gets wrong. One hour of passive AI-assisted work produced measurable skill erosion. The insidious part is that you don’t notice the decline because the tool compensates for it. You feel productive. The PRs are shipping. Mihaly Csikszentmihalyi’s research on flow showed that the state of flow depends on a balance between challenge and skill. Your mind needs to be stretched just enough. Real flow produces growth. Rachel Thomas called what AI-assisted work produces “dark flow” , a term borrowed from gambling research, describing the trance-like state slot machines are designed to induce. You feel absorbed, but the challenge-skill balance is gone because the AI handles the challenge. It feels like the flow state of deep work, but the feedback loop is broken. You’re not getting better, you’re getting dependent. No Code, Only Review There’s this observation that keeps coming up in HN comments: if the AI writes all the code and you only review it, where does the skill to review come from? You can’t have one without the other. You don’t learn to recognize good code by reading about it in a textbook, or a PR. You learn by writing bad code, getting it torn apart, and building intuition through years of practice. This creates what I’d call the review paradox: the more AI writes, the less qualified humans become to review what it wrote. The Shen-Tamkin study puts numbers on this. Developers who fully delegated to AI finished tasks fastest but scored worst on evaluations. The novices who benefit most from AI productivity are exactly the ones who need debugging skills to supervise it, and AI erodes those skills first. Storey’s proposed fix is simple: “require humans to understand each AI-generated change before deployment.” That’s the right answer. It’s also the one that gets skipped first when velocity is the metric. The Seniority Collapse This goes deeper than individual skill decay. We used to have juniors, mids, seniors, staff engineers, architects. It was a pipeline where each level built on years of hands-on struggle. A junior spends years writing code that is rejected during the code review not because they were not careful, but didn’t know better. It’s how you build the judgment that separates someone who can write a function from someone who can architect a system. You can’t become a senior overnight. Unless you use AI, of course. Now, a junior with Claude Code (Opus 4.5+) delivers PRs that look like senior engineer work. And overall that’s a good thing, I think. But does it mean that the senior hat fits everyone now? From day one? But the head underneath hasn’t changed. That junior doesn’t know why that architecture was chosen. From my experience, sometimes CC misses a new DB transaction where it’s needed. Sometimes it creates a lock on a resource, that shouldn’t be locked, due to number of reasons. I can defend my decisions and I enjoy when my code is challenged, when reviewers disagree, and we have a discussion. What will a junior do? Ask Claude. It’s a two-sided collapse. Seniors who stop writing code and only review AI output lose their own depth. Juniors who skip the struggle never build it. Organizations are spending senior time every day on reviews while simultaneously breaking the mechanisms that create it. The pipeline that produced senior engineers, writing bad code, getting bad code reviewed, building intuition through failure, is being bypassed entirely. Nobody’s talking about what happens when that pipeline runs dry. What C-Levels Got Right and Wrong Look at what lands on C-level desks every week. Microsoft’s AI chief Mustafa Suleyman says all white-collar work will be automated within 18 months . Anthropic’s CEO Dario Amodei predicts AI will replace software engineers in 6-12 months and quoted his engineers saying they don’t write any code anymore, just let the model write it and edit the output. Sundar Pichai (CEO, Google) reported 25% of Google’s new code was AI-generated in late 2024. Months later, Google Research reported that number had reached 50% of code characters . If you’re a CTO watching that curve, of course you’re going to push your teams. The problem is that predictions come from people selling AI or trying to prop the stock with AI hype. They have every incentive to accelerate adoption and zero accountability when the timelines slip, which, historically, they always do. And “50% of code characters” at Google, a company that has built its own models, tooling, and infrastructure from scratch, says very little about what your team can achieve with off-the-shelf agents next Monday. AI adoption is not a switch to flip, rather a skill to calibrate. It’s not as simple as mandating specific tools, setting “AI-first” policies, measuring developers on how much AI they use (/r/ExperiencedDevs is full of these stories). A lot of good practices like usage of design patterns, proper test coverage, manual testing before merging, are often skipped these days because it reduces the pace. AI broke it? AI will fix it. You need a review? AI will do it. Not even Greptile or CodeRabbit. Just delegate the PR to Claude Code reviewer agent. Or Gemini. Or Codex. Pick your poison. And here’s what actually happens when you force the AI usage. One developer on r/ExperiencedDevs described their company tracking AI usage per engineer: “I just started asking my bots to do random things I don’t even care about. The other day I told Claude to examine random directories to ‘find bugs’ or answer questions I already knew the answer to.” This thread is full of engineers reporting that AI has made code reviews “infinitely harder due to the AI slop produced by tech leads who have been off the tools long enough to be dangerous.” This is sad, because being able to work with the AI tools is a perk for developers and since it improves pace, it’s something management wants as well. It’s obvious that the people gaming the metrics (not really using the AI the way the should) would be fired on the spot if the management learned how they are gaming the metrics (and it’s fair), but they are gaming the metrics because they don’t want to be fired… Who should be responsible for setting the threshold of AI usage at the company? What if your top performing engineer just refuses to use AI? What if the newly hired junior uses AI all the time? These are the new questions and management is trying to find an answer to them, but it’s not as simple as measuring the AI usage. This is Goodhart’s law in action: “When a measure becomes a target, it ceases to be a good measure.” Track AI usage per engineer and you won’t get better engineering, you’ll get compliance theater. Developers game the metrics, resent the tools, and the actual productivity gains that AI could deliver get buried under organizational dysfunction. The Cost Nobody Talks About The financial cost is obvious. Agent time for non-trivial features is measured in hours, and those hours aren’t free. But the human cost is potentially worse, and it’s barely discussed. Writing code can put you in a flow state, mentioned before. That deep, focused, creative problem-solving where hours disappear and you emerge with something you built and understand. And you’re proud of it. Someone wrote under your PR “Good job!” and gave you an approval. Reviewing AI-generated code does not do this. It’s the opposite. It’s a mental drain. Developers need the dopamine hit of creation. That’s not a perk, it’s what keeps good engineers engaged, learning, retained, and prevents burnout. The joy of coding is probably what allowed them to become experienced devs in the first place. Replace creation with oversight and you get faster burnout, not faster shipping. You’ve turned engineering, the creative work, into the worst form of QA. The AI does all the art, the human folds the laundry. Finding Your Threshold I use AI every day. I use AI heavily at work, I use AI in my sideprojects, and I don’t want to go back. I love it! That’s why I’m worried. I’m afraid I became addicted and dependent. I’ve implemented countless custom commands, skills, and agents. I check CC release notes daily. And I know many are in similar situation right now, and we all wonder about what the future brings. Are we going to replace ourselves with AI? Or will we be responsible for cleaning AI slop? What’s the right amount of AI usage for me? AI is just a tool. An extraordinarily powerful one, but a tool nonetheless. You wouldn’t mandate that every engineer uses a specific IDE, or measure people on how many lines they write per day (…right?). You’d let them pick the tools that make them most effective and measure what actually matters, the work that ships. The right amount of AI is not zero. And it’s not maximum. The Shen-Tamkin study identified six distinct AI interaction patterns among developers. Three led to poor learning: full delegation, progressive reliance, and outsourcing debugging to AI. Three preserved learning even with full AI access: asking for explanations, posing conceptual questions, and writing code independently while using AI for clarification. The differentiator wasn’t whether developers used AI, it was whether they stayed cognitively engaged. Software engineering was never just about typing code. It’s defining the problem well, understanding the problem, translating the language from business to product to code, clarifying ambiguity, making tradeoffs, understanding what breaks when you change something. Someone has to do that before AGI, and AGI is nowhere close (luckily). You’re on call, the phone rings at 3am, can you triage the issue without an agent? If not, you’ve probably taken AI coding too far. If the AI usage becomes a new performance metric of developer, maybe using AI too often, too much, should be discouraged as well? Not because these tools are bad, but because the coding skills are worth maintaining. The Risk of Too Little (anecdata) If you’re using no AI at all in 2026, you are leaving real gains on the table: Search and context. AI is genuinely better than Google for navigating unfamiliar codebases, understanding legacy code, and finding relevant patterns. This alone justifies having it in your workflow (since 2023, Cursor etc) Boilerplate and scaffolding. Writing the hundredth CRUD endpoint, config file, or test scaffold by hand when an agent can produce it in seconds isn’t craftsmanship, it’s stubbornness. Just use AI. You’re not a CRUD developer anymore anyway, because we all wear many hats these days (post 2025 Sonnet) The workflow itself. The investigate, plan, implement, test, validate cycle that works with customized agents is a real improvement in how features get de",
      "cover_image_url": "/_astro/accept_the_plan.DMU951nt.jpg"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Acme Weather looks like the Dark Sky replacement we’ve been waiting for",
      "url": "https://www.theverge.com/tech/886462/acme-weather-samsung-s26-installer",
      "published": "2026-02-28T13:00:00+00:00",
      "summary": "Hi, friends! Welcome to Installer No. 117, your guide to the best and Verge-iest stuff in the world. (If you're new here, welcome, please send Android tips, and also you can read all the old editions at the Installer homepage.) This week, I've been reading about Eileen Gu and Ozempic and fancy grocery stores, trying [&#8230;]",
      "content_text": "Hi, friends! Welcome to Installer No. 117, your guide to the best and Verge -iest stuff in the world. (If you’re new here, welcome, please send Android tips, and also you can read all the old editions at the Installer homepage .) This week, I’ve been reading about Eileen Gu and Ozempic and fancy grocery stores , trying out the beautiful Shiori bookmarking app, trying to temper my expectations for the Scrubs reboot, continuing my test of the Pixel 10 Pro , building my dream to-do list app with Claude Code (it’s almost done!), enjoying the beginnings of The Fall and Rise of Reggie Dinkins , recording the next season of Version History , watching all of The Earliest Show again after it showed up on my YouTube, and eating altogether too many Garden Salsa Sun Chips . I also have for you the first big phone launch of the year, a new-old weather app, a way to maybe make your YouTube a little cheaper, a bunch of stuff to watch this weekend, and much more. Missed you last week! Let’s get back at it. (As always, the best part of Installer is your ideas and tips. What are you reading / watching / playing / listening to / turning up to 11 this week? Tell me everything: installer@theverge.com . And if you know someone else who might enjoy Installer , forward it to them and tell them to subscribe here .) Acme Weather . Years after it was acquired by Apple and went away, there’s still no good replacement for Dark Sky. (Though I have been pretty happy with Hello Weather !) Super exciting to see the team go back out on their own, and I already like what they’re up to with their new iOS app. The multi-forecast stuff in particular is just fabulous. Samsung’s Galaxy S26 Ultra . A relatively minor upgrade this year, but I think the built-in privacy display is a genuinely great new bit of hardware. Terrible for me, an incorrigible snoop of other people’s phones, but probably a good thing for society at large. And really cleverly implemented! Resident Evil Requiem . I have really come to love a game that scares me, because it keeps me engaged like basically nothing else. By all accounts, this game is all that and even more. I will be playing alone, in the dark, terrified, as we are meant to do. Current . This is from last week, but it feels relevant: This is the RSS app Terry Godier promised a couple of issues ago ! It’s clean, it’s quiet, it feels practically meditative next to most RSS readers. It’s not exactly meant for my frenetic newsgathering use case, but wow is it nice to use. Wispr Flow for Android . The more I use these cross-app, AI-powered dictation apps, the more I enjoy talking instead of typing on all my devices. There are a lot of good apps on iOS (including Monologue , which launched last week!), but Android is woefully underserved. This is a welcome addition to the options. “ The Internet Was Weeks Away From Disaster and No One Knew .” The title is… a lot, but this Veritasium video is actually a really good primer on a lot of really important security things, and has one of the most delightful hero stories you’ll find. Notion Custom Agents . Notion is doing a really good job of bringing AI features to the tools you’re already using, and I keep hearing good things about custom agents. They know where your data is, they can build almost anything, they’re totally autonomous... vibe coding, but make it business. “ How Red Bull Built Its Empire .” I have always wondered how an energy drink company managed to fund all the sports teams, stunts, and various shenanigans that Red Bull does. This is a fascinating history of a company that is way more than a beverage company… but is actually very much a beverage company. The New York Times Midi. Oh, what’s that? Another crossword to do every day instead of working, that won’t be punishingly difficult half the time but also will take more than 34 seconds to complete? Oh okay cool sounds great I will do it every day forever thanks. YouTube Premium Lite . This is mostly a PSA, because I didn’t know this tier even existed. But now that it includes video downloads and (most importantly) background playback, Premium Lite is about half the price of Premium but has almost all of the best features. I might need to downgrade. Meredith Haggerty is one of those people you meet and you’re immediately like, Oh, you’re much cooler than I am. The more I get to know Meredith, a new(ish) editor here at The Verge , the more I realize how correct my first assumption was. Meredith has written about fashion and culture and brands and TV shows and also recently made a Pride and Prejudice joke that made me laugh so hard I spilled coffee all over my keyboard. Technically, Meredith owes me a keyboard. I asked Meredith to share her homescreen with us, both because I think it’s a fun way to get to know new people here and because I want her to tell me about cool things but I don’t want to just constantly badger her for TV recs. Here’s her homescreen, plus some info on the apps she uses and why: The phone: An iPhone 17. Until very recently, I was clinging to an iPhone 12 mini that I’d gotten as a hand-me-down corporate gift from a friend; it was so tiny and good and I had the perfect phone case. (Ben Affleck smoking a cigarette in a mask. A conversation starter!) But the battery became glacial, even after a couple of trips to the Genius Bar, and I had to give it up. The wallpaper: A screenshot of Roku City, fall edition. I find Roku City very calming, so I decided to keep it with me. The apps: Spotify, Messages, Mail, Chrome. I’m especially dependent on Notes, and here you can see my three main categories of Note: things I need to do, things I need to buy, thoughts I probably would have tweeted a few years ago. I love that the MTA app will tell me when I should leave for the train, but I almost never check it before I leave my house. For the weather, I actually rely on the New York Metro Weather Instagram account ; my boyfriend hates it when I tell him what number the vibes are. To be clear, this attempt to simplify my homescreen hasn’t alleviated my time-wasting at all. Beyond this page, I have a loopy number of apps, mostly put into folders to keep me away from them, which doesn’t work. I’m still always scrolling to the last page, to the last folder, to the last page of that last folder, so I can play a mobile game I don’t enjoy called Drop the Cat . There’s maybe nothing worse in my life than the hold that mobile games I don’t enjoy have on me. I’m not even a cat person. I also asked Meredith to share a few things she’s into right now. Here’s what she sent back: Love Story: John F. Kennedy Jr. & Carolyn Bessette . I’m appropriately ashamed of watching this show (I’m sorry, Schlossberg family!), but it’s a fantastic combination of cool and dumb. One second it makes smoking a cigarette in 1994 while wearing Calvin Klein look like the apex of human existence; the next, Fake JFK Jr. is pointing to an actor in a thick white wig, saying, “Have you met my uncle Teddy?” We shouldn’t even talk about the scene where Jackie O dances to Camelot . I recently downloaded an app called Rodeo that might actually solve a phone-based problem for me. It parses the deluge of recommendations from TikTok or Instagram, if you happen to be on the “wealthy children pose with food” side of those apps. You screenshot the clip, send it to Rodeo, and it grabs the relevant information and can save it in fairly handy lists. The library. This might be stolen valor from the Meredith who had not yet downloaded Drop the Cat , but a little over a year ago I moved closer to the library and have really been cashing in on how free those books are. Plus, the Brooklyn Public Library app is so good, letting me put things on hold whenever I happen to think of them. I’m currently reading Louise Erdrich’s The Sentence , which I am probably incorrectly not as into as her The Mighty Red , and we don’t have to talk about how many times I’ve renewed it because I’ve been playing phone games instead. Nirvanna the Band the Show the Movie . I’d never watched Viceland’s Nirvanna the Band the Show before I went to see the movie, and you currently cannot do so legally, so probably I still haven’t. I didn’t need it to enjoy the movie, though, which is hilarious and sweet and made me go “How did they do that???” so many times. Here’s what the Installer community is into this week. I want to know what you’re into right now as well! Email installer@theverge.com or message me on Signal — @davidpierce.11 — with your recommendations for anything and everything, and we’ll feature some of our favorites here every week. For even more great recommendations, check out the replies to this post on Threads and this post on Bluesky . “ Marathon (a new extraction shooter game by Bungie) is having an open play-test / demo this weekend so that’s what I’ll be into for the next few days.” – Janego “Really enjoying Agnes Aubert’s Mystical Cat Shelter by Heather Fawcett (author of the delightful Emily Wilde series). Feels like a cross between Jonathan Strange & Mr Norrell and Howl’s Moving Castle .” — Spencer “Since 1Password have upped their price I’ve spent a few hours moving over to Apple Passwords and Uplock . Was mostly okay, but it’s a shame you can’t transfer over all your passkeys to Apple Passwords. Uplock having a lifetime purchase is a big plus.” — Matthew “Been watching Demon Slayer this past month, and FINALLY watched the Infinity Castle movie in a theater, and, it’s so clear how these anime movies are wildly different (and spectacular!) in tone, direction and characterization from our current crop of Hollywood blockbusters.” — Anshuman “I just yesterday switched my family from my grandfathered free Google Apps plan for our custom domain email to Fastmail . Fastmail is private but supports industry standard IMAP and CalDAV protocols, so we can use the built-in mail apps on our phones and computers.” — Mike “I’ve been listening to Comedy Bang Bang! Still super funny. Big Paul F. Tompkins fan.” — Mo “ Star Trek Voyager: Across the Unknown . Despite the occasionally brutal RNG, it’s so fun to be able to dive into my favourite Trek stories and tweak the outcomes.” — Jono “Reading the first book in the On the Calculation of Volume series. It’s a time loop story, like Groundhog Day but way more realistic and sorta sad but it’s great so far!” — Colin “The news of the YouTube app coming to the Apple Vision Pro made me re-watch the only good use of 360 video I’ve seen: ‘ How TV screens made watching movies worse ,’ a fully 3D-animated, 20-minute video essay about how the home releases of movies differ from their theatrical cuts and why that matters, and how the physical size of TV screens makes an impact on content. If you have a Vision Pro it’s worth pulling out just for this video. After that, watch everything else that YouTuber ( Noodle ) has made.” — Nathan This winter has been a disaster, where I live and many other places. So much snow, so many snow days, so much chaos. First of all, I hope you’ve all stayed safe and warm and well! Second of all, there is one bit of good news in all this: Casey Neistat is out in New York City vlogging again . All these years later, nobody YouTubes quite like Casey YouTubes. Between this and the return of Paul Ford’s blog , it almost feels like the good internet is coming back. Here’s hoping. Follow topics and authors from this story to see more like this in your personalized homepage feed and to receive email updates. David Pierce Apps Gadgets Installer Streaming Tech",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/Installer-117.png?quality=90&strip=all&crop=0%2C10.711631919237%2C100%2C78.576736161526&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "cheat.sh/latency",
      "url": "https://cheat.sh/latency",
      "published": "2026-02-28T12:58:09+00:00",
      "summary": "<p>Article URL: <a href=\"https://cheat.sh/latency\">https://cheat.sh/latency</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47194781\">https://news.ycombinator.com/item?id=47194781</a></p> <p>Points: 21</p> <p># Comments: 8</p>",
      "content_text": "# Latency numbers every programmer should know 1ns Main memory reference: Send 2,000 bytes Read 1,000,000 bytes ▗▖ 100ns over commodity network: 5ns sequentially from SSD: ▗▖ ▗ 12.245us L1 cache reference: 1ns ▗ ▗▖ 1.0us SSD random read: 16.0us ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗ Disk seek: 1.649384ms Branch mispredict: 3ns ▗▖▗ ▗▖▗▖▗▖ Read 1,000,000 bytes Compress 1KB wth Snappy: sequentially from memory: Read 1,000,000 bytes L2 cache reference: 4ns 2.0us 741ns sequentially from disk: ▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗ 358.968us ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗ Mutex lock/unlock: 16ns Round trip ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ in same datacenter: 500.0us Packet roundtrip ▗▖▗▖▗▖▗▖▗▖▗▖▗ 10.0us = ▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ CA to Netherlands: 150.0ms ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ 100ns = ▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ 1.0ms = ▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ # [github.com/chubin/late.nz] [MIT License] ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ # Console port of \"Jeff Dean's latency numbers\" ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ # from [github.com/colin-scott/interactive_latencies] ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ ▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖▗▖ $ cheat.sh late.nz",
      "cover_image_url": null
    }
  ]
}