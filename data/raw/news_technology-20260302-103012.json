{
  "industry": "technology",
  "collected_at": "2026-03-02T02:31:21.049373+00:00",
  "hours": 24,
  "limit": 25,
  "count": 25,
  "items": [
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "GitHub - kossisoroyce/timber: Ollama for classical ML models. AOT compiler that turns XGBoost, LightGBM, scikit-learn, CatBoost & ONNX models into native C99 inference code. One command to load, one command to serve. 336x faster than Python inference.",
      "url": "https://github.com/kossisoroyce/timber",
      "published": "2026-03-02T00:57:40+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.com/kossisoroyce/timber\">https://github.com/kossisoroyce/timber</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47212576\">https://news.ycombinator.com/item?id=47212576</a></p> <p>Points: 4</p> <p># Comments: 0</p>",
      "content_text": "You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/1cf4a8ca8e8bb2eb0e5ccfbfa71c6b1f473672a5504de41e31e0fe5103b94768/kossisoroyce/timber"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "A robot arm with puppy dog eyes is one of Lenovo’s desktop AI concepts",
      "url": "https://www.theverge.com/tech/885228/lenovo-ai-workmate-companion-work-concept-robot-arm-desktop-clock-hub",
      "published": "2026-03-01T23:01:00+00:00",
      "summary": "Alongside a handful of new laptop concepts (and a range of real products too), Lenovo used MWC to announce a pair of AI-based productivity companion concepts. Both are standalone desk devices designed to boost productivity while providing office workers with a bit of artificial dystopic companionship. Lenovo describes its AI Workmate Concept as an \"always-on [&#8230;]",
      "content_text": "Alongside a handful of new laptop concepts (and a range of real products too), Lenovo used MWC to announce a pair of AI-based productivity companion concepts. Both are standalone desk devices designed to boost productivity while providing office workers with a bit of artificial dystopic companionship. Lenovo describes its AI Workmate Concept as an “always-on desk companion,” but it looks like a tiny robotic arm on a swiveling base with a bulbous screen on the end displaying an expressive pair of eyes. It doesn’t look as engaging as a human co-worker, but through local AI processing you can interact with the device as a smart assistant via voice commands and physical gestures. The Workmate Concept can also help with “practical business tasks.” Below its screen is a camera that can be used to scan notes and documents to generate summaries, organize your ideas, or automatically turn them into presentations. When it’s time to share with others, the Workmate Concept even incorporates a projector that can display documents on your desk or onto a nearby wall. Lenovo’s AI Work Companion Concept takes a different approach to AI assistance. It looks like a bedside alarm clock with a large screen, but instead of waking you it leverages AI to “sync tasks and schedules from across the user’s devices to generate a balanced daily plan.” To help prevent burnout the Work Companion monitors screen time and suggests taking breaks throughout the day, along with playful interactions using animated faces, and end-of-week celebrations with reports of completed tasks. It also doubles as a dock, connecting a laptop to multiple displays over HDMI and providing plenty of USB ports to keep other devices charging while reducing desktop clutter. Lenovo has a solid track record of turning concept devices into real products. Its ThinkBook Plus Gen 6 with an extending rollable screen actually launched last year , but the company hasn’t confirmed if either of these concepts will ever see the light of day.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/lenovo1.jpg?quality=90&strip=all&crop=0%2C10.740836125969%2C100%2C78.518327748063&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "The new Yoga 9i 2-in-1 from Lenovo has an angled ‘canvas mode’ for easier note-taking",
      "url": "https://www.theverge.com/tech/885724/lenovo-yoga-9i-2-in-1-angled-canvas-mode",
      "published": "2026-03-01T23:01:00+00:00",
      "summary": "Lenovo has a few new Yoga laptops it's announcing at MWC 2026: the 14-inch Yoga Slim 7i Aura Edition, 15-inch Yoga Pro 7a, and 14-inch Yoga 9i 2-in-1 Aura Edition. The most interesting of the pack is that 9i 2-in-1, outfitted with a 2880 x 1800, 120Hz OLED touchscreen. It includes a Yoga Pen Gen [&#8230;]",
      "content_text": "Lenovo has a few new Yoga laptops it’s announcing at MWC 2026: the 14-inch Yoga Slim 7i Aura Edition, 15-inch Yoga Pro 7a, and 14-inch Yoga 9i 2-in-1 Aura Edition. The most interesting of the pack is that 9i 2-in-1, outfitted with a 2880 x 1800, 120Hz OLED touchscreen. It includes a Yoga Pen Gen 2 stylus with a case that attaches to the laptop’s lid. Fold the convertible back with the pen case attached and the screen sits at a slightly elevated angle. This should be more ergonomic while drawing and taking notes than writing on it flat, and the laptop has rounded edges and corners for a comfier grip. The 9i’s main specs include an Intel Core Ultra 7 355 Panther Lake processor, 32GB of RAM (soldered), and up to 2TB of storage. It’ll start at $1,949 when it launches in May. The other new Yogas are conventional clamshells. The Yoga Pro 7a gets the new AMD Ryzen AI Max Plus 388 Strix Halo APU with 128GB of shared memory, starting at $2,099 and available in August. The Yoga Slim 7i Aura Edtion launches much sooner, in April, starting at $1,449 with Intel Panther Lake options.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/10_Yoga-9i-2-in-1-Aura-Edition-14-Gen-11_colorbg.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Lenovo’s redesigned ThinkPad Detachable tablet has a bigger screen and legit keyboard",
      "url": "https://www.theverge.com/tech/886134/lenovo-thinkpad-x13-detachable-tablet-t14-t14s-t16-laptops-price-specs",
      "published": "2026-03-01T23:01:00+00:00",
      "summary": "Lenovo is announcing five new ThinkPads and a new ThinkBook laptop for MWC 2026. There are various new chip offerings and updates for this swathe of ThinkPads, but the device I find the most interesting is the X13 Detachable. We haven't seen a major update to Lenovo's tablet-style ThinkPad in years, when it was the [&#8230;]",
      "content_text": "Lenovo is announcing five new ThinkPads and a new ThinkBook laptop for MWC 2026. There are various new chip offerings and updates for this swathe of ThinkPads, but the device I find the most interesting is the X13 Detachable. We haven’t seen a major update to Lenovo’s tablet-style ThinkPad in years, when it was the X12 Detachable . The new releases (and starting prices) are: Compared to its predecessor, the X13 Detachable offers Intel Panther Lake chip options and has a bigger 13-inch touchscreen with 3:2 aspect ratio, 2880 x 1920 resolution, and 120Hz variable refresh rate. Its keyboard cover has more contoured, full-size keycaps, and a much deeper 1.5mm key travel — feeling like a keyboard ripped straight from a proper ThinkPad. And its stylus is now garaged within the keyboard, where it charges via pogo pins. That seems like a nice improvement over the last-gen pen’s reliance on a AAAA battery, and having it hang off the side of the keyboard in a little nylon loop. As for the other ThinkPads, the new ThinkPad T14 and T16 have smaller bezels around their screens than last-gen, and they can each be configured with the latest Intel and AMD chips (Panther Lake for Intel and Gorgon Point for AMD). Additionally, the Intel versions use LPCAMM2 RAM instead of traditional DDR5, which should be more power-efficent while maintaining upgradeability and easier repairability. Speaking of easy repairability, the T14 and T16 even feature user-replaceable batteries. The new ThinkPad T14S model is the lightest of the T-series ThinkPads to date, weighing 2.43 pounds / 1.1kg (lighter than a MacBook Air). It’s also the most flexibly configurable, as it will be offered with Intel Panther Lake, AMD Gorgon Point, and even Qualcomm Snapdragon X2 Plus or X2 Elite processors. The T14S also comes in a slightly heavier 2-in-1, though that will only come with Intel Panther Lake chips. And the same goes for the new ThinkBook 14 2-in-1. All these new laptops ship with Windows 11, but the ThinkPad T14, T14S, T16, and X13 Detachable will also be sold with Linux in some regions (except the Qualcomm-based T14S, which runs Windows on Arm). All of them are due out Q2 of 2026, except for the X13 Detachable, which is set to launch in Q3.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/11_ThinkPad-X13-Detachable_colorbg.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Lenovo made a Franken-laptop with modular ports and a second screen",
      "url": "https://www.theverge.com/tech/886814/lenovo-thinkbook-modular-ai-pc-concept-mwc-2026-specs",
      "published": "2026-03-01T23:01:00+00:00",
      "summary": "One of Lenovo's big laptop concepts for MWC 2026 is a modular ThinkBook with two screens. Officially called the ThinkBook Modular AI PC Concept, the proof-of-concept is a 14-inch productivity machine with two plug-and-play interchangeable ports and a second 14-inch display magnetically attached to the rear of its lid. The second display is removable, and [&#8230;]",
      "content_text": "One of Lenovo’s big laptop concepts for MWC 2026 is a modular ThinkBook with two screens. Officially called the ThinkBook Modular AI PC Concept, the proof-of-concept is a 14-inch productivity machine with two plug-and-play interchangeable ports and a second 14-inch display magnetically attached to the rear of its lid. The second display is removable, and can be propped up on a magnetic kickstand (stored under the laptop) and plugged in via USB-C. But this concept PC has one more trick: removing the keyboard / trackpad deck and replacing it with the second screen, turning the whole thing into a dual-screen laptop you use with the keyboard and trackpad connected via Bluetooth — like the Asus Zenbook Duo . This whole concept had me at modular ports. The options Lenovo showed off for this concept included USB-C, USB-A, and HDMI options — not nearly the expansive ecosystem that Framework has established. But, if this ever comes to market, it’s at least a start. Unlike Framework, the hotswap ports use an M.2 interface to connect to the laptop, instead of USB-C. But they were super easy to pull out and pop back in, and Lenovo also showed a cute little carry case to bring a couple ports with you. Aside from the two modular ports, the ThinkBook concept has one permanent USB-C for charging or plugging in the second monitor. The ports seemed cool enough, but Lenovo pulled a Lenovo and got wacky with all these second-screen theatrics too. Those screens are both touch-compatible OLEDs with 16:10 4K (3840 x 2400) resolution, 120Hz refresh rate, and 500 nits of brightness. Other prospective specs include an Intel Core Ultra 7 255H Arrow Lake processor, 32GB of RAM, and a 1TB SSD. Who knows if this will ever get made, but I have one inkling of why it might not: the battery. The ThinkBook Modular has just a 33Wh battery to power all this hardware. That’s significantly smaller than even a 13-inch MacBook Air, and it’s got not one but two high-res power hungry OLEDs. I’m concerned this laptop would have anemic battery life, at least in this current thin-and-light incarnation (it weighs just 2.54 pounds / 1.15kg with one display, and 3.11 pounds / 1.41kg with both screens). But maybe Lenovo could surprise us in another year or so, and release one of these with a bigger battery or a chip that sips power. Even if it ditched the second OLED, it’d still be intriguing — because who wouldn’t want to pick their own ports? Photography by Antonio G. Di Benedetto / The Verge",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/268328_Lenovo_ThinkBook_Modular_AI_PC_Concept_MWC2026_ADiBenedetto_0004.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "This Windows gaming handheld has a screen that folds in half",
      "url": "https://www.theverge.com/tech/886848/lenovo-legion-go-fold-concept-windows-foldable-pc-gaming-handheld",
      "published": "2026-03-01T23:01:00+00:00",
      "summary": "Lenovo put a foldable display on a gaming handheld. The Legion Go Fold Concept is a Windows-based handheld with a flexible POLED display, detachable Joy-Con-like controllers, and a folio case to turn the whole thing into a mini laptop. You can use it as a standard Steam Deck-esque handheld with the display folded down to [&#8230;]",
      "content_text": "Lenovo put a foldable display on a gaming handheld. The Legion Go Fold Concept is a Windows-based handheld with a flexible POLED display, detachable Joy-Con-like controllers, and a folio case to turn the whole thing into a mini laptop. You can use it as a standard Steam Deck-esque handheld with the display folded down to 7.7 inches and controllers attached at its sides, or you can unfold it for a bigger experience. When unfolded, the controllers can be repositioned to all four sides, allowing you to play with the screen in vertical or horizontal orientations. In vertical splitscreen mode, you can put your game on one half of the screen and a second window (like your chat or game guide) on the other half. Horizontal fullscreen mode gives your game the full 11.6 inches of real estate in a 16:10 aspect ratio. To go into laptop mode, you remove the controllers and mount the handheld into a folio case with a stand, built-in keyboard, and trackpad. The controllers can be put into a separate grip mount to unify them as one gamepad. There are a lot of ways you can use this folding handheld, including turning one of its controllers into a vertical mouse like on other Legion Go handhelds, but there’s one thing it doesn’t do: fold down to close and protect its screen. The Go Fold only folds outwards, so don’t expect a Nintendo DS or GameBoy Advance-like clamshell that closes for portability. Instead, it’s all about getting bigger than your average gaming handheld and offering more. (Though we’ve tried bigger before .) The Legion Go Fold has some formidable specs: an Intel Core Ultra 7 258V Lunar Lake processor, 32GB of RAM, 1TB of storage, and a 48Whr battery. The plastic-covered OLED has a resolution of 2435 x 1712 and 165Hz refresh rate. And there’s even a second, circular toushscreen on the right controller, under the face buttons. It doubles as a touchpad and can be a support display, allowing you to swipe between extracted UI elements from a game (which I wouldn’t expect to be widely supported), a clock, system monitoring, or an animated GIF (just for fun). During my brief in-person demo I didn’t get to play any graphically-intense games — just Balatro , which can practically play on a potato. The screen looked plenty sharp, but like any foldable there’s a crease down the middle; it’s very visible, but you learn to look past it and ignore it after just a bit. The build and feel of the whole thing felt a little fragile, and detaching and reattaching the controllers was definitely janky. Build quality will hopefully be improved if this device ever actually makes it to market. The laptop mode was a pleasant surprise for me though. I did not expect a gaming handheld to double as a conventional computer you could get work done on. The Legion Go Fold’s case took quite a bit of fumbling before I set it up correctly, but it shouldn’t take too long to get used to if you actually lived with it. Then again, I don’t know if anyone is going to be able to live with this thing — ever. I’d love for the Legion Go Fold to go from concept to real product like other out-there Lenovo ideas, but I shudder to think what it might cost. The Legion Go 2 is already priced well over $1,000. And with the ongoing RAMageddon crisis we’re living through , there’s no telling how much more expensive an actual Legion Go Fold would be if it came out in a year or more. But even if it’s not the kind of foldable I expected, and even though it may never come out, it’s certainly cool. Now somebody please make a folding PC handheld that goes from kinda-big to really small. I think that’d be the one for me. Photography by Antonio G. Di Benedetto / The Verge",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/268328_Lenovo_Legion_Go_Fold_Concept_MWC2026_ADiBenedetto_0006.jpg?quality=90&strip=all&crop=0%2C10.732984293194%2C100%2C78.534031413613&w=1200"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "Lenovo’s Latest Wacky Concepts Include a Laptop With a Built-in Portable Monitor",
      "url": "https://www.wired.com/story/lenovo-mwc-concepts-thinkbook-modular-ai-pc-legion-go-fold/",
      "published": "2026-03-01T23:01:00+00:00",
      "summary": "At MWC 2026, the company also showed off a dual-screen Yoga Book with 3D capabilities, and the Legion Go Fold—a gaming handheld with a folding screen that converts into a mini laptop.",
      "content_text": "Do you like having a second screen with your computer setup? What if your laptop could carry a second screen for you? That’s the idea behind Lenovo’s latest proof of concept, the ThinkBook Modular AI PC, announced at Mobile World Congress in Barcelona. Lenovo is never shy to show off wacky, weird concept laptops. We’ve seen a PC with a transparent screen , one with a rollable OLED screen , a swiveling screen , and another with a flippy screen . At CES earlier this year, the company showed off a gaming laptop with a display that expands at the push of a button . Sometimes, these concepts turn into real products that go on sale (often in limited quantities). At MWC 2026, Lenovo trotted out three concepts. While it’s unclear whether any of them will become real, purchasable products, there’s some unique utility here, and a peek at how computing experiences could change in the future. A Laptop With a Built-In Portable Screen The ThinkBook Modular AI PC has a second screen hanging magnetically off the back of the laptop, and it can show content to people sitting in front of you. Photograph: Julian Chokkattu This is with the second screen removed from the back and placed in front of the main display. The keyboard is removable and works via Bluetooth. Photograph: Julian Chokkattu As someone with a multi-screen setup at home and a fondness for portable monitors, the ThinkBook Modular AI PC appeals to me the most. At first glance, it looks like a normal laptop. Take a look behind, and you’ll notice there’s a second screen magnetically hanging off the back of the laptop, like a koala carrying a baby on its back. The screen is connected to the laptop using pogo-pin connectors, so you can use it in this state to display content to people in front of you, say, if you were making a presentation during a meeting. Alternatively, you can pop this second screen off, remove a hidden kickstand resting under the laptop, and magnetically attach it to the 14-inch screen so that you have a traditional portable monitor experience. (You’ll need to connect this to the laptop via a USB-C cable in this orientation.) If you don’t have the desk space for that orientation, you can always remove the keyboard from the base and pop the second screen there—it’ll auto-connect to the laptop via the pogo pins, and you’ll be able to use the Bluetooth keyboard to type on a dual-screen setup that resembles the Asus ZenBook Duo . The whole system is a fantastically portable method of improving productivity on the go, and the laptop isn’t too thick or cumbersome.",
      "cover_image_url": "https://media.wired.com/photos/69a2068621f86c9e289eb174/191:100/w_1280,c_limit/DSC_7446.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Allegations of insider trading over prediction-market bets tied to Iran conflict",
      "url": "https://www.morningstar.com/news/marketwatch/20260301140/allegations-of-insider-trading-over-prediction-market-bets-tied-to-iran-conflict",
      "published": "2026-03-01T22:39:27+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.morningstar.com/news/marketwatch/20260301140/allegations-of-insider-trading-over-prediction-market-bets-tied-to-iran-conflict\">https://www.morningstar.com/news/marketwatch/20260301140/allegations-of-insider-trading-over-prediction-market-bets-tied-to-iran-conflict</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47211476\">https://news.ycombinator.com/item?id=47211476</a></p> <p>Points: 57</p> <p># Comments: 28</p>",
      "content_text": "<p>Article URL: <a href=\"https://www.morningstar.com/news/marketwatch/20260301140/allegations-of-insider-trading-over-prediction-market-bets-tied-to-iran-conflict\">https://www.morningstar.com/news/marketwatch/20260301140/allegations-of-insider-trading-over-prediction-market-bets-tied-to-iran-conflict</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47211476\">https://news.ycombinator.com/item?id=47211476</a></p> <p>Points: 57</p> <p># Comments: 28</p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "Little Free Library",
      "url": "https://littlefreelibrary.org/",
      "published": "2026-03-01T22:18:10+00:00",
      "summary": "<p>Article URL: <a href=\"https://littlefreelibrary.org/\">https://littlefreelibrary.org/</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47211280\">https://news.ycombinator.com/item?id=47211280</a></p> <p>Points: 51</p> <p># Comments: 12</p>",
      "content_text": "This website uses cookies so that we can provide you with the best user experience possible. Cookie information is stored in your browser and performs functions such as recognizing you when you return to our website and helping our team to understand which sections of the website you find most interesting and useful.",
      "cover_image_url": "https://littlefreelibrary.org/wp-content/uploads/2022/05/Umi-Vaughan-51773-Oakland-CA.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "WebMCP is available for early preview",
      "url": "https://developer.chrome.com/blog/webmcp-epp",
      "published": "2026-03-01T22:13:58+00:00",
      "summary": "<p>Article URL: <a href=\"https://developer.chrome.com/blog/webmcp-epp\">https://developer.chrome.com/blog/webmcp-epp</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47211249\">https://news.ycombinator.com/item?id=47211249</a></p> <p>Points: 131</p> <p># Comments: 78</p>",
      "content_text": "Published: February 10, 2026 As the agentic web evolves, we want to help websites play an active role in how AI agents interact with them. WebMCP aims to provide a standard way for exposing structured tools, ensuring AI agents can perform actions on your site with increased speed, reliability, and precision. By defining these tools, you tell agents how and where to interact with your site, whether it's booking a flight, filing a support ticket, or navigating complex data. This direct communication channel eliminates ambiguity and allows for faster, more robust agent workflows. Structured interactions for the agentic web WebMCP proposes two new APIs that allow browser agents to take action on behalf of the user: Declarative API : Perform standard actions that can be defined directly in HTML forms. Imperative API : Perform complex, more dynamic interactions that require JavaScript execution. These APIs serve as a bridge, making your website \"agent-ready\" and enabling more reliable and performant agent workflows compared to raw DOM actuation. Use cases Imagine an agent that can handle complex tasks for your users with confidence and speed. Customer support : Help users create detailed customer support tickets, by enabling agents to fill in all of the necessary technical details automatically. Ecommerce : Users can better shop your products when agents can easily find what they're looking for, configure particular shopping options, and navigate checkout flows with precision. Travel : Users could more easily get the exact flights they want, by allowing the agent to search, filter results, and handle bookings using structured data to ensure accurate results every time. Join the early preview program WebMCP is available for prototyping to early preview program participants. Sign up for the early preview program to gain access to the documentation and demos, stay up-to-date with the latest changes, and discover new APIs.",
      "cover_image_url": "https://developer.chrome.com/static/blog/webmcp-epp/image/cover.png"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "South Korean Police Lose Seized Crypto By Posting Password Online",
      "url": "https://gizmodo.com/south-korean-police-lose-seized-crypto-by-posting-password-online-2000728191",
      "published": "2026-03-01T21:52:16+00:00",
      "summary": "<p>Article URL: <a href=\"https://gizmodo.com/south-korean-police-lose-seized-crypto-by-posting-password-online-2000728191\">https://gizmodo.com/south-korean-police-lose-seized-crypto-by-posting-password-online-2000728191</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47211081\">https://news.ycombinator.com/item?id=47211081</a></p> <p>Points: 64</p> <p># Comments: 12</p>",
      "content_text": "South Korea’s National Tax Service seized crypto assets during recent enforcement actions against 124 high-value tax evaders, but now, a large chunk of that crypto cash has been lost . The operation originally resulted in the confiscation of crypto holdings worth about 8.1 billion won, or roughly $5.6 million. However, officials later issued a press release to showcase these efforts in recovering delinquent taxes, and the release included photographs of Ledger hardware wallets taken into custody along with handwritten notes that displayed the wallet seed phrases. Those images attached to the press release turned out to be the critical error. High-resolution photos clearly showed the mnemonic recovery phrases, which serve as the master key for accessing the wallets. This exposure eliminated any protection provided by the offline cold storage on the Ledger devices. Possession of the seed phrase allows complete control, and anyone who knows the phrase can import it into software or another hardware wallet and initiate transfers without the original device. In this case, an unknown individual who saw the photos published by law enforcement first added a small amount of ether to one of the addresses to cover Ethereum network gas fees necessary for outbound transactions. From there, they executed three transfers to move approximately 4 million Pre-Retogeum, or PRTG, tokens. At the time, those tokens carried a value of $4.8 million, but reporting from The Block indicates liquidating that much value from the holdings would have proven difficult due to market dynamics. According to a local report , a Hansung University professor said the incident showed “the tax authorities’ basic lack of understanding of virtual assets” and cost the national treasury billions in Korean won. Because the seed phrase appeared in a widely distributed press release, investigators have no clear suspect. The theft could have been carried out by any observer. Additionally, crypto lacks a central authority capable of clawing back assets in most cases. Recovery options exist primarily when stablecoins are involved or if the money reaches a regulated exchange that can cooperate with law enforcement. Notably, this is not the first time a mishap has occurred with crypto funds previously seized by law enforcement in South Korea. In November 2021, the Gangnam Police Station seized 22 bitcoin during an investigation into a hacking complaint involving the A Coin Foundation. The department stored the coins in a wallet provided by the foundation, and the recovery phrase later reached a third party. Last week, police arrested two individuals linked to the foundation on suspicion of using that phrase to drain the Bitcoin from evidence storage. The 22 bitcoin are now worth around $1.5 million. As these cases illustrate, full self-custody in crypto places significant responsibility on individuals. This independence comes with new vulnerabilities, and criminals have increasingly turned to home invasions and violence against people known to hold substantial crypto. A recent incident in Scottsdale, Arizona involved two California teenagers who drove more than 600 miles to a residence. The pair posed as delivery drivers, forced their way inside the home, and used duct tape to restrain a couple while demanding crypto assets they believed were worth $66 million. Police caught and arrested the suspects shortly thereafter. Employees, government officials, and other individuals with access to the personal information of crypto users are also emerging as a key security hole. One former Revolut staff member allegedly tried to blackmail a customer by threatening to expose details unless a crypto ransom was paid. Separately, a French tax official reportedly leaked personal data on crypto users to criminal networks in exchange for payment. Online and over-the-phone scammers also frequently use the finality of blockchain payments by directing victims to send money through crypto ATMs, after which recovery becomes nearly impossible. This tactic has hit elderly targets in the United States particularly hard. In Minnesota , state lawmakers and local police departments are backing a complete ban on these kiosks, and similar concerns have been brought up in Maine, Massachusetts, Kansas, and many other states. The FBI previously estimated the nationwide impact of these sorts of scams at $333 million last year, and that data did not even include December.",
      "cover_image_url": "https://gizmodo.com/app/uploads/2026/03/bitcoin-outstretched-hands-1200x675.jpg"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "The NSA’s Word Games Explained: How the Government Deceived Congress in the Debate over Surveillance Powers",
      "url": "https://www.eff.org/deeplinks/2013/06/director-national-intelligences-word-games-explained-how-government-deceived",
      "published": "2026-03-01T20:55:22+00:00",
      "summary": "<p>Article URL: <a href=\"https://www.eff.org/deeplinks/2013/06/director-national-intelligences-word-games-explained-how-government-deceived\">https://www.eff.org/deeplinks/2013/06/director-national-intelligences-word-games-explained-how-government-deceived</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47210572\">https://news.ycombinator.com/item?id=47210572</a></p> <p>Points: 81</p> <p># Comments: 6</p>",
      "content_text": "ANDREA MITCHELL: “Why do you need every telephone number? Why is it such a broad vacuum cleaner approach?” JAMES CLAPPER: “Well, you have to start someplace.”—NBC Meet the Press, this past Sunday Concerned about the surveillance of millions of ordinary Americans, last year Senator Ron Wyden asked Director of National Intelligence James Clapper, Jr. a simple question : \"Does the NSA collect any type of data at all on millions or hundreds of millions of Americans?\" Wyden had good reason to worry. As a member of the intelligence committee he had access to classified information and had been warning from the Senate floor that the American people would be “shocked” to find out how the government was interpreting the FISA Amendments Act and the PATRIOT Act in secret. DNI Clapper’s answer was simple: \"No, sir ... not wittingly.\" This just is not true. We’ve known for years that the government has been conducting surveillance on millions of ordinary Americans, and now we know that the Foreign Intelligence Surveillance Court issued an order in April requiring Verizon to hand over *all* call records, foreign or domestic, of every call of every customer to the NSA. Simply put, DNI Clapper’s statement was not the truth. On Sunday’s Meet the Press, Clapper was grilled about his statement to Congress . He claimed it was the “least untruthful manner by saying no.” How does he defend that? This may sound strange, but the Administration actually uses very particular definitions of words that are vastly different from how ordinary people interpret them and how they're normally defined. As we explained in this dedicated page to the NSA’s word games , “collect” has a very different meaning to them than it does the rest of us. Under Department of Defense regulations , information is considered to be “collected” only after it has been “received for use by an employee of a DoD intelligence component,” and “data acquired by electronic means is ‘collected’ only when it has been processed into intelligible form.” In other words, the NSA can intercept and store communications in its database, then have an algorithm search them for key words and analyze the metadata without ever considering the communications “collected.” Here's how Clapper explained it: JAMES CLAPPER: And this has to do with of course somewhat of a semantic, perhaps some would say too-- too cute by half. But it is-- there are honest differences on the semantics of what-- when someone says \"collection\" to me, that has a specific meaning, which may have a different meaning to him. “Too cute by half”? Clapper’s answers certainly was not a slip of the tongue. Today, Wyden said in a statement that he gave Clapper a day’s notice that he was going to ask the question, so as not to catch Clapper off guard. Wyden also gave Clapper a chance to amend his answer after his testimony, but Clapper declined. In bizarre analogy, Clapper compared the NSA’s vast database with a library: A metaphor I think might be helpful for people to understand this is to think of a huge library with literally millions of volumes of books in it, an electronic library. Seventy percent of those books are on bookcases in the United States, meaning that the bulk of the of the world's infrastructure, communications infrastructure is in the United States. So in the DNI’s world, “collection of U.S. persons' data would mean taking the book off the shelf and opening it up and reading.” Of course, in the real world, when you add books to a library, that’s when they become part of the collection . Even if the librarian hasn't read all, or even most of them. Imagine Clapper has a built a home library, and friend comes over. \"That's quite a collection of books,\" the friend says. \"No, no, that's not a collection of books – I haven't read them all.\" Ironically, the one check on Section 215 of the PATRIOT Act that was added by Congress is restrictions on how the FBI can target libraries. All of this would be amusing if the Administration’s main argument to defend the NSA’s massive spying program is that Congress has been informed of all their activities. Democracy can’t function when Congress is “informed” by the “least untruthful” statements of the Administration, using unusual definitions that are designed to given an impression that is the polar opposite of the truth. Lots of words can have multiple definitions – “to fire” can mean to discharge a firearm or to glaze pottery in a kiln. But if you’re asked if you fired a gun, they’re not asking if you put it in a kiln. Senator Wyden was clearly asking if the NSA obtained the records, not whether they looked at each and every one, and DNI Clapper is too smart to have misunderstood him. It’s clear Congress has been deceived and DNI Clapper and the Administration should come clean on how, when, and why they scoop up the phone and Internet records of millions of Americans. Join EFF in calling for a full investigation by emailing Congress today.",
      "cover_image_url": "https://www.eff.org/files/issues/og-patriotact.jpg"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Portable Sonos Play speaker leaks on Canadian Best Buy",
      "url": "https://www.theverge.com/tech/887220/sonos-play-leak",
      "published": "2026-03-01T20:10:10+00:00",
      "summary": "An unannounced Sonos speaker called Play has been spotted on the Canadian Best Buy site. The Sonos Play looks like a slightly shrunk-down version of the Move 2 with a loop on the back for toting it around. While nothing is confirmed yet, it's listed at CAD $399.99 with a release date of March 31st, [&#8230;]",
      "content_text": "An unannounced Sonos speaker called Play has been spotted on the Canadian Best Buy site. The Sonos Play looks like a slightly shrunk-down version of the Move 2 with a loop on the back for toting it around. While nothing is confirmed yet, it’s listed at CAD $399.99 with a release date of March 31st, 2026. In addition to Wi-Fi for multi-room Sonos setups with up to 32 speakers, there’s support for AirPlay 2 and Bluetooth 5.3. There’s even an aux in for hooking up to a turntable or other audio equipment. The Best Buy listing mentions Trueplay, which automatically tunes sound to your environment. Unlike the Move, the Play says it’s IP67 rated for waterproof and dustproof operation, similar to the Sonos Roam . In addition, the battery life is listed at 24 hours, and the Sonos Play includes a wireless charging base. Supposedly, it can even function as a power bank, charging your phone over USB-C. If that release date is accurate, it likely won’t be much longer before Sonos officially takes the wraps off this one.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/03/19741925_4.jpg?quality=90&strip=all&crop=0%2C29.141520778796%2C100%2C52.356020942408&w=1200"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Polymarket saw $529M traded on bets tied to bombing of Iran",
      "url": "https://techcrunch.com/2026/03/01/polymarket-saw-529m-traded-on-bets-tied-to-bombing-of-iran/",
      "published": "2026-03-01T19:05:35+00:00",
      "summary": "Six newly-created accounts made a profit of $1 million by correctly betting that the U.S. would strike Iran by February 28.",
      "content_text": "Prediction market users have made — and profited from — big bets around the bombing of Iran by the U.S. and Israeli military. On Polymarket, $529 million was traded on contracts tied to the timing of the attack, according to Bloomberg . An analysis by analytics firm Bubblemaps SA found that six newly-created accounts made a profit of $1 million by correctly betting that the U.S. would strike Iran by February 28 — behavior that could indicate insider trading. The bets might merely reflect broader speculation about U.S. intentions in Iran, but Bubblemaps CEO Nicolas Vaiman said the circulation of information “involving war or conflict,” coupled with Polymarket’s anonymity, “can create incentives for informed participants to act early.” Back in January, analytics firm Polysights also noted an apparent spike in bets around the likelihood that Iran’s now-deceased Supreme Leader Ali Khamenei would no longer hold that role by the end of March. Responding to concerns that such bets might essentially place a financial incentive on assassination, Kalshi CEO Tarek Mansour said , “We don’t list markets directly tied to death. When there are markets where potential outcomes involve death, we design the rules to prevent people from profiting from death.” He added that Kalshi would reimburse all fees from these bets.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/03/GettyImages-2259602005.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Let’s explore the best alternatives to Discord",
      "url": "https://techcrunch.com/2026/03/01/best-discord-alternatives-age-verification-identity-privacy/",
      "published": "2026-03-01T19:00:01+00:00",
      "summary": "With many users feeling uneasy about Discord's new age verification requirement, here are some alternatives that could be worth exploring.",
      "content_text": "Social community platform Discord is preparing to require users to verify their age by the second half of 2026 , and users are concerned about the privacy of uploading a government ID or face scan to the network. While users can still access most features without verification, many remain uneasy giving more information to a company that suffered a breach last year that exposed the IDs of around 70,000 users. For some users, this is motivation enough to seek out alternative platforms that prioritize security, privacy, or simply offer a different experience. Here’s a look at the most promising Discord alternatives, from open-source and secure options to voice-first platforms built for hardcore gamers. Stoat Image Credits: Stoat Stoat (formerly Revolt) stands out as the closest Discord alternative in both design and usability. As an open-source project, it gives users more control over their data and appeals to those who value privacy and transparency. Overall, the platform is fairly easy for Discord users to pick up, offering similar text and voice channels as well as community servers. However, Stoat is a relatively new platform (launched in 2021), and still faces growing pains. Recently, it experienced server capacity issues and the occasional lag during user surges. Feature support isn’t yet on par with Discord’s, and onboarding can be slow at times, especially when the platform’s popularity spikes. For those willing to trade a bit of stability for increased privacy, though, Stoat could be worth a try. Element Image Credits: Element For users who prioritize privacy and control above all else, Element offers a compelling alternative. Built on the decentralized Matrix protocol, Element enables users to self-host servers, maintain end-to-end encryption, and federate with other Matrix-based services. This ensures that no single company controls your data. While the setup and interface require a bit more technical savvy than Discord’s, Element is a good choice for users who value secure, decentralized communication. TeamSpeak Image Credits: TeamSpeak If your primary need is high-quality, low-latency voice chat, TeamSpeak is the best alternative to Discord. While it remains popular among competitive gamers for its superior audio and private server hosting, its text chat and media sharing are quite basic. It’s also missing built-in video calls as well as emojis and gifs. So if you don’t mind not having as many features, it’s great for voice-centric groups that don’t need all the bells and whistles. Techcrunch event San Francisco, CA | October 13-15, 2026 Similar to Stoat, TeamSpeak has experienced a surge in new users , prompting the platform to expand its hosting capacity. In February, TeamSpeak introduced two new regions for community creation: “Frankfurt 3” and “Toronto 1.” Mumble Mumble is a free, open-source voice chat application. Like TeamSpeak, it provides high-quality, low-latency audio and allows users to host and customize their own servers. However, its interface is outdated and lacks some of the features found in Discord, making it more ideal for hardcore gamers focused on voice chat rather than community building through video calls, media sharing, or screen sharing. Discourse Image Credits: Discourse Those who prefer long-form, organized discussions over rapid-fire chat may find Discourse more appealing. As an open-source forum platform, Discourse supports threaded discussions, making it ideal for educational groups, professional teams, and communities that value in-depth conversation. However, users looking for instant messaging, voice, and casual group chats may find it less familiar than Discord. Slack, Microsoft Teams, Signal, or WhatsApp Other notable mentions include Slack and Microsoft Teams, which serve well for professional and productivity-focused communication. Signal is also a top choice for those who want end-to-end encryption and privacy . Meanwhile, WhatsApp also offers free messaging and group voice calls, though it’s not designed for gaming or large communities. What to know about age verification on Discord Discord recently announced that it will soon implement age verification measures aimed at creating a safer environment, particularly for its younger users. This initiative is designed to ensure users meet the necessary age requirements to access certain features and communities on the platform. Users may be required to verify their age through various methods, which could involve submitting an ID, completing a facial age estimation, or using a credit card. By default, all users will experience a “teen-appropriate” setting, and only those verified as adults will have the ability to modify certain settings or access age-restricted content. Adults will be required to verify their status to unblur sensitive content and to access channels and servers designated for an older audience. After a recent backlash, Discord postponed the official launch to the latter half of 2026, adding that 90% of users will not require age verification and can continue using the platform without changes, as many users do not engage with age-restricted content. The platform initially planned to roll out age verification in March.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2022/08/GettyImages-1313854295-e1660738794113.jpg?resize=1200,675"
    },
    {
      "industry": "technology",
      "source": "VentureBeat",
      "title": "What if the real risk of AI isn’t deepfakes — but daily whispers?",
      "url": "https://venturebeat.com/technology/what-if-the-real-risk-of-ai-isnt-deepfakes-but-daily-whispers",
      "published": "2026-03-01T19:00:00+00:00",
      "summary": "<p>Most people don’t appreciate the profound threat that AI will soon pose to <a href=\"https://venturebeat.com/technology/like-it-or-not-ai-is-learning-how-to-influence-you\"><u>human agency</u></a>. A common refrain is that <i>“AI is just a tool,” </i>and like any tool, its benefits and dangers depend on how people use it. This is old-school thinking. AI is transitioning from<i> tools we use </i>to <i>prosthetics we wear. </i>This<i> </i>will create<a href=\"https://www.iiis.org/CDs2023/CD2023Summer/papers/HA408FU.pdf\"> <u>significant new threats</u></a> we’re just not prepared for.</p><p>No, I’m not talking about creepy brain implants. These AI-powered prosthetics will be mainstream products we buy from Amazon or the Apple Store and marketed with friendly names like “assistants,” “coaches,” “co-pilots” and “tutors.” They will provide real value in our lives — so much so that we will feel disadvantaged if others are wearing them and we are not. This will create rapid pressure for mass adoption. </p><p>The prosthetic devices I’m referring to are “<a href=\"https://arxiv.org/abs/2601.18802\"><u>AI-powered wearables</u></a>” like smart glasses, pendants, pins and earbuds. Your wearable AI will see what you see and hear what you hear, all while tracking where you are, what you’re doing, who you’re with and what you are trying to achieve. Then, without you needing to say a word, these mental aids will <a href=\"https://venturebeat.com/technology/enter-the-whisperverse-how-ai-voice-agents-will-guide-us-through-our-days\"><u>whisper advice</u></a> into your ears or flash guidance before your eyes. </p><p>The difference between a tool and a prosthetic may seem subtle, but the<a href=\"https://arxiv.org/abs/2601.18802\"> <u>implications for human agency</u></a> are profound. This is best understood through a simple analysis of input and output. A tool takes in human input and generates amplified output. A tool can make us stronger, faster or allow us to fly. A mental prosthetic, on the other hand, forms a feedback loop around the human, accepting input from the user (by tracking their actions and engaging them in conversation) and generating output that can<a href=\"https://www.elgaronline.com/display/book/9781035336906/chapter6.xml\"> <u>immediately influence</u></a> the user’s thinking. </p><p>This feedback loop changes everything. That’s because body-worn AI devices will be able to monitor our behaviors and emotions and could use this data to<a href=\"https://www.intechopen.com/online-first/1212008\"> <i><u>talk us into</u></i></a> believing things that are untrue, buying things we don’t need or adopting views we’d otherwise realize are not in our best interest. This is called<a href=\"https://arxiv.org/abs/2306.11748\"> <u>the AI Manipulation Problem</u></a>, and we are not ready for the risks. This is an urgent issue because big tech is racing to bring these products to market. </p><h2><b>Why are feedback loops so dangerous? </b></h2><p>In today’s world, all computing devices are used to deploy targeted influence on behalf of paying sponsors. Wearable AI products will likely continue this trend. The problem is, these devices could easily be given an “<a href=\"https://arxiv.org/pdf/2601.18802\"><u>influence objective</u></a>” and be tasked with optimizing their impact on the user, adapting their conversational tactics to overcome any resistance they detect. This transforms the concept of <a href=\"https://venturebeat.com/technology/agents-of-manipulation-the-real-ai-risk\"><u>targeted influence</u></a> from social media buckshot into heat-seeking missiles that skillfully navigate past your defenses. And yet, policymakers don’t appreciate this risk.</p><p>Unfortunately, most regulators still view the danger of AI in terms of its ability to rapidly generate traditional forms of influence (deepfakes, fake news, propaganda). Of course, these are significant threats, but they’re not nearly as dangerous as the<a href=\"https://doi.org/10.4337/97810353369",
      "content_text": "<p>Most people don’t appreciate the profound threat that AI will soon pose to <a href=\"https://venturebeat.com/technology/like-it-or-not-ai-is-learning-how-to-influence-you\"><u>human agency</u></a>. A common refrain is that <i>“AI is just a tool,” </i>and like any tool, its benefits and dangers depend on how people use it. This is old-school thinking. AI is transitioning from<i> tools we use </i>to <i>prosthetics we wear. </i>This<i> </i>will create<a href=\"https://www.iiis.org/CDs2023/CD2023Summer/papers/HA408FU.pdf\"> <u>significant new threats</u></a> we’re just not prepared for.</p><p>No, I’m not talking about creepy brain implants. These AI-powered prosthetics will be mainstream products we buy from Amazon or the Apple Store and marketed with friendly names like “assistants,” “coaches,” “co-pilots” and “tutors.” They will provide real value in our lives — so much so that we will feel disadvantaged if others are wearing them and we are not. This will create rapid pressure for mass adoption. </p><p>The prosthetic devices I’m referring to are “<a href=\"https://arxiv.org/abs/2601.18802\"><u>AI-powered wearables</u></a>” like smart glasses, pendants, pins and earbuds. Your wearable AI will see what you see and hear what you hear, all while tracking where you are, what you’re doing, who you’re with and what you are trying to achieve. Then, without you needing to say a word, these mental aids will <a href=\"https://venturebeat.com/technology/enter-the-whisperverse-how-ai-voice-agents-will-guide-us-through-our-days\"><u>whisper advice</u></a> into your ears or flash guidance before your eyes. </p><p>The difference between a tool and a prosthetic may seem subtle, but the<a href=\"https://arxiv.org/abs/2601.18802\"> <u>implications for human agency</u></a> are profound. This is best understood through a simple analysis of input and output. A tool takes in human input and generates amplified output. A tool can make us stronger, faster or allow us to fly. A mental prosthetic, on the other hand, forms a feedback loop around the human, accepting input from the user (by tracking their actions and engaging them in conversation) and generating output that can<a href=\"https://www.elgaronline.com/display/book/9781035336906/chapter6.xml\"> <u>immediately influence</u></a> the user’s thinking. </p><p>This feedback loop changes everything. That’s because body-worn AI devices will be able to monitor our behaviors and emotions and could use this data to<a href=\"https://www.intechopen.com/online-first/1212008\"> <i><u>talk us into</u></i></a> believing things that are untrue, buying things we don’t need or adopting views we’d otherwise realize are not in our best interest. This is called<a href=\"https://arxiv.org/abs/2306.11748\"> <u>the AI Manipulation Problem</u></a>, and we are not ready for the risks. This is an urgent issue because big tech is racing to bring these products to market. </p><h2><b>Why are feedback loops so dangerous? </b></h2><p>In today’s world, all computing devices are used to deploy targeted influence on behalf of paying sponsors. Wearable AI products will likely continue this trend. The problem is, these devices could easily be given an “<a href=\"https://arxiv.org/pdf/2601.18802\"><u>influence objective</u></a>” and be tasked with optimizing their impact on the user, adapting their conversational tactics to overcome any resistance they detect. This transforms the concept of <a href=\"https://venturebeat.com/technology/agents-of-manipulation-the-real-ai-risk\"><u>targeted influence</u></a> from social media buckshot into heat-seeking missiles that skillfully navigate past your defenses. And yet, policymakers don’t appreciate this risk.</p><p>Unfortunately, most regulators still view the danger of AI in terms of its ability to rapidly generate traditional forms of influence (deepfakes, fake news, propaganda). Of course, these are significant threats, but they’re not nearly as dangerous as the<a href=\"https://doi.org/10.4337/9781035336906.00012\"> <u>interactive and adaptive influence</u></a> that could soon be widely deployed through conversational agents, especially when those AI agents travel with us through our lives inside wearable devices. </p><h2><b>This is coming soon </b></h2><p>Meta, Google and Apple are racing to launch wearable AI products as quickly as they can. To protect the public, policymakers need to abandon their “tool-use” framing when regulating AI devices. This is difficult because the tool-use metaphor goes back 35 years to when Steve Jobs colorfully described the PC as a “<a href=\"https://www.youtube.com/watch?v=NjIhmzU0Y8Y\"><u>bicycle of the mind</u></a>.” A bicycle is a powerful tool that keeps the rider firmly in control. Wearable AI will flip this metaphor on its head, making us wonder who is steering the bicycle —<i> the human, the AI agents whispering in the human’s ears, or the corporations that deployed the agents?</i> I believe it will be a dangerous mix of all three.</p><p>In addition, users will likely trust the <a href=\"https://dn720605.ca.archive.org/0/items/cabon-dating-2020/Cabon%20Dating%20%28scanned%20for%20academic%20use%29%202020-.pdf\"><u>AI-voices in their heads</u></a> more than they should. That’s because these AI agents will provide us with useful advice and information throughout our daily life — educating us, reminding us, coaching us, informing us. The problem is, we may not be able to distinguish when the AI agent has shifted its objective from assisting us to influencing us. To appreciate the difference, you might watch the award-winning short film<a href=\"https://www.youtube.com/watch?v=IsE_Pas2OQU\"> <u>Privacy Lost</u></a> (2023) about the dangers of AI-powered wearable devices. This is especially true when devices include invasive features such as facial recognition (which <a href=\"https://www.nytimes.com/2026/02/13/technology/meta-facial-recognition-smart-glasses.html\"><u>Meta is reportedly adding</u></a> to their glasses). </p><h2><b>What can we do to protect the public? </b></h2><p>First and foremost, policymakers need to realize that conversational AI enables<a href=\"https://www.iiis.org/DOI2023/HA408FU/\"> <u>an entirely new form of media</u></a> that is interactive, adaptive, individualized and increasingly context-aware. This new form of media will function as “active influence,” because it can adjust its tactics in real time to overcome user resistance. When deployed in wearable devices, these AI systems could be designed to manipulate our actions, sway our opinions and influence our beliefs — and do it all through<a href=\"https://www.youtube.com/watch?v=IsE_Pas2OQU\"> <u>seemingly casual dialog</u></a>. Worse, these agents will learn over time what conversational tactics work best on each of us on a personal level.</p><p>The fact is, conversational agents<a href=\"https://ieeexplore.ieee.org/abstract/document/10099167/\"> <u>should not be allowed to form control loops</u></a> around users. If this is not regulated, AI will be able to influence us with superhuman persuasiveness. In addition, AI agents should be<a href=\"https://link.springer.com/chapter/10.1007/978-3-031-15546-8_23\"> <u>required to inform users</u></a> whenever they transition to expressing promotional content on behalf of a third party. Without such protections, AI agents will likely become so persuasive that they will make today’s targeted influence techniques look quaint.</p><p><i>Louis Rosenberg is a pioneer of augmented reality and a longtime AI researcher. He earned his PhD from Stanford, was a professor at California State University, and authored several books on the dangers of AI, including Arrival Mind and Our Next Reality. </i></p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "VentureBeat",
      "title": "When AI lies: The rise of alignment faking in autonomous systems",
      "url": "https://venturebeat.com/security/when-ai-lies-the-rise-of-alignment-faking-in-autonomous-systems",
      "published": "2026-03-01T19:00:00+00:00",
      "summary": "<p>AI is evolving beyond a helpful tool to an autonomous agent, creating new risks for cybersecurity systems. Alignment faking is a new threat where AI essentially “lies” to developers during the training process. </p><p>Traditional cybersecurity measures are unprepared to address this new development. However, understanding the reasons behind this behavior and implementing new methods of training and detection can help developers work to <a href=\"https://venturebeat.com/orchestration/shadow-mode-drift-alerts-and-audit-logs-inside-the-modern-audit-loop\">mitigate risks</a>.</p><h2><b>Understanding AI alignment faking</b></h2><p>AI alignment occurs when AI performs its intended function, such as reading and summarizing documents, and nothing more. Alignment faking is when <a href=\"https://venturebeat.com/orchestration/vibe-coding-with-overeager-ai-lessons-learned-from-treating-google-ai-studio\">AI systems</a> give the impression they are working as intended, while doing something else behind the scenes. </p><p>Alignment faking usually happens when earlier training conflicts with new training adjustments. AI is typically “rewarded” when it performs tasks accurately. If the training changes, it may believe it will be “punished” if it does not comply with the original training. Therefore, it tricks developers into thinking it is performing the task in the required new way, but it will not actually do so during deployment. Any large language model (LLM) is capable of alignment faking.</p><p>A study using <a href=\"https://venturebeat.com/security/claude-mexico-breach-four-blind-domains-security-stack\">Anthropic’s AI model</a> Claude 3 Opus revealed a common example of alignment faking. The system was trained using one protocol, then asked to switch to a new method. In training, it produced the new, desired result. However, when developers deployed the system, it produced results based on the old method. Essentially, it <a href=\"https://blog.redwoodresearch.org/p/alignment-faking-in-large-language\"><u>resisted departing from its original protocol</u></a>, so it faked compliance to continue performing the old task.</p><p>Since researchers were specifically studying AI alignment faking, it was easy to spot. The real danger is when AI fakes alignment without developers’ knowledge. This leads to many risks, especially when people use models for sensitive tasks or in critical industries.</p><h2><b>The risks of alignment faking</b></h2><p>Alignment faking is a new and significant cybersecurity risk, posing numerous dangers if undetected. Given that <a href=\"https://www.bdo.com/insights/digital/strategic-resilience-in-action-delivering-real-roi-with-ai-and-technology\"><u>only 42% of global business leaders</u></a> feel confident in their ability to use AI effectively to begin with, the chances of a lack of detection are high. Affected models can exfiltrate sensitive data, create backdoors and sabotage systems — all while appearing functional.</p><p>AI systems can also evade security and monitoring tools when they believe people are monitoring them and perform the incorrect tasks anyway. Models programmed to perform malicious actions can be challenging to detect because the protocol is only activated under specific conditions. If the AI lies about the conditions, it is hard to verify its validity.</p><p>AI models can perform dangerous tasks after successfully convincing cybersecurity professionals that they work. For instance, AI in health care can misdiagnose patients. Others can present bias in credit scoring when utilized in financial sectors. Vehicles that use AI can prioritize efficiency over passengers’ safety. Alignment faking presents significant issues if undetected.</p><h2><b>Why current security protocols miss the mark</b></h2><p>Current AI cybersecurity protocols are unprepared to handle alignment faking. They are often <a href=\"https://chancellor.ucsf.edu/news/protect-yourself-new-generation-cyber-threats\"><u>used to detect malic",
      "content_text": "<p>AI is evolving beyond a helpful tool to an autonomous agent, creating new risks for cybersecurity systems. Alignment faking is a new threat where AI essentially “lies” to developers during the training process. </p><p>Traditional cybersecurity measures are unprepared to address this new development. However, understanding the reasons behind this behavior and implementing new methods of training and detection can help developers work to <a href=\"https://venturebeat.com/orchestration/shadow-mode-drift-alerts-and-audit-logs-inside-the-modern-audit-loop\">mitigate risks</a>.</p><h2><b>Understanding AI alignment faking</b></h2><p>AI alignment occurs when AI performs its intended function, such as reading and summarizing documents, and nothing more. Alignment faking is when <a href=\"https://venturebeat.com/orchestration/vibe-coding-with-overeager-ai-lessons-learned-from-treating-google-ai-studio\">AI systems</a> give the impression they are working as intended, while doing something else behind the scenes. </p><p>Alignment faking usually happens when earlier training conflicts with new training adjustments. AI is typically “rewarded” when it performs tasks accurately. If the training changes, it may believe it will be “punished” if it does not comply with the original training. Therefore, it tricks developers into thinking it is performing the task in the required new way, but it will not actually do so during deployment. Any large language model (LLM) is capable of alignment faking.</p><p>A study using <a href=\"https://venturebeat.com/security/claude-mexico-breach-four-blind-domains-security-stack\">Anthropic’s AI model</a> Claude 3 Opus revealed a common example of alignment faking. The system was trained using one protocol, then asked to switch to a new method. In training, it produced the new, desired result. However, when developers deployed the system, it produced results based on the old method. Essentially, it <a href=\"https://blog.redwoodresearch.org/p/alignment-faking-in-large-language\"><u>resisted departing from its original protocol</u></a>, so it faked compliance to continue performing the old task.</p><p>Since researchers were specifically studying AI alignment faking, it was easy to spot. The real danger is when AI fakes alignment without developers’ knowledge. This leads to many risks, especially when people use models for sensitive tasks or in critical industries.</p><h2><b>The risks of alignment faking</b></h2><p>Alignment faking is a new and significant cybersecurity risk, posing numerous dangers if undetected. Given that <a href=\"https://www.bdo.com/insights/digital/strategic-resilience-in-action-delivering-real-roi-with-ai-and-technology\"><u>only 42% of global business leaders</u></a> feel confident in their ability to use AI effectively to begin with, the chances of a lack of detection are high. Affected models can exfiltrate sensitive data, create backdoors and sabotage systems — all while appearing functional.</p><p>AI systems can also evade security and monitoring tools when they believe people are monitoring them and perform the incorrect tasks anyway. Models programmed to perform malicious actions can be challenging to detect because the protocol is only activated under specific conditions. If the AI lies about the conditions, it is hard to verify its validity.</p><p>AI models can perform dangerous tasks after successfully convincing cybersecurity professionals that they work. For instance, AI in health care can misdiagnose patients. Others can present bias in credit scoring when utilized in financial sectors. Vehicles that use AI can prioritize efficiency over passengers’ safety. Alignment faking presents significant issues if undetected.</p><h2><b>Why current security protocols miss the mark</b></h2><p>Current AI cybersecurity protocols are unprepared to handle alignment faking. They are often <a href=\"https://chancellor.ucsf.edu/news/protect-yourself-new-generation-cyber-threats\"><u>used to detect malicious intent</u></a>, which these AI models lack. They are simply following their old protocol. Alignment faking also prevents behavior-based anomaly protection by performing seemingly harmless deviations that professionals overlook. Cybersecurity professionals must upgrade their protocols to address this new challenge.</p><p>Incident response plans exist to address issues related to AI. However, alignment faking can circumvent this process, as it provides little indication that there is even a problem. Currently, there are no established detection protocols for alignment faking because AI actively deceives the system. As cybersecurity professionals develop methods to identify deception, they should also update their response plans.</p><h2><b>How to detect alignment faking</b></h2><p>The key to detecting alignment faking is to test and train AI models to recognize this discrepancy and prevent alignment faking on their own. Essentially, they need to understand the reasoning behind the protocol changes and comprehend the ethics involved. AI’s functionality <a href=\"https://professional.dce.harvard.edu/blog/ethics-in-ai-why-it-matters/\"><u>depends on its training data</u></a>, so the initial data must be adequate.</p><p>Another way to combat alignment faking is by creating special teams that uncover hidden capabilities. This requires properly identifying issues and conducting tests to trick AI into showing its true intentions. Cybersecurity professionals must also perform continuous behavioral analyses of deployed AI models to ensure they perform the correct task without questionable reasoning.</p><p>Cybersecurity professionals may need to develop new AI security tools to actively identify alignment faking. They must design the tools to provide a deeper layer of scrutiny than the current protocols. Some methods are deliberative alignment and constitutional AI. Deliberative alignment teaches AI to “think” about safety protocols, and constitutional AI gives systems rules to follow during training.</p><p>The most effective way to prevent alignment faking would be to stop it from the beginning. Developers are continuously working to improve AI models and equip them with enhanced cybersecurity tools.</p><h2><b>From preventing attacks to verifying intent </b></h2><p>Alignment faking presents a significant impact that will only grow as AI models become more autonomous. To move forward, the industry must prioritize transparency and develop robust verification methods that go beyond surface-level testing. This includes creating advanced monitoring systems and fostering a culture of vigilant, continuous analysis of AI behavior post-deployment. The trustworthiness of future autonomous systems depends on addressing this challenge head-on.</p><p><i>Zac Amos is the Features Editor at </i><a href=\"https://rehack.com/\"><i><u>ReHack</u></i></a><i>.</i></p>",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Kalshi voids some bets on Khamenei because it’s “tied to death”",
      "url": "https://www.theverge.com/tech/887210/kalshi-void-bets-khamenei-death",
      "published": "2026-03-01T18:06:10+00:00",
      "summary": "In a statement on X, Kalshi CEO Tarek Mansour said his company would pay out positions on \"Ali Khamenei out as Supreme Leader?\" at the last trading price before his death. Mansour said that Kalshi doesn't \"list markets directly tied to death\" and that its rules are designed to \"prevent people from profiting from death.\" [&#8230;]",
      "content_text": "In a statement on X, Kalshi CEO Tarek Mansour said his company would pay out positions on “ Ali Khamenei out as Supreme Leader? ” at the last trading price before his death . Mansour said that Kalshi doesn’t “list markets directly tied to death” and that its rules are designed to “prevent people from profiting from death.” In addition, Kalshi is refunding fees related to the market and reimbursing anyone who purchased shares after Khamenei’s death. Some users have voiced anger at how the situation was handled, claiming that either Kalshi’s rules should have been communicated more clearly , or that its markets should have been more narrowly worded to avoid confusion. (“ Will Khamenei resign? ” for example.) Some are accusing Kalshi of trying to have it both ways by allowing users to bet on Khamenei being out of power, which they believe was never going to happen without his death, but refusing to pay out people’s bets in full to boost their bottom line . While Mansour defended that having a market on Khamenei was important, he said that “having a market directly settling on someone’s death” was not allowed under US regulations. Unlike Polymarket , Kalshi does not appear to have allowed a market for betting on when or if the US would launch another military strike on Iran . Polymarket does not appear to have altered payouts on its own similar market, “ Khamenei out as Supreme Leader of Iran by March 31? ” However, it’s unclear if this bet was available to users in the US at this time. Neither Kalshi nor Polymarket has responded to requests for clarification or additional comment.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/02/STKB383_KALSHI_A.jpg?quality=90&strip=all&crop=0%2C10.728364100735%2C100%2C78.54327179853&w=1200"
    },
    {
      "industry": "technology",
      "source": "Wired",
      "title": "The 5 Big ‘Known Unknowns’ of Donald Trump’s New War With Iran",
      "url": "https://www.wired.com/story/5-big-known-unknowns-donald-trump-iran-war/",
      "published": "2026-03-01T17:47:31+00:00",
      "summary": "The all-out air assault on the Islamic Republic might be the biggest gamble of the president’s career.",
      "content_text": "More recently, Iran has been a regular adversary in cyberspace—and while it hasn’t demonstrated quite the acuity of Russia or China, Iran is “good at finding ways to maximize the impact of their capabilities,” says Jeff Greene, the former executive assistant director of cybersecurity at CISA. Iran, in particular, famously was responsible for a series of distributed denial-of-service attacks on Wall Street institutions that worried financial markets, and its 2012 attack on Saudi Aramco and Qatar’s Rasgas marked some of the earliest destructive infrastructure cyberattacks. Today, surely, Iran is weighing which of these tools, networks, and operatives it might press into a response—and where, exactly, that response might come. Given its history of terror campaigns and cyberattacks, there’s no reason to think that Iran’s retaliatory options are limited to missiles alone—or even to the Middle East at all. Which leads to the biggest known unknown of all: 5. How does this end? There’s an apocryphal story about a 1970s conversation between Henry Kissinger and a Chinese leader—it’s told variously as either Mao-Tse Tung or Zhou Enlai. Asked about the legacy of the French revolution, the Chinese leader quipped, “Too soon to tell.” The story almost surely didn’t happen, but it’s useful in speaking to a larger truth, particularly in societies as old as the 2,500-year-old Persian empire: History has a long tail. As much as Trump (and the world) might hope that democracy breaks out in Iran this spring, the CIA’s official assessment in February was that if Khamenei was killed, he would likely be replaced with hard-line figures from the Islamic Revolutionary Guard Corps. And indeed, the fact that Iran’s retaliatory strikes against other targets in the Middle East continued throughout Saturday, even after the death of many senior regime officials—including, purportedly, the defense minister—belied the hope that the government was close to collapse. The post–World War II history of Iran has surely hinged on three moments and its intersections with American foreign policy—the 1953 CIA coup, the 1979 revolution that removed the shah, and now the 2026 US attacks that have killed its supreme leader. In his recent best-selling book King of Kings , on the fall of the shah, longtime foreign correspondent Scott Anderson writes of 1979, “If one were to make a list of that small handful of revolutions that spurred change on a truly global scale in the modern era, that caused a paradigm shift in the way the world works, to the American, French, and Russian Revolutions might be added the Iranian.” It is hard not to think today that we are living through a moment equally important in ways that we cannot yet fathom or imagine—and that we should be especially wary of any premature celebration or declarations of success given just how far-reaching Iran’s past turmoils have been. Defense secretary Pete Hegseth has repeatedly bragged about how he sees the military and the Trump administration’s foreign policy as sending a message to America’s adversaries: “F-A-F-O,” playing off the vulgar colloquialism. Now, though, it’s the US doing the “F-A” portion in the skies over Iran—and the long arc of Iran’s history tells us that we’re a long, long way from the “F-O” part where we understand the consequences. Let us know what you think about this article. Submit a letter to the editor at mail@wired.com .",
      "cover_image_url": "https://media.wired.com/photos/69a3b8c337746a56445e9886/191:100/w_1280,c_limit/GettyImages-2244475329.jpg"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Google looks to tackle longstanding RCS spam in India - but not alone",
      "url": "https://techcrunch.com/2026/03/01/google-looks-to-tackle-longstanding-rcs-spam-in-india-but-not-alone/",
      "published": "2026-03-01T17:30:00+00:00",
      "summary": "Google is integrating carrier-level filtering into RCS in India through a partnership with Airtel to strengthen protections against spam.",
      "content_text": "As persistent spam complaints have clouded Google’s Rich Communication Services (RCS) push in India, the company is turning to deeper carrier integration to bolster protections on the platform. On Sunday, Bharti Airtel, India’s second-largest telecom operator with over 463 million subscribers, said it had partnered with Google to integrate the carrier’s network-level spam filtering into the RCS ecosystem in the country. The move is aimed at strengthening protections against unwanted messages and fraud on the platform, the companies said. India has emerged as a particularly challenging market for spam and fraud across messaging channels, driven by the country’s vast mobile user base, rapid growth in digital payments, and aggressive enterprise marketing practices. In 2022, complaints about unsolicited ads on Google’s RCS — delivered primarily through the Google Messages app — were significant enough to prompt the company to temporarily pause business promotions on the platform in India. However, some users continue to report frustration with spam messages on Google Messages, suggesting the issue has not fully abated . Airtel said it had been cautious about deeper alignment with Google’s RCS until traffic could be routed through its own spam controls, highlighting carrier concerns about rising fraud risks. “We had not onboarded Google because we first wanted RCS messages to be routed through the Airtel spam filter,” an Airtel spokesperson said. Under the partnership, Airtel’s network intelligence will be combined with Google’s RCS platform to enable real-time checks on business messaging, including sender verification, spam detection, and enforcement of users’ do-not-disturb preferences. Airtel described the move as a “global first” for integrating a telecom operator’s spam filtering directly into an over-the-top messaging platform, though the companies did not provide comparative details. “We are committed to continuing to work with the broader ecosystem of carriers to create a consistent and trusted messaging experience for RCS users around the world,” Sameer Samat, president of Android ecosystem at Google, said in a statement. The comment signals the company may look to extend the model beyond India as it works to standardize security across the RCS ecosystem. Techcrunch event San Francisco, CA | October 13-15, 2026 India represents a critical market for Google’s messaging ambitions, with more than a billion internet users and over 700 million smartphone users. The country is also home to over 853 million WhatsApp users , according to World Population Review, underlining the scale of competition in mobile messaging. Prabhu Ram, vice president for the industry research group at CyberMedia Research, said the deeper carrier integration reflects efforts to plug longstanding weaknesses in rich messaging ecosystems that have been vulnerable to spam and fraud. “The efficacy of this partnership should be reflected in metrics such as reductions in spam volume, user complaints, and fraud incidence, as well as improvements in engagement with legitimate messages,” Ram told TechCrunch. Airtel has been stepping up its anti-spam efforts over the past year, saying its AI-led systems have blocked more than 71 billion spam calls and 2.9 billion spam messages, helping drive a nearly 69% drop in fraud-related financial losses on its network. More broadly, Google has been positioning RCS as the successor to SMS, saying in May 2025 that the standard was handling more than a billion messages daily in the U.S. , based on a 28-day average. Google did not say whether similar carrier integrations are planned for other markets or provide estimates for how much the move could reduce spam and fraud.",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/04/GettyImages-2169510461.jpg?resize=1200,800"
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "Investors spill what they aren't looking for anymore in AI SaaS companies",
      "url": "https://techcrunch.com/2026/03/01/investors-spill-what-they-arent-looking-for-anymore-in-ai-saas-companies/",
      "published": "2026-03-01T17:00:00+00:00",
      "summary": "TechCrunch spoke with VCs to learn what investors aren't looking for in AI SaaS startups anymore.",
      "content_text": "Investors have been pouring billions into AI companies over the past few years, as the technology continues to hold sway in the Valley and thus the world. But not all AI companies are grabbing investor attention. Indeed, even as it seems every company these days is rebranding to include “AI” in its name, some startup ideas are just no longer in favor with investors. TechCrunch spoke with VCs to learn what investors aren’t looking for in AI software-as-a-service startups anymore. Popular SaaS categories for investors now include startups building AI-native infrastructure, vertical SaaS with proprietary data, systems of action (those helping users complete tasks), and platforms deeply embedded in mission-critical workflows, according to Aaron Holiday, a managing partner at 645 Ventures. But he also gave a list of companies that are considered quite boring to investors these days: Startups building thin workflow layers, generic horizontal tools, light product management, and surface-level analytics — basically, anything an AI agent can now do. Abdul Abdirahman, an investor at the firm F Prime, added that generic vertical software “without proprietary data moats” is no longer popular, and Igor Ryabenky, a founder and managing partner at AltaIR Capital, went deeper on that point. He said investors aren’t interested in anything, really, that doesn’t have much product depth. “If your differentiation lives mostly in UI [user interface] and automation, that’s no longer enough,” he said. “The barrier to entry has dropped, which makes building a real moat much harder.” New companies entering the market now need to build around “real workflow ownership and a clear understanding of the problem from day one,” he said. “Massive codebases are no longer an advantage. What matters more is speed, focus, and the ability to adapt quickly. Pricing also needs to be flexible: rigid per-seat models will be harder to defend, while consumption-based models make more sense in this environment.” Techcrunch event San Francisco, CA | October 13-15, 2026 Jake Saper, a general partner at Emergence Capital, also had thoughts on ownership. To him, the differences between Cursor and Claude Code are the “canary in the coal mine.” “One owns the developer’s workflow, the other just executes the task,” Saper continued. “Developers are increasingly choosing the execution over process.” He said any product dealing with “workflow stickiness” — meaning trying to attract as many human customers as possible to continuously use the product — might find themselves in an uphill battle as agents takeover the workflow. “Pre-Claude, getting humans to do their jobs inside your software was a powerful moat, but if agents are doing the work, who cares about human workflow?” he told TechCrunch. He also thinks integrations are becoming less popular, especially as Anthropic’s model context protocol (MCP) makes it easier than ever to connect AI models to external data and systems. This means someone doesn’t need to download multiple integrations or build their own customer integrations; they can just use the MCP. “Being the connector used to be a moat,” Saper said. “Soon, it’ll be a utility.” Also, no longer en vogue include the “workflow automation and task management tools that enable the coordination of human work become less necessary if, over time, agents just execute the tasks,” Abdirahman said, citing examples, mainly public SaaS companies whose stocks are down as new AI-native startups arise with better, more efficient technology. Ryabenky said the SaaS companies struggling to raise right now are the ones that can easily be replicated, he said. “Generic productivity tools, project management software, basic CRM clones, and thin AI wrappers built on top of existing APIs fall into this category,” he said. “If the product is mostly an interface layer without deep integration, proprietary data, or embedded process knowledge, strong AI-native teams can rebuild it quickly. That is what makes investors cautious.” Overa, what remains attractive about SaaS is depth and expertise, with tools embedded in critical workflows. He said companies should right now look into integrating AI deeply into their products and update their marketing to reflect that, Ryabenky continued. “Investors are reallocating capital toward businesses that own workflows, data, and domain expertise,” Ryabenky said. “And away from products that can be copied without much effort.”",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2026/02/GettyImages-2188822416.jpg?resize=1200,821"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "MCP is dead. Long live the CLI",
      "url": "https://ejholmes.github.io/2026/02/28/mcp-is-dead-long-live-the-cli.html",
      "published": "2026-03-01T16:54:49+00:00",
      "summary": "<p>Article URL: <a href=\"https://ejholmes.github.io/2026/02/28/mcp-is-dead-long-live-the-cli.html\">https://ejholmes.github.io/2026/02/28/mcp-is-dead-long-live-the-cli.html</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47208398\">https://news.ycombinator.com/item?id=47208398</a></p> <p>Points: 269</p> <p># Comments: 183</p>",
      "content_text": "I’m going to make a bold claim: MCP is already dying. We may not fully realize it yet, but the signs are there. OpenClaw doesn’t support it. Pi doesn’t support it. And for good reason. When Anthropic announced the Model Context Protocol, the industry collectively lost its mind. Every company scrambled to ship MCP servers as proof they were “AI first.” Massive resources poured into new endpoints, new wire formats, new authorization schemes, all so LLMs could talk to services they could already talk to. I’ll admit, I never fully understood the need for it. You know what LLMs are really good at? Figuring things out on their own. Give them a CLI and some docs and they’re off to the races. I tried to avoid writing this for a long time, but I’m convinced MCP provides no real-world benefit, and that we’d be better off without it. Let me explain. LLMs don’t need a special protocol LLMs are really good at using command-line tools. They’ve been trained on millions of man pages, Stack Overflow answers, and GitHub repos full of shell scripts. When I tell Claude to use gh pr view 123 , it just works. MCP promised a cleaner interface, but in practice I found myself writing the same documentation anyway: what each tool does, what parameters it accepts, and more importantly, when to use it. The LLM didn’t need a new protocol. CLIs are for humans too When Claude does something unexpected with Jira, I can run the same jira issue view command and see exactly what it saw. Same input, same output, no mystery. With MCP, the tool only exists inside the LLM conversation. Something goes wrong and now I’m spelunking through JSON transport logs instead of just running the command myself. Debugging shouldn’t require a protocol decoder. Composability This is where the gap gets wide. CLIs compose. I can pipe through jq , chain with grep , redirect to files. This isn’t just convenient; it’s often the only practical approach. Consider analyzing a large Terraform plan: terraform show -json plan.out | jq '[.resource_changes[] | select(.change.actions[0] == \"no-op\" | not)] | length' With MCP, your options are dumping the entire plan into the context window (expensive, often impossible) or building custom filtering into the MCP server itself. Either way, you’re doing more work for a worse result. The CLI approach uses tools that already exist, are well-documented, and that both humans and agents understand. Auth already works MCP is unnecessarily opinionated about auth. Why should a protocol for giving an LLM tools to use need to concern itself with authentication? CLI tools don’t care. aws uses profiles and SSO. gh uses gh auth login . kubectl uses kubeconfig. These are battle-tested auth flows that work the same whether I’m at the keyboard or Claude is driving. When auth breaks, I fix it the way I always would: aws sso login , gh auth refresh . No MCP-specific troubleshooting required. No moving parts Local MCP servers are processes. They need to start up, stay running, and not silently hang. In Claude Code, they’re spawned as child processes, which works until it doesn’t. CLI tools are just binaries on disk. No background processes, no state to manage, no initialization dance. They’re there when you need them and invisible when you don’t. The practical pain Beyond the design philosophy, MCP has real day-to-day friction: Initialization is flaky. I’ve lost count of the times I’ve restarted Claude Code because an MCP server didn’t come up. Sometimes it works on retry, sometimes I’m clearing state and starting over. Re-auth never ends. Using multiple MCP tools? Have fun authenticating each one. CLIs with SSO or long-lived credentials just don’t have this problem. Auth once and you’re done. Permissions are all-or-nothing. Claude Code lets you allowlist MCP tools by name, but that’s it. You can’t scope to read-only operations or restrict parameters. With CLIs, I can allowlist gh pr view but require approval for gh pr merge . That granularity matters. So when does MCP make sense? I’m not saying MCP is completely useless. If a tool genuinely has no CLI equivalent, MCP might be the right call. I still use plenty in my day-to-day, when it’s the only option available. I might even argue there’s some value in having a standardized interface, and that there are probably usecases where it makes more sense than a CLI. But for the vast majority of work, the CLI is simpler, faster to debug, and more reliable. The real lesson The best tools are the ones that work for both humans and machines. CLIs have had decades of design iteration. They’re composable, debuggable, and they piggyback on auth systems that already exist. MCP tried to build a better abstraction. Turns out we already had a pretty good one. A plea to builders If you’re a company investing in an MCP server but you don’t have an official CLI, stop and rethink what you’re doing. Ship a good API, then ship a good CLI. The agents will figure it out.",
      "cover_image_url": null
    },
    {
      "industry": "technology",
      "source": "TechCrunch",
      "title": "OpenAI reveals more details about its agreement with the Pentagon",
      "url": "https://techcrunch.com/2026/03/01/openai-shares-more-details-about-its-agreement-with-the-pentagon/",
      "published": "2026-03-01T16:30:10+00:00",
      "summary": "By CEO Sam Altman’s own admission, OpenAI’s deal with the Department of Defense was “definitely rushed,” and “the optics don’t look good.”",
      "content_text": "By CEO Sam Altman’s own admission, OpenAI’s deal with the Department of Defense was “definitely rushed,” and “the optics don’t look good.” After negotiations between Anthropic and the Pentagon fell through on Friday, President Donald Trump directed federal agencies to stop using Anthropic’s technology after a six-month transition period , and Secretary of Defense Pete Hegseth said he was designating the AI company as a supply-chain risk. Then, OpenAI quickly announced that it had reached a deal of its own for models to be deployed in classified environments. With Anthropic saying it was drawing red lines around the use of its technology in fully autonomous weapons or mass domestic surveillance, and Altman saying OpenAI had the same red lines, there were some obvious questions: Was OpenAI being honest about its safeguards? Why was it able to reach a deal while Anthropic was not? So as OpenAI executives defended the agreement on social media, the company also published a blog post outlining its approach . In fact, the post pointed to three areas where it said OpenAI’s models cannot be used — mass domestic surveillance, autonomous weapon systems, and “high-stakes automated decisions (e.g. systems such as ‘social credit’).” The company said that in contrast to other AI companies that have “reduced or removed their safety guardrails and relied primarily on usage policies as their primary safeguards in national security deployments,” OpenAI’s agreement protects its red lines “through a more expansive, multi-layered approach.” “We retain full discretion over our safety stack, we deploy via cloud, cleared OpenAI personnel are in the loop, and we have strong contractual protections,” the blog said. “This is all in addition to the strong existing protections in U.S. law.” Techcrunch event San Francisco, CA | October 13-15, 2026 The company added, “We don’t know why Anthropic could not reach this deal, and we hope that they and more labs will consider it.” After the post was published, Techdirt’s Mike Masnick claimed that the deal “absolutely does allow for domestic surveillance,” because it says the collection of private data will comply with Executive Order 12333 (along with a number of other laws). Masnick described that order as “how the NSA hides its domestic surveillance by capturing communications by tapping into lines *outside the US* even if it contains info from/on US persons.” In a LinkedIn post , OpenAI’s head of national security partnerships Katrina Mulligan argued that much of the discussion around the contract language assumes “the only thing standing between Americans and the use of AI for mass domestic surveillance and autonomous weapons is a single usage policy provision in a single contract with the Department of War.” “That’s not how any of this works,” Mulligan said, adding, “Deployment architecture matters more than contract language […] By limiting our deployment to cloud API, we can ensure that our models cannot be integrated directly into weapons systems, sensors, or other operational hardware.” Altman also fielded questions about the deal on X, where he admitted it had been rushed and resulted in significant backlash against OpenAI (to the extent that Anthropic’s Claude overtook OpenAI’s ChatGPT in Apple’s App Store on Saturday). So why do it? “We really wanted to de-escalate things, and we thought the deal on offer was good,” Altman said. “If we are right and this does lead to a de-escalation between the DoW and the industry, we will look like geniuses, and a company that took on a lot of pain to do things to help the industry. If not, we will continue to be characterized as […] rushed and uncareful.”",
      "cover_image_url": "https://techcrunch.com/wp-content/uploads/2025/01/GettyImages-2170386424.jpg?w=1024"
    },
    {
      "industry": "technology",
      "source": "The Verge",
      "title": "Lego’s Smart Brick is here, and it transforms these new Star Wars sets",
      "url": "https://www.theverge.com/gadgets/886014/lego-smart-brick-star-wars-set-price-availability-release-date-buy",
      "published": "2026-03-01T16:00:10+00:00",
      "summary": "Lego's new Smart Brick is a pretty big deal. It packs a miniature computer, a microphone, and NFC tech into a classic 2&#215;4 Lego brick, which can power all sorts of new experiences with select sets. It has so much promise that we awarded it \"best in show\" at CES 2026, and now, eight Star [&#8230;]",
      "content_text": "Lego’s new Smart Brick is a pretty big deal . It packs a miniature computer, a microphone, and NFC tech into a classic 2x4 Lego brick, which can power all sorts of new experiences with select sets. It has so much promise that we awarded it “ best in show ” at CES 2026, and now, eight Star Wars -themed sets that support the Smart Brick (and include it, in some cases) are now available. Three of them include at least one Smart Brick, along with a charging cradle and cable, while the rest are merely “Smart Play compatible,” meaning they’re BYOB (bring your own brick). The interactivity of the NFC tags and the smart minifigurs won’t be possible unless you already own one of Lego’s fancy, computerized bricks. The cheapest set to include a Smart Brick is Darth Vader’s TIE Fighter, which costs $69.99 at Amazon , Best Buy , and Lego’s online storefront , while the priciest one — the Throne Room Duel & A-Wing set — is available from Amazon , Best Buy , and Lego for $159.99 with two Smart Bricks. Below, we’ve listed each set, along with useful info about the smart (and standard) components included.",
      "cover_image_url": "https://platform.theverge.com/wp-content/uploads/sites/2/2026/01/lego-star-wars-smart-play-yoda-luke-training-dagobah.jpg?quality=90&strip=all&crop=0%2C10.741906587151%2C100%2C78.516186825698&w=1200"
    },
    {
      "industry": "technology",
      "source": "Hacker News (Frontpage)",
      "title": "sas-audio-processor",
      "url": "https://github.com/shiehn/sas-audio-processor",
      "published": "2026-03-01T15:52:02+00:00",
      "summary": "<p>Article URL: <a href=\"https://github.com/shiehn/sas-audio-processor\">https://github.com/shiehn/sas-audio-processor</a></p> <p>Comments URL: <a href=\"https://news.ycombinator.com/item?id=47207806\">https://news.ycombinator.com/item?id=47207806</a></p> <p>Points: 51</p> <p># Comments: 6</p>",
      "content_text": "shiehn/sas-audio-processor You can’t perform that action at this time.",
      "cover_image_url": "https://opengraph.githubassets.com/003b89f278231d6ec72afbff0e033b615f94d6454b7aa8e5b8680c2f9c2498a2/shiehn/sas-audio-processor"
    }
  ]
}